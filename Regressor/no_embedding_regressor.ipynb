{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_MyModule = '..'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, path_to_MyModule) \n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from MyModule.GeneralFunctions import *\n",
    "from MyModule.SummarizationFunctions import *\n",
    "from MyModule.SamplingFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('..\\datos.xlsx')[['ID','texto','desafio','rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df.drop_duplicates(subset='texto', inplace=True)\n",
    "\n",
    "# Quitando texto de mas en columna \"desafio\"\n",
    "df['desafio'] = df['desafio'].apply(lambda x: re.findall('[0-9]+', x)[0])\n",
    "\n",
    "# A str\n",
    "df['texto'] = df['texto'].astype(str)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dfs\n",
    "df_predic = pd.read_csv('df_predic.csv')[['ID', 'desafio', 'target', 'doc_pos', 'doc_neg', 'doc_neu', 'doc_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semantic = pd.read_csv('../Semantic_Analysis/Datasets/df_semantic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>desafio</th>\n",
       "      <th>target</th>\n",
       "      <th>doc_pos</th>\n",
       "      <th>doc_neg</th>\n",
       "      <th>doc_neu</th>\n",
       "      <th>doc_len</th>\n",
       "      <th>sem_variability</th>\n",
       "      <th>sem_granularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>749</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.168139</td>\n",
       "      <td>0.318913</td>\n",
       "      <td>0.512949</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>748</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.827293</td>\n",
       "      <td>0.163122</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.546193</td>\n",
       "      <td>0.439239</td>\n",
       "      <td>12</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>746</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.565521</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.411416</td>\n",
       "      <td>23</td>\n",
       "      <td>0.053762</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>0.495369</td>\n",
       "      <td>0.476630</td>\n",
       "      <td>31</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.070960</td>\n",
       "      <td>0.601193</td>\n",
       "      <td>0.327847</td>\n",
       "      <td>16</td>\n",
       "      <td>0.051103</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>164</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.485169</td>\n",
       "      <td>0.089189</td>\n",
       "      <td>0.425642</td>\n",
       "      <td>23</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>163</td>\n",
       "      <td>13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.966732</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>26</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>162</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.630141</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.316240</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>161</td>\n",
       "      <td>13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.013606</td>\n",
       "      <td>0.884570</td>\n",
       "      <td>0.101824</td>\n",
       "      <td>14</td>\n",
       "      <td>0.065680</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  desafio  target   doc_pos   doc_neg   doc_neu  doc_len  \\\n",
       "0    749       15    0.00  0.168139  0.318913  0.512949        1   \n",
       "1    748       13    0.00  0.009585  0.827293  0.163122       13   \n",
       "2    747       14    0.00  0.014568  0.546193  0.439239       12   \n",
       "3    746       12    0.00  0.565521  0.023063  0.411416       23   \n",
       "4    745       16    0.00  0.028001  0.495369  0.476630       31   \n",
       "..   ...      ...     ...       ...       ...       ...      ...   \n",
       "500  165       13   -0.33  0.070960  0.601193  0.327847       16   \n",
       "501  164       15   -0.40  0.485169  0.089189  0.425642       23   \n",
       "502  163       13    0.11  0.004152  0.966732  0.029116       26   \n",
       "503  162       15   -0.20  0.630141  0.053619  0.316240        3   \n",
       "504  161       13    0.19  0.013606  0.884570  0.101824       14   \n",
       "\n",
       "     sem_variability  sem_granularity  \n",
       "0                NaN         0.000000  \n",
       "1           0.005862         9.500000  \n",
       "2           0.016918         4.500000  \n",
       "3           0.053762         5.166667  \n",
       "4           0.008742         6.750000  \n",
       "..               ...              ...  \n",
       "500         0.051103         4.500000  \n",
       "501         0.018819         3.333333  \n",
       "502         0.022065         6.000000  \n",
       "503              NaN         9.000000  \n",
       "504         0.065680         9.000000  \n",
       "\n",
       "[505 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predic = df_predic.join(df_semantic, how='left')\n",
    "df_predic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos StandardScaler de la libreria sklear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciamos la funcion para escalar\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Escalamos las variables\n",
    "scaled = scaler.fit_transform(df_predic.drop(['ID','desafio'], axis=1))\n",
    "df_predic_scaled = pd.DataFrame(scaled, columns = df_predic.columns[2:])\n",
    "df_predic_scaled.fillna(0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partición en train y test\n",
    "y = df_predic_scaled.loc[:, df_predic_scaled.columns == 'target']['target'].values.tolist()\n",
    "X = df_predic_scaled.loc[:, df_predic_scaled.columns != 'target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=semilla)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=semilla)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia del modelo\n",
    "linearRegr = LinearRegression()\n",
    "\n",
    "# entrenamiento\n",
    "linearRegr.fit(X_train, y_train)\n",
    "\n",
    "# basic performance\n",
    "y_pred = linearRegr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: 0.0057253299567038285\n",
      "Mean Squared Error: 0.7858695615271343\n",
      "Mean Absolute Error: 0.7189707112664292\n"
     ]
    }
   ],
   "source": [
    "# Claramente las clases estan desbalanceadas\n",
    "print_performance(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (politics_nlp)",
   "language": "python",
   "name": "politics_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
