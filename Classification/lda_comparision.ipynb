{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification: are this two documents from the same desafio?\n",
    "\n",
    "Objectivos:\n",
    "\n",
    "        Comparar LDA con el anterior ganador: Transformers Sentence Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_MyModule = '..'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, path_to_MyModule) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from MyModule.GeneralFunctions import *\n",
    "from MyModule.SummarizationFunctions import *\n",
    "from MyModule.SamplingFunctions import *\n",
    "\n",
    "from MyModule.TopicModelingFunctinos import *\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('..\\datos.xlsx')[['ID','texto','desafio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "df.drop_duplicates(subset='texto', inplace=True)\n",
    "\n",
    "# Quitando texto de mas en columna \"desafio\"\n",
    "df['desafio'] = df['desafio'].apply(lambda x: re.findall('[0-9]+', x)[0])\n",
    "\n",
    "# A str\n",
    "df['texto'] = df['texto'].astype(str)\n",
    "\n",
    "pp = Preprocess()\n",
    "df['prepro_text'] = pp.preprocess(df['texto'])\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target variable: \n",
    "True if the pair comes from the same desafio, false otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples containing all possible pairs of strings and ID's\n",
    "import itertools\n",
    "id_pairs = list(itertools.combinations(df['ID'].values, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target: 1 if both ID's are from the same desafio, 0 otherwise\n",
    "target = []\n",
    "for id1, id2 in id_pairs:\n",
    "    for desafio in df['desafio'].unique():\n",
    "        ids_desafio = df[df['desafio']==desafio]['ID'].values\n",
    "        if id1 in ids_desafio and id2 in ids_desafio:\n",
    "            target.append(1)\n",
    "            break\n",
    "        elif id1 in ids_desafio or id2 in ids_desafio:\n",
    "            target.append(0)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predic = pd.DataFrame([id_pairs, target]).T\n",
    "df_predic.columns = ['id_pairs','target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are this two ideas from the same desafio?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embedding feature\n",
    "\n",
    "Create a sentence embedding for each document using LSA/LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data and model\n",
    "documents = df['prepro_text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 300\n",
    "\n",
    "# Create the TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# fit Model\n",
    "model = LatentDirichletAllocation(n_components=n_components)\n",
    "lda_matrix = model.fit_transform(X)\n",
    "\n",
    "# Normalize the matrix\n",
    "normalizer = Normalizer(copy=False)\n",
    "lda_matrix = normalizer.fit_transform(lda_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as featrues the document vectors for each document in the pair\n",
    "\n",
    "first_doc_emb = []\n",
    "second_doc_emb = []\n",
    "\n",
    "for pair1, pair2 in df_predic['id_pairs'].values:\n",
    "    \n",
    "    indice_pair1 = df[df['ID']==pair1].index[0]\n",
    "    first_doc_emb.append(lda_matrix[indice_pair1])\n",
    "    \n",
    "    indice_pair2 = df[df['ID']==pair2].index[0]\n",
    "    second_doc_emb.append(lda_matrix[indice_pair2])\n",
    "    \n",
    "\n",
    "# create dataframe\n",
    "df_emb_1 = pd.DataFrame(first_doc_emb)\n",
    "df_emb_2 = pd.DataFrame(second_doc_emb)\n",
    "\n",
    "# rename columns\n",
    "df_emb_1.columns = [f'first_doc_emb_dim_{i+1}' for i in range(len(first_doc_emb[0]))]\n",
    "df_emb_2.columns = [f'second_doc_emb_dim_{i+1}' for i in range(len(second_doc_emb[0]))]\n",
    "df_emb = df_emb_1.join(df_emb_2)\n",
    "\n",
    "# join with main df\n",
    "df_predic = df_predic.join(df_emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis feature\n",
    "\n",
    "Evaluate positive, negative and neutral sentiment for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the three sentiments for each doc\n",
    "from MyModule.SentimentAnalysisFunctions import sentiment_analyzer_3d\n",
    "\n",
    "all_emotions = {}\n",
    "analyzer = sentiment_analyzer_3d()\n",
    "\n",
    "for i, this_id in enumerate(df['ID'].values):\n",
    "    all_emotions[this_id] = analyzer.predict_sentiment_3d(df['texto'].values.tolist()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as featrues the document vectors for each document in the pair\n",
    "\n",
    "first_doc_pos = []\n",
    "first_doc_neg = []\n",
    "first_doc_neu = []\n",
    "\n",
    "second_doc_pos = []\n",
    "second_doc_neg = []\n",
    "second_doc_neu = []\n",
    "\n",
    "for pair1, pair2 in df_predic['id_pairs'].values:\n",
    "    \n",
    "    first_doc_pos.append(all_emotions[pair1][0])\n",
    "    first_doc_neg.append(all_emotions[pair1][1])\n",
    "    first_doc_neu.append(all_emotions[pair1][2])\n",
    "    \n",
    "    second_doc_pos.append(all_emotions[pair2][0])\n",
    "    second_doc_neg.append(all_emotions[pair2][1])\n",
    "    second_doc_neu.append(all_emotions[pair2][2])\n",
    "    \n",
    "\n",
    "df_predic['first_doc_pos'] = first_doc_pos\n",
    "df_predic['first_doc_neg'] = first_doc_neg\n",
    "df_predic['first_doc_neu'] = first_doc_neu\n",
    "\n",
    "df_predic['second_doc_pos'] = second_doc_pos\n",
    "df_predic['second_doc_neg'] = second_doc_neg\n",
    "df_predic['second_doc_neu'] = second_doc_neu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document's Length Feature\n",
    "\n",
    "Compute document length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lengths = {}\n",
    "\n",
    "for i, this_id in enumerate(df['ID'].values):\n",
    "    all_lengths[this_id] = len(df['texto'][i].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc_len = []\n",
    "second_doc_len = []\n",
    "\n",
    "for pair1, pair2 in df_predic['id_pairs'].values:\n",
    "    \n",
    "    first_doc_len.append(all_lengths[pair1])\n",
    "    second_doc_len.append(all_lengths[pair2])\n",
    "\n",
    "df_predic['first_doc_len'] = first_doc_len\n",
    "df_predic['second_doc_len'] = second_doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "# df_predic.to_csv('df_predic.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def print_performance(y_test, y_pred, y_proba=None):\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('Recall: %f' % recall)\n",
    "\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "    # ROC\n",
    "    logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print('AUC: %f' % logit_roc_auc)\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_proba[:,1])\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('Log_ROC')\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "import pickle\n",
    "def save_model(model, filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "def load_model(filename): \n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dfs\n",
    "df_predic = pd.read_csv('df_predic.csv')\n",
    "df_predic['id_pairs'] = df_predic['id_pairs'].apply(lambda x: string_to_tuple(x)) # recovering tuples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Since features have different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos StandardScaler de la libreria sklear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciamos la funcion para escalar\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Escalamos las variables\n",
    "scaled = scaler.fit_transform(df_predic.drop(['id_pairs','target'], axis=1))\n",
    "df_predic_scaled = pd.DataFrame(scaled, columns = df_predic.columns[2:])\n",
    "df_predic_scaled = df_predic_scaled.join(df_predic[['id_pairs','target']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "80% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partición en train y test\n",
    "y = df_predic_scaled.loc[:, df_predic_scaled.columns == 'target']['target'].values.tolist()\n",
    "X = df_predic_scaled.loc[:, df_predic_scaled.columns != 'target'].drop('id_pairs', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=semilla)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns\n",
    "os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
    "\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  173982\n",
      "Number of 0 in oversampled data 86991\n",
      "Number of 1 86991\n",
      "Proportion of 0 data in oversampled data is  0.5\n",
      "Proportion of 1 data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of 0 in oversampled data\",len(os_data_y[os_data_y['target']==0]))\n",
    "print(\"Number of 1\",len(os_data_y[os_data_y['target']==1]))\n",
    "print(\"Proportion of 0 data in oversampled data is \",len(os_data_y[os_data_y['target']==0])/len(os_data_X))\n",
    "print(\"Proportion of 1 data in oversampled data is \",len(os_data_y[os_data_y['target']==1])/len(os_data_X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de clases: subsampleo de clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14817 14817\n"
     ]
    }
   ],
   "source": [
    "train = X_train\n",
    "train['target'] = y_train\n",
    "\n",
    "positivos = train[train.target == 1]\n",
    "negativos = train[train.target == 0]\n",
    "\n",
    "negativos_sub = negativos.sample(n=len(positivos), random_state=semilla)\n",
    "\n",
    "train_sub = pd.concat([positivos, negativos_sub])\n",
    "\n",
    "y_train = train_sub.loc[:, train_sub.columns == 'target']\n",
    "X_train = train_sub.loc[:, train_sub.columns != 'target']\n",
    "print(len(positivos), len(negativos_sub))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# instancia del modelo\n",
    "logisticRegr = LogisticRegression(max_iter=10000, fit_intercept=True)\n",
    "\n",
    "# entrenamiento\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# basic performance\n",
    "y_pred = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of class 0: 0.8544397296872545\n",
      "Accuracy: 0.521688\n",
      "Precision: 0.169387\n",
      "Recall: 0.585109\n",
      "F1 score: 0.262718\n",
      "AUC: 0.547993\n"
     ]
    }
   ],
   "source": [
    "# Claramente las clases estan desbalanceadas\n",
    "targets = df_predic_scaled['target'].value_counts()\n",
    "print(f'Percentage of class 0: {targets[0]/sum(targets)}')\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento\n",
    "logisticRegr.fit(os_data_X, os_data_y)\n",
    "\n",
    "# basic performance\n",
    "y_pred = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.573354\n",
      "Precision: 0.170354\n",
      "Recall: 0.498516\n",
      "F1 score: 0.253933\n",
      "AUC: 0.542314\n"
     ]
    }
   ],
   "source": [
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el modelo y algunas funciones auxiliares\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.linear_model import  SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_classifier = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los parametros\n",
    "sgd_parametros={'loss': ['hinge','log_loss','modified_hube','squared_hinge','perceptron'],\n",
    "            'penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "             'alpha': loguniform(1e-4, 1e0),\n",
    "             'l1_ratio':stats.uniform(0, 1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 893, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'perceptron', 'hinge', 'log' (deprecated), 'epsilon_insensitive', 'squared_epsilon_insensitive', 'huber', 'log_loss', 'squared_error', 'modified_huber'}. Got 'modified_hube' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.54261996 0.53438618 0.53354255 0.53637713 0.50988729        nan\n",
      " 0.5308767  0.54754674 0.51808733 0.50178849        nan 0.50550044\n",
      " 0.50739016 0.53334008 0.51960586 0.55061753        nan 0.5\n",
      " 0.56833367 0.53779443]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros {'alpha': 0.00999550089604053, 'l1_ratio': 0.3642569891908011, 'loss': 'hinge', 'penalty': 'l2'} \n",
      "\n",
      "Definición del Modelo SGDClassifier(alpha=0.00999550089604053, l1_ratio=0.3642569891908011) \n",
      "\n",
      "Combinaciones Evaluadas RandomizedSearchCV(cv=3, estimator=SGDClassifier(), n_iter=20,\n",
      "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000222141B4370>,\n",
      "                                        'l1_ratio': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x00000222141B6F10>,\n",
      "                                        'loss': ['hinge', 'log_loss',\n",
      "                                                 'modified_hube',\n",
      "                                                 'squared_hinge',\n",
      "                                                 'perceptron'],\n",
      "                                        'penalty': ['l2', 'l1', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   random_state=2023, scoring='accuracy') \n"
     ]
    }
   ],
   "source": [
    "#Ajustamos el modelo\n",
    "cv = 3\n",
    "n_iteraciones = 20\n",
    "\n",
    "sgd_classifier = SGDClassifier()\n",
    "sgd_random_search = RandomizedSearchCV(estimator=sgd_classifier, n_iter = n_iteraciones, param_distributions = sgd_parametros,\n",
    "                                   cv = cv, scoring ='accuracy', random_state = semilla )\n",
    "sgd_random_search.fit(X_train, y_train)\n",
    "\n",
    "print('Mejor combinación de parámetros %s \\n'% sgd_random_search.best_params_)\n",
    "print('Definición del Modelo %s \\n'% sgd_random_search.best_estimator_)\n",
    "print('Combinaciones Evaluadas %s '% sgd_random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.523967\n",
      "Precision: 0.188117\n",
      "Recall: 0.684111\n",
      "F1 score: 0.295090\n",
      "AUC: 0.590389\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd_random_search.best_estimator_.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.785518\n",
      "Precision: 0.391825\n",
      "Recall: 0.855948\n",
      "F1 score: 0.537569\n",
      "AUC: 0.814730\n"
     ]
    }
   ],
   "source": [
    "# instanciemos y entrenemos el modelo\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10,weights='uniform')\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los parametros\n",
    "knn_parametros={'n_neighbors':list(range(1, 20)),\n",
    "                'weights':['uniform', 'distance'],\n",
    "                'metric':['euclidean', 'chebyshev', 'manhattan']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;chebyshev&#x27;, &#x27;manhattan&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'chebyshev', 'manhattan'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ajustamos el modelo\n",
    "cv = 3\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_grid_search = GridSearchCV(estimator=knn_classifier, param_grid = knn_parametros,\n",
    "                                   cv=cv, scoring ='accuracy')\n",
    "knn_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'} \n",
      "\n",
      "Definición del Modelo KNeighborsClassifier(metric='manhattan', n_neighbors=4, weights='distance') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Mejor combinación de parámetros %s \\n'% knn_grid_search.best_params_)\n",
    "print('Definición del Modelo %s \\n'% knn_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795419\n",
      "Precision: 0.407567\n",
      "Recall: 0.892096\n",
      "F1 score: 0.559513\n",
      "AUC: 0.835517\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = knn_grid_search.predict(X_test)\n",
    "y_pred_proba = knn_grid_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DecisionTree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a Simple DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.432068\n",
      "Precision: 0.161885\n",
      "Recall: 0.694092\n",
      "F1 score: 0.262538\n",
      "AUC: 0.540746\n"
     ]
    }
   ],
   "source": [
    "# instanciemos el modelo y entremoslo en el conjunto de autos\n",
    "arbol = DecisionTreeClassifier(criterion='gini', max_depth=2, min_samples_leaf=1, min_samples_split=2, ccp_alpha=0)\n",
    "arbol.fit(X_train,y_train)\n",
    "\n",
    "y_pred = arbol.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\AppData\\Local\\Temp\\ipykernel_19800\\3721313899.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  importances = pd.Series(arbol.feature_importances_).sort_values(ascending=False)[:15]\n"
     ]
    }
   ],
   "source": [
    "# calculando las 5 feature importances mas altas\n",
    "importances = pd.Series(arbol.feature_importances_).sort_values(ascending=False)[:15]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b DecisionTree hyperparameter opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=48, min_samples_leaf=30, min_samples_split=19; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=48, min_samples_leaf=30, min_samples_split=19; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=48, min_samples_leaf=30, min_samples_split=19; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=40, min_samples_leaf=28, min_samples_split=35; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=40, min_samples_leaf=28, min_samples_split=35; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=40, min_samples_leaf=28, min_samples_split=35; total time=   0.3s\n",
      "[CV] END max_depth=100, max_features=log2, max_leaf_nodes=18, min_samples_leaf=2, min_samples_split=13; total time=   0.2s\n",
      "[CV] END max_depth=100, max_features=log2, max_leaf_nodes=18, min_samples_leaf=2, min_samples_split=13; total time=   0.2s\n",
      "[CV] END max_depth=100, max_features=log2, max_leaf_nodes=18, min_samples_leaf=2, min_samples_split=13; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=34, min_samples_leaf=37, min_samples_split=13; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=34, min_samples_leaf=37, min_samples_split=13; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=34, min_samples_leaf=37, min_samples_split=13; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=17, min_samples_leaf=38, min_samples_split=36; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=17, min_samples_leaf=38, min_samples_split=36; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=17, min_samples_leaf=38, min_samples_split=36; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=100, max_features=auto, max_leaf_nodes=57, min_samples_leaf=10, min_samples_split=28; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=100, max_features=auto, max_leaf_nodes=57, min_samples_leaf=10, min_samples_split=28; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=100, max_features=auto, max_leaf_nodes=57, min_samples_leaf=10, min_samples_split=28; total time=   0.3s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=47, min_samples_leaf=34, min_samples_split=37; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=47, min_samples_leaf=34, min_samples_split=37; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=47, min_samples_leaf=34, min_samples_split=37; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=51, min_samples_leaf=4, min_samples_split=7; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=51, min_samples_leaf=4, min_samples_split=7; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=51, min_samples_leaf=4, min_samples_split=7; total time=   0.1s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=51, min_samples_leaf=23, min_samples_split=38; total time=   0.2s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=51, min_samples_leaf=23, min_samples_split=38; total time=   0.2s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=51, min_samples_leaf=23, min_samples_split=38; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=30, min_samples_leaf=39, min_samples_split=23; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=30, min_samples_leaf=39, min_samples_split=23; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=30, min_samples_leaf=39, min_samples_split=23; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=18, min_samples_leaf=17, min_samples_split=16; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=18, min_samples_leaf=17, min_samples_split=16; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=18, min_samples_leaf=17, min_samples_split=16; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=57, min_samples_leaf=23, min_samples_split=29; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=57, min_samples_leaf=23, min_samples_split=29; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=57, min_samples_leaf=23, min_samples_split=29; total time=   0.3s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=11, min_samples_leaf=23, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=11, min_samples_leaf=23, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=11, min_samples_leaf=23, min_samples_split=39; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=39, min_samples_leaf=6, min_samples_split=34; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=39, min_samples_leaf=6, min_samples_split=34; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=39, min_samples_leaf=6, min_samples_split=34; total time=   0.3s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=26, min_samples_leaf=5, min_samples_split=31; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=26, min_samples_leaf=5, min_samples_split=31; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=26, min_samples_leaf=5, min_samples_split=31; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=52, min_samples_leaf=39, min_samples_split=24; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=52, min_samples_leaf=39, min_samples_split=24; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, max_leaf_nodes=52, min_samples_leaf=39, min_samples_split=24; total time=   0.3s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=59, min_samples_leaf=30, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=59, min_samples_leaf=30, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=59, min_samples_leaf=30, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=30, min_samples_leaf=17, min_samples_split=38; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=30, min_samples_leaf=17, min_samples_split=38; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=30, min_samples_leaf=17, min_samples_split=38; total time=   0.0s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=29, min_samples_leaf=20, min_samples_split=38; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=29, min_samples_leaf=20, min_samples_split=38; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=29, min_samples_leaf=20, min_samples_split=38; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=27, min_samples_leaf=33, min_samples_split=3; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=27, min_samples_leaf=33, min_samples_split=3; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=27, min_samples_leaf=33, min_samples_split=3; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=26, min_samples_leaf=7, min_samples_split=13; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=26, min_samples_leaf=7, min_samples_split=13; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=26, min_samples_leaf=7, min_samples_split=13; total time=   0.3s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=23, min_samples_leaf=37, min_samples_split=39; total time=   0.2s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=23, min_samples_leaf=37, min_samples_split=39; total time=   0.2s\n",
      "[CV] END max_depth=3, max_features=sqrt, max_leaf_nodes=23, min_samples_leaf=37, min_samples_split=39; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=2, max_features=auto, max_leaf_nodes=59, min_samples_leaf=16, min_samples_split=29; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=2, max_features=auto, max_leaf_nodes=59, min_samples_leaf=16, min_samples_split=29; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=2, max_features=auto, max_leaf_nodes=59, min_samples_leaf=16, min_samples_split=29; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=None, max_leaf_nodes=51, min_samples_leaf=14, min_samples_split=17; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, max_leaf_nodes=51, min_samples_leaf=14, min_samples_split=17; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=None, max_leaf_nodes=51, min_samples_leaf=14, min_samples_split=17; total time=   0.0s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=17, min_samples_leaf=30, min_samples_split=18; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=17, min_samples_leaf=30, min_samples_split=18; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=log2, max_leaf_nodes=17, min_samples_leaf=30, min_samples_split=18; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=50, min_samples_leaf=2, min_samples_split=2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=50, min_samples_leaf=2, min_samples_split=2; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, max_features=auto, max_leaf_nodes=50, min_samples_leaf=2, min_samples_split=2; total time=   0.3s\n",
      "[CV] END max_depth=100, max_features=sqrt, max_leaf_nodes=25, min_samples_leaf=24, min_samples_split=14; total time=   0.3s\n",
      "[CV] END max_depth=100, max_features=sqrt, max_leaf_nodes=25, min_samples_leaf=24, min_samples_split=14; total time=   0.3s\n",
      "[CV] END max_depth=100, max_features=sqrt, max_leaf_nodes=25, min_samples_leaf=24, min_samples_split=14; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=37, min_samples_leaf=32, min_samples_split=6; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=37, min_samples_leaf=32, min_samples_split=6; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, max_leaf_nodes=37, min_samples_leaf=32, min_samples_split=6; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=47, min_samples_leaf=8, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=47, min_samples_leaf=8, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, max_leaf_nodes=47, min_samples_leaf=8, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=43, min_samples_leaf=37, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=43, min_samples_leaf=37, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=43, min_samples_leaf=37, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=2, max_features=None, max_leaf_nodes=19, min_samples_leaf=31, min_samples_split=22; total time=   0.0s\n",
      "[CV] END max_depth=2, max_features=None, max_leaf_nodes=19, min_samples_leaf=31, min_samples_split=22; total time=   0.0s\n",
      "[CV] END max_depth=2, max_features=None, max_leaf_nodes=19, min_samples_leaf=31, min_samples_split=22; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=log2, max_leaf_nodes=43, min_samples_leaf=14, min_samples_split=6; total time=   0.1s\n",
      "[CV] END max_depth=1, max_features=log2, max_leaf_nodes=43, min_samples_leaf=14, min_samples_split=6; total time=   0.1s\n",
      "[CV] END max_depth=1, max_features=log2, max_leaf_nodes=43, min_samples_leaf=14, min_samples_split=6; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=None, max_leaf_nodes=19, min_samples_leaf=15, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=None, max_leaf_nodes=19, min_samples_leaf=15, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=None, max_leaf_nodes=19, min_samples_leaf=15, min_samples_split=39; total time=   0.0s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=51, min_samples_leaf=33, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=51, min_samples_leaf=33, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=100, max_features=None, max_leaf_nodes=51, min_samples_leaf=33, min_samples_split=4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=52, min_samples_leaf=26, min_samples_split=9; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=52, min_samples_leaf=26, min_samples_split=9; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=52, min_samples_leaf=26, min_samples_split=9; total time=   0.1s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=59, min_samples_leaf=10, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=59, min_samples_leaf=10, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=3, max_features=None, max_leaf_nodes=59, min_samples_leaf=10, min_samples_split=5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=54, min_samples_leaf=17, min_samples_split=26; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=54, min_samples_leaf=17, min_samples_split=26; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=1, max_features=auto, max_leaf_nodes=54, min_samples_leaf=17, min_samples_split=26; total time=   0.1s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=42, min_samples_leaf=37, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=42, min_samples_leaf=37, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=2, max_features=sqrt, max_leaf_nodes=42, min_samples_leaf=37, min_samples_split=18; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=45, min_samples_leaf=4, min_samples_split=10; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=45, min_samples_leaf=4, min_samples_split=10; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, max_leaf_nodes=45, min_samples_leaf=4, min_samples_split=10; total time=   0.3s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=19, min_samples_leaf=28, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=19, min_samples_leaf=28, min_samples_split=4; total time=   0.0s\n",
      "[CV] END max_depth=1, max_features=None, max_leaf_nodes=19, min_samples_leaf=28, min_samples_split=4; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "33 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "33 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'auto' (deprecated), 'log2', 'sqrt'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.52716474 0.62165081 0.5678275  0.61544172 0.57535264 0.64014308\n",
      " 0.53276642 0.51785112 0.55277722 0.56806371 0.58922184 0.63467639\n",
      "        nan 0.62937842        nan 0.63872579        nan        nan\n",
      " 0.53300263 0.57045961 0.58672471 0.54758048 0.53236148        nan\n",
      " 0.52088817 0.63940069 0.60039144 0.63120065 0.589863          nan\n",
      "        nan 0.50772761        nan        nan 0.51812108        nan\n",
      " 0.51278936 0.52632112 0.60619559        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=40,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2, 3, 10, 30, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;None&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [10, 11, 12, 13, 14,\n",
       "                                                           15, 16, 17, 18, 19,\n",
       "                                                           20, 21, 22, 23, 24,\n",
       "                                                           25, 26, 27, 28, 29,\n",
       "                                                           30, 31, 32, 33, 34,\n",
       "                                                           35, 36, 37, 38, 39, ...],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=40,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2, 3, 10, 30, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;None&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [10, 11, 12, 13, 14,\n",
       "                                                           15, 16, 17, 18, 19,\n",
       "                                                           20, 21, 22, 23, 24,\n",
       "                                                           25, 26, 27, 28, 29,\n",
       "                                                           30, 31, 32, 33, 34,\n",
       "                                                           35, 36, 37, 38, 39, ...],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_iter=40,\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 10, 30, 100],\n",
       "                                        'max_features': ['None', 'auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'max_leaf_nodes': [10, 11, 12, 13, 14,\n",
       "                                                           15, 16, 17, 18, 19,\n",
       "                                                           20, 21, 22, 23, 24,\n",
       "                                                           25, 26, 27, 28, 29,\n",
       "                                                           30, 31, 32, 33, 34,\n",
       "                                                           35, 36, 37, 38, 39, ...],\n",
       "                                        'min_samples_leaf': [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...]},\n",
       "                   scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_parameters = {\n",
    "    'max_depth' : [1, 2, 3, 10, 30, 100],\n",
    "    'min_samples_split':list(range(2, 40)),\n",
    "    'min_samples_leaf':list(range(2, 40)),\n",
    "    'max_features':['None','auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes':list(range(10, 60))\n",
    "}\n",
    "\n",
    "n_iter = 40\n",
    "cv = 3\n",
    "\n",
    "dt_tree = DecisionTreeClassifier()\n",
    "\n",
    "dt_grid_search = RandomizedSearchCV(estimator=dt_tree, \n",
    "                                         param_distributions=dt_parameters, n_iter=n_iter, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.640143078895863 {'min_samples_split': 28, 'min_samples_leaf': 10, 'max_leaf_nodes': 57, 'max_features': 'auto', 'max_depth': 100} \n",
      "\n",
      "Accuracy: 0.522827\n",
      "Precision: 0.204096\n",
      "Recall: 0.785001\n",
      "F1 score: 0.323963\n",
      "AUC: 0.631567\n"
     ]
    }
   ],
   "source": [
    "# This suggests overfitting\n",
    "print('train accuracy:',dt_grid_search.best_score_, dt_grid_search.best_params_, '\\n')\n",
    "\n",
    "y_pred = dt_grid_search.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a Simple RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\AppData\\Local\\Temp\\ipykernel_19800\\2651474788.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903112\n",
      "Precision: 0.604796\n",
      "Recall: 0.966010\n",
      "F1 score: 0.743872\n",
      "AUC: 0.929200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b RandomForestClassifier hyperparameter opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=sqrt, min_samples_leaf=22, min_samples_split=14, n_estimators=332; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=sqrt, min_samples_leaf=22, min_samples_split=14, n_estimators=332; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=sqrt, min_samples_leaf=22, min_samples_split=14, n_estimators=332; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=auto, min_samples_leaf=3, min_samples_split=37, n_estimators=203; total time=  58.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=auto, min_samples_leaf=3, min_samples_split=37, n_estimators=203; total time=  57.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=auto, min_samples_leaf=3, min_samples_split=37, n_estimators=203; total time=  57.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=34, min_samples_split=5, n_estimators=214; total time=  44.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=34, min_samples_split=5, n_estimators=214; total time=  44.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=34, min_samples_split=5, n_estimators=214; total time=  44.5s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=28, min_samples_split=38, n_estimators=483; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=28, min_samples_split=38, n_estimators=483; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=28, min_samples_split=38, n_estimators=483; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=27, n_estimators=298; total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=27, n_estimators=298; total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=27, n_estimators=298; total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=37, n_estimators=403; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=37, n_estimators=403; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=37, n_estimators=403; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=25, min_samples_split=2, n_estimators=269; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=25, min_samples_split=2, n_estimators=269; total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=25, min_samples_split=2, n_estimators=269; total time=  19.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=29, min_samples_split=29, n_estimators=158; total time=  35.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=29, min_samples_split=29, n_estimators=158; total time=  34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=29, min_samples_split=29, n_estimators=158; total time=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=6, min_samples_split=27, n_estimators=475; total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=6, min_samples_split=27, n_estimators=475; total time=  37.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=6, min_samples_split=27, n_estimators=475; total time=  37.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=15, min_samples_split=15, n_estimators=308; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=15, min_samples_split=15, n_estimators=308; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=15, min_samples_split=15, n_estimators=308; total time= 1.3min\n",
      "[CV] END criterion=gini, max_depth=550, max_features=None, min_samples_leaf=34, min_samples_split=38, n_estimators=290; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=550, max_features=None, min_samples_leaf=34, min_samples_split=38, n_estimators=290; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=550, max_features=None, min_samples_leaf=34, min_samples_split=38, n_estimators=290; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=153; total time=  48.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=153; total time=  47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=153; total time=  47.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=10, min_samples_split=37, n_estimators=83; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=10, min_samples_split=37, n_estimators=83; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=10, min_samples_split=37, n_estimators=83; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=250, max_features=None, min_samples_leaf=36, min_samples_split=19, n_estimators=462; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=250, max_features=None, min_samples_leaf=36, min_samples_split=19, n_estimators=462; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=250, max_features=None, min_samples_leaf=36, min_samples_split=19, n_estimators=462; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=8, min_samples_split=37, n_estimators=379; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=8, min_samples_split=37, n_estimators=379; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=8, min_samples_split=37, n_estimators=379; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=212; total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=212; total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=log2, min_samples_leaf=8, min_samples_split=2, n_estimators=212; total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=330; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=330; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=auto, min_samples_leaf=6, min_samples_split=2, n_estimators=330; total time= 1.6min\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=35, min_samples_split=16, n_estimators=282; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=35, min_samples_split=16, n_estimators=282; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=35, min_samples_split=16, n_estimators=282; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=5, min_samples_split=27, n_estimators=269; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=5, min_samples_split=27, n_estimators=269; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=5, min_samples_split=27, n_estimators=269; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=6, min_samples_split=7, n_estimators=438; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=6, min_samples_split=7, n_estimators=438; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=6, min_samples_split=7, n_estimators=438; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=36, min_samples_split=13, n_estimators=346; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=36, min_samples_split=13, n_estimators=346; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=36, min_samples_split=13, n_estimators=346; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=9, min_samples_split=25, n_estimators=13; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=9, min_samples_split=25, n_estimators=13; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=9, min_samples_split=25, n_estimators=13; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=12, min_samples_split=36, n_estimators=375; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=12, min_samples_split=36, n_estimators=375; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=12, min_samples_split=36, n_estimators=375; total time= 1.8min\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=9, min_samples_split=34, n_estimators=136; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=9, min_samples_split=34, n_estimators=136; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=9, min_samples_split=34, n_estimators=136; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=20, min_samples_split=21, n_estimators=258; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=20, min_samples_split=21, n_estimators=258; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=20, min_samples_split=21, n_estimators=258; total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=sqrt, min_samples_leaf=27, min_samples_split=13, n_estimators=427; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=sqrt, min_samples_leaf=27, min_samples_split=13, n_estimators=427; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=550, max_features=sqrt, min_samples_leaf=27, min_samples_split=13, n_estimators=427; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=28, min_samples_split=18, n_estimators=145; total time=  31.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=28, min_samples_split=18, n_estimators=145; total time=  31.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=sqrt, min_samples_leaf=28, min_samples_split=18, n_estimators=145; total time=  31.3s\n",
      "[CV] END criterion=entropy, max_depth=100, max_features=None, min_samples_leaf=27, min_samples_split=11, n_estimators=109; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=100, max_features=None, min_samples_leaf=27, min_samples_split=11, n_estimators=109; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=100, max_features=None, min_samples_leaf=27, min_samples_split=11, n_estimators=109; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=22, min_samples_split=19, n_estimators=376; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=22, min_samples_split=19, n_estimators=376; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=22, min_samples_split=19, n_estimators=376; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=357; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=357; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=357; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=auto, min_samples_leaf=29, min_samples_split=36, n_estimators=170; total time=  41.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=auto, min_samples_leaf=29, min_samples_split=36, n_estimators=170; total time=  41.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=auto, min_samples_leaf=29, min_samples_split=36, n_estimators=170; total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=auto, min_samples_leaf=16, min_samples_split=30, n_estimators=99; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=auto, min_samples_leaf=16, min_samples_split=30, n_estimators=99; total time=  27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=auto, min_samples_leaf=16, min_samples_split=30, n_estimators=99; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=283; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=283; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=11, n_estimators=283; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=13, min_samples_split=33, n_estimators=220; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=13, min_samples_split=33, n_estimators=220; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=13, min_samples_split=33, n_estimators=220; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=18, min_samples_split=36, n_estimators=226; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=18, min_samples_split=36, n_estimators=226; total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=18, min_samples_split=36, n_estimators=226; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=15, min_samples_split=18, n_estimators=205; total time=  57.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=15, min_samples_split=18, n_estimators=205; total time=  57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=15, min_samples_split=18, n_estimators=205; total time=  57.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=29, n_estimators=134; total time=  41.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=29, n_estimators=134; total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=29, n_estimators=134; total time=  40.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=14, min_samples_split=18, n_estimators=312; total time=  22.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=14, min_samples_split=18, n_estimators=312; total time=  22.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=14, min_samples_split=18, n_estimators=312; total time=  22.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=9, min_samples_split=15, n_estimators=60; total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=9, min_samples_split=15, n_estimators=60; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=9, min_samples_split=15, n_estimators=60; total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=7, min_samples_split=14, n_estimators=224; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=7, min_samples_split=14, n_estimators=224; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=7, min_samples_split=14, n_estimators=224; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=30, min_samples_split=5, n_estimators=243; total time=  16.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=30, min_samples_split=5, n_estimators=243; total time=  16.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=30, min_samples_split=5, n_estimators=243; total time=  16.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=27, min_samples_split=20, n_estimators=417; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=27, min_samples_split=20, n_estimators=417; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=27, min_samples_split=20, n_estimators=417; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=log2, min_samples_leaf=15, min_samples_split=36, n_estimators=404; total time=  32.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=log2, min_samples_leaf=15, min_samples_split=36, n_estimators=404; total time=  32.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=log2, min_samples_leaf=15, min_samples_split=36, n_estimators=404; total time=  32.2s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=22, min_samples_split=19, n_estimators=295; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=22, min_samples_split=19, n_estimators=295; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=22, min_samples_split=19, n_estimators=295; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=23, min_samples_split=32, n_estimators=429; total time=  31.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=23, min_samples_split=32, n_estimators=429; total time=  31.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=23, min_samples_split=32, n_estimators=429; total time=  31.2s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=21, min_samples_split=18, n_estimators=288; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=21, min_samples_split=18, n_estimators=288; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=250, max_features=None, min_samples_leaf=21, min_samples_split=18, n_estimators=288; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=150, max_features=None, min_samples_leaf=26, min_samples_split=27, n_estimators=343; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=150, max_features=None, min_samples_leaf=26, min_samples_split=27, n_estimators=343; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=150, max_features=None, min_samples_leaf=26, min_samples_split=27, n_estimators=343; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=33, min_samples_split=23, n_estimators=247; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=33, min_samples_split=23, n_estimators=247; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=33, min_samples_split=23, n_estimators=247; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=6, min_samples_split=39, n_estimators=109; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=6, min_samples_split=39, n_estimators=109; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=None, min_samples_leaf=6, min_samples_split=39, n_estimators=109; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=22, min_samples_split=35, n_estimators=149; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=22, min_samples_split=35, n_estimators=149; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=22, min_samples_split=35, n_estimators=149; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=log2, min_samples_leaf=33, min_samples_split=18, n_estimators=176; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=log2, min_samples_leaf=33, min_samples_split=18, n_estimators=176; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=log2, min_samples_leaf=33, min_samples_split=18, n_estimators=176; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=35, min_samples_split=5, n_estimators=93; total time=  21.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=35, min_samples_split=5, n_estimators=93; total time=  21.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=sqrt, min_samples_leaf=35, min_samples_split=5, n_estimators=93; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=39, min_samples_split=18, n_estimators=382; total time=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=39, min_samples_split=18, n_estimators=382; total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=39, min_samples_split=18, n_estimators=382; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=550, max_features=None, min_samples_leaf=2, min_samples_split=29, n_estimators=222; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=550, max_features=None, min_samples_leaf=2, min_samples_split=29, n_estimators=222; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=550, max_features=None, min_samples_leaf=2, min_samples_split=29, n_estimators=222; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=19, n_estimators=12; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=19, n_estimators=12; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=33, min_samples_split=19, n_estimators=12; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=sqrt, min_samples_leaf=29, min_samples_split=22, n_estimators=26; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=sqrt, min_samples_leaf=29, min_samples_split=22, n_estimators=26; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=sqrt, min_samples_leaf=29, min_samples_split=22, n_estimators=26; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=10, min_samples_split=5, n_estimators=381; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=10, min_samples_split=5, n_estimators=381; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=10, min_samples_split=5, n_estimators=381; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=27, min_samples_split=16, n_estimators=233; total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=27, min_samples_split=16, n_estimators=233; total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=27, min_samples_split=16, n_estimators=233; total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=22, min_samples_split=4, n_estimators=443; total time=  32.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=22, min_samples_split=4, n_estimators=443; total time=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=22, min_samples_split=4, n_estimators=443; total time=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=log2, min_samples_leaf=12, min_samples_split=30, n_estimators=371; total time=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=log2, min_samples_leaf=12, min_samples_split=30, n_estimators=371; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=150, max_features=log2, min_samples_leaf=12, min_samples_split=30, n_estimators=371; total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=21, min_samples_split=29, n_estimators=465; total time=  31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=21, min_samples_split=29, n_estimators=465; total time=  31.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=100, max_features=log2, min_samples_leaf=21, min_samples_split=29, n_estimators=465; total time=  31.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=487; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=487; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=487; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=13, min_samples_split=32, n_estimators=348; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=13, min_samples_split=32, n_estimators=348; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=sqrt, min_samples_leaf=13, min_samples_split=32, n_estimators=348; total time= 1.6min\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=34, n_estimators=497; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=34, n_estimators=497; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=34, n_estimators=497; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=9, min_samples_split=27, n_estimators=128; total time=  39.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=9, min_samples_split=27, n_estimators=128; total time=  39.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=9, min_samples_split=27, n_estimators=128; total time=  38.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=21, min_samples_split=6, n_estimators=46; total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=21, min_samples_split=6, n_estimators=46; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=21, min_samples_split=6, n_estimators=46; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=24, min_samples_split=11, n_estimators=203; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=24, min_samples_split=11, n_estimators=203; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=24, min_samples_split=11, n_estimators=203; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=38, min_samples_split=20, n_estimators=214; total time=  48.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=38, min_samples_split=20, n_estimators=214; total time=  48.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=38, min_samples_split=20, n_estimators=214; total time=  47.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=35, min_samples_split=10, n_estimators=17; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=35, min_samples_split=10, n_estimators=17; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=35, min_samples_split=10, n_estimators=17; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=18, min_samples_split=38, n_estimators=26; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=18, min_samples_split=38, n_estimators=26; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=350, max_features=auto, min_samples_leaf=18, min_samples_split=38, n_estimators=26; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=auto, min_samples_leaf=31, min_samples_split=25, n_estimators=413; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=auto, min_samples_leaf=31, min_samples_split=25, n_estimators=413; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=auto, min_samples_leaf=31, min_samples_split=25, n_estimators=413; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=24, n_estimators=165; total time=  50.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=24, n_estimators=165; total time=  50.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=sqrt, min_samples_leaf=8, min_samples_split=24, n_estimators=165; total time=  50.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=4, min_samples_split=12, n_estimators=365; total time=  37.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=4, min_samples_split=12, n_estimators=365; total time=  37.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=350, max_features=log2, min_samples_leaf=4, min_samples_split=12, n_estimators=365; total time=  37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=209; total time=  51.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=209; total time=  51.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=sqrt, min_samples_leaf=27, min_samples_split=32, n_estimators=209; total time=  50.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=19, min_samples_split=20, n_estimators=41; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=19, min_samples_split=20, n_estimators=41; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=log2, min_samples_leaf=19, min_samples_split=20, n_estimators=41; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=10, min_samples_split=21, n_estimators=362; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=10, min_samples_split=21, n_estimators=362; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=auto, min_samples_leaf=10, min_samples_split=21, n_estimators=362; total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=auto, min_samples_leaf=13, min_samples_split=7, n_estimators=94; total time=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=auto, min_samples_leaf=13, min_samples_split=7, n_estimators=94; total time=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=auto, min_samples_leaf=13, min_samples_split=7, n_estimators=94; total time=  23.8s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=12, min_samples_split=16, n_estimators=54; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=12, min_samples_split=16, n_estimators=54; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=12, min_samples_split=16, n_estimators=54; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=log2, min_samples_leaf=36, min_samples_split=8, n_estimators=93; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=log2, min_samples_leaf=36, min_samples_split=8, n_estimators=93; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=350, max_features=log2, min_samples_leaf=36, min_samples_split=8, n_estimators=93; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=log2, min_samples_leaf=11, min_samples_split=33, n_estimators=384; total time=  32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=log2, min_samples_leaf=11, min_samples_split=33, n_estimators=384; total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=150, max_features=log2, min_samples_leaf=11, min_samples_split=33, n_estimators=384; total time=  32.4s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=22, min_samples_split=11, n_estimators=303; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=22, min_samples_split=11, n_estimators=303; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=22, min_samples_split=11, n_estimators=303; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=auto, min_samples_leaf=21, min_samples_split=5, n_estimators=266; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=auto, min_samples_leaf=21, min_samples_split=5, n_estimators=266; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=100, max_features=auto, min_samples_leaf=21, min_samples_split=5, n_estimators=266; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=25, min_samples_split=37, n_estimators=74; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=25, min_samples_split=37, n_estimators=74; total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=25, min_samples_split=37, n_estimators=74; total time=  18.4s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=3, n_estimators=77; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=3, n_estimators=77; total time=   0.0s\n",
      "[CV] END criterion=log_loss, max_depth=550, max_features=None, min_samples_leaf=32, min_samples_split=3, n_estimators=77; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=32, min_samples_split=21, n_estimators=489; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=32, min_samples_split=21, n_estimators=489; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=32, min_samples_split=21, n_estimators=489; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=15, min_samples_split=30, n_estimators=323; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=15, min_samples_split=30, n_estimators=323; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=150, max_features=sqrt, min_samples_leaf=15, min_samples_split=30, n_estimators=323; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=13, min_samples_split=15, n_estimators=89; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=13, min_samples_split=15, n_estimators=89; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=log2, min_samples_leaf=13, min_samples_split=15, n_estimators=89; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=34, min_samples_split=30, n_estimators=367; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=34, min_samples_split=30, n_estimators=367; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=34, min_samples_split=30, n_estimators=367; total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=23, min_samples_split=24, n_estimators=287; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=23, min_samples_split=24, n_estimators=287; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=250, max_features=auto, min_samples_leaf=23, min_samples_split=24, n_estimators=287; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=16, n_estimators=18; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=16, n_estimators=18; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=16, n_estimators=18; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=324; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=324; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=250, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=324; total time= 1.3min\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=25, min_samples_split=36, n_estimators=135; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=25, min_samples_split=36, n_estimators=135; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=150, max_features=None, min_samples_leaf=25, min_samples_split=36, n_estimators=135; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=auto, min_samples_leaf=11, min_samples_split=38, n_estimators=280; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=auto, min_samples_leaf=11, min_samples_split=38, n_estimators=280; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=auto, min_samples_leaf=11, min_samples_split=38, n_estimators=280; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=sqrt, min_samples_leaf=17, min_samples_split=30, n_estimators=18; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=sqrt, min_samples_leaf=17, min_samples_split=30, n_estimators=18; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=250, max_features=sqrt, min_samples_leaf=17, min_samples_split=30, n_estimators=18; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=12, n_estimators=387; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=12, n_estimators=387; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=350, max_features=None, min_samples_leaf=2, min_samples_split=12, n_estimators=387; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=39, n_estimators=440; total time=  37.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=39, n_estimators=440; total time=  37.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=39, n_estimators=440; total time=  37.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=18, min_samples_split=10, n_estimators=337; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=18, min_samples_split=10, n_estimators=337; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=30, max_features=auto, min_samples_leaf=18, min_samples_split=10, n_estimators=337; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=5, min_samples_split=19, n_estimators=484; total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=5, min_samples_split=19, n_estimators=484; total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=100, max_features=auto, min_samples_leaf=5, min_samples_split=19, n_estimators=484; total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=76; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=76; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=76; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=17, min_samples_split=28, n_estimators=437; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=17, min_samples_split=28, n_estimators=437; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=550, max_features=auto, min_samples_leaf=17, min_samples_split=28, n_estimators=437; total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "66 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 341, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'auto' (deprecated), 'log2', 'sqrt'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.86717959 0.88546939 0.85337788        nan 0.86684214 0.85496389\n",
      " 0.83117365 0.85550381 0.8661335  0.87696565        nan 0.88415334\n",
      " 0.84423298        nan 0.88034015 0.86333266 0.89427684        nan\n",
      "        nan 0.89360194 0.8515219  0.82732672 0.87554836        nan\n",
      " 0.8396774  0.86093676 0.85584126        nan 0.86650469 0.89242087\n",
      " 0.85364784 0.867787          nan 0.8769319  0.84352433 0.87308497\n",
      " 0.87814672 0.8521968  0.87318621 0.88840521 0.82462712 0.86279274\n",
      " 0.84693258        nan 0.83650537        nan        nan        nan\n",
      "        nan 0.8359317  0.81835054 0.8444017  0.816967          nan\n",
      " 0.80009449 0.82725923        nan 0.82837282 0.83984612 0.85371533\n",
      " 0.84075724 0.86070055 0.87666194        nan 0.87875413 0.85371533\n",
      "        nan 0.84639266 0.80846325 0.84389553 0.85648242 0.88054262\n",
      " 0.87683067 0.85921577 0.81632584 0.88435581 0.87483971        nan\n",
      " 0.80842951 0.85300668        nan 0.86785449 0.85405278        nan\n",
      " 0.85415401 0.87821421 0.84463792 0.85374907 0.86589728 0.81932915\n",
      " 0.87534589        nan 0.87689816 0.8250658         nan 0.85263549\n",
      " 0.87102652 0.89140852 0.87031788 0.87450226]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [30, 100, 150, 250, 350,\n",
       "                                                      550],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;None&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...],\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 500)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [30, 100, 150, 250, 350,\n",
       "                                                      550],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;None&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
       "                                                         &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...],\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 500)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy',\n",
       "                                                      'log_loss'],\n",
       "                                        'max_depth': [30, 100, 150, 250, 350,\n",
       "                                                      550],\n",
       "                                        'max_features': ['None', 'auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9, 10, 11, 12,\n",
       "                                                             13, 14, 15, 16, 17,\n",
       "                                                             18, 19, 20, 21, 22,\n",
       "                                                             23, 24, 25, 26, 27,\n",
       "                                                             28, 29, 30, 31, ...],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10, 11, 12,\n",
       "                                                              13, 14, 15, 16,\n",
       "                                                              17, 18, 19, 20,\n",
       "                                                              21, 22, 23, 24,\n",
       "                                                              25, 26, 27, 28,\n",
       "                                                              29, 30, 31, ...],\n",
       "                                        'n_estimators': range(10, 500)},\n",
       "                   scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_parameters = {\n",
    "    'n_estimators':range(10,500),\n",
    "    'criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth' : [30, 100, 150, 250, 350, 550],\n",
    "    'min_samples_split':list(range(2, 40)),\n",
    "    'min_samples_leaf':list(range(2, 40)),\n",
    "    'max_features':['None','auto', 'sqrt', 'log2'],\n",
    "    # 'max_leaf_nodes':list(range(10, 100))\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "cv = 3\n",
    "\n",
    "rf_tree = RandomForestClassifier()\n",
    "\n",
    "rf_randomized_search = RandomizedSearchCV(estimator=rf_tree, \n",
    "                                         param_distributions=rf_parameters, n_iter=n_iter, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "rf_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8942768441654856 {'n_estimators': 330, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'auto', 'max_depth': 100, 'criterion': 'gini'} \n",
      "\n",
      "Accuracy: 0.886492\n",
      "Precision: 0.564818\n",
      "Recall: 0.961424\n",
      "F1 score: 0.711590\n",
      "AUC: 0.917571\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This suggests overfitting\n",
    "print('train accuracy:',rf_randomized_search.best_score_, rf_randomized_search.best_params_, '\\n')\n",
    "\n",
    "y_pred = rf_randomized_search.predict(X_test)\n",
    "y_pred_proba = rf_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.a Simple Bagging ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.883742\n",
      "Precision: 0.559084\n",
      "Recall: 0.954680\n",
      "F1 score: 0.705191\n",
      "AUC: 0.913164\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_bagging = BaggingClassifier(ExtraTreesClassifier())\n",
    "\n",
    "dt_bagging.fit(X_train,y_train)\n",
    "\n",
    "y_pred = dt_bagging.predict(X_test)\n",
    "y_pred_proba = dt_bagging.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b Bagging ExtraTrees Hyperparameter Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_parameter = {\n",
    "    'estimator__max_depth' : [1, 2, 3, 10, 30, 100],\n",
    "    'estimator__min_samples_split':list(range(2, 40)),\n",
    "    'estimator__min_samples_leaf':list(range(2, 40)),\n",
    "    'estimator__max_features':['None','auto', 'sqrt', 'log2'],\n",
    "    'estimator__max_leaf_nodes':list(range(10, 60)),\n",
    "    \n",
    "    'max_samples' : [0.05, 0.1, 0.2, 0.5],\n",
    "    'n_estimators':[5, 10, 20, 40, 100],\n",
    "    'max_features':[0.1,0.25,0.5,0.75,0.99]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 1/3; 1/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100;, score=0.642 total time=  21.7s\n",
      "[CV 2/3; 1/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 1/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100;, score=0.642 total time=  25.1s\n",
      "[CV 3/3; 1/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=22, estimator__min_samples_split=37, max_features=0.99, max_samples=0.5, n_estimators=100;, score=0.638 total time=  24.9s\n",
      "[CV 1/3; 2/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 2/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100;, score=0.592 total time=  11.7s\n",
      "[CV 2/3; 2/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 2/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100;, score=0.593 total time=  11.6s\n",
      "[CV 3/3; 2/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 2/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=22, estimator__min_samples_split=30, max_features=0.5, max_samples=0.1, n_estimators=100;, score=0.599 total time=  11.5s\n",
      "[CV 1/3; 3/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.720 total time=   8.2s\n",
      "[CV 2/3; 3/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 3/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.718 total time=   8.2s\n",
      "[CV 3/3; 3/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 3/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=2, estimator__min_samples_split=4, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.720 total time=   8.2s\n",
      "[CV 1/3; 4/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 4/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.640 total time=   1.2s\n",
      "[CV 2/3; 4/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 4/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.647 total time=   1.2s\n",
      "[CV 3/3; 4/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 4/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=10, estimator__min_samples_split=30, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.635 total time=   1.2s\n",
      "[CV 1/3; 5/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 5/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20;, score=0.519 total time=   3.2s\n",
      "[CV 2/3; 5/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 5/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20;, score=0.510 total time=   3.2s\n",
      "[CV 3/3; 5/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 5/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=26, estimator__min_samples_split=6, max_features=0.75, max_samples=0.05, n_estimators=20;, score=0.509 total time=   3.2s\n",
      "[CV 1/3; 6/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 6/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.717 total time=   1.8s\n",
      "[CV 2/3; 6/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 6/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.716 total time=   1.8s\n",
      "[CV 3/3; 6/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 6/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=12, estimator__min_samples_split=28, max_features=0.5, max_samples=0.5, n_estimators=10;, score=0.703 total time=   1.8s\n",
      "[CV 1/3; 7/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40\n",
      "[CV 1/3; 7/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 2/3; 7/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 7/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 3/3; 7/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40\n",
      "[CV 3/3; 7/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=15, estimator__min_samples_leaf=6, estimator__min_samples_split=39, max_features=0.5, max_samples=0.1, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 1/3; 8/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 8/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 8/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10\n",
      "[CV 2/3; 8/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 8/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 8/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=21, estimator__min_samples_split=37, max_features=0.75, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 9/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 9/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.586 total time=   0.6s\n",
      "[CV 2/3; 9/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 9/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.579 total time=   0.6s\n",
      "[CV 3/3; 9/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 9/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=29, estimator__min_samples_split=28, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.572 total time=   0.6s\n",
      "[CV 1/3; 10/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 10/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.522 total time=   2.2s\n",
      "[CV 2/3; 10/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 10/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.507 total time=   2.1s\n",
      "[CV 3/3; 10/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 10/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=21, estimator__min_samples_split=6, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.519 total time=   2.2s\n",
      "[CV 1/3; 11/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 11/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.645 total time=   5.3s\n",
      "[CV 2/3; 11/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 11/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.615 total time=   5.4s\n",
      "[CV 3/3; 11/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 11/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=37, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.626 total time=   5.3s\n",
      "[CV 1/3; 12/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40\n",
      "[CV 1/3; 12/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 2/3; 12/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 12/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 3/3; 12/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40\n",
      "[CV 3/3; 12/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=18, estimator__min_samples_split=30, max_features=0.99, max_samples=0.05, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 1/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100\n",
      "[CV 2/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=16, estimator__min_samples_leaf=36, estimator__min_samples_split=7, max_features=0.5, max_samples=0.1, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 14/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 14/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.544 total time=   5.4s\n",
      "[CV 2/3; 14/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 14/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.551 total time=   5.4s\n",
      "[CV 3/3; 14/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 14/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=10, estimator__min_samples_leaf=7, estimator__min_samples_split=37, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.549 total time=   5.4s\n",
      "[CV 1/3; 15/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40\n",
      "[CV 1/3; 15/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 2/3; 15/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 15/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 3/3; 15/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40\n",
      "[CV 3/3; 15/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=2, estimator__min_samples_split=32, max_features=0.1, max_samples=0.5, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 1/3; 16/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 16/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5;, score=0.572 total time=   0.6s\n",
      "[CV 2/3; 16/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 16/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5;, score=0.595 total time=   0.6s\n",
      "[CV 3/3; 16/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 16/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=21, estimator__min_samples_split=28, max_features=0.5, max_samples=0.1, n_estimators=5;, score=0.577 total time=   0.6s\n",
      "[CV 1/3; 17/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 17/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100;, score=0.632 total time=   2.5s\n",
      "[CV 2/3; 17/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 17/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100;, score=0.631 total time=   2.5s\n",
      "[CV 3/3; 17/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 17/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=45, estimator__min_samples_leaf=3, estimator__min_samples_split=13, max_features=0.1, max_samples=0.05, n_estimators=100;, score=0.642 total time=   2.5s\n",
      "[CV 1/3; 18/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10\n",
      "[CV 1/3; 18/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 18/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10\n",
      "[CV 2/3; 18/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 18/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 18/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=21, max_features=0.1, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 19/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n",
      "[CV 1/3; 19/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 2/3; 19/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 19/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 3/3; 19/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n",
      "[CV 3/3; 19/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=12, estimator__min_samples_leaf=21, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 1/3; 20/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 20/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.582 total time=   1.2s\n",
      "[CV 2/3; 20/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 20/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.593 total time=   1.2s\n",
      "[CV 3/3; 20/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 20/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=13, estimator__min_samples_split=19, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.587 total time=   1.2s\n",
      "[CV 1/3; 21/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20\n",
      "[CV 1/3; 21/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3; 21/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 21/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3; 21/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20\n",
      "[CV 3/3; 21/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=24, estimator__min_samples_split=23, max_features=0.75, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 1/3; 22/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 22/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.545 total time=   0.8s\n",
      "[CV 2/3; 22/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 22/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.561 total time=   0.8s\n",
      "[CV 3/3; 22/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 22/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=34, estimator__min_samples_leaf=4, estimator__min_samples_split=23, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.559 total time=   0.9s\n",
      "[CV 1/3; 23/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 23/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5;, score=0.578 total time=   0.8s\n",
      "[CV 2/3; 23/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 23/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5;, score=0.572 total time=   0.8s\n",
      "[CV 3/3; 23/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 23/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=4, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=5;, score=0.576 total time=   0.8s\n",
      "[CV 1/3; 24/50] START estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 24/50] END estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.594 total time=   0.6s\n",
      "[CV 2/3; 24/50] START estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 24/50] END estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.569 total time=   0.6s\n",
      "[CV 3/3; 24/50] START estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 24/50] END estimator__max_depth=30, estimator__max_features=auto, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=16, estimator__min_samples_split=39, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.567 total time=   0.6s\n",
      "[CV 1/3; 25/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100\n",
      "[CV 1/3; 25/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 25/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 25/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 25/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100\n",
      "[CV 3/3; 25/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=5, estimator__min_samples_split=20, max_features=0.1, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 26/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 26/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20;, score=0.571 total time=   0.5s\n",
      "[CV 2/3; 26/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 26/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20;, score=0.587 total time=   0.5s\n",
      "[CV 3/3; 26/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 26/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=20, estimator__min_samples_leaf=23, estimator__min_samples_split=5, max_features=0.1, max_samples=0.2, n_estimators=20;, score=0.585 total time=   0.5s\n",
      "[CV 1/3; 27/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10\n",
      "[CV 1/3; 27/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 27/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 27/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 27/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10\n",
      "[CV 3/3; 27/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=34, estimator__min_samples_split=38, max_features=0.5, max_samples=0.05, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 28/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 28/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.566 total time=  16.2s\n",
      "[CV 2/3; 28/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 28/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.556 total time=  16.2s\n",
      "[CV 3/3; 28/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 28/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=36, estimator__min_samples_split=32, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.562 total time=  16.2s\n",
      "[CV 1/3; 29/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 29/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.506 total time=   0.9s\n",
      "[CV 2/3; 29/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 29/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.525 total time=   0.8s\n",
      "[CV 3/3; 29/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 29/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=31, estimator__min_samples_split=28, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.540 total time=   0.8s\n",
      "[CV 1/3; 30/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10\n",
      "[CV 1/3; 30/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 30/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 30/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 30/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10\n",
      "[CV 3/3; 30/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=8, estimator__min_samples_split=16, max_features=0.75, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 31/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 31/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40;, score=0.604 total time=   6.9s\n",
      "[CV 2/3; 31/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 31/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40;, score=0.602 total time=   6.9s\n",
      "[CV 3/3; 31/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 31/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=37, estimator__min_samples_split=26, max_features=0.75, max_samples=0.05, n_estimators=40;, score=0.612 total time=   6.9s\n",
      "[CV 1/3; 32/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20\n",
      "[CV 1/3; 32/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3; 32/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 32/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3; 32/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20\n",
      "[CV 3/3; 32/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=57, estimator__min_samples_leaf=2, estimator__min_samples_split=26, max_features=0.5, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 1/3; 33/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 33/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.538 total time=   4.3s\n",
      "[CV 2/3; 33/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 33/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.537 total time=   4.4s\n",
      "[CV 3/3; 33/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 33/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=22, estimator__min_samples_split=34, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.541 total time=   4.3s\n",
      "[CV 1/3; 34/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 34/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.713 total time=   4.8s\n",
      "[CV 2/3; 34/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 34/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.709 total time=   4.7s\n",
      "[CV 3/3; 34/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 34/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=36, estimator__min_samples_split=38, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.718 total time=   4.7s\n",
      "[CV 1/3; 35/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 35/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10;, score=0.610 total time=   2.0s\n",
      "[CV 2/3; 35/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 35/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10;, score=0.622 total time=   2.0s\n",
      "[CV 3/3; 35/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 35/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=8, estimator__min_samples_split=18, max_features=0.75, max_samples=0.1, n_estimators=10;, score=0.612 total time=   2.0s\n",
      "[CV 1/3; 36/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5\n",
      "[CV 1/3; 36/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 2/3; 36/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 36/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 3/3; 36/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5\n",
      "[CV 3/3; 36/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=13, estimator__min_samples_split=11, max_features=0.5, max_samples=0.1, n_estimators=5;, score=nan total time=   0.0s\n",
      "[CV 1/3; 37/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 37/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40;, score=0.579 total time=   8.8s\n",
      "[CV 2/3; 37/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 37/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40;, score=0.576 total time=   8.9s\n",
      "[CV 3/3; 37/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 37/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=52, estimator__min_samples_leaf=15, estimator__min_samples_split=21, max_features=0.99, max_samples=0.05, n_estimators=40;, score=0.569 total time=   8.8s\n",
      "[CV 1/3; 38/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40\n",
      "[CV 1/3; 38/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40;, score=nan total time=   0.1s\n",
      "[CV 2/3; 38/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 38/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 3/3; 38/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40\n",
      "[CV 3/3; 38/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=11, estimator__min_samples_split=25, max_features=0.99, max_samples=0.1, n_estimators=40;, score=nan total time=   0.0s\n",
      "[CV 1/3; 39/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 39/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100;, score=0.562 total time=  10.9s\n",
      "[CV 2/3; 39/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 39/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100;, score=0.560 total time=  10.9s\n",
      "[CV 3/3; 39/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 39/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=36, estimator__min_samples_split=36, max_features=0.5, max_samples=0.05, n_estimators=100;, score=0.570 total time=  10.9s\n",
      "[CV 1/3; 40/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 40/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.679 total time=   1.9s\n",
      "[CV 2/3; 40/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 40/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.679 total time=   1.9s\n",
      "[CV 3/3; 40/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 40/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=5, estimator__min_samples_split=24, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.669 total time=   1.9s\n",
      "[CV 1/3; 41/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 41/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.548 total time=   0.9s\n",
      "[CV 2/3; 41/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 41/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.587 total time=   0.9s\n",
      "[CV 3/3; 41/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 41/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=22, estimator__min_samples_leaf=4, estimator__min_samples_split=27, max_features=0.75, max_samples=0.2, n_estimators=5;, score=0.571 total time=   0.9s\n",
      "[CV 1/3; 42/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 42/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.530 total time=  16.2s\n",
      "[CV 2/3; 42/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 42/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.545 total time=  16.0s\n",
      "[CV 3/3; 42/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 42/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.516 total time=  16.1s\n",
      "[CV 1/3; 43/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20\n",
      "[CV 1/3; 43/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3; 43/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 43/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3; 43/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20\n",
      "[CV 3/3; 43/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=35, estimator__min_samples_split=30, max_features=0.25, max_samples=0.2, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 1/3; 44/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 44/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20;, score=0.523 total time=   0.4s\n",
      "[CV 2/3; 44/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 44/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20;, score=0.545 total time=   0.4s\n",
      "[CV 3/3; 44/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 44/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=17, estimator__min_samples_split=26, max_features=0.1, max_samples=0.05, n_estimators=20;, score=0.528 total time=   0.4s\n",
      "[CV 1/3; 45/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 45/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.564 total time=   0.6s\n",
      "[CV 2/3; 45/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 45/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.576 total time=   0.6s\n",
      "[CV 3/3; 45/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 45/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=6, estimator__min_samples_split=23, max_features=0.25, max_samples=0.05, n_estimators=10;, score=0.582 total time=   0.6s\n",
      "[CV 1/3; 46/50] START estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 46/50] END estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40;, score=0.725 total time=  11.8s\n",
      "[CV 2/3; 46/50] START estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 46/50] END estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40;, score=0.735 total time=  11.8s\n",
      "[CV 3/3; 46/50] START estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 46/50] END estimator__max_depth=100, estimator__max_features=auto, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=34, estimator__min_samples_split=14, max_features=0.99, max_samples=0.5, n_estimators=40;, score=0.740 total time=  11.9s\n",
      "[CV 1/3; 47/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10\n",
      "[CV 1/3; 47/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 47/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 47/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 47/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10\n",
      "[CV 3/3; 47/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=14, estimator__min_samples_leaf=35, estimator__min_samples_split=18, max_features=0.25, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 48/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 48/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.543 total time=   5.4s\n",
      "[CV 2/3; 48/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 48/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.551 total time=   5.5s\n",
      "[CV 3/3; 48/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 48/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=40, estimator__min_samples_leaf=32, estimator__min_samples_split=27, max_features=0.25, max_samples=0.05, n_estimators=100;, score=0.527 total time=   5.5s\n",
      "[CV 1/3; 49/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 49/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.600 total time=   1.1s\n",
      "[CV 2/3; 49/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 49/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.593 total time=   1.2s\n",
      "[CV 3/3; 49/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 49/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=16, estimator__min_samples_split=22, max_features=0.99, max_samples=0.5, n_estimators=5;, score=0.573 total time=   1.1s\n",
      "[CV 1/3; 50/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 50/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100;, score=0.547 total time=   2.2s\n",
      "[CV 2/3; 50/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 50/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100;, score=0.550 total time=   2.2s\n",
      "[CV 3/3; 50/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 50/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=24, estimator__min_samples_split=16, max_features=0.1, max_samples=0.1, n_estimators=100;, score=0.530 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "48 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 339, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 474, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 143, in _parallel_build_estimators\n",
      "    estimator_fit(X_, y, sample_weight=curr_sample_weight)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'auto' (deprecated), 'log2', 'sqrt'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.640683   0.59441857 0.7193089  0.64081798 0.51235068 0.71205372\n",
      "        nan        nan 0.57896335 0.51602889 0.62870352        nan\n",
      "        nan 0.54801917        nan 0.58135925 0.63494635        nan\n",
      "        nan 0.58766957        nan 0.55507188 0.57501519 0.57656746\n",
      "        nan 0.58088682        nan 0.56128096 0.52362152        nan\n",
      " 0.60619559        nan 0.53863805 0.71347101 0.61486806        nan\n",
      " 0.57454275        nan 0.56411554 0.67554161 0.5688061  0.53040427\n",
      "        nan 0.5318553  0.57403658 0.73338058        nan 0.54005534\n",
      " 0.58885064 0.54241749]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=DecisionTreeClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;estimator__max_depth&#x27;: [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        &#x27;estimator__max_features&#x27;: [&#x27;None&#x27;,\n",
       "                                                                    &#x27;auto&#x27;,\n",
       "                                                                    &#x27;sqrt&#x27;,\n",
       "                                                                    &#x27;log2&#x27;],\n",
       "                                        &#x27;estimator__max_leaf_nodes&#x27;: [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        &#x27;estimator...leaf&#x27;: [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        &#x27;estimator__min_samples_split&#x27;: [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        &#x27;max_features&#x27;: [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        &#x27;max_samples&#x27;: [0.05, 0.1, 0.2, 0.5],\n",
       "                                        &#x27;n_estimators&#x27;: [5, 10, 20, 40, 100]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=DecisionTreeClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;estimator__max_depth&#x27;: [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        &#x27;estimator__max_features&#x27;: [&#x27;None&#x27;,\n",
       "                                                                    &#x27;auto&#x27;,\n",
       "                                                                    &#x27;sqrt&#x27;,\n",
       "                                                                    &#x27;log2&#x27;],\n",
       "                                        &#x27;estimator__max_leaf_nodes&#x27;: [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        &#x27;estimator...leaf&#x27;: [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        &#x27;estimator__min_samples_split&#x27;: [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        &#x27;max_features&#x27;: [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        &#x27;max_samples&#x27;: [0.05, 0.1, 0.2, 0.5],\n",
       "                                        &#x27;n_estimators&#x27;: [5, 10, 20, 40, 100]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=DecisionTreeClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'estimator__max_depth': [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        'estimator__max_features': ['None',\n",
       "                                                                    'auto',\n",
       "                                                                    'sqrt',\n",
       "                                                                    'log2'],\n",
       "                                        'estimator__max_leaf_nodes': [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        'estimator...leaf': [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        'estimator__min_samples_split': [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        'max_features': [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
       "                                        'n_estimators': [5, 10, 20, 40, 100]},\n",
       "                   scoring='accuracy', verbose=100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 50\n",
    "cv = 3\n",
    "\n",
    "bagging_tree = BaggingClassifier(DecisionTreeClassifier())\n",
    "\n",
    "bagging_dt_randomized_search = RandomizedSearchCV(estimator=bagging_tree, \n",
    "                                         param_distributions=bagging_parameter, n_iter=n_iter, cv=cv, scoring='accuracy',verbose=100)\n",
    "\n",
    "bagging_dt_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.7333805763649862 {'n_estimators': 40, 'max_samples': 0.5, 'max_features': 0.99, 'estimator__min_samples_split': 14, 'estimator__min_samples_leaf': 34, 'estimator__max_leaf_nodes': 27, 'estimator__max_features': 'auto', 'estimator__max_depth': 100} \n",
      "\n",
      "Accuracy: 0.779860\n",
      "Precision: 0.367450\n",
      "Recall: 0.708929\n",
      "F1 score: 0.484022\n",
      "AUC: 0.750441\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('train accuracy:',bagging_dt_randomized_search.best_score_, bagging_dt_randomized_search.best_params_, '\\n')\n",
    "\n",
    "y_pred = bagging_dt_randomized_search.predict(X_test)\n",
    "y_pred_proba = bagging_dt_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b Simple Bagging RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=RandomForestClassifier())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_rf = BaggingClassifier(RandomForestClassifier())\n",
    "\n",
    "bagging_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878791\n",
      "Precision: 0.548337\n",
      "Recall: 0.951713\n",
      "F1 score: 0.695789\n",
      "AUC: 0.909037\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = bagging_rf.predict(X_test)\n",
    "y_pred_proba = bagging_rf.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.b Bagging RandomForest Hyperparameter Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_parameter = {\n",
    "    'estimator__max_depth' : [1, 2, 3, 10, 30, 100],\n",
    "    'estimator__min_samples_split':list(range(2, 40)),\n",
    "    'estimator__min_samples_leaf':list(range(2, 40)),\n",
    "    'estimator__max_features':['None','auto', 'sqrt', 'log2'],\n",
    "    'estimator__max_leaf_nodes':list(range(10, 60)),\n",
    "    \n",
    "    'max_samples' : [0.05, 0.1, 0.2, 0.5],\n",
    "    'n_estimators':[5, 10, 20, 40, 100],\n",
    "    'max_features':[0.1,0.25,0.5,0.75,0.99]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 1/3; 1/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.593 total time=   9.5s\n",
      "[CV 2/3; 1/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 1/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.593 total time=   9.6s\n",
      "[CV 3/3; 1/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=21, estimator__min_samples_split=18, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.587 total time=   9.6s\n",
      "[CV 1/3; 2/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 2/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100;, score=0.557 total time= 1.9min\n",
      "[CV 2/3; 2/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 2/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100;, score=0.557 total time= 1.9min\n",
      "[CV 3/3; 2/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 2/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=36, estimator__min_samples_split=11, max_features=0.75, max_samples=0.5, n_estimators=100;, score=0.543 total time= 1.9min\n",
      "[CV 1/3; 3/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 3/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.684 total time= 1.3min\n",
      "[CV 2/3; 3/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 3/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.680 total time= 1.3min\n",
      "[CV 3/3; 3/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 3/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=19, estimator__min_samples_split=37, max_features=0.5, max_samples=0.5, n_estimators=40;, score=0.686 total time= 1.3min\n",
      "[CV 1/3; 4/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 4/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40;, score=0.577 total time=  15.4s\n",
      "[CV 2/3; 4/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 4/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40;, score=0.591 total time=  15.4s\n",
      "[CV 3/3; 4/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 4/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=37, estimator__min_samples_split=16, max_features=0.1, max_samples=0.05, n_estimators=40;, score=0.574 total time=  15.6s\n",
      "[CV 1/3; 5/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 5/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.534 total time=  14.2s\n",
      "[CV 2/3; 5/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 5/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.497 total time=  14.2s\n",
      "[CV 3/3; 5/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 5/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=36, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.568 total time=  14.2s\n",
      "[CV 1/3; 6/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10\n",
      "[CV 1/3; 6/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 6/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 6/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 6/50] START estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10\n",
      "[CV 3/3; 6/50] END estimator__max_depth=2, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=33, estimator__min_samples_split=31, max_features=0.25, max_samples=0.5, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 7/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 7/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.693 total time=  58.3s\n",
      "[CV 2/3; 7/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 7/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.683 total time=  57.9s\n",
      "[CV 3/3; 7/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 7/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=34, estimator__min_samples_split=24, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.695 total time=  57.5s\n",
      "[CV 1/3; 8/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 8/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.581 total time= 1.1min\n",
      "[CV 2/3; 8/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 8/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.581 total time= 1.1min\n",
      "[CV 3/3; 8/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 8/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=7, estimator__min_samples_split=15, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.573 total time= 1.1min\n",
      "[CV 1/3; 9/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 9/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.619 total time=   7.2s\n",
      "[CV 2/3; 9/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 9/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.608 total time=   7.2s\n",
      "[CV 3/3; 9/50] START estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 9/50] END estimator__max_depth=10, estimator__max_features=sqrt, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=9, estimator__min_samples_split=27, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.623 total time=   7.2s\n",
      "[CV 1/3; 10/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 10/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20;, score=0.556 total time=  13.7s\n",
      "[CV 2/3; 10/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 10/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20;, score=0.552 total time=  13.8s\n",
      "[CV 3/3; 10/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 10/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=53, estimator__min_samples_leaf=8, estimator__min_samples_split=19, max_features=0.25, max_samples=0.5, n_estimators=20;, score=0.546 total time=  13.8s\n",
      "[CV 1/3; 11/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 11/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.728 total time= 8.4min\n",
      "[CV 2/3; 11/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 11/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.716 total time= 8.3min\n",
      "[CV 3/3; 11/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 11/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=9, estimator__min_samples_split=17, max_features=0.5, max_samples=0.5, n_estimators=100;, score=0.728 total time= 8.3min\n",
      "[CV 1/3; 12/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 12/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20;, score=0.623 total time=  43.2s\n",
      "[CV 2/3; 12/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 12/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20;, score=0.621 total time=  43.4s\n",
      "[CV 3/3; 12/50] START estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 12/50] END estimator__max_depth=3, estimator__max_features=sqrt, estimator__max_leaf_nodes=30, estimator__min_samples_leaf=22, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=20;, score=0.625 total time=  43.4s\n",
      "[CV 1/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n",
      "[CV 1/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 2/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 3/3; 13/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n",
      "[CV 3/3; 13/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=5, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=nan total time=   0.0s\n",
      "[CV 1/3; 14/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 14/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.670 total time= 3.3min\n",
      "[CV 2/3; 14/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 14/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.670 total time= 3.3min\n",
      "[CV 3/3; 14/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 14/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=32, estimator__min_samples_leaf=38, estimator__min_samples_split=11, max_features=0.25, max_samples=0.2, n_estimators=100;, score=0.669 total time= 3.3min\n",
      "[CV 1/3; 15/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 15/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20;, score=0.579 total time=   8.8s\n",
      "[CV 2/3; 15/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 15/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20;, score=0.564 total time=   8.8s\n",
      "[CV 3/3; 15/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 15/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=31, estimator__min_samples_leaf=19, estimator__min_samples_split=24, max_features=0.25, max_samples=0.05, n_estimators=20;, score=0.568 total time=   8.7s\n",
      "[CV 1/3; 16/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 16/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.556 total time=   2.2s\n",
      "[CV 2/3; 16/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 16/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.515 total time=   2.3s\n",
      "[CV 3/3; 16/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 16/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=24, estimator__min_samples_leaf=16, estimator__min_samples_split=25, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.535 total time=   2.2s\n",
      "[CV 1/3; 17/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 17/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.610 total time=  57.9s\n",
      "[CV 2/3; 17/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 17/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.602 total time=  57.6s\n",
      "[CV 3/3; 17/50] START estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 17/50] END estimator__max_depth=30, estimator__max_features=log2, estimator__max_leaf_nodes=47, estimator__min_samples_leaf=36, estimator__min_samples_split=22, max_features=0.75, max_samples=0.05, n_estimators=100;, score=0.597 total time=  57.5s\n",
      "[CV 1/3; 18/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100\n",
      "[CV 1/3; 18/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 18/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 18/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 18/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100\n",
      "[CV 3/3; 18/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=42, estimator__min_samples_leaf=28, estimator__min_samples_split=13, max_features=0.5, max_samples=0.5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 19/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 19/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.570 total time=  12.9s\n",
      "[CV 2/3; 19/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 19/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.556 total time=  12.9s\n",
      "[CV 3/3; 19/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 19/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=18, estimator__min_samples_split=25, max_features=0.5, max_samples=0.2, n_estimators=20;, score=0.532 total time=  12.9s\n",
      "[CV 1/3; 20/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 20/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.628 total time=   9.2s\n",
      "[CV 2/3; 20/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 20/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.620 total time=   9.2s\n",
      "[CV 3/3; 20/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 20/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=21, estimator__min_samples_leaf=32, estimator__min_samples_split=36, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.617 total time=   9.2s\n",
      "[CV 1/3; 21/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 21/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.535 total time=  11.1s\n",
      "[CV 2/3; 21/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 21/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.558 total time=  11.2s\n",
      "[CV 3/3; 21/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 21/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=41, estimator__min_samples_leaf=26, estimator__min_samples_split=29, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.543 total time=  11.1s\n",
      "[CV 1/3; 22/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 22/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=0.555 total time=  25.4s\n",
      "[CV 2/3; 22/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 22/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=0.559 total time=  25.5s\n",
      "[CV 3/3; 22/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 22/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=14, estimator__min_samples_split=33, max_features=0.99, max_samples=0.5, n_estimators=20;, score=0.544 total time=  25.4s\n",
      "[CV 1/3; 23/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 23/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.583 total time=  12.8s\n",
      "[CV 2/3; 23/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 23/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.589 total time=  12.8s\n",
      "[CV 3/3; 23/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 23/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=11, estimator__min_samples_leaf=31, estimator__min_samples_split=39, max_features=0.99, max_samples=0.05, n_estimators=20;, score=0.587 total time=  12.8s\n",
      "[CV 1/3; 24/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 24/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.557 total time=  11.1s\n",
      "[CV 2/3; 24/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 24/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.557 total time=  11.1s\n",
      "[CV 3/3; 24/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 24/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=27, estimator__min_samples_leaf=13, estimator__min_samples_split=31, max_features=0.75, max_samples=0.5, n_estimators=10;, score=0.531 total time=  11.1s\n",
      "[CV 1/3; 25/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 25/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40;, score=0.531 total time=  17.0s\n",
      "[CV 2/3; 25/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 25/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40;, score=0.564 total time=  16.9s\n",
      "[CV 3/3; 25/50] START estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 25/50] END estimator__max_depth=1, estimator__max_features=log2, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=25, estimator__min_samples_split=38, max_features=0.5, max_samples=0.2, n_estimators=40;, score=0.536 total time=  16.9s\n",
      "[CV 1/3; 26/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 26/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20;, score=0.612 total time=  20.7s\n",
      "[CV 2/3; 26/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 26/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20;, score=0.611 total time=  20.9s\n",
      "[CV 3/3; 26/50] START estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 26/50] END estimator__max_depth=3, estimator__max_features=auto, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=9, estimator__min_samples_split=21, max_features=0.1, max_samples=0.5, n_estimators=20;, score=0.614 total time=  20.7s\n",
      "[CV 1/3; 27/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 27/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.593 total time=   5.4s\n",
      "[CV 2/3; 27/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 27/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.591 total time=   5.4s\n",
      "[CV 3/3; 27/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 27/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=30, estimator__min_samples_split=13, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.603 total time=   5.4s\n",
      "[CV 1/3; 28/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 28/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40;, score=0.626 total time=  42.7s\n",
      "[CV 2/3; 28/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 28/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40;, score=0.635 total time=  42.6s\n",
      "[CV 3/3; 28/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 28/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=26, estimator__min_samples_leaf=15, estimator__min_samples_split=26, max_features=0.5, max_samples=0.05, n_estimators=40;, score=0.625 total time=  42.2s\n",
      "[CV 1/3; 29/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 29/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10;, score=0.672 total time=  19.0s\n",
      "[CV 2/3; 29/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 29/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10;, score=0.670 total time=  19.1s\n",
      "[CV 3/3; 29/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 29/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=55, estimator__min_samples_leaf=18, estimator__min_samples_split=19, max_features=0.5, max_samples=0.1, n_estimators=10;, score=0.659 total time=  19.0s\n",
      "[CV 1/3; 30/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 30/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20;, score=0.638 total time=  22.6s\n",
      "[CV 2/3; 30/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 30/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20;, score=0.642 total time=  22.7s\n",
      "[CV 3/3; 30/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 30/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=35, estimator__min_samples_split=11, max_features=0.25, max_samples=0.1, n_estimators=20;, score=0.633 total time=  22.4s\n",
      "[CV 1/3; 31/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 31/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10;, score=0.560 total time=   6.7s\n",
      "[CV 2/3; 31/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 31/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10;, score=0.551 total time=   6.7s\n",
      "[CV 3/3; 31/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 31/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=30, estimator__min_samples_split=11, max_features=0.75, max_samples=0.05, n_estimators=10;, score=0.571 total time=   6.8s\n",
      "[CV 1/3; 32/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 32/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.545 total time=  48.7s\n",
      "[CV 2/3; 32/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 32/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.560 total time=  48.6s\n",
      "[CV 3/3; 32/50] START estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 32/50] END estimator__max_depth=1, estimator__max_features=sqrt, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=19, estimator__min_samples_split=18, max_features=0.1, max_samples=0.5, n_estimators=100;, score=0.544 total time=  48.4s\n",
      "[CV 1/3; 33/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 33/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.507 total time=   4.1s\n",
      "[CV 2/3; 33/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 33/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.544 total time=   4.0s\n",
      "[CV 3/3; 33/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 33/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=25, estimator__min_samples_leaf=27, estimator__min_samples_split=27, max_features=0.5, max_samples=0.05, n_estimators=10;, score=0.527 total time=   4.0s\n",
      "[CV 1/3; 34/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 34/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5;, score=0.576 total time=   1.9s\n",
      "[CV 2/3; 34/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 34/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5;, score=0.572 total time=   1.9s\n",
      "[CV 3/3; 34/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 34/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=3, estimator__min_samples_split=33, max_features=0.25, max_samples=0.05, n_estimators=5;, score=0.564 total time=   1.9s\n",
      "[CV 1/3; 35/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 35/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.628 total time=  30.3s\n",
      "[CV 2/3; 35/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 35/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.622 total time=  30.1s\n",
      "[CV 3/3; 35/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 35/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=18, estimator__min_samples_split=38, max_features=0.25, max_samples=0.05, n_estimators=40;, score=0.620 total time=  30.0s\n",
      "[CV 1/3; 36/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 36/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.590 total time=   4.2s\n",
      "[CV 2/3; 36/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 36/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.605 total time=   4.2s\n",
      "[CV 3/3; 36/50] START estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 36/50] END estimator__max_depth=3, estimator__max_features=log2, estimator__max_leaf_nodes=39, estimator__min_samples_leaf=24, estimator__min_samples_split=21, max_features=0.25, max_samples=0.5, n_estimators=5;, score=0.606 total time=   4.1s\n",
      "[CV 1/3; 37/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 37/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.722 total time=  32.1s\n",
      "[CV 2/3; 37/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 37/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.728 total time=  31.6s\n",
      "[CV 3/3; 37/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 37/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=33, estimator__min_samples_leaf=11, estimator__min_samples_split=17, max_features=0.75, max_samples=0.5, n_estimators=5;, score=0.718 total time=  31.5s\n",
      "[CV 1/3; 38/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 38/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.564 total time=   5.0s\n",
      "[CV 2/3; 38/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 38/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.566 total time=   5.0s\n",
      "[CV 3/3; 38/50] START estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 38/50] END estimator__max_depth=2, estimator__max_features=sqrt, estimator__max_leaf_nodes=17, estimator__min_samples_leaf=17, estimator__min_samples_split=33, max_features=0.5, max_samples=0.2, n_estimators=5;, score=0.551 total time=   5.0s\n",
      "[CV 1/3; 39/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 39/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.629 total time=   9.1s\n",
      "[CV 2/3; 39/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 39/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.626 total time=   9.1s\n",
      "[CV 3/3; 39/50] START estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 39/50] END estimator__max_depth=100, estimator__max_features=log2, estimator__max_leaf_nodes=59, estimator__min_samples_leaf=36, estimator__min_samples_split=24, max_features=0.99, max_samples=0.1, n_estimators=10;, score=0.630 total time=   9.1s\n",
      "[CV 1/3; 40/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 40/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10;, score=0.725 total time= 1.2min\n",
      "[CV 2/3; 40/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 40/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10;, score=0.718 total time= 1.1min\n",
      "[CV 3/3; 40/50] START estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 40/50] END estimator__max_depth=30, estimator__max_features=sqrt, estimator__max_leaf_nodes=29, estimator__min_samples_leaf=22, estimator__min_samples_split=26, max_features=0.99, max_samples=0.5, n_estimators=10;, score=0.730 total time= 1.1min\n",
      "[CV 1/3; 41/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100\n",
      "[CV 1/3; 41/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 41/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 41/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 41/50] START estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100\n",
      "[CV 3/3; 41/50] END estimator__max_depth=3, estimator__max_features=None, estimator__max_leaf_nodes=48, estimator__min_samples_leaf=12, estimator__min_samples_split=25, max_features=0.5, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 42/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 42/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 2/3; 42/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10\n",
      "[CV 2/3; 42/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 3/3; 42/50] START estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 42/50] END estimator__max_depth=30, estimator__max_features=None, estimator__max_leaf_nodes=38, estimator__min_samples_leaf=2, estimator__min_samples_split=23, max_features=0.5, max_samples=0.1, n_estimators=10;, score=nan total time=   0.0s\n",
      "[CV 1/3; 43/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 43/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.504 total time=   2.3s\n",
      "[CV 2/3; 43/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 43/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.566 total time=   2.3s\n",
      "[CV 3/3; 43/50] START estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 43/50] END estimator__max_depth=2, estimator__max_features=log2, estimator__max_leaf_nodes=43, estimator__min_samples_leaf=37, estimator__min_samples_split=21, max_features=0.75, max_samples=0.05, n_estimators=5;, score=0.526 total time=   2.3s\n",
      "[CV 1/3; 44/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 44/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5;, score=0.716 total time=  13.0s\n",
      "[CV 2/3; 44/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 44/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5;, score=0.707 total time=  12.5s\n",
      "[CV 3/3; 44/50] START estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 44/50] END estimator__max_depth=100, estimator__max_features=sqrt, estimator__max_leaf_nodes=51, estimator__min_samples_leaf=25, estimator__min_samples_split=10, max_features=0.1, max_samples=0.5, n_estimators=5;, score=0.713 total time=  12.5s\n",
      "[CV 1/3; 45/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100\n",
      "[CV 1/3; 45/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 45/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 45/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 45/50] START estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100\n",
      "[CV 3/3; 45/50] END estimator__max_depth=100, estimator__max_features=None, estimator__max_leaf_nodes=49, estimator__min_samples_leaf=7, estimator__min_samples_split=14, max_features=0.1, max_samples=0.2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 46/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 46/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40;, score=0.536 total time=  19.7s\n",
      "[CV 2/3; 46/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 46/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40;, score=0.558 total time=  19.8s\n",
      "[CV 3/3; 46/50] START estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 46/50] END estimator__max_depth=1, estimator__max_features=auto, estimator__max_leaf_nodes=56, estimator__min_samples_leaf=35, estimator__min_samples_split=24, max_features=0.25, max_samples=0.2, n_estimators=40;, score=0.545 total time=  19.7s\n",
      "[CV 1/3; 47/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 47/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.625 total time= 1.4min\n",
      "[CV 2/3; 47/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 47/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.626 total time= 1.4min\n",
      "[CV 3/3; 47/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 47/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=19, estimator__min_samples_leaf=35, estimator__min_samples_split=38, max_features=0.75, max_samples=0.1, n_estimators=100;, score=0.627 total time= 1.4min\n",
      "[CV 1/3; 48/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100\n",
      "[CV 1/3; 48/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3; 48/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 48/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3; 48/50] START estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100\n",
      "[CV 3/3; 48/50] END estimator__max_depth=10, estimator__max_features=None, estimator__max_leaf_nodes=35, estimator__min_samples_leaf=27, estimator__min_samples_split=28, max_features=0.99, max_samples=0.05, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3; 49/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 49/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5;, score=0.635 total time=   4.3s\n",
      "[CV 2/3; 49/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 49/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5;, score=0.632 total time=   4.3s\n",
      "[CV 3/3; 49/50] START estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 49/50] END estimator__max_depth=10, estimator__max_features=log2, estimator__max_leaf_nodes=28, estimator__min_samples_leaf=35, estimator__min_samples_split=29, max_features=0.1, max_samples=0.2, n_estimators=5;, score=0.636 total time=   4.3s\n",
      "[CV 1/3; 50/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 50/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.740 total time= 6.5min\n",
      "[CV 2/3; 50/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 50/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.732 total time= 6.5min\n",
      "[CV 3/3; 50/50] START estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 50/50] END estimator__max_depth=10, estimator__max_features=auto, estimator__max_leaf_nodes=50, estimator__min_samples_leaf=22, estimator__min_samples_split=39, max_features=0.25, max_samples=0.5, n_estimators=100;, score=0.739 total time= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "21 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 339, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 474, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 143, in _parallel_build_estimators\n",
      "    estimator_fit(X_, y, sample_weight=curr_sample_weight)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 341, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'auto' (deprecated), 'log2', 'sqrt'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.59114531 0.55233853 0.68313424 0.58048188 0.53283391        nan\n",
      " 0.69028818 0.57828845 0.61652156 0.55132618 0.72426942 0.62289937\n",
      "        nan 0.66997368 0.57032463 0.53533104 0.60285483        nan\n",
      " 0.55284471 0.62175204 0.54515084 0.55264224 0.5861173  0.54825538\n",
      " 0.54383478 0.61260714 0.59563339 0.62866977 0.66663292 0.63788216\n",
      " 0.56036985 0.54980765 0.52615239 0.57069582 0.62347304 0.60029021\n",
      " 0.7226834  0.56053857 0.62833232 0.7244044         nan        nan\n",
      " 0.53188905 0.71201998        nan 0.54619694 0.62593642        nan\n",
      " 0.63447392 0.73722751]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=RandomForestClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;estimator__max_depth&#x27;: [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        &#x27;estimator__max_features&#x27;: [&#x27;None&#x27;,\n",
       "                                                                    &#x27;auto&#x27;,\n",
       "                                                                    &#x27;sqrt&#x27;,\n",
       "                                                                    &#x27;log2&#x27;],\n",
       "                                        &#x27;estimator__max_leaf_nodes&#x27;: [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        &#x27;estimator...leaf&#x27;: [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        &#x27;estimator__min_samples_split&#x27;: [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        &#x27;max_features&#x27;: [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        &#x27;max_samples&#x27;: [0.05, 0.1, 0.2, 0.5],\n",
       "                                        &#x27;n_estimators&#x27;: [5, 10, 20, 40, 100]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=RandomForestClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={&#x27;estimator__max_depth&#x27;: [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        &#x27;estimator__max_features&#x27;: [&#x27;None&#x27;,\n",
       "                                                                    &#x27;auto&#x27;,\n",
       "                                                                    &#x27;sqrt&#x27;,\n",
       "                                                                    &#x27;log2&#x27;],\n",
       "                                        &#x27;estimator__max_leaf_nodes&#x27;: [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        &#x27;estimator...leaf&#x27;: [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        &#x27;estimator__min_samples_split&#x27;: [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        &#x27;max_features&#x27;: [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        &#x27;max_samples&#x27;: [0.05, 0.1, 0.2, 0.5],\n",
       "                                        &#x27;n_estimators&#x27;: [5, 10, 20, 40, 100]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=BaggingClassifier(estimator=RandomForestClassifier()),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'estimator__max_depth': [1, 2, 3, 10,\n",
       "                                                                 30, 100],\n",
       "                                        'estimator__max_features': ['None',\n",
       "                                                                    'auto',\n",
       "                                                                    'sqrt',\n",
       "                                                                    'log2'],\n",
       "                                        'estimator__max_leaf_nodes': [10, 11,\n",
       "                                                                      12, 13,\n",
       "                                                                      14, 15,\n",
       "                                                                      16, 17,\n",
       "                                                                      18, 19,\n",
       "                                                                      20, 21,\n",
       "                                                                      22, 23,\n",
       "                                                                      24, 25,\n",
       "                                                                      26, 27,\n",
       "                                                                      28, 29,\n",
       "                                                                      30, 31,\n",
       "                                                                      32, 33,\n",
       "                                                                      34, 35,\n",
       "                                                                      36, 37,\n",
       "                                                                      38, 39, ...],\n",
       "                                        'estimator...leaf': [2, 3, 4,\n",
       "                                                                        5, 6, 7,\n",
       "                                                                        8, 9,\n",
       "                                                                        10, 11,\n",
       "                                                                        12, 13,\n",
       "                                                                        14, 15,\n",
       "                                                                        16, 17,\n",
       "                                                                        18, 19,\n",
       "                                                                        20, 21,\n",
       "                                                                        22, 23,\n",
       "                                                                        24, 25,\n",
       "                                                                        26, 27,\n",
       "                                                                        28, 29,\n",
       "                                                                        30, 31, ...],\n",
       "                                        'estimator__min_samples_split': [2, 3,\n",
       "                                                                         4, 5,\n",
       "                                                                         6, 7,\n",
       "                                                                         8, 9,\n",
       "                                                                         10, 11,\n",
       "                                                                         12, 13,\n",
       "                                                                         14, 15,\n",
       "                                                                         16, 17,\n",
       "                                                                         18, 19,\n",
       "                                                                         20, 21,\n",
       "                                                                         22, 23,\n",
       "                                                                         24, 25,\n",
       "                                                                         26, 27,\n",
       "                                                                         28, 29,\n",
       "                                                                         30, 31, ...],\n",
       "                                        'max_features': [0.1, 0.25, 0.5, 0.75,\n",
       "                                                         0.99],\n",
       "                                        'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
       "                                        'n_estimators': [5, 10, 20, 40, 100]},\n",
       "                   scoring='accuracy', verbose=100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 50\n",
    "cv = 3\n",
    "\n",
    "bagging_random_forest = BaggingClassifier(RandomForestClassifier())\n",
    "\n",
    "bagging_rf_randomized_search = RandomizedSearchCV(estimator=bagging_random_forest, \n",
    "                                         param_distributions=bagging_parameter, n_iter=n_iter, cv=cv, scoring='accuracy', verbose=100)\n",
    "\n",
    "bagging_rf_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.737227508942431 {'n_estimators': 100, 'max_samples': 0.5, 'max_features': 0.25, 'estimator__min_samples_split': 39, 'estimator__min_samples_leaf': 22, 'estimator__max_leaf_nodes': 50, 'estimator__max_features': 'auto', 'estimator__max_depth': 10} \n",
      "\n",
      "Accuracy: 0.798837\n",
      "Precision: 0.395318\n",
      "Recall: 0.719719\n",
      "F1 score: 0.510329\n",
      "AUC: 0.766022\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('train accuracy:',bagging_rf_randomized_search.best_score_, bagging_rf_randomized_search.best_params_, '\\n')\n",
    "\n",
    "y_pred = bagging_rf_randomized_search.predict(X_test)\n",
    "y_pred_proba = bagging_rf_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ExtraTrees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.a Simple ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\AppData\\Local\\Temp\\ipykernel_19800\\636858048.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  extra_trees.fit(X_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier()\n",
    "extra_trees.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.911205\n",
      "Precision: 0.625542\n",
      "Recall: 0.972484\n",
      "F1 score: 0.761352\n",
      "AUC: 0.936622\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = extra_trees.predict(X_test)\n",
    "y_pred_proba = extra_trees.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.b ExtraTrees hyperparameter opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_parameter = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 500, 1000, 1200, 1500, 1800, 1900, 2000, 2100, 3000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 5, 8, 13, 21, 34, 53, 54, 55, 89, None],\n",
    "    'min_samples_split': [2, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377],\n",
    "    'min_samples_leaf': [1, 2, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377],\n",
    "    # 'min_weight_fraction_leaf': [x / 10 for x in range(0, 6)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 2, 5, 8, 13, 21, 34, None],\n",
    "    'max_leaf_nodes': [2, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, None],\n",
    "    'min_impurity_decrease': [x / 100 for x in range(0, 11)],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "    #'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "    'n_estimators': range(1800, 2100, 10),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=21, n_estimators=2080, oob_score=False, warm_start=True; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=21, n_estimators=2080, oob_score=False, warm_start=True; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=21, n_estimators=2080, oob_score=False, warm_start=True; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=2, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time=  58.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=2, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time=  58.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=2, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time=  58.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=5, max_leaf_nodes=5, min_impurity_decrease=0.08, min_samples_leaf=21, min_samples_split=2, n_estimators=1940, oob_score=False, warm_start=False; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=5, max_leaf_nodes=5, min_impurity_decrease=0.08, min_samples_leaf=21, min_samples_split=2, n_estimators=1940, oob_score=False, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=5, max_leaf_nodes=5, min_impurity_decrease=0.08, min_samples_leaf=21, min_samples_split=2, n_estimators=1940, oob_score=False, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.09, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.09, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.09, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time=   6.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=13, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=8, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=13, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=8, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=13, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=8, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=55, min_samples_split=144, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=55, min_samples_split=144, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=55, min_samples_split=144, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.0min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.06, min_samples_leaf=377, min_samples_split=5, n_estimators=2040, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.06, min_samples_leaf=377, min_samples_split=5, n_estimators=2040, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.06, min_samples_leaf=377, min_samples_split=5, n_estimators=2040, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=34, min_samples_split=21, n_estimators=2010, oob_score=False, warm_start=False; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=34, min_samples_split=21, n_estimators=2010, oob_score=False, warm_start=False; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=34, min_samples_split=21, n_estimators=2010, oob_score=False, warm_start=False; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=2, n_estimators=1880, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=233, n_estimators=2040, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=233, n_estimators=2040, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=233, n_estimators=2040, oob_score=False, warm_start=False; total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.07, min_samples_leaf=144, min_samples_split=21, n_estimators=2040, oob_score=False, warm_start=False; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.07, min_samples_leaf=144, min_samples_split=21, n_estimators=2040, oob_score=False, warm_start=False; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.07, min_samples_leaf=144, min_samples_split=21, n_estimators=2040, oob_score=False, warm_start=False; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=34, min_impurity_decrease=0.06, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=  58.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=34, min_impurity_decrease=0.06, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=  58.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=34, min_impurity_decrease=0.06, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=  58.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=89, n_estimators=1810, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=89, n_estimators=1810, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=89, n_estimators=1810, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=34, n_estimators=1820, oob_score=False, warm_start=True; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=34, n_estimators=1820, oob_score=False, warm_start=True; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=34, n_estimators=1820, oob_score=False, warm_start=True; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=21, max_leaf_nodes=8, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=34, n_estimators=2000, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=21, max_leaf_nodes=8, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=34, n_estimators=2000, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=21, max_leaf_nodes=8, min_impurity_decrease=0.08, min_samples_leaf=55, min_samples_split=34, n_estimators=2000, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=8, n_estimators=1820, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=8, n_estimators=1820, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=55, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=8, n_estimators=1820, oob_score=False, warm_start=True; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=377, n_estimators=2020, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=377, n_estimators=2020, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=377, n_estimators=2020, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=auto, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=89, n_estimators=2070, oob_score=False, warm_start=False; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=auto, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=89, n_estimators=2070, oob_score=False, warm_start=False; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=auto, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=89, n_estimators=2070, oob_score=False, warm_start=False; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=21, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=233, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=21, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=233, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=auto, max_leaf_nodes=21, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=233, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=377, n_estimators=1920, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=377, n_estimators=1920, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=13, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=377, n_estimators=1920, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=auto, max_leaf_nodes=377, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=144, n_estimators=1980, oob_score=False, warm_start=False; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=auto, max_leaf_nodes=377, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=144, n_estimators=1980, oob_score=False, warm_start=False; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=55, max_features=auto, max_leaf_nodes=377, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=144, n_estimators=1980, oob_score=False, warm_start=False; total time=   9.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=55, n_estimators=2080, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=55, n_estimators=2080, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=55, n_estimators=2080, oob_score=True, warm_start=True; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.04, min_samples_leaf=5, min_samples_split=8, n_estimators=1930, oob_score=False, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.04, min_samples_leaf=5, min_samples_split=8, n_estimators=1930, oob_score=False, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.04, min_samples_leaf=5, min_samples_split=8, n_estimators=1930, oob_score=False, warm_start=True; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=13, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=34, min_samples_split=233, n_estimators=1920, oob_score=False, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=13, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=34, min_samples_split=233, n_estimators=1920, oob_score=False, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=13, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=34, min_samples_split=233, n_estimators=1920, oob_score=False, warm_start=True; total time=   5.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.05, min_samples_leaf=55, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.05, min_samples_leaf=55, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.05, min_samples_leaf=55, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=34, max_leaf_nodes=21, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=34, max_leaf_nodes=21, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=34, max_leaf_nodes=21, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=144, n_estimators=1990, oob_score=False, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=144, n_estimators=1990, oob_score=False, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=144, n_estimators=1990, oob_score=False, warm_start=False; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=55, max_features=2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=34, n_estimators=2020, oob_score=False, warm_start=True; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=55, max_features=2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=34, n_estimators=2020, oob_score=False, warm_start=True; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=55, max_features=2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=34, n_estimators=2020, oob_score=False, warm_start=True; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.02, min_samples_leaf=89, min_samples_split=2, n_estimators=2010, oob_score=False, warm_start=True; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.02, min_samples_leaf=89, min_samples_split=2, n_estimators=2010, oob_score=False, warm_start=True; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=None, max_leaf_nodes=5, min_impurity_decrease=0.02, min_samples_leaf=89, min_samples_split=2, n_estimators=2010, oob_score=False, warm_start=True; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.06, min_samples_leaf=34, min_samples_split=89, n_estimators=1810, oob_score=True, warm_start=False; total time=  59.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.06, min_samples_leaf=34, min_samples_split=89, n_estimators=1810, oob_score=True, warm_start=False; total time=  59.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.06, min_samples_leaf=34, min_samples_split=89, n_estimators=1810, oob_score=True, warm_start=False; total time=  59.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=21, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=8, n_estimators=1810, oob_score=False, warm_start=True; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=21, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=8, n_estimators=1810, oob_score=False, warm_start=True; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=21, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=8, n_estimators=1810, oob_score=False, warm_start=True; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.02, min_samples_leaf=55, min_samples_split=2, n_estimators=1840, oob_score=False, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.02, min_samples_leaf=55, min_samples_split=2, n_estimators=1840, oob_score=False, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=log2, max_leaf_nodes=377, min_impurity_decrease=0.02, min_samples_leaf=55, min_samples_split=2, n_estimators=1840, oob_score=False, warm_start=False; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=auto, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=2010, oob_score=False, warm_start=False; total time=  39.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=auto, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=2010, oob_score=False, warm_start=False; total time=  39.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=auto, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=2010, oob_score=False, warm_start=False; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=34, max_leaf_nodes=144, min_impurity_decrease=0.02, min_samples_leaf=8, min_samples_split=5, n_estimators=1840, oob_score=False, warm_start=False; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=34, max_leaf_nodes=144, min_impurity_decrease=0.02, min_samples_leaf=8, min_samples_split=5, n_estimators=1840, oob_score=False, warm_start=False; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=34, max_leaf_nodes=144, min_impurity_decrease=0.02, min_samples_leaf=8, min_samples_split=5, n_estimators=1840, oob_score=False, warm_start=False; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.08, min_samples_leaf=2, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.08, min_samples_leaf=2, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=5, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.08, min_samples_leaf=2, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.06, min_samples_leaf=144, min_samples_split=34, n_estimators=1850, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.06, min_samples_leaf=144, min_samples_split=34, n_estimators=1850, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=5, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.06, min_samples_leaf=144, min_samples_split=34, n_estimators=1850, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, max_features=13, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=False; total time=  58.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, max_features=13, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=False; total time=  59.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, max_features=13, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=233, min_samples_split=144, n_estimators=1800, oob_score=True, warm_start=False; total time=  59.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=377, min_samples_split=55, n_estimators=1830, oob_score=False, warm_start=True; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=377, min_samples_split=55, n_estimators=1830, oob_score=False, warm_start=True; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=377, min_samples_split=55, n_estimators=1830, oob_score=False, warm_start=True; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=1, min_samples_split=144, n_estimators=1980, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=1, min_samples_split=144, n_estimators=1980, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=1, min_samples_split=144, n_estimators=1980, oob_score=True, warm_start=True; total time= 1.1min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=34, max_leaf_nodes=89, min_impurity_decrease=0.08, min_samples_leaf=144, min_samples_split=144, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=34, max_leaf_nodes=89, min_impurity_decrease=0.08, min_samples_leaf=144, min_samples_split=144, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=34, max_leaf_nodes=89, min_impurity_decrease=0.08, min_samples_leaf=144, min_samples_split=144, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=False; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=144, n_estimators=1940, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=144, n_estimators=1940, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=55, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=144, n_estimators=1940, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=21, n_estimators=1870, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=21, n_estimators=1870, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=None, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=21, min_samples_split=21, n_estimators=1870, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=2, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=False; total time=  58.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=2, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=False; total time=  58.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=2, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=89, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=False; total time=  57.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=21, n_estimators=2080, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=21, n_estimators=2080, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, max_features=8, max_leaf_nodes=89, min_impurity_decrease=0.01, min_samples_leaf=233, min_samples_split=21, n_estimators=2080, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=144, min_impurity_decrease=0.06, min_samples_leaf=55, min_samples_split=89, n_estimators=2020, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=144, min_impurity_decrease=0.06, min_samples_leaf=55, min_samples_split=89, n_estimators=2020, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=5, max_features=None, max_leaf_nodes=144, min_impurity_decrease=0.06, min_samples_leaf=55, min_samples_split=89, n_estimators=2020, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.06, min_samples_leaf=5, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.06, min_samples_leaf=5, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.06, min_samples_leaf=5, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=auto, max_leaf_nodes=34, min_impurity_decrease=0.0, min_samples_leaf=144, min_samples_split=377, n_estimators=2080, oob_score=True, warm_start=False; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=auto, max_leaf_nodes=34, min_impurity_decrease=0.0, min_samples_leaf=144, min_samples_split=377, n_estimators=2080, oob_score=True, warm_start=False; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=34, max_features=auto, max_leaf_nodes=34, min_impurity_decrease=0.0, min_samples_leaf=144, min_samples_split=377, n_estimators=2080, oob_score=True, warm_start=False; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.0, min_samples_leaf=55, min_samples_split=55, n_estimators=1860, oob_score=False, warm_start=True; total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.0, min_samples_leaf=55, min_samples_split=55, n_estimators=1860, oob_score=False, warm_start=True; total time=  16.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.0, min_samples_leaf=55, min_samples_split=55, n_estimators=1860, oob_score=False, warm_start=True; total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=233, min_impurity_decrease=0.01, min_samples_leaf=89, min_samples_split=13, n_estimators=1900, oob_score=False, warm_start=True; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=233, min_impurity_decrease=0.01, min_samples_leaf=89, min_samples_split=13, n_estimators=1900, oob_score=False, warm_start=True; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=8, max_features=5, max_leaf_nodes=233, min_impurity_decrease=0.01, min_samples_leaf=89, min_samples_split=13, n_estimators=1900, oob_score=False, warm_start=True; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=21, max_leaf_nodes=89, min_impurity_decrease=0.09, min_samples_leaf=8, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=13, max_leaf_nodes=233, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=13, max_leaf_nodes=233, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=13, max_leaf_nodes=233, min_impurity_decrease=0.07, min_samples_leaf=55, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.1, min_samples_leaf=89, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.1, min_samples_leaf=89, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.1, min_samples_leaf=89, min_samples_split=21, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.05, min_samples_leaf=2, min_samples_split=2, n_estimators=1800, oob_score=False, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.05, min_samples_leaf=2, min_samples_split=2, n_estimators=1800, oob_score=False, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.05, min_samples_leaf=2, min_samples_split=2, n_estimators=1800, oob_score=False, warm_start=True; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=377, n_estimators=1950, oob_score=False, warm_start=True; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=377, n_estimators=1950, oob_score=False, warm_start=True; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.04, min_samples_leaf=233, min_samples_split=377, n_estimators=1950, oob_score=False, warm_start=True; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=34, n_estimators=1880, oob_score=False, warm_start=True; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=34, n_estimators=1880, oob_score=False, warm_start=True; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=13, max_leaf_nodes=377, min_impurity_decrease=0.09, min_samples_leaf=233, min_samples_split=34, n_estimators=1880, oob_score=False, warm_start=True; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=53, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=233, n_estimators=1840, oob_score=False, warm_start=True; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=53, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=233, n_estimators=1840, oob_score=False, warm_start=True; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=53, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=233, n_estimators=1840, oob_score=False, warm_start=True; total time=   7.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=34, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=13, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=34, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=13, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=34, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=34, min_samples_split=13, n_estimators=2070, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=auto, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=5, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=auto, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=5, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=1, max_features=auto, max_leaf_nodes=2, min_impurity_decrease=0.03, min_samples_leaf=5, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=21, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=89, n_estimators=1850, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=21, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=89, n_estimators=1850, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=21, min_impurity_decrease=0.03, min_samples_leaf=34, min_samples_split=89, n_estimators=1850, oob_score=False, warm_start=True; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=34, n_estimators=1930, oob_score=False, warm_start=True; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=34, n_estimators=1930, oob_score=False, warm_start=True; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.01, min_samples_leaf=2, min_samples_split=34, n_estimators=1930, oob_score=False, warm_start=True; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=sqrt, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=233, min_samples_split=233, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=sqrt, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=233, min_samples_split=233, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=13, max_features=sqrt, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=233, min_samples_split=233, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=5, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=89, n_estimators=1950, oob_score=False, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=5, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=89, n_estimators=1950, oob_score=False, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=8, max_features=5, max_leaf_nodes=377, min_impurity_decrease=0.07, min_samples_leaf=2, min_samples_split=89, n_estimators=1950, oob_score=False, warm_start=False; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=55, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=False; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=21, min_samples_split=21, n_estimators=1810, oob_score=False, warm_start=True; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=21, min_samples_split=21, n_estimators=1810, oob_score=False, warm_start=True; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=21, min_samples_split=21, n_estimators=1810, oob_score=False, warm_start=True; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=34, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=5, n_estimators=1920, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=34, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=5, n_estimators=1920, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=5, max_features=34, max_leaf_nodes=377, min_impurity_decrease=0.03, min_samples_leaf=233, min_samples_split=5, n_estimators=1920, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=13, max_leaf_nodes=2, min_impurity_decrease=0.01, min_samples_leaf=55, min_samples_split=21, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=13, max_leaf_nodes=2, min_impurity_decrease=0.01, min_samples_leaf=55, min_samples_split=21, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=8, max_features=13, max_leaf_nodes=2, min_impurity_decrease=0.01, min_samples_leaf=55, min_samples_split=21, n_estimators=2010, oob_score=True, warm_start=True; total time= 1.1min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=55, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=55, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=13, min_impurity_decrease=0.02, min_samples_leaf=1, min_samples_split=55, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=34, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=13, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=34, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=13, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=34, max_leaf_nodes=34, min_impurity_decrease=0.05, min_samples_leaf=13, min_samples_split=13, n_estimators=1820, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=5, max_leaf_nodes=8, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=5, max_leaf_nodes=8, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=5, max_leaf_nodes=8, min_impurity_decrease=0.0, min_samples_leaf=5, min_samples_split=377, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.01, min_samples_leaf=34, min_samples_split=377, n_estimators=2030, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.01, min_samples_leaf=34, min_samples_split=377, n_estimators=2030, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.01, min_samples_leaf=34, min_samples_split=377, n_estimators=2030, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=8, min_samples_split=144, n_estimators=1810, oob_score=False, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=8, min_samples_split=144, n_estimators=1810, oob_score=False, warm_start=False; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=8, max_leaf_nodes=2, min_impurity_decrease=0.07, min_samples_leaf=8, min_samples_split=144, n_estimators=1810, oob_score=False, warm_start=False; total time=   4.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=2, min_samples_split=8, n_estimators=1890, oob_score=True, warm_start=False; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=2, min_samples_split=8, n_estimators=1890, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=sqrt, max_leaf_nodes=233, min_impurity_decrease=0.02, min_samples_leaf=2, min_samples_split=8, n_estimators=1890, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=13, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=13, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=None, max_leaf_nodes=233, min_impurity_decrease=0.05, min_samples_leaf=34, min_samples_split=13, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=1, min_samples_split=21, n_estimators=1800, oob_score=False, warm_start=False; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=1, min_samples_split=21, n_estimators=1800, oob_score=False, warm_start=False; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=8, max_features=sqrt, max_leaf_nodes=144, min_impurity_decrease=0.09, min_samples_leaf=1, min_samples_split=21, n_estimators=1800, oob_score=False, warm_start=False; total time=   8.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=34, max_leaf_nodes=8, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=34, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=34, max_leaf_nodes=8, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=34, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=2, max_features=34, max_leaf_nodes=8, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=34, n_estimators=1840, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=55, max_features=log2, max_leaf_nodes=13, min_impurity_decrease=0.04, min_samples_leaf=34, min_samples_split=5, n_estimators=2040, oob_score=False, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=55, max_features=log2, max_leaf_nodes=13, min_impurity_decrease=0.04, min_samples_leaf=34, min_samples_split=5, n_estimators=2040, oob_score=False, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=55, max_features=log2, max_leaf_nodes=13, min_impurity_decrease=0.04, min_samples_leaf=34, min_samples_split=5, n_estimators=2040, oob_score=False, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=5, min_samples_split=8, n_estimators=2030, oob_score=False, warm_start=False; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=5, min_samples_split=8, n_estimators=2030, oob_score=False, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=54, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=5, min_samples_split=8, n_estimators=2030, oob_score=False, warm_start=False; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.01, min_samples_leaf=13, min_samples_split=144, n_estimators=2020, oob_score=False, warm_start=False; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.06, min_samples_leaf=13, min_samples_split=34, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.06, min_samples_leaf=13, min_samples_split=34, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.06, min_samples_leaf=13, min_samples_split=34, n_estimators=1820, oob_score=True, warm_start=True; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, max_leaf_nodes=21, min_impurity_decrease=0.1, min_samples_leaf=1, min_samples_split=144, n_estimators=1840, oob_score=False, warm_start=True; total time=   3.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=53, max_features=8, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=53, max_features=8, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=53, max_features=8, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=377, n_estimators=2000, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=377, min_samples_split=89, n_estimators=1920, oob_score=False, warm_start=True; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=377, min_samples_split=89, n_estimators=1920, oob_score=False, warm_start=True; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, max_features=34, max_leaf_nodes=13, min_impurity_decrease=0.1, min_samples_leaf=377, min_samples_split=89, n_estimators=1920, oob_score=False, warm_start=True; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=34, min_samples_split=21, n_estimators=2000, oob_score=False, warm_start=False; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=34, min_samples_split=21, n_estimators=2000, oob_score=False, warm_start=False; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=13, max_features=None, max_leaf_nodes=13, min_impurity_decrease=0.07, min_samples_leaf=34, min_samples_split=21, n_estimators=2000, oob_score=False, warm_start=False; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=34, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=True; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=34, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=True; total time=  21.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=89, max_features=21, max_leaf_nodes=13, min_impurity_decrease=0.0, min_samples_leaf=34, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=True; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=21, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=True; total time=  58.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=21, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=True; total time=  58.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=54, max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.01, min_samples_leaf=21, min_samples_split=144, n_estimators=1810, oob_score=True, warm_start=True; total time=  58.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=2, max_features=log2, max_leaf_nodes=21, min_impurity_decrease=0.0, min_samples_leaf=377, min_samples_split=34, n_estimators=1980, oob_score=False, warm_start=True; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=2, max_features=log2, max_leaf_nodes=21, min_impurity_decrease=0.0, min_samples_leaf=377, min_samples_split=34, n_estimators=1980, oob_score=False, warm_start=True; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=2, max_features=log2, max_leaf_nodes=21, min_impurity_decrease=0.0, min_samples_leaf=377, min_samples_split=34, n_estimators=1980, oob_score=False, warm_start=True; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.06, min_samples_leaf=2, min_samples_split=21, n_estimators=2050, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.06, min_samples_leaf=2, min_samples_split=21, n_estimators=2050, oob_score=True, warm_start=False; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=gini, max_depth=13, max_features=2, max_leaf_nodes=55, min_impurity_decrease=0.06, min_samples_leaf=2, min_samples_split=21, n_estimators=2050, oob_score=True, warm_start=False; total time= 1.1min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=1, min_samples_split=377, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=1, min_samples_split=377, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=1, max_features=log2, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=1, min_samples_split=377, n_estimators=1870, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.09, min_samples_leaf=5, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=True; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.09, min_samples_leaf=5, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=True; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=1, max_features=sqrt, max_leaf_nodes=8, min_impurity_decrease=0.09, min_samples_leaf=5, min_samples_split=8, n_estimators=1800, oob_score=False, warm_start=True; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=21, max_leaf_nodes=5, min_impurity_decrease=0.0, min_samples_leaf=13, min_samples_split=5, n_estimators=1860, oob_score=False, warm_start=True; total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=21, max_leaf_nodes=5, min_impurity_decrease=0.0, min_samples_leaf=13, min_samples_split=5, n_estimators=1860, oob_score=False, warm_start=True; total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=21, max_leaf_nodes=5, min_impurity_decrease=0.0, min_samples_leaf=13, min_samples_split=5, n_estimators=1860, oob_score=False, warm_start=True; total time=  14.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=34, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=377, min_samples_split=21, n_estimators=1810, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=34, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=377, min_samples_split=21, n_estimators=1810, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=89, max_features=34, max_leaf_nodes=2, min_impurity_decrease=0.09, min_samples_leaf=377, min_samples_split=21, n_estimators=1810, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=144, min_samples_split=144, n_estimators=2040, oob_score=False, warm_start=True; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=144, min_samples_split=144, n_estimators=2040, oob_score=False, warm_start=True; total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=55, max_features=auto, max_leaf_nodes=5, min_impurity_decrease=0.05, min_samples_leaf=144, min_samples_split=144, n_estimators=2040, oob_score=False, warm_start=True; total time=  10.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=log2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=13, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=log2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=13, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=54, max_features=log2, max_leaf_nodes=144, min_impurity_decrease=0.03, min_samples_leaf=1, min_samples_split=13, n_estimators=1800, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.1, min_samples_leaf=8, min_samples_split=21, n_estimators=1830, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.1, min_samples_leaf=8, min_samples_split=21, n_estimators=1830, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=2, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.1, min_samples_leaf=8, min_samples_split=21, n_estimators=1830, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=377, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=False; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=377, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=False; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=34, max_features=auto, max_leaf_nodes=8, min_impurity_decrease=0.05, min_samples_leaf=377, min_samples_split=8, n_estimators=1860, oob_score=False, warm_start=False; total time=   9.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=2, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=5, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=2, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=5, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=2, max_leaf_nodes=34, min_impurity_decrease=0.08, min_samples_leaf=5, min_samples_split=34, n_estimators=1920, oob_score=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=5, n_estimators=1930, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=5, n_estimators=1930, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=53, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.03, min_samples_leaf=377, min_samples_split=5, n_estimators=1930, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.04, min_samples_leaf=89, min_samples_split=144, n_estimators=2030, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.04, min_samples_leaf=89, min_samples_split=144, n_estimators=2030, oob_score=True, warm_start=True; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=54, max_features=2, max_leaf_nodes=8, min_impurity_decrease=0.04, min_samples_leaf=89, min_samples_split=144, n_estimators=2030, oob_score=True, warm_start=True; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.03, min_samples_leaf=89, min_samples_split=8, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.03, min_samples_leaf=89, min_samples_split=8, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=sqrt, max_leaf_nodes=89, min_impurity_decrease=0.03, min_samples_leaf=89, min_samples_split=8, n_estimators=1860, oob_score=True, warm_start=True; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "72 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 435, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.5        0.5        0.5        0.5               nan 0.5\n",
      "        nan 0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan 0.5\n",
      " 0.5        0.5        0.5               nan 0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.63383276 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5               nan 0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.68836472\n",
      " 0.54913275 0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5               nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5               nan        nan        nan 0.5        0.5\n",
      "        nan        nan 0.5               nan 0.5        0.5\n",
      " 0.5        0.5        0.5               nan 0.5        0.5\n",
      " 0.63126814 0.5        0.57359789 0.5               nan 0.5\n",
      " 0.59937909        nan 0.5               nan        nan 0.5\n",
      "        nan        nan        nan 0.5       ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:425: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=ExtraTreesClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 5, 8, 13, 21, 34,\n",
       "                                                      53, 54, 55, 89, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;,\n",
       "                                                         2, 5, 8, 13, 21, 34,\n",
       "                                                         None],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [2, 5, 8, 13, 21, 34,\n",
       "                                                           55, 89, 144, 233,\n",
       "                                                           377, None],\n",
       "                                        &#x27;min_impurity_decrease&#x27;: [0.0, 0.01,\n",
       "                                                                  0.02, 0.03,\n",
       "                                                                  0.04, 0.05,\n",
       "                                                                  0.06, 0.07,\n",
       "                                                                  0.08, 0.09,\n",
       "                                                                  0.1],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 5, 8, 13, 21,\n",
       "                                                             34, 55, 89, 144,\n",
       "                                                             233, 377],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 8, 13, 21,\n",
       "                                                              34, 55, 89, 144,\n",
       "                                                              233, 377],\n",
       "                                        &#x27;n_estimators&#x27;: range(1800, 2100, 10),\n",
       "                                        &#x27;oob_score&#x27;: [True, False],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=ExtraTreesClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 5, 8, 13, 21, 34,\n",
       "                                                      53, 54, 55, 89, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;,\n",
       "                                                         2, 5, 8, 13, 21, 34,\n",
       "                                                         None],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [2, 5, 8, 13, 21, 34,\n",
       "                                                           55, 89, 144, 233,\n",
       "                                                           377, None],\n",
       "                                        &#x27;min_impurity_decrease&#x27;: [0.0, 0.01,\n",
       "                                                                  0.02, 0.03,\n",
       "                                                                  0.04, 0.05,\n",
       "                                                                  0.06, 0.07,\n",
       "                                                                  0.08, 0.09,\n",
       "                                                                  0.1],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 5, 8, 13, 21,\n",
       "                                                             34, 55, 89, 144,\n",
       "                                                             233, 377],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 8, 13, 21,\n",
       "                                                              34, 55, 89, 144,\n",
       "                                                              233, 377],\n",
       "                                        &#x27;n_estimators&#x27;: range(1800, 2100, 10),\n",
       "                                        &#x27;oob_score&#x27;: [True, False],\n",
       "                                        &#x27;warm_start&#x27;: [True, False]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=ExtraTreesClassifier(), n_iter=100,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [1, 2, 5, 8, 13, 21, 34,\n",
       "                                                      53, 54, 55, 89, None],\n",
       "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         2, 5, 8, 13, 21, 34,\n",
       "                                                         None],\n",
       "                                        'max_leaf_nodes': [2, 5, 8, 13, 21, 34,\n",
       "                                                           55, 89, 144, 233,\n",
       "                                                           377, None],\n",
       "                                        'min_impurity_decrease': [0.0, 0.01,\n",
       "                                                                  0.02, 0.03,\n",
       "                                                                  0.04, 0.05,\n",
       "                                                                  0.06, 0.07,\n",
       "                                                                  0.08, 0.09,\n",
       "                                                                  0.1],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 8, 13, 21,\n",
       "                                                             34, 55, 89, 144,\n",
       "                                                             233, 377],\n",
       "                                        'min_samples_split': [2, 5, 8, 13, 21,\n",
       "                                                              34, 55, 89, 144,\n",
       "                                                              233, 377],\n",
       "                                        'n_estimators': range(1800, 2100, 10),\n",
       "                                        'oob_score': [True, False],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 100\n",
    "cv = 3\n",
    "\n",
    "extra_trees = ExtraTreesClassifier()\n",
    "\n",
    "extra_trees_randomized_search = RandomizedSearchCV(estimator=extra_trees, \n",
    "                                         param_distributions=extra_trees_parameter, n_iter=n_iter, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "extra_trees_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.773377\n",
      "Precision: 0.345479\n",
      "Recall: 0.621527\n",
      "F1 score: 0.444102\n",
      "AUC: 0.710396\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2oUlEQVR4nO3dd3xN9//A8de92YkkRkiCENTeu0ZpbUp3aSkxSr9mK11Wxajxq1KtUUXNUq1WVUspWoqqvUcU0aCCGElk3eTez++PU5eQkBs3OUnu+/l43If7+dxzzn3fe5Pct880KKUUQgghhBAOyKh3AEIIIYQQepFESAghhBAOSxIhIYQQQjgsSYSEEEII4bAkERJCCCGEw5JESAghhBAOSxIhIYQQQjgsZ70DyGkWi4V///0Xb29vDAaD3uEIIYQQIhOUUsTFxVG8eHGMRvu14zhcIvTvv/8SFBSkdxhCCCGEyILz589TsmRJu13P4RIhb29vQHsjfXx8dI5GCCGEEJkRGxtLUFCQ9XvcXhwuEbrdHebj4yOJkBBCCJHH2HtYiwyWFkIIIYTDkkRICCGEEA5LEiEhhBBCOCxJhIQQQgjhsCQREkIIIYTDkkRICCGEEA5LEiEhhBBCOCxJhIQQQgjhsCQREkIIIYTDkkRICCGEEA5LEiEhhBBCOCxdE6E//viDTp06Ubx4cQwGA6tXr37oOVu2bKFOnTq4ubnx2GOPsWjRomyPUwghhBD5k66JUHx8PDVr1mTWrFmZOj4iIoKnn36ap556ioMHD/LWW2/x+uuvs2HDhmyOVAghhBD5ka67z7dv35727dtn+vg5c+ZQpkwZpk6dCkDlypXZvn07n3zyCW3bts2uMIUQQohcTSlFYooZpcCiFApQSqu/u86iFCiwKFAo7V+lSEqxcCPBxO193ZX1utrjt+v+u4vCeifNsbcfu3P/Tny376PunG89TqU99t7nA0XCjeuP8hZlSNdEyFY7d+6kVatWaeratm3LW2+9leE5ycnJJCcnW8uxsbHZFZ4QQggBQKLJTExiCilmCylmLcmITUrFbFakWhSpFgupZsWxf2P492YSqRYLTkaDNWmx3JPEWNTtxEBpZQvsPHuNEgU9SLVYuByb/NCY8jKDsrB08VvZcu08lQhFRUXh7++fps7f35/Y2FgSExPx8PC475xJkyYxduzYnApRCCFEPpGcaiY51YLZrEixWDBbFDcTUthz7jqnr9xi19nrFPNxIznVwu6I6/gVcMWUaiE2KTXHYrx4M9Gm4w0GMBoMGND+xQBGAxgwkJhixt/HDU9XLTUwWE+6c99gMKR5zPDfubfv86DjDLcvl/Z4w12FtNdNe62NT4fAgjCbXm9m5KlEKCuGDx9OaGiotRwbG0tQUJCOEQkhhMhuZovicmwSCSYzEdHxpJotHL4Yg5erE6kWhfmu25mr8SSlmHFxMvB7+FXK+HkRER2fqecJvxxnvR99y3Tf4+4uRlycjLg6GbkWb6JqcR/cXZxwNhpwdtK+4G8mpFApwIcK/gXwdHXCYDBgNBi0BMVAmrLRYLirTnud5YoWwM3ZSDFvd1ydjdak4+6E5/Y5ecr+/XDlCrRrB0BsbDXGOXoiFBAQwOXLl9PUXb58GR8fn3RbgwDc3Nxwc3PLifCEEELYQYIp1dpdlGpWJKWYOXctARcnAylmRarZws3EFCKuxuPmYmTb39EUL+hOSqpi97nreLo6kWAyZ/n5M0qCXJwMOBkNJKVYqBTgTcUAb4IKeVKluA9uzkY8XJwI8HXHxcmIh6sTfgXkuydLLBb4+GMYNQoKFIDDh6FkyWx7ujyVCDVq1Ih169alqdu4cSONGjXSKSIhhBC2OHP1FmevxmNK1cbNnIuO59y1eMwWxe/hVynq7cbVONvHu9ydvNydBHm5OmFRWvdPndKFuHgjkUbliuBsNOBkNOL8X3ITn5xKqcKeFPV2w9lopJiPGx4uTpT3L4CL0YjRmMdaU/Kq8+chJAR+/10rP/kkZNDQYS+6JkK3bt3i9OnT1nJERAQHDx6kcOHClCpViuHDh3Px4kWWLFkCwP/+9z9mzpzJe++9R+/evfntt9/49ttvWbt2rV4vQQghHIpSitjEVJJTzSSmmIm8nkCqWXHkYgwuTka2n75KMW93TGYLKakW/jp7Db8CbliU4ty1hIde/+4kyK+AK85GIy7OWitMqtlCjZIFcXEy4Gw0kmqx4OpspFKADwCPFSuAq5MRF2cj5Yp64e+jtc6IPGLlSnjjDbhxAzw94bPPoHfvtIOPsoGuidDevXt56qmnrOXbY3lCQkJYtGgRly5dIjIy0vp4mTJlWLt2LUOHDuXTTz+lZMmSzJ8/X6bOCyGEnSil+DcmiURTKjtOX+NavIkDkTfY/88NvN1diIpNsvma6Q0ebhBcGFdnIylmC15uzhQv6E71Er4U8nSlXLEClC7sibMkMY7BYoHXX4eFC7Vy/fqwbBmUL58jT29Q6s4sfUcQGxuLr68vMTEx+Pj46B2OEELoSinFjtPX+HbveQ6cv8H565mfheTuYiQpxYKvhwvlixXgWryJJ8r7EZeUSs2Svjj/N0jYZLZQMcAbd2cnivm44e/jno2vSORJAwfCnDkwfDiEhYGLy32HZNf3d54aIySEEOLhlFIkmMxcuJFITGIKl2ISuRSTxMq95/Fyc8aiFKlmxbV4U4bjcZyNBgp5uRJ9K5nna5XA3dWJZuX9KO/vjb+PO17/zW4SIktSUyE2FgoX1spTpsBrr4EOY34lERJCiDzkwo0Ert0ycepyHNG3TOyOuIaXm/N/C/cpfjt5JUvXdXM28kT5orSp6k+H6oEUcJOvB5FNIiK0pMfFBTZvBicnbUyQThOf5CddCCFyoX+uxXM5NpnkVDOrD/zLL0cvZXlKeKUAb2ITU6hS3Bdvd2faVg2ggJszLk4GXJyNlPXzoqCnq51fgRD3UAq++krrBouLAx8fOHECqlXTNSxJhIQQIheIS0rh58OXmLbx1EOnjxsNULqIF9duJdOgTBH8fdyoHOhjnU3l4+FC/eBC+Hq4SPeVyB1u3oT+/WHFCq3cpImWFAUH6xkVIImQEELoIiYhhb3/XGf5rkh2RVznVnL62zJUCvDG3cWJVIuF0NYVqFbCl2LeMthY5CFbt0L37toaQU5OMGYMDBsGzrkjBckdUQghRD5nsSiW7fqHSb+cfGAX12PFCtCsfFEGtXiMwl7SXSXyOIsFhgzRkqBy5bRp8Q0b6h1VGpIICSGEnVksin+uJ/DnmWgu3EgkPCouw0HMnq5OvFCnBC/XDaJqcR9ZO0fkL0YjLFkCs2bBtGnalhm5jCRCQgjxiMwWxZAVB7h+y8Tpq7ceOMYnwMedj16qQc2SBfH1vH+tFCHyNKVg/ny4dQuGDtXqataEuXP1jesBJBESQogsunAjgc+3nGHZrsh0H/d2cyYhxUynGoGUKuxJ0/JFaVCmcA5HKUQOiY6Gvn1h9Wpt/E+bNlC1qt5RPZQkQkIIkQ6LRXHhRiKXYhI5deUWzkYDKWYLplQLW09dZdvf0fed4+5iZMardfBxd6ZaCV+8ZC0e4Sh+/RV69oRLl7T1gSZNgsqV9Y4qU+S3VAgh7nL6Shyh3x7i8IWYTJ/ToXoA77erROkiXtkYmRC5UFKSti3G9OlauXJlWL4catXSMyqbSCIkhBDA7+FXeHflIaJvme57rHQRT1JSLdQqVVDbDd3JiNlioVPN4rSs7K9DtELkAmYzNGsGe/Zo5YED4aOPtFWi8xBJhIQQDm3Pueu8PGfnffVDWpanf/NyeLg66RCVEHmAkxN06wbnzsGCBdCxo94RZYnsPi+EcDiXY5P4v/UnWbX/4n2PhTQqzQcdq8g0diHSExWlDYq+vS2GxQLXr4OfX7Y/tew+L4QQj+BqXDLbT19l7E/HuZmQct/jy15vSJPHsv+PuRB51k8/Qe/eULAgHDigrQlkNOZIEpSdJBESQuRLCaZU9v9zkz6L95Ccakn3mEoB3gxrX4nmFYrKnlxCZCQhAd55Bz7/XCsXL661CuXCxRGzQhIhIUS+ciPeRMjC3RnO+ipdxJMu9YN4o1k5nIyS/AjxQPv3a+OATp7Uym+/DRMmgJubvnHZkSRCQoh842RULO2mb0tTV9jLlceKFuDz1+pQpED++eMtRLayWODjj2HUKEhJgcBAbauMVq30jszuJBESQuR5p6/c4unPtqXpAmsQXJh5PerJNhZCZIXBAL//riVBzz8P8+ZBkSJ6R5UtJBESQuRZvxy5xMDl+7HcM/f1u/81ol6wbGUhhM1SU7XtMQwGWLgQ1q+HkBCtnE9JIiSEyDMiryVw5GIM3++/kO5u7i/XLcmE56vj6ixT34WwSVwcDBmiJTwLFmh1AQHathn5nCRCQohcLfpWMt/vu8CkX05meEzXhqX48NlqGGXwsxC2++svbUD02bPadPi3384Tm6XaiyRCQohcKcGUSo0xv5J6b78X0KhsEUxmC0NbVaBp+by9hokQuklNhYkTYdw4bbuMUqXgq68cKgkCSYSEELlQVEwSj0/anKbO38eNt1pV4NUGpXSKSoh8JCICXnsN/vxTK7/6KsyerS2W6GAkERJC5CpKKXot2mMthzQqzdhnq+kYkRD5jNkMbdvC33+Dj4+WAHXrpndUupERhUKIXOPizUTKDF/HiUuxAAxu8ZgkQULYm5MTTJ8OTZvCoUMOnQSBtAgJIXKRZ2Zst97v2TiYt9tU1DEaIfKRP/6AmBjo1Ekrd+gA7dvn62nxmSUtQkII3W37+yrBw9ZyLd4EQMtKxRjzjGMN2BQiW5hMMGIEPPkk9OgB58/feUySIEBahIQQOklKMdN70R7+PHMtTX2DMoX5smd9naISIh8JD9e6vfbt08ovvOCQg6EfRhIhIUSOO30ljlbT/rivfvxz1ej+eGkdIhIiH1EK5s+Ht97Sdo4vVEjbIuPFF/WOLFeSREgIkWMu3kzktfm7iIiOt9Y1CC7Mxy/XpFQRTx0jEyKfMJvh5Zfhhx+0cosWsHgxlCypb1y5mCRCQogc8fXuSIavOpKm7qMXa9C5fpBOEQmRDzk5QVAQuLhoiyWGhmqrRYsMSSIkhMg2qWYLX/xxlikbwtPUd21Yig+eroKHq5NOkQmRjyQlQWwsFCumlSdPhj59oEYNfePKIyQREkJki4zGAS3qVZ8nKxbTISIh8qFjx6BrV20Q9G+/aS1CHh6SBNlAEiEhhN0t/vMcYWuOWctli3ox8fnqNCxTGINM2RXi0SkFM2fCu+9CcjIULQpnzkCFCnpHludIIiSEsJvDF27S/6v9XLyZaK2b8lINXq4n44CEsJuoKOjVC9av18rt28PCheDvr29ceZQkQkKIRxablMKAr/az/XR0mvo9I1tR1NtNp6iEyId++gl694boaHB3hylTYOBAWRzxEUgiJITIsuvxJuqM33hf/VutyjPoqcdwdpLZKkLYTWoqjBypJUE1asDy5VBVVmB/VJIICSFslmgyM+O3v5m95Uya+kZli/Blz3p4usqfFiHsztkZli2DpUth/Hhwk9ZWe5C/VkKITFNKMXvLmfumw79SP4hJL1SXgdBC2JPFAlOnav++/75WV706fPSRvnHlM5IICSEyJcVsocsXO9kfedNa52w0sPJ/jahdqpB+gQmRH124ACEhd6bEP/ssVKqkd1T5kiRCQoiH2nE6mm7zd6Wp+3VoMyr4e+sUkRD52MqV8MYbcOMGeHrCp59CxYp6R5VvSSIkhHigE5di0yRBdUoV5Lv/NcZolG4wIewqLg7efFObCg9Qr542JkjWBspWkggJITL08YZwZv5+2lr+9JVaPFurhI4RCZFPpaZC48Zw9Kg2FX7ECAgL0/YME9lKEiEhxH1+P3mFXov2pKmb/EJ1SYKEyC7OztCvH3z8MXz1FTzxhN4ROQyDUkrpHUROio2NxdfXl5iYGHx8fPQOR4hcZdmufxj5w9H76pf3bUjjcn46RCREPhYRATExUKuWVlZK6x6T76Z0Zdf3t7QICSEA+PDn48zfHpGmbkynKoQ0DpZp8ULYk1La2J8BA7Q9wg4eBG9vrUtMkqAcJ4mQEIL6EzZxNS7ZWv6+f2PqlpYp8ULY3c2b0L8/rFihlWvU0FqBvGUGpl4kERLCgSWlmOk0Y3uaJOjY2LZ4ucmfBiHs7o8/oHt3iIzU1gYaMwaGDdPGBwndyLsvhIMa//NxvrynK+zImDaSBAlhb6mpMHo0TJ6sdYuVK6d1jTVsqHdkAkmEhHAoSimW7PyHsDXH0tTLHmFCZCMnJzh0SEuCeveG6dOlKywXkb96QjiI01fiaDXtj/vqD41ug6+nrFUihF0pBSaTtjGqwaAtkrh9O7zwgt6RiXtIIiSEA7BYVJokqKCnC590rsVTlYrpGJUQ+dS1a9C3r9bqs3ixVlesmCRBuZQkQkI4gE4zt1vvP1erONNfqa1jNELkYxs3apulXrqkrQo9cqRskZHLGfUOQAiRvTrP2cmxf2MBKO7rLkmQENkhKQlCQ6FNGy0JqlwZdu2SJCgPkBYhIfKpff9c58XPd1rL3m7O/Dm8pY4RCZFPHTsGXbvC4cNaecAAmDJF2zle5HqSCAmRz1gsit6L97Al/Kq1zsvViUNhbXSMSoh8KjUVOnaEc+e0VaIXLNDKIs+QREiIfCTRZKby6PVp6no2DmbMM1V1ikiIfM7ZGT7/HGbM0JIgf3+9IxI2kkRIiHxi+qZTTN/0d5q6vye0x8VJhgIKYVc//6xNjb89C6xdO2jbVpsmL/IcSYSEyAeGrzrM17vPW8ttq/rzRfd6OkYkRD6UkADvvKO1APn6Qr16UKqU9pgkQXmW7v9VnDVrFsHBwbi7u9OwYUN27979wOOnT59OxYoV8fDwICgoiKFDh5KUlJRD0QqRuySlmHl+9o40SdCm0GaSBAlhb/v3Q926WhIE0KePdIPlE7q2CH3zzTeEhoYyZ84cGjZsyPTp02nbti3h4eEUK3b/Qm/Lly9n2LBhLFiwgMaNG3Pq1Cl69uyJwWBg2rRpOrwCIfShlGLSLyeZ+8dZa13JQh5sfrs5bs5OOkYmRD5jscDUqdp6QCkpEBioLZLYurXekQk7MSillF5P3rBhQ+rXr8/MmTMBsFgsBAUFMXjwYIYNG3bf8YMGDeLEiRNs3rzZWvf222+za9cutm/fft/xAMnJySQn39lZOzY2lqCgIGJiYvDx8bHzKxIieymleHvlIVbtv5imvlXlYszqVkeSICHsKSUF2reH2985zz8Pc+eCn5++cTmo2NhYfH197f79rVvXmMlkYt++fbRq1epOMEYjrVq1YufOneme07hxY/bt22ftPjt79izr1q2jQ4cOGT7PpEmT8PX1td6CgoLs+0KEyCHb/46mzPB19yVBS/s0YH5IfUmChLA3FxeoXl1bD2jePPj+e0mC8iHdusaio6Mxm83439PH6u/vz8mTJ9M9p2vXrkRHR9O0aVOUUqSmpvK///2PESNGZPg8w4cPJzQ01Fq+3SIkRF6RlGLmzRUH2HDscpr6Hwc2oWZQQX2CEiK/iovTbsWLa+VJk2DgQHjsMX3jEtlG98HSttiyZQsTJ05k9uzZ7N+/n1WrVrF27VrGjx+f4Tlubm74+PikuQmRV8QlpVDpg/VpkqCpL9fk3OSnJQkSwt7++gtq14bOnbWFEgHc3SUJyud0axHy8/PDycmJy5fT/i/38uXLBAQEpHvOBx98QPfu3Xn99dcBqF69OvHx8fTr14+RI0diNOapvE6IB1qy8xyjfzxmLdctXYhlrzfE3UW6wISwq9RUmDgRxo0Ds1kbG3T+PJQpo3dkIgfoljm4urpSt27dNAOfLRYLmzdvplGjRumek5CQcF+y4+SkfSnoOOZbCLsb99PxNEnQS3VL8n3/xpIECWFvERHQvDmEhWlJ0KuvwqFDkgQ5EF2nz4eGhhISEkK9evVo0KAB06dPJz4+nl69egHQo0cPSpQowaRJkwDo1KkT06ZNo3bt2jRs2JDTp0/zwQcf0KlTJ2tCJEReN/ePMyzYEWEtbwptxmPFvHWMSIh8SClYtkzbIDUuDry9tTWCunXTOzKRw3RNhLp06cLVq1cZPXo0UVFR1KpVi/Xr11sHUEdGRqZpARo1ahQGg4FRo0Zx8eJFihYtSqdOnZgwYYJeL0EIu7l2K5m6H25KUxf+YTuZDSZEdkhNhY8/1pKgJk1g6VJpBXJQuq4jpIfsWodAiEeRYrZQfuQvaep2j2hJMR93nSISwgEcPw6rVsGwYdrmqSJXy67vb/nkhcgF2n7yh/V+q8r+zOtRF4PsXSSE/aSkwJgx4OEBo0ZpdVWqaDfh0CQREkJHPx36l/e+O0xiihmAAB935ofIPmFC2NWpU9rYn717wclJGxBdrpzeUYlcQhIhIXSglOKlOTvZ98+NNPUbQ5vpFJEQ+ZBSMH8+vPWWtnN8oULaCtGSBIm7SCIkRA6LiI7nqY+3pKmb9EJ1utQLwmiU7jAh7CI6Gvr2hdWrtXKLFtpmqSVL6hqWyH0kERIiB/15Jpqu83ZZy2X8vFg35Ak8XGVmmBB2k5ICjz8OZ85o+4VNmgRDh4IsuivSIYmQEDlAKcXri/ey+eQVa93rTcsw8unKMihaCHtzcYHQUJg5U1srqHZtvSMSuZhMnxcim12PN1Fn/MY0deOfrUr3RsH6BCREfnT0KCQmQv36WlkpSErSZomJfEGmzwuRB237+yrdv9xtLZcr6sWqAU3w9XDRMSoh8hGltJafd9+FwEBtewwfHzAYJAkSmSKJkBDZwGxRPD5pM1fjkq11n75Si2drldAxKiHymago6NUL1q/XypUrg8mkb0wiz5GRY0LYWaLJTLkR69IkQR+/XFOSICHs6eefoUYNLQlyd4cZM2DtWvDz0zsykcdIi5AQdnQrOZVqYRusZb8Cruwe0UqmxQthLykp8Oab2gapoCVDy5dD1ar6xiXyLGkREsJO9v1zI00S9GqDUuwd1VqSICHsydkZLl7U7r/9NuzeLUmQeCTSIiTEI1p/9BJDvj6IyWyx1r1UtySTXqiuY1RC5CMWizYDzNNTGwQ9fz4cPgwtW+odmcgHJBESIotSzRbeXnmIHw/+m6Z+WueavFBHVq8Vwi7On4eQECheHL76SqsrWlSSIGE3kggJkUXvfXc4TRL08+CmVC3uIwskCmEvK1dCv35w86bWGhQRAWXK6B2VyGdkjJAQNkpKMdNjwW5WHbhorftzWAuqlfCVJEgIe4iLg549oXNnLQmqXx8OHpQkSGQLaRESwgYbj1+m75K9aerCP2yHm7PsFSaEXfz1F3TrBmfPanuDDR8OYWHathlCZANJhITIpOmbTjF909/W8hPl/ZjZtY4kQULYi8mktQKdPw+lSmljgp54Qu+oRD4niZAQD5FgSqXTjO2cuRpvrZvbvS5tqgboGJUQ+ZCrK3z5JSxaBLNmQcGCekckHIAkQkI8wJW4JBpM2Gwtl/Hz4suQepQtWkDHqITIJ5TSWn1cXOCVV7S61q21mxA5RBIhIR7go/Xh1vs1gwryQ//GskCiEPZw8yb07w8rVoC3NzRurHWHCZHDJBESIh1KKQYtP8DaI5cAeKFOCaZ1rqVvUELkF1u3Qvfu2lggJyd47z1tnSAhdCCJkBD3iL6VzLMzd3DxZqK1LqyjLOEvxCMzmWDMGJg8WesWK1cOli2Dhg31jkw4MEmEhLiLKdXCU1O2EJecCkBRbze2v/+UzAwT4lElJ2szwPbs0cq9e8Onn0IBGW8n9CWJkBD/sVgUlT74BYvSyrJVhhB25OYGzZrB6dMwbx68+KLeEQkByMrSQgBaEtRsyu/WJOjxsoUlCRLiUUVHa+OAbpswAY4ckSRI5CqSCAmHN/ePM5QdsY4LN7QxQQE+7izpLWMWhHgkv/4K1atDly6QqnU14+YGJUroG5cQ95CuMeGw4pNT6bN4D3+dvW6te6F2CaZ2ril7hgmRVUlJ2rYY06dr5UKFICoKSkoLq8idJBESDmnSLyf4YutZa7mQpwtb3nkKX0/Zz0iILDt6FLp21bq/AAYMgClTtJ3jhcilHikRSkpKwt3d3V6xCJHtlFL0WLCbbX9HW+s6VA9gxqt1cJKFEoXIGqVg5kx4911tdljRorBgAXTsqHdkQjyUzWOELBYL48ePp0SJEhQoUICzZ7X/VX/wwQd8+eWXdg9QCHt665uDaZKgPSNbMbtbXUmChHgUKSmwcKGWBLVvr7UISRIk8gibE6EPP/yQRYsW8dFHH+Hq6mqtr1atGvPnz7drcELY0+RfTvLjwX8B8PdxI2JSB4p6u+kclRB5mPpvmqWrKyxfDjNmwNq14O+vb1xC2MDmRGjJkiXMnTuXbt264eR0Z5G5mjVrcvLkSbsGJ4S9fLv3PHO2ngEgqLAH295rIQOihciqhARtn7AxY+7UVaoEgwaB/F6JPMbmMUIXL17kscceu6/eYrGQkpJil6CEsKefD//Le98dBqB2qYJ897/G0hUmRFbt3w/dusHJk+DsrK0QXbq03lEJkWU2J0JVqlRh27ZtlL7nB/+7776jdu3adgtMiEd19GIMHWdsT1O3ot/jkgQJkRUWC3z8MYwapY0JCgyExYslCRJ5ns2J0OjRowkJCeHixYtYLBZWrVpFeHg4S5Ys4eeff86OGIWw2dw/zjBxXdqu2p8HN5U9w4TIivPnISQEfv9dKz//vLZNRpEi+sYlhB0YlLo92i3ztm3bxrhx4zh06BC3bt2iTp06jB49mjZt2mRHjHYVGxuLr68vMTEx+Pj46B2OsLO5f5zh+30XCb8cZ62b+nJNXqwri7kJkSXJyfDYY3DhgrYe0Gefad1hMhZI5LDs+v7OUiKUl0kilH+1m/4HJ6Pi0tT9NbwlAb6y1pUQj2TuXK0FaNkyqFBB72iEg8qu72+bZ42VLVuWa9eu3Vd/8+ZNypYta5eghLDFreRUqodtSJMELexZn/AP20kSJERW/PUX7Nx5p9y3L/z5pyRBIl+yeYzQuXPnMJvN99UnJydz8eJFuwQlRGalNyD69IT2ODvJfsJC2Cw1FSZOhHHjtM1RDx2CggW1bjAX2X5G5E+ZToTWrFljvb9hwwZ8fX2tZbPZzObNmwkODrZrcEI8yC9HLtF/2X5ruWWlYsx+rY4kQUJkRUQEvPaa1vID0KSJjAMSDiHTidBzzz0HgMFgICQkJM1jLi4uBAcHM3XqVLsGJ0RG9py7niYJkgHRQmSRUvDVVzBwIMTFgY8PzJ6trRUkhAPIdCJksVgAKFOmDHv27MHPzy/bghLiQT7eEM7M309by2uHNKVqcd8HnCGESFdyMvTsCStWaOUmTbSkSFr3hQOxeYxQREREdsQhxEP9fTmOKRvC+fX4ZWvdstcbShIkRFa5ukJSEjg5adtlDBumrRYthAPJ0k98fHw8W7duJTIyEpPJlOaxIUOG2CUwIe7255lous7blaZu14iW+PvIrDAhbGIyaS1B3t7aGKB58+DsWWjQQO/IhNCFzYnQgQMH6NChAwkJCcTHx1O4cGGio6Px9PSkWLFikggJu7JYFCN+OMKKPeetda2r+DO6YxVJgoSw1alT2tifcuXg66+1RMjPT7sJ4aBsToSGDh1Kp06dmDNnDr6+vvz111+4uLjw2muv8eabb2ZHjMJB/XX2Gq/M/StN3dd9H6dROVnWXwibKAXz58Nbb2k7x585o60UHRSkd2RC6M7mecYHDx7k7bffxmg04uTkRHJyMkFBQXz00UeMGDEiO2IUDujjDeH3JUF/DW8pSZAQtoqOhhdegH79tCSoRQs4fFiSICH+Y3Mi5OLigtGonVasWDEiIyMB8PX15fz58w86VYhM2RJ+Jc2ssGmda3Ju8tOySrQQttq4EWrUgNWrtQURp0zR6krKUhNC3GZz11jt2rXZs2cP5cuXp3nz5owePZro6GiWLl1KtWrVsiNG4UCSUsz0XLjHWt47qhV+Bdx0jEiIPCopSdsc9dIlqFxZ2yesdm29oxIi17G5RWjixIkEBgYCMGHCBAoVKkT//v25evUqX3zxhd0DFI4j0WSm0gfrreWfBjWVJEiIrHJ3h8WLYcAA2LtXkiAhMiC7z4tc4e/LcbT+5A9rufvjpRn/nLQwCpFpSsHMmVCokLZVhhD5TK7ZfT4j+/fvp2PHjva6nHAgC7ZHpEmCXm1QSpIgIWwRFQUdOsCQIdC/vzYjTAiRKTYlQhs2bOCdd95hxIgRnD17FoCTJ0/y3HPPUb9+fes2HEJk1sbjlxn383Fr+Y1mZZn0QnUdIxIij/npJ6heHdav17rDJk3Sdo4XQmRKpgdLf/nll/Tt25fChQtz48YN5s+fz7Rp0xg8eDBdunTh6NGjVK5cOTtjFflM6DcHWXXgorV8bGxbvNxkeX8hMiUhAd55Bz7/XCvXqAHLl0PVqvrGJUQek+kWoU8//ZT/+7//Izo6mm+//Zbo6Ghmz57NkSNHmDNnjiRBwia/HotKkwR9+0YjSYKEyKzERKhf/04S9PbbsHu3JEFCZEGmv3nOnDnDyy+/DMALL7yAs7MzU6ZMoaSsRyFstON0NP2W7rOWj4xpg7e7i44RCZHHeHhAx45w44Y2M6x1a70jEiLPynQilJiYiKenJwAGgwE3NzfrNHohMsNiUQxecYC1hy9Z65b0biBJkBCZceECpKRAmTJaefx4eO89KCKrrQvxKGzqi5g/fz4FChQAIDU1lUWLFuF3z2Z9sumqSM/RizF0nLE9TZ3sGyZEJq1cCW+8ARUqwLZt2irRrq6SBAlhB5leRyg4OBiDwfDgixkM1tlkmTVr1iymTJlCVFQUNWvWZMaMGTRo0CDD42/evMnIkSNZtWoV169fp3Tp0kyfPp0OHTpk6vlkHaGcdyU2iQYTN1vLVQJ9+GlwU5yMD/55EsLhxcXBm2/CwoVauV49+Pln8PfXNy4hdJBd39+ZbhE6d+6c3Z70tm+++YbQ0FDmzJlDw4YNmT59Om3btiU8PJxixYrdd7zJZKJ169YUK1aM7777jhIlSvDPP/9QsGBBu8cmHl2q2cKo1UdZsefOHnRTXqrBy/Vks0chHuqvv7SFEc+cAYMBRoyAsDCtNUgIYTe6rizdsGFD6tevz8yZMwGwWCwEBQUxePBghg0bdt/xc+bMYcqUKZw8eRKXLP4xkBahnGG2KMqNWJembkSHSvRrVk6niITII1JTtbWAxo4FsxlKlYKlS6FZM70jE0JXuX5laVuZTCb27dtHq1at7gRjNNKqVSt27tyZ7jlr1qyhUaNGDBw4EH9/f6pVq8bEiRMxm80ZPk9ycjKxsbFpbiJ7xSWl0PqTrdZyYS9Xdg5vIUmQEJlhscCPP2pJ0KuvwqFDkgQJkY10W7glOjoas9mM/z193f7+/pw8eTLdc86ePctvv/1Gt27dWLduHadPn2bAgAGkpKQQFhaW7jmTJk1i7Nixdo9fpE8pRfUxv1rLAT7u/DWipY4RCZEHKKXdjEZtEPSyZbBnj+wZJkQO0K1FKCssFgvFihVj7ty51K1bly5dujBy5EjmzJmT4TnDhw8nJibGejt//nyGx4pHY7EoXvj8T2u5YZnCbHq7uY4RCZEH3LwJXbvC6NF36ipWlCRIiByiW4uQn58fTk5OXL58OU395cuXCQgISPecwMBAXFxccHJystZVrlyZqKgoTCYTrq6u953j5uaGm5ubfYMX6Sp715igtlX9+aJ7PR2jESIP+OMP6N4dIiO1lqD+/WWfMCFyWJZahM6cOcOoUaN49dVXuXLlCgC//PILx44dy/Q1XF1dqVu3Lps335lWbbFY2Lx5M40aNUr3nCZNmnD69Ok0m7ueOnWKwMDAdJMgkTMsFkXZ4Wut5Y41AiUJEuJBTCZtFtiTT2pJULlyWlIkSZAQOc7mRGjr1q1Ur16dXbt2sWrVKm7dugXAoUOHMhynk5HQ0FDmzZvH4sWLOXHiBP379yc+Pp5evXoB0KNHD4YPH249vn///ly/fp0333yTU6dOsXbtWiZOnMjAgQNtfRnCTpJSzJQdsQ7LXXMPZ3ato19AQuR2p05BkybazDCloHdvOHAAGjbUOzIhHJLNXWPDhg3jww8/JDQ0FG9vb2t9ixYtrNPgM6tLly5cvXqV0aNHExUVRa1atVi/fr11AHVkZCRG451cLSgoiA0bNjB06FBq1KhBiRIlePPNN3n//fdtfRnCDuKTU6katsFarlOqIKsGNNExIiFyucREeOIJuHIFChWCuXPhpZf0jkoIh2bzOkIFChTgyJEjlClTBm9vbw4dOkTZsmU5d+4clSpVIikpKbtitQtZR8g+YpNSqHHX7LBKAd6sf0um+ArxUF9+CcuXa5ulyqbVQmRarllHqGDBgly6dOm++gMHDlBC+rcdxt1JUPtqAZIECZGRjRth+1377PXurdVJEiRErmBzIvTKK6/w/vvvExUVhcFgwGKxsGPHDt555x169OiRHTGKXOadlYes92uU9OXz1+rqGI0QuVRSEoSGQps22vT4Gze0eoNBWy9ICJEr2PzbOHHiRCpVqkRQUBC3bt2iSpUqNGvWjMaNGzNq1KjsiFHkIrsjrvPdvgsAeLo6sWZQU50jEiIXOnZMG/z8ySdauVMnkGU8hMiVsrzXWGRkJEePHuXWrVvUrl2b8uXL2zu2bCFjhLJu299X6f7lbgDKFvVi09DmGGUHeSHuUApmzoR334XkZChaFBYsgI4d9Y5MiDxP993nb9u+fTtNmzalVKlSlCpVym6BiNztSmySNQkC+KpPQ0mChLhbQgK8+CKsX6+V27eHhQvhnm2EhBC5i81dYy1atKBMmTKMGDGC48ePZ0dMIpc5dTmOBhPvLHy5cWgzihf00DEiIXIhDw8oUEDrApsxA9aulSRIiDzA5kTo33//5e2332br1q1Uq1aNWrVqMWXKFC5cuJAd8QmdRd9Kps0nf1jL/Z8sR3l/7wecIYQDSUiAmBjtvsEAX3wB+/bBoEFaWQiR69mcCPn5+TFo0CB27NjBmTNnePnll1m8eDHBwcG0aNEiO2IUOur/1T7r/Tmv1eX9dpV0jEaIXOTAAahbF/r21cYGARQuDFWr6huXEMImjzSHs0yZMgwbNozJkydTvXp1tm7daq+4hM4sFkXraVvZc06b8hvaugLtqqW/Ga4QDsVigSlTtFlhJ09qawRFRekdlRAii7KcCO3YsYMBAwYQGBhI165dqVatGmvXrn34iSJPePLjLfx9RdtHrlHZIgxpmTdmBQqRrS5cgNat4b33ICUFnn8eDh+GwEC9IxNCZJHNs8aGDx/OihUr+Pfff2ndujWffvopzz77LJ6entkRn9DB1lNXibyeYC0v7t1Ax2iEyCW++w769dMWRvT0hE8/hT59ZCyQEHmczYnQH3/8wbvvvkvnzp3x8/PLjpiEjraeukrIgjvT5M9O7CDT5IVISIChQ7UkqF49WLYMKlTQOyohhB3YnAjt2LEjO+IQucDec9fTJEELe9aXJEgI0FqAliyBTZtgzBhwcdE7IiGEnWQqEVqzZg3t27fHxcWFNWvWPPDYZ555xi6BiZx1Pd7ES3N2WsuzutbhqUrFdIxICB2lpsKkSRAUBD17anVPPaXdhBD5Sqa22DAajURFRVGsWDGMD9gs0GAwYDab7RqgvckWG+mrNe5XbiakAPBeu4oMePIxnSMSQicREdC9O+zYAV5e8PffMhhaiFxA1y02LBZLuvdF/rDn3HVrEtSpZnFJgoRjUkob+zNgAMTFgY8PzJ4tSZAQ+ZzN0+eXLFlCcnLyffUmk4klS5bYJSiRc67EJvHyXV1iU16qoWM0Qujk5k3o1k1rCYqLgyZN4NAhrU4Ika/ZnAj16tWLmNtLyt8lLi6OXr162SUokTMSTKk0m/K7tbyoV33cXZx0jEgIHSQkQJ068PXX4OQE48fDli0QHKx3ZEKIHGBzIqSUwpDOuhkXLlzA19fXLkGJ7KeUosroDSSlaF2dIzpU4smKMjhaOCBPT+jSBcqV08YFjRoFzjZPqBVC5FGZ/m2vXbs2BoMBg8FAy5Ytcb7rD4XZbCYiIoJ27dplS5DCvuKSUqg+5ldruV+zsvRrVk7HiITIYadOgdEIj/03Hm7sWBgxArxlQ2EhHE2mE6HnnnsOgIMHD9K2bVsKFChgfczV1ZXg4GBefPFFuwco7MtsUWmSoAZlCjOiQ2UdIxIiBykF8+fDW29BlSrw55/amkCurtpNCOFwMp0IhYWFARAcHEyXLl1wd3fPtqBE9nn724PW+6M7VqF30zL6BSNEToqO1naKX71aK/v4QGwsFCmia1hCCH3ZPEYoJCREkqA8SinF6oP/AvBK/SBJgoTj+PVXqFFDS4JcXODjj2HjRkmChBCZaxEqXLgwp06dws/Pj0KFCqU7WPq269ev2y04YT+JJjOVR6+3lt9rV0nHaITIIcnJMHw4fPKJVq5cGZYvh1q1dA1LCJF7ZCoR+uSTT/D+bxDhJ5988sBESOQ+py7H0eaTP6zl5hWKUthLxkMIB2A0wvbt2v2BA+Gjj7RZYkII8Z9MbbGRnzjaFhvxyalUDdtgLTcqW4TlfRtKMivyL6XAbL4zBf7vvyE8HDp21DcuIcQjya7vb5vHCO3fv58jR45Yyz/++CPPPfccI0aMwGQy2S0w8eiUUmmSoFFPV+brfo9LEiTyr6go6NBBWwvotvLlJQkSQmTI5kTojTfe4NSpUwCcPXuWLl264OnpycqVK3nvvffsHqDIGrNFUWb4ujR1rz9RVqdohMgBP/0E1avD+vUwYwZcvqx3REKIPMDmROjUqVPU+m+g4cqVK2nevDnLly9n0aJFfP/99/aOT2TRN3vOpymfndhBp0iEyGYJCdC/PzzzjDZFvkYN2L0b/P31jkwIkQdkaYuN2zvQb9q0iQ4dtC/YoKAgoqOj7RudyJL45FRG/KB1XzZ9zI9zk5/GaJTuMJEP7d+v7RM2Z45WfvttLQmqWlXfuIQQeYbNG+rUq1ePDz/8kFatWrF161Y+//xzACIiIvCX/4HlCnePC/rwuWo6RiJENrp1C1q3huvXoXhxWLwYWrXSOyohRB5jc4vQ9OnT2b9/P4MGDWLkyJE89t9ePd999x2NGze2e4DCNsNX3RnI/kbzsgT7eekYjRDZqEABmDoVnn8eDh+WJEgIkSV2mz6flJSEk5MTLi4u9rhctsnP0+d/D79Cr4V7rOVzk5/WMRohssHKlVC0KDz5pFa+/edLZkIKke9l1/e3zV1jt+3bt48TJ04AUKVKFerUqWO3oITtUs2WNEnQyfHtdIxGCDuLi4MhQ2DRIihRQmsBKlxYEiAhxCOzORG6cuUKXbp0YevWrRQsWBCAmzdv8tRTT7FixQqKFi1q7xhFJjSa/Jv1/qoBjXF3cdIxGiHs6K+/oFs3OHtWS3x69oT/VroXQohHZfMYocGDB3Pr1i2OHTvG9evXuX79OkePHiU2NpYhQ4ZkR4ziIX47eZmrcckABPq6U6dUIZ0jEsIOUlNh3Dho2lRLgkqVgq1b4cMPtY1ThRDCDmweI+Tr68umTZuoX79+mvrdu3fTpk0bbt68ac/47C6/jRG6GpdM/QmbAHB1NnLqw/Y6RySEHdy6BW3bwp9/auWuXWHWLPivFVoI4XhyzRghi8WS7oBoFxcX6/pCImeYLcqaBAHMeU3GaYl8wssLgoLAxwdmz9a6xoQQIhvY3DXWokUL3nzzTf79919r3cWLFxk6dCgtW7a0a3AiY4kmM+VG3NlC4+nqgbSoJOs4iTzs5k1tTSDQxgJ9/jkcPChJkBAiW9mcCM2cOZPY2FiCg4MpV64c5cqVo0yZMsTGxjJjxozsiFGkY8K649b7wUU8mdVNWoNEHrZ1q7Y1xuuv35kSX6gQlCmjb1xCiHzP5q6xoKAg9u/fz+bNm63T5ytXrkwrWcwsx0ReS+CrvyIBqFnSlx8HNdU5IiGyyGSCMWNg8mQtAXJ1hatXoVgxvSMTQjgImxKhb775hjVr1mAymWjZsiWDBw/OrrhEBpRSvPHVPmv5i+71dIxGiEcQHq51e+377+e5d2+YPl2mxgshclSmE6HPP/+cgQMHUr58eTw8PFi1ahVnzpxhypQp2RmfuEevRXs4cSkWgInPVyfA113niISwkVIwfz689Za2c3yhQjBvHrz4ot6RCSEcUKbHCM2cOZOwsDDCw8M5ePAgixcvZvbs2dkZm7jHhmNRbAm/CsAT5f3o2rCUzhEJkQXx8dpaQAkJ0KKFtkq0JEFCCJ1keh0hDw8PTpw4QXBwMKBNo/fw8ODcuXMEBgZmZ4x2lVfXEUpKMVPpg/XW8qkP2+PqbPNYdyFyh23bYNcuCA0Fo/wcCyEeTvd1hJKTk/HyurOTudFoxNXVlcTERLsFI9KXnGqmatgGa3n3yJaSBIm8IykJRoyAypWhb1+t7okntJsQQujMpsHSH3zwAZ6entayyWRiwoQJ+Pr6WuumTZtmv+gEADN/O43ZojXc9WoSTDFvGRck8oijR7VVoY8c0RZJfO45bfd4IYTIJTKdCDVr1ozw8PA0dY0bN+bs2bPWskF2gra7Q+dvMuO30wB0rBFIWKeqOkckRCYoBTNnwrvvQnKylvwsWCBJkBAi18l0IrRly5ZsDENk5NlZO6z3J79YQ8dIhMikqCjo1QvW/zemrX17WLgQ/GXlcyFE7mPzgooi5zw/+04S9PHLNSngJh+XyOXi4qB2bS0ZcneHKVNg4EBtywwhhMiFZMRtLnX831gORN4EIMDHnZfqltQ3ICEyw9tb2yajRg3YuxcGDZIkSAiRq2V6+nx+kRemz2//O5rXvtxlLZ+e0B5nJ8lZRS514AB4ekLFilo5JQUsFnBz0zcuIUS+kl3f3/LtmsvciDelSYK+6fe4JEEid7JYtK6vhg21mWEmk1bv4iJJkBAiz5BBJ7nM2ysPWe9/3fdxGpYtomM0QmTgwgUICYHfftPKpUtDYqK2aaoQQuQhWWpq2LZtG6+99hqNGjXi4sWLACxdupTt27fbNThHczk2id9OXgGgQXBhGpWTJEjkQitXamOAfvtN6xKbNw++/x7uWk9MCCHyCpsToe+//562bdvi4eHBgQMHSE5OBiAmJoaJEyfaPUBHYUq10HDiZmt5Qa/6OkYjRDoSErQd4jt3hhs3oF49bXzQ66/LgGghRJ5lcyL04YcfMmfOHObNm4eLi4u1vkmTJuzfv9+uwTmSrvP+st4f92xVmSovch9XVzhxQkt6Ro6EP/+EChX0jkoIIR6Jzd+24eHhNGvW7L56X19fbt68aY+YHE5sUgp7/7kBQKUAb3o0CtY3ICFuS03VBkW7uoKzM3z1FVy8COn8DRBCiLzI5hahgIAATp8+fV/99u3bKVu2rF2CcjTTfj1lvf9d/8Y6RiLEXSIioHlzGDXqTl25cpIECSHyFZsTob59+/Lmm2+ya9cuDAYD//77L8uWLeOdd96hf//+WQpi1qxZBAcH4+7uTsOGDdm9e3emzluxYgUGg4HnnnsuS8+bW2w9dRWAIl6u0iUm9KcULF0KNWtq3V/z5kF0tN5RCSFEtrD5W3fYsGFYLBZatmxJQkICzZo1w83NjXfeeYfBgwfbHMA333xDaGgoc+bMoWHDhkyfPp22bdsSHh5OsWLFMjzv3LlzvPPOOzzxxBM2P2ducupyHBHR8QB83e9xnaMRDu/mTejfH1as0MpNmmjdYX5+uoYlhBDZJcsrS5tMJk6fPs2tW7eoUqUKBQoUyFIADRs2pH79+sycORMAi8VCUFAQgwcPZtiwYemeYzabadasGb1792bbtm3cvHmT1atXZ+r5ctPK0kopygxfB4Crs5FTH7bXNR7h4LZuhe7d4fx5cHKCMWNg2DBtbJAQQugsu76/s/wXztXVlSpVqjzSk5tMJvbt28fw4cOtdUajkVatWrFz584Mzxs3bhzFihWjT58+bNu27YHPkZycbJ3iD9obmVv0WHCnC/C5WsV1jEQ4vJgYePZZ7d9y5WDZMm3FaCGEyOdsToSeeuopDA9YM+S32yvNZkJ0dDRmsxl/f/809f7+/pw8eTLdc7Zv386XX37JwYMHM/UckyZNYuzYsZmOKackp5rZ9vedcRf/92INHaMRDs/XFz77TGsVmj5d2zxVCCEcgM2DpWvVqkXNmjWttypVqmAymdi/fz/Vq1fPjhit4uLi6N69O/PmzcMvk2MWhg8fTkxMjPV2/vz5bI0xs1pP+8N6f92QJx6YXAphd0ppg6A3bbpT16MHfPmlJEFCCIdic4vQJ598km79mDFjuHXrlk3X8vPzw8nJicuXL6epv3z5MgEBAfcdf+bMGc6dO0enTp2sdRaLBQBnZ2fCw8MpV65cmnPc3Nxwy2UbQH6/7wKR1xMAcHM2UqW4vmOVhIOJjoa+fWH1aggMhGPHoFAhvaMSQghd2G1b89dee40FCxbYdI6rqyt169Zl8+Y7W0tYLBY2b95Mo0aN7ju+UqVKHDlyhIMHD1pvzzzzDE899RQHDx4kKCjokV9HTvhog9bt5+3mzIlx7XSORjiUX3/V9glbvVrbJT40VPYIE0I4NLtNB9m5cyfu7u42nxcaGkpISAj16tWjQYMGTJ8+nfj4eHr16gVAjx49KFGiBJMmTcLd3Z1q1aqlOb9gwYIA99XnVpdiErkcqw3entWtDkajdImJHJCUBMOHa+N/ACpX1gZE166ta1hCCKE3mxOhF154IU1ZKcWlS5fYu3cvH3zwgc0BdOnShatXrzJ69GiioqKoVasW69evtw6gjoyMxGi0W8OV7iasPWG931h2lxc5ISYGnngCjhzRygMGwJQp2s7xQgjh4GxeR+h2S81tRqORokWL0qJFC9q0aWPX4LKDnusInb+ewBMf/Q7AqKcr8/oTsiWJyAFKQbdu2sDoBQugY0e9IxJCCJvlinWEzGYzvXr1onr16hSSwZU2G/fzcev97o1K6xiJyPeiorQxQEWKaLvFz54Nyclwz1IVQgjh6Gzqc3JycqJNmzayy3wWXYpJBKBjjUDcnJ10jkbkWz/9BNWrQ58+WmsQQMGCkgQJIUQ6bB58U61aNc6ePZsdseRrG45FcfSitqr1wKce0zkakS8lJGjjf555RpsiHxEBN27oHZUQQuRqNidCH374Ie+88w4///wzly5dIjY2Ns1NpO+Npfus9ysFyIJ1ws7274e6deHzz7VyaCjs3g2FC+sblxBC5HKZHiM0btw43n77bTp06ADAM888k2Y1ZKUUBoMBs9ls/yjzuNNX7iw0Oax9JVlFWtiPxQIffwyjRkFKirZA4uLF0Lq13pEJIUSekOlZY05OTly6dIkTJ0488LjmzZvbJbDsosessRYfb+FsdDwAZyd2kLWDhP3ExmoLJP7zDzz/vLZtRhFZlkEIkf/oPmvsdr6U2xOd3CY8Ks6aBL3RrKwkQcI+lNJmg/n4aAsjnjihDY6W1kYhhLCJTWOEpEvHdqNWH7Hef79dJR0jEflCXBz06gVz596pa9IEXn9dkiAhhMgCm9YRqlChwkOToevXrz9SQPnJxZuJ7Dmnzdr5oGMVaQ0Sj+avv7SFEc+ehe++g5dflsHQQgjxiGxKhMaOHYuvbNCYabN+Pw1AUW83ejcJ1jcYkXelpsLEiTBuHJjNUKoULF0qSZAQQtiBTYnQK6+8QrFixbIrlnwlwZTK8l2RABQv6CHdiiJrIiLgtdfgzz+18quvaqtE/7fZsBBCiEeT6URIvshtM+TrA9b7E5+vpmMkIs+6eVNbG+jGDfD21tYI6tZN76iEECJfsXnWmHi4VLOFLeFXAWhV2Z+qxaU7UWRBwYIwZIi2WerSpVCmjN4RCSFEvpPpWWMWi0W6xTLpm73nSbVoiePnr9XRORqRp/zxhzYV/rZRo2DLFkmChBAim9i8xYZ4uJE/HAWgrJ8XLk7yFotMSEmBkSPhySeha1dtp3gAZ2ftJoQQIlvIX1g7W380ynp/7LNVdYxE5BmnTmljf/bu1cq1a2szxdzc9I1LCCEcgDRX2NmIH+4soPhE+aI6RiJyPaW0LTFq19aSoEKFYOVKWLAAvLz0jk4IIRyCtAjZUXKqmevxJgDGPyczxcQDxMVBjx6werVWbtFC2yy1ZEldwxJCCEcjLUJ21PaTP6z3X6ojX2jiATw84MoVcHGBKVNg40ZJgoQQQgfSImQnaw79y7lrCQDUDy6Eh6uTzhGJXOf2AGg3N20A9FdfaWsF1a6ta1hCCOHIpEXITu5eQPHbNxrpGInIlY4dgwYNYMSIO3VlykgSJIQQOpNEyA52nrlmvT+rax1ZhVvcoRTMmAH16sHhw1or0I0bekclhBDiP5II2cHuiOvW+0/XCNQxEpGrREXB009rq0MnJUG7dnDokDY7TAghRK4giZAdfLLpFAA9GwfrG4jIPX7+GWrUgF9+0cYEzZgB69ZBQIDekQkhhLiLDJZ+RGbLnT3YShX21DESkWvcuKHtGB8ToyVDy5dDVVlcUwghciNJhB7R059ts97v3qi0jpGIXKNQIZg9G/btg4kTZYVoIYTIxaRr7BGcuXqLk1FxADxR3k/2FXNUFou2FtCGDXfqunaFqVMlCRJCiFxOWoQewedbzljvL+ndQMdIhG4uXICQEPjtN238z4kTULCg3lEJIYTIJGnCeAT7I7Vp0MW83WTKvCNauVIbA/Tbb9reYBMmgK+v3lEJIYSwgbQIZdGlmETOXo0HoFtDGRvkUOLitCnxixZp5fr1YdkyKF9e17CEEELYThKhLBq8XFtJ2sloYEjLx3SORuSY69e1xOfsWTAYtJWiw8K0PcOEEELkOZIIZdHef7RusWolfKVbzJEULgyNG0NqKixdCs2a6R2REEKIRyCJUBbciDdZ73/SuaaOkYgcERGhjQEqVkwrz5qlzRSTQdFCCJHnyWDpLNj3z529osoWLaBjJCJbKaW1+tSsCX36aGUAHx9JgoQQIp+QRCgL9vyj7S3m7S4NavnWzZvaWkA9emiDo2/ehNhYvaMSQghhZ5IIZcHiP88B0Lqyv76BiOzxxx9aK9CKFeDkBB9+CFu2yNR4IYTIhyQRygI3ZydAGygt8pGUFBg5Ep58EiIjoVw52LFDq3Ny0js6IYQQ2UASIRudvXqLmMQUAF6uV1LnaIRdJSbC119rY4H69IGDB6FhQ72jEkIIkY1kkIuNVh+4CEBwEU+83WXtmDzv9gBog0EbBL18OVy8CC++qG9cQgghcoS0CNnos99OA1DGz0vnSMQji46G55+Hzz+/U/f445IECSGEA5FEyAbqdusB0KF6oI6RiEf2669QvTr8+KO2OnRMjN4RCSGE0IEkQjY4feWW9X57SYTypqQkGDoU2raFqCioXFlmhAkhhAOTMUI2WPXf+CBno4ECbvLW5TlHj2prAx05opUHDIApU8DTU9+4hBBC6Ea+zW3wzzVtt/nqJaX1IM+5dg0aNYJbt6BoUViwADp21DsqIYQQOpNEKJOSUsysOxIFQMcaxXWORtisSBF47z3YuRMWLgR/WQxTCCGEJEKZtubgv9b7z9WSRChP+OknKFMGqlXTyiNGgNGoTZUXQgghkMHSmTZ1YzgAbav6U6SAm87RiAdKSID+/eGZZ6BbN22ANGirQ0sSJIQQ4i7SIpQJSikuxyYD8ET5ojpHIx5o/35tQHS4lrjSqpUkP0IIITIkLUKZsOfcDev9jjVk2nyuZLHARx9pCyKGh0NgIGzcCFOngpu04AkhhEiftAhlwrDvDwNQ2MuVgp6uOkcj7nPjhrYa9O+/a+Xnn4d587QB0kIIIcQDSItQJiSnWgBIMVt0jkSky8dH2zne0xPmz4fvv5ckSAghRKZIi1AmWP7bWmNkh8o6RyKs4uLAxQXc3bVB0MuWQXIylC+vd2RCCCHyEGkRegilFJditFlHDcoU1jkaAcBff0GtWjBs2J26UqUkCRJCCGEzSYQe4reTVwBwdzFSvKCHztE4uNRUGDcOmjaFs2dh9WqIjdU7KiGEEHmYJEIPsXLvBQBqBRXE3cVJ52gcWEQENG8OYWFgNmtT5A8e1MYHCSGEEFkkidADWCyK9ce0bTVaVZYtGXShFCxdCjVrwp9/aonPV19pY4IKFtQ7OiGEEHmcDJZ+gD/PXLPef7ZWCR0jcWDXrsHgwdrg6CZNtCQoOFjvqIQQQuQTkgg9wLa/rwJQuognRb1lUT5d+PnBF1/A339rg6Od5UdWCCGE/ci3ygNs+K9b7MU6JXWOxIGYTDBmjDYgukMHra5LF11DEkIIkX9JIpSBa7eSOXctAdAGSoscEB6ubZK6bx8UKwanT4O3t95RCSGEyMdyxWDpWbNmERwcjLu7Ow0bNmT37t0ZHjtv3jyeeOIJChUqRKFChWjVqtUDj8+qdUejrPebVZCNVrOVUtqWGHXqaElQoUIwe7YkQUIIIbKd7onQN998Q2hoKGFhYezfv5+aNWvStm1brly5ku7xW7Zs4dVXX+X3339n586dBAUF0aZNGy5evGjXuK7d0nabLyFrB2Wv6Gh44QXo1w8SEqBFCzh8WNs7TAghhMhmBqX+2z9CJw0bNqR+/frMnDkTAIvFQlBQEIMHD2bY3SsHZ8BsNlOoUCFmzpxJjx497ns8OTmZ5ORkazk2NpagoCBiYmLwecAaNOVHriPFrAhtXYEhLWXF4mxx9ao2Lf7SJW27jEmTYOhQMOqenwshhMhlYmNj8fX1fej3t610/cYxmUzs27ePVq1aWeuMRiOtWrVi586dmbpGQkICKSkpFC6c/vYXkyZNwtfX13oLCgrK1HVTzFp+6Okqiyhmm6JFoU0bqFwZdu2Ct9+WJEgIIUSO0vVbJzo6GrPZjL9/2sUK/f39iYqKyuCstN5//32KFy+eJpm62/Dhw4mJibHezp8//9BrmlLv7DIvCyna2bFjcPnynfLMmbB3L9SurV9MQgghHFae/u/35MmTWbFiBT/88APu7u7pHuPm5oaPj0+a28Mcv3Rn/6pShT3tFq9DUwpmzIC6daF3b60MUKAAeMp7LIQQQh+6Tp/38/PDycmJy3e3EACXL18mICDgged+/PHHTJ48mU2bNlGjRg27xjV/21kA3JyNGI0Gu17bIUVFQa9esH79nbr4eC0JEkIIIXSka4uQq6srdevWZfPmzdY6i8XC5s2badSoUYbnffTRR4wfP57169dTr149u8e1O+I6AOWKyhf1I/vpJ6heXUuC3N21rrCff5YkSAghRK6g+4KKoaGhhISEUK9ePRo0aMD06dOJj4+nV69eAPTo0YMSJUowadIkAP7v//6P0aNHs3z5coKDg61jiQoUKEABO3y5KqW4EqfNMnujedlHvp7DSkjQBj/PmaOVa9SA5cuhalV94xJCCCHuonsi1KVLF65evcro0aOJioqiVq1arF+/3jqAOjIyEuNdM4k+//xzTCYTL730UprrhIWFMWbMmEeOJ95ktt5v+pjfI1/PYZnNsHGjdv/tt2HCBHCT/dqEEELkLrqvI5TTHrYOwcmoWNpN3wZAxKQOGAwyRijTLP/NtruduO7ZAzExkMGMPiGEECKz8uU6QrnRbyfvrGgtSZANLlyA1q21MUC31a8vSZAQQohcTRKhe1z9b3yQt7vuvYZ5x8qV2hig336DcePg1i29IxJCCCEyRRKhe9xOhDrWCNQ5kjwgLk6bFt+5M9y4obUA7dwpM8KEEELkGZII3WPrqasANConA6Uf6K+/oFYtWLQIDAYYORJ27IDysi+bEEKIvEP6f+4Sl5RCXFIqAEGFZNf5DF2+DE89BUlJUKoUfPUVPPGE3lEJIYQQNpNE6C77I29a79csWVC3OHI9f3/44AM4ehRmz4aCBfWOSAghhMgSSYTusuGYtjhjg+DCsrXG3ZTSWn1q1tQGRQMMH651iQkhhBB5mIwRusvyXZEAuLnI22J18yZ07Qo9emj/JiZq9ZIECSGEyAekRSgdVQLtt1BTnrZ1K3TvDufPg5MTvPIKuLjoHZUQQghhN5II/Sfxrq01nq1VQsdIcgGTCcaMgcmTtW6xcuVg2TJo2FDvyIQQQgi7kkToP/sjb1jvVw701jESnV29Ch06wN69Wrl3b5g+Hbwd+D0RQgiRb0ki9J9fjl4C4MmKRR17a43ChcHLCwoVgrlz4Z7NbYUQQoj8RBKh/3y79wIAFf0dsOUjOlpLfjw8tLFAX32l1ZcsqW9cQgghRDaT6VH/MaVqO6cXL+hgCyn++qs2Jf699+7UlSwpSZAQQgiHIIkQd5IggDZV/XWMJAclJUFoKLRtC5cuwebNEB+vd1RCCCFEjpJECNgdcd1639/bXcdIcsixY9oMsE8+0coDBmiDo7289I1LCCGEyGGSCAGLd54DoJi3W/5eUVopmDED6taFw4ehaFH46SeYNQs8PfWOTgghhMhxMlgauHBDWy35mZrFdY4km125AmFhkJwM7dvDwoXavmFCCCGEg3L4RCg+OZUTl2IB6FI/SOdospm/P8ybp40JGjhQtskQQgjh8Bw+ETp04SYArk5GHitWQN9g7C0hAd55R1sgsWNHre7FF/WNSQghhMhFHD4R2hOhrSidYrHkr4UU9++Hbt3g5En4/ns4e1YGQwshhBD3cPjB0re7xSoF5JONVi0WmDIFHn9cS4ICA7UFEiUJEkIIIe7j8C1C649FAVAryFfnSOzgwgUICYHfftPKzz+vjQkqUkTfuIQQQohcyuETodvqlCqkdwiP5tIlbYXoGze0qfCffgp9+siAaCGEEOIBHDoRSkoxW++3rJzHp5EHBmotQIcPw7JlUKGC3hEJIYQQuZ5DJ0JX45Kt9wt5uugYSRbt2gWlSmlJEGiLJbq4aDchhBBCPJRDD5b+6+w1APwKuOatGWOpqTBuHDRpAr16aQOkQesSkyRICCGEyDSHbhE6fz0BgOhbJp0jsUFEBLz2Gvz5p1YuXFhbKdrDQ9+4hBBCiDzIoVuEDl6IAaBjjUCdI8kEpbRp8DVrakmQj49WXr5ckiAhhBAiixy6Rejkf2sIVfD31jmSh4iNhf/9D77+Wis3aQJLl0KZMvrGJYQQQuRxDpsIKaW48t9g6SaP5fJ1dpycYO9e7d+wMBg+HJwd9qMTuYTZbCYlJUXvMIQQ+YiLiwtOTk45+pwO+20afevOjLHqJQrqF0hGUlK0xMdo1FaFXrFCq2vYUO/IhODWrVtcuHABpZTeoQgh8hGDwUDJkiUpUCDn9v502ETozJV4ALzdnHF1zmVDpU6d0vYJ69YN3npLq6tTR9eQhLjNbDZz4cIFPD09KVq0aN6acSmEyLWUUly9epULFy5Qvnz5HGsZcthEaNnufwCoUzoXrSitFMyfryU/CQlw8SL066dNixcil0hJSUEpRdGiRfGQgfpCCDsqWrQo586dIyUlJccSoVzWFJJzrsZqXWOJd60uravoaHjhBS3xSUiAFi1g925JgkSuJS1BQgh70+PvisMmQrf34GpfLUDnQIBff9X2CVu9WlsQccoU2LgRSpbUOzIhhBAiX3PYrrGjF2MwunkS6OuubyD//gudOoHJBJUra/uE1a6tb0xCCCGEg3DYFiFvd63v0cdd5y0pihfXtssYMECbIi9JkBB5VnBwMNOnT8/y+YsWLaJgwYJ2iyc/edT31hbdu3dn4sSJOfJcjmTOnDl06tRJ7zDu47CJUFySNjaoYkAOL6aoFMycCQcP3ql77z2YNUvGAwmRjXr27Mlzzz2Xrc+xZ88e+vXrl6lj0/ti79KlC6dOncry8y9atAiDwYDBYMBoNBIYGEiXLl2IjIzM8jVzC1ve20dx6NAh1q1bx5AhQ7L9ufQSGRnJ008/jaenJ8WKFePdd98lNTU1w+O3bNli/bm697Znzx4AkpKS6NmzJ9WrV8fZ2Tnd37XevXuzf/9+tm3bll0vLUscNhG6rUgBt5x7sqgoePppGDwYunaFpCStXgadCpEvFC1aFM9H+A+Nh4cHxYoVe6QYfHx8uHTpEhcvXuT7778nPDycl19++ZGumRnZvbjmo763mTVjxgxefvnlR1rHRin1wMRCT2azmaeffhqTycSff/7J4sWLWbRoEaNHj87wnMaNG3Pp0qU0t9dff50yZcpQr14963U9PDwYMmQIrVq1Svc6rq6udO3alc8++yxbXltWOXQi5GzMwQTk55+1AdG//AJublpXmFsOJmFCZBOlFAmmVF1u9lzQcevWrTRo0AA3NzcCAwMZNmxYmi+zuLg4unXrhpeXF4GBgXzyySc8+eSTvHV7rS/StvIopRgzZgylSpXCzc2N4sWLW1sZnnzySf755x+GDh1q/Z81pN819tNPP1G/fn3c3d3x8/Pj+eeff+DrMBgMBAQEEBgYSOPGjenTpw+7d+8mNjbWesyPP/5InTp1cHd3p2zZsowdOzbNaz158iRNmzbF3d2dKlWqsGnTJgwGA6tXrwbg3LlzGAwGvvnmG5o3b467uzvLli0DYP78+VSuXBl3d3cqVarE7Nmzrdc1mUwMGjSIwMBA3N3dKV26NJMmTXro+3Xvewtaq8azzz5LgQIF8PHxoXPnzly+fNn6+JgxY6hVqxZLly4lODgYX19fXnnlFeLi4jJ878xmM99999193TdLly6lXr16eHt7ExAQQNeuXbly5Yr18dstJr/88gt169bFzc2N7du3Y7FYmDRpEmXKlMHDw4OaNWvy3XffpXm+Pn36WB+vWLEin3766QM/30f166+/cvz4cb766itq1apF+/btGT9+PLNmzcJkSn8DcldXVwICAqy3IkWK8OOPP9KrVy/rz66Xlxeff/45ffv2JSAg40lInTp1Ys2aNSQmJmbL68sKhx0sDVCthG/2P0lCArzzDnz+uVauUUPbKLVq1ex/biFyQGKKmSqjN+jy3MfHtcXT9dH/jF28eJEOHTrQs2dPlixZwsmTJ+nbty/u7u6MGTMGgNDQUHbs2MGaNWvw9/dn9OjR7N+/n1q1aqV7ze+//55PPvmEFStWULVqVaKiojh06BAAq1atombNmvTr14++fftmGNfatWt5/vnnGTlyJEuWLMFkMrFu3bpMv64rV67www8/4OTkZF2TZdu2bfTo0YPPPvuMJ554gjNnzli7nMLCwjCbzTz33HOUKlWKXbt2ERcXx9tvv53u9YcNG8bUqVOpXbu2NRkaPXo0M2fOpHbt2hw4cIC+ffvi5eVFSEgIn332GWvWrOHbb7+lVKlSnD9/nvPnzz/0/bqXxWKxJkFbt24lNTWVgQMH0qVLF7Zs2WI97syZM6xevZqff/6ZGzdu0LlzZyZPnsyECRPSve7hw4eJiYmxtnLclpKSwvjx46lYsSJXrlwhNDSUnj173vdZDBs2jI8//piyZctSqFAhJk2axFdffcWcOXMoX748f/zxB6+99hpFixalefPmWCwWSpYsycqVKylSpAh//vkn/fr1IzAwkM6dO2f4uT6steq1115jzpw56T62c+dOqlevjr+/v7Wubdu29O/fn2PHjlE7E+NU16xZw7Vr1+jVq9dDj71XvXr1SE1NZdeuXTz55JM2n58dHDoRyvYZY5cuaesBnTyplUNDYeJEaQkSIpeZPXs2QUFBzJw5E4PBQKVKlfj33395//33GT16NPHx8SxevJjly5fTsmVLABYuXEjx4sUzvGZkZCQBAQG0atUKFxcXSpUqRYMGDQAoXLgwTk5O1haGjEyYMIFXXnmFsWPHWutq1qz5wNcSExNDgQIFtJa6hAQAhgwZgpeXFwBjx45l2LBhhISEAFC2bFnGjx/Pe++9R1hYGBs3buTMmTNs2bLFGtuECRNo3br1fc/11ltv8cILL1jLYWFhTJ061VpXpkwZjh8/zhdffEFISAiRkZGUL1+epk2bYjAYKF26dKber3tt3ryZI0eOEBERQVBQEABLliyhatWq7Nmzh/r16wNawrRo0SK8vbWxoN27d2fz5s0ZJkL//PMPTk5O93VP9u7d23q/bNmyfPbZZ9SvX59bt26lSUrGjRtnfZ+Sk5OZOHEimzZtolGjRtZzt2/fzhdffEHz5s1xcXFJ89mWKVOGnTt38u233z4wETp49xjTdPj4+GT4WFRUVJokCLCWo6KiHnjd27788kvatm1LySws8eLp6Ymvry///POPzedmF4dOhMoVzea9TPz9ITAQYmJg8WJI5w+JEHmdh4sTx8e11e257eHEiRM0atQozWJuTZo0se6pduPGDVJSUtJ8Mfv6+lKxYsUMr/nyyy8zffp0ypYtS7t27ejQoQOdOnXC2YYNkw8ePPjAFqP0eHt7s3//flJSUvjll19YtmxZmi/+Q4cOsWPHjjR1ZrOZpKQkEhISCA8PJygoKE2CllFCcnfLSXx8PGfOnKFPnz5pYk5NTcXXV2t979mzJ61bt6ZixYq0a9eOjh070qZNG8C29+vEiRMEBQVZkyCAKlWqULBgQU6cOGFNhIKDg61JEEBgYGCaLq17JSYm4ubmdt+ifvv27WPMmDEcOnSIGzduYLFYAC15q1KlSrrvx+nTp0lISLgvgTSZTGlaXWbNmsWCBQuIjIwkMTERk8mUYSvjbY899tgDH89OFy5cYMOGDXz77bdZvoaHh4c1Sc8NHDoRcsqOMUIXLkDhwtoMMKNRWxfIxQX8/Oz/XELkAgaDwS7dU/lNUFAQ4eHhbNq0iY0bNzJgwACmTJnC1q1bcXHJ3LIdWdnCxGg0Wr8oK1euzJkzZ+jfvz9Lly4FtA1zx44dm6Yl5zZ3d9tayW+3Mt2+LsC8efNoeM/m0Le75erUqUNERAS//PILmzZtonPnzrRq1YrvvvvOLu/Xve49z2AwWJOY9Pj5+ZGQkIDJZMLV1RXQEry2bdvStm1bli1bRtGiRYmMjKRt27b3jalJ7/1Yu3YtJUqUSHOc23+9AitWrOCdd95h6tSpNGrUCG9vb6ZMmcKuXbse+LoepWssICCA3bt3p6m7PbbqQa2Tty1cuJAiRYrwzDPPPPTYjFy/fp2iRYtm+Xx7c+i/XnbvGlu5Et54A155BW4PEAwMtO9zCCHsrnLlynz//fcopaytATt27MDb25uSJUtSqFAhXFxc2LNnD6VKlQK0LqhTp07RrFmzDK/r4eFBp06d6NSpEwMHDqRSpUocOXKEOnXq4Orqitn84C1+atSowebNm7M0FuO2YcOGUa5cOYYOHUqdOnWoU6cO4eHhGbYqVKxYkfPnz3P58mVrl8ntKdIP4u/vT/HixTl79izdunXL8DgfHx+6dOlCly5deOmll2jXrh3Xr1+ncOHCD3y/7la5cmXr+KLbrULHjx/n5s2baVpobHW7Jeb48ePW+ydPnuTatWtMnjzZ+lx79+596LWqVKmCm5sbkZGRNG/ePN1jduzYQePGjRkwYIC17syZMw+99qN0jTVq1IgJEyZw5coVaxfgxo0b8fHxeeh7p5Ri4cKF9OjRI8vJ6ZkzZ0hKSsrUWKSc4tCJkL+PnRKhuDh4801YuFAr79sHiYkgG1IKkavExMTc9yVSpEgRBgwYwPTp0xk8eDCDBg0iPDycsLAwQkNDMRqNeHt7ExISwrvvvkvhwoUpVqwYYWFhGI3GDPdGWrRoEWazmYYNG+Lp6clXX32Fh4eHdVxMcHAwf/zxB6+88gpubm74pdNqHBYWRsuWLSlXrhyvvPIKqamprFu3jvfffz/TrzkoKIjnn3+e0aNH8/PPPzN69Gg6duxIqVKleOmllzAajRw6dIijR4/y4Ycf0rp1a8qVK0dISAgfffQRcXFxjBo1Cnj4PlBjx45lyJAh+Pr60q5dO5KTk9m7dy83btwgNDSUadOmERgYSO3atTEajaxcuZKAgAAKFiz40Pfrbq1ataJ69ep069aN6dOnk5qayoABA2jevPl9A51tUbRoUerUqcP27dutiVCpUqVwdXVlxowZ/O9//+Po0aOMHz/+odfy9vbmnXfeYejQoVgsFpo2bUpMTAw7duzAx8eHkJAQypcvz5IlS9iwYQNlypRh6dKl7NmzhzJlyjzw2o/SNdamTRuqVKlC9+7d+eijj4iKimLUqFEMHDjQ2lK1e/duevTowebNm9O0Zv32229ERETw+uuvp3vt48ePYzKZuH79OnFxcdbftbu7+rZt20bZsmUpV65cll+D3SkHExMTowAV9Na36nJM4qNfcOdOpcqVUwqUMhiUGjlSKZPp0a8rRC6VmJiojh8/rhIT7fD7k4NCQkIUcN+tT58+SimltmzZourXr69cXV1VQECAev/991VKSor1/NjYWNW1a1fl6empAgIC1LRp01SDBg3UsGHDrMeULl1affLJJ0oppX744QfVsGFD5ePjo7y8vNTjjz+uNm3aZD12586dqkaNGsrNzU3d/lO8cOFC5evrmybu77//XtWqVUu5uroqPz8/9cILL2T4GtM7//ZzAWrXrl1KKaXWr1+vGjdurDw8PJSPj49q0KCBmjt3rvX4EydOqCZNmihXV1dVqVIl9dNPPylArV+/XimlVEREhALUgQMH7nuuZcuWWeMtVKiQatasmVq1apVSSqm5c+eqWrVqKS8vL+Xj46Natmyp9u/fn6n36+73Viml/vnnH/XMM88oLy8v5e3trV5++WUVFRVlfTwsLEzVrFkzTWyffPKJKl26dIbvn1JKzZ49Wz3++ONp6pYvX66Cg4OVm5ubatSokVqzZk2a1//7778rQN24cSPNeRaLRU2fPl1VrFhRubi4qKJFi6q2bduqrVu3KqWUSkpKUj179lS+vr6qYMGCqn///mrYsGH3xW1v586dU+3bt1ceHh7Kz89Pvf3222l+1m+/noiIiDTnvfrqq6px48YZXrd06dLp/o7drU2bNmrSpEkZXuNBf19uf3/HxMRk8pVmjkEpOy7EkQfExsbi6+tL0Fvf8s+0l7K+021qqjYDbNw4MJuhVClYuhQe0EwuRH6QlJREREQEZcqUsXlMSX4SHx9PiRIlmDp1Kn369NE7nGy1Y8cOmjZtyunTp3PX/+SzQWJiIhUrVuSbb76xzvYS9nHs2DFatGjBqVOnrAPo7/Wgvy+3v79jYmIe2P1nK4ftGnN1zrhJO1OuXoVPP9WSoFdf1cYEyR5BQuRbBw4c4OTJkzRo0ICYmBjGjRsHwLPPPqtzZPb3ww8/UKBAAcqXL8/p06d58803adKkSb5PgkAb17VkyRKio6P1DiXfuXTpEkuWLMkwCdKLwyZCptSMZw5kSmAgLFigjQ967TX7BCWEyNU+/vhjwsPDcXV1pW7dumzbti3dsT15XVxcHO+//z6RkZH4+fnRqlUrpk6dqndYOSa3LPSX32S09YbeHDYRqhxo42arN29C//7ajLDb/wPMh/8TFEKkr3bt2uzbt0/vMHJEjx496NGjh95hCJEjHHavsUJerpk/eOtWbWuMFSvgf/+7s1mqEEIIIfI0h02EXJ0y8dJNJhg+HJ56Cs6fh3LlYPVqcOABokLc5mDzLIQQOUCPvysO2zUWm5jy4APCw6FbN21NIIDevbXB0Q9Z0VOI/O72KsEmkylLKx8LIURGbq/WffvvTE5w2ESocuADpt6dPw916mg7xxcqBPPmwYsv5lxwQuRizs7OeHp6cvXqVVxcXDAaHbZhWQhhRxaLhatXr+Lp6WnTnnyPymEToRvxpowfDArSZoKdPq1tlpqFHXaFyK8MBgOBgYFERETkqh2khRB5n9FopFSpUo+2vI2NHDYRqnTvrLGNG6FqVSheXCt/9pm2War8b1eI+7i6ulK+fPn7Np0UQohH4erqmuOtzA6bCMUmpmp3kpK0AdHTp0OrVrBhg5b8/LfnihAifUaj0aFXlhZC5A+5orlj1qxZBAcH4+7uTsOGDdm9e/cDj1+5ciWVKlXC3d2d6tWrs27dOpufs1QRTzh6FBo00JIggAoVIOUhg6iFEEIIkW/ongh98803hIaGEhYWxv79+6lZsyZt27blypUr6R7/559/8uqrr9KnTx8OHDjAc889x3PPPcfRo0dtet7yq5dBvXpw5AgULQo//QSzZklLkBBCCOFAdN90tWHDhtSvX5+ZM2cC2qjxoKAgBg8ezLBhw+47vkuXLsTHx/Pzzz9b6x5//HFq1arFnDlzHvp81k3bAB+A9u1h4ULw97fTKxJCCCGEveXLTVdNJhP79u1j+PDh1jqj0UirVq3YuXNnuufs3LmT0NDQNHVt27Zl9erV6R6fnJxMcnKytRwTEwPADWcXmDgB+vUDgwFiYx/x1QghhBAiu8T+9z1t7/YbXROh6OhozGYz/ve0xvj7+3Py5Ml0z4mKikr3+KioqHSPnzRpEmPHjr2vPjg1Bd57T7sJIYQQIk+4du2aXXewz/ezxoYPH56mBenmzZuULl2ayMhIu76RwnaxsbEEBQVx/vx5uzZziqyRzyP3kM8i95DPIveIiYmhVKlSFC5c2K7X1TUR8vPzw8nJicuXL6epv3z5MgEBAemeExAQYNPxbm5uuKUzANrX11d+qHMJHx8f+SxyEfk8cg/5LHIP+SxyD3uvM6TrrDFXV1fq1q3L5s2brXUWi4XNmzfTqFGjdM9p1KhRmuMBNm7cmOHxQgghhBAZ0b1rLDQ0lJCQEOrVq0eDBg2YPn068fHx9OrVC4AePXpQokQJJk2aBMCbb75J8+bNmTp1Kk8//TQrVqxg7969zJ07V8+XIYQQQog8SPdEqEuXLly9epXRo0cTFRVFrVq1WL9+vXVAdGRkZJpmsMaNG7N8+XJGjRrFiBEjKF++PKtXr6ZatWqZej43NzfCwsLS7S4TOUs+i9xFPo/cQz6L3EM+i9wjuz4L3dcREkIIIYTQi+4rSwshhBBC6EUSISGEEEI4LEmEhBBCCOGwJBESQgghhMPKl4nQrFmzCA4Oxt3dnYYNG7J79+4HHr9y5UoqVaqEu7s71atXZ926dTkUaf5ny2cxb948nnjiCQoVKkShQoVo1arVQz87YRtbfzduW7FiBQaDgeeeey57A3Qgtn4WN2/eZODAgQQGBuLm5kaFChXkb5Wd2PpZTJ8+nYoVK+Lh4UFQUBBDhw4lKSkph6LNv/744w86depE8eLFMRgMGe4herctW7ZQp04d3NzceOyxx1i0aJHtT6zymRUrVihXV1e1YMECdezYMdW3b19VsGBBdfny5XSP37Fjh3JyclIfffSROn78uBo1apRycXFRR44cyeHI8x9bP4uuXbuqWbNmqQMHDqgTJ06onj17Kl9fX3XhwoUcjjx/svXzuC0iIkKVKFFCPfHEE+rZZ5/NmWDzOVs/i+TkZFWvXj3VoUMHtX37dhUREaG2bNmiDh48mMOR5z+2fhbLli1Tbm5uatmyZSoiIkJt2LBBBQYGqqFDh+Zw5PnPunXr1MiRI9WqVasUoH744YcHHn/27Fnl6empQkND1fHjx9WMGTOUk5OTWr9+vU3Pm+8SoQYNGqiBAwday2azWRUvXlxNmjQp3eM7d+6snn766TR1DRs2VG+88Ua2xukIbP0s7pWamqq8vb3V4sWLsytEh5KVzyM1NVU1btxYzZ8/X4WEhEgiZCe2fhaff/65Klu2rDKZTDkVosOw9bMYOHCgatGiRZq60NBQ1aRJk2yN09FkJhF67733VNWqVdPUdenSRbVt29am58pXXWMmk4l9+/bRqlUra53RaKRVq1bs3Lkz3XN27tyZ5niAtm3bZni8yJysfBb3SkhIICUlxe4b7DmirH4e48aNo1ixYvTp0ycnwnQIWfks1qxZQ6NGjRg4cCD+/v5Uq1aNiRMnYjabcyrsfCkrn0Xjxo3Zt2+ftfvs7NmzrFu3jg4dOuRIzOIOe31/676ytD1FR0djNputq1Lf5u/vz8mTJ9M9JyoqKt3jo6Kisi1OR5CVz+Je77//PsWLF7/vB13YLiufx/bt2/nyyy85ePBgDkToOLLyWZw9e5bffvuNbt26sW7dOk6fPs2AAQNISUkhLCwsJ8LOl7LyWXTt2pXo6GiaNm2KUorU1FT+97//MWLEiJwIWdwlo+/v2NhYEhMT8fDwyNR18lWLkMg/Jk+ezIoVK/jhhx9wd3fXOxyHExcXR/fu3Zk3bx5+fn56h+PwLBYLxYoVY+7cudStW5cuXbowcuRI5syZo3doDmfLli1MnDiR2bNns3//flatWsXatWsZP3683qGJLMpXLUJ+fn44OTlx+fLlNPWXL18mICAg3XMCAgJsOl5kTlY+i9s+/vhjJk+ezKZNm6hRo0Z2hukwbP08zpw5w7lz5+jUqZO1zmKxAODs7Ex4eDjlypXL3qDzqaz8bgQGBuLi4oKTk5O1rnLlykRFRWEymXB1dc3WmPOrrHwWH3zwAd27d+f1118HoHr16sTHx9OvXz9GjhyZZm9Mkb0y+v728fHJdGsQ5LMWIVdXV+rWrcvmzZutdRaLhc2bN9OoUaN0z2nUqFGa4wE2btyY4fEic7LyWQB89NFHjB8/nvXr11OvXr2cCNUh2Pp5VKpUiSNHjnDw4EHr7ZlnnuGpp57i4MGDBAUF5WT4+UpWfjeaNGnC6dOnrckowKlTpwgMDJQk6BFk5bNISEi4L9m5naAq2bozR9nt+9u2cdy534oVK5Sbm5tatGiROn78uOrXr58qWLCgioqKUkop1b17dzVs2DDr8Tt27FDOzs7q448/VidOnFBhYWEyfd5ObP0sJk+erFxdXdV3332nLl26ZL3FxcXp9RLyFVs/j3vJrDH7sfWziIyMVN7e3mrQoEEqPDxc/fzzz6pYsWLqww8/1Osl5Bu2fhZhYWHK29tbff311+rs2bPq119/VeXKlVOdO3fW6yXkG3FxcerAgQPqwIEDClDTpk1TBw4cUP/8849SSqlhw4ap7t27W4+/PX3+3XffVSdOnFCzZs2S6fO3zZgxQ5UqVUq5urqqBg0aqL/++sv6WPPmzVVISEia47/99ltVoUIF5erqqqpWrarWrl2bwxHnX7Z8FqVLl1bAfbewsLCcDzyfsvV3426SCNmXrZ/Fn3/+qRo2bKjc3NxU2bJl1YQJE1RqamoOR50/2fJZpKSkqDFjxqhy5copd3d3FRQUpAYMGKBu3LiR84HnM7///nu63wG33/+QkBDVvHnz+86pVauWcnV1VWXLllULFy60+XkNSklbnhBCCCEcU74aIySEEEIIYQtJhIQQQgjhsCQREkIIIYTDkkRICCGEEA5LEiEhhBBCOCxJhIQQQgjhsCQREkIIIYTDkkRICCGEEA5LEiEhRBqLFi2iYMGCeoeRZQaDgdWrVz/wmJ49e/Lcc8/lSDxCiNxNEiEh8qGePXtiMBjuu50+fVrv0Fi0aJE1HqPRSMmSJenVqxdXrlyxy/UvXbpE+/btATh37hwGg4GDBw+mOebTTz9l0aJFdnm+jIwZM8b6Op2cnAgKCqJfv35cv37dputI0iZE9nLWOwAhRPZo164dCxcuTFNXtGhRnaJJy8fHh/DwcCwWC4cOHaJXr178+++/bNiw4ZGvHRAQ8NBjfH19H/l5MqNq1aps2rQJs9nMiRMn6N27NzExMXzzzTc58vxCiIeTFiEh8ik3NzcCAgLS3JycnJg2bRrVq1fHy8uLoKAgBgwYwK1btzK8zqFDh3jqqafw9vbGx8eHunXrsnfvXuvj27dv54knnsDDw4OgoCCGDBlCfHz8A2MzGAwEBARQvHhx2rdvz5AhQ9i0aROJiYlYLBbGjRtHyZIlcXNzo1atWqxfv956rslkYtCgQQQGBuLu7k7p0qWZNGlSmmvf7horU6YMALVr18ZgMPDkk08CaVtZ5s6dS/HixbFYLGlifPbZZ+ndu7e1/OOPP1KnTh3c3d0pW7YsY8eOJTU19YGv09nZmYCAAEqUKEGrVq14+eWX2bhxo/Vxs9lMnz59KFOmDB4eHlSsWJFPP/3U+viYMWNYvHgxP/74o7V1acuWLQCcP3+ezp07U7BgQQoXLsyzzz7LuXPnHhiPEOJ+kggJ4WCMRiOfffYZx44dY/Hixfz222+89957GR7frVs3SpYsyZ49e9i3bx/Dhg3DxcUFgDNnztCuXTtefPFFDh8+zDfffMP27dsZNGiQTTF5eHhgsVhITU3l008/ZerUqXz88cccPnyYtm3b8swzz/D3338D8Nlnn7FmzRq+/fZbwsPDWbZsGcHBweled/fu3QBs2rSJS5cusWrVqvuOefnll7l27Rq///67te769eusX7+ebt26AbBt2zZ69OjBm2++yfHjx/niiy9YtGgREyZMyPRrPHfuHBs2bMDV1dVaZ7FYKFmyJCtXruT48eOMHj2aESNG8O233wLwzjvv0LlzZ9q1a8elS5e4dOkSjRs3JiUlhbZt2+Lt7c22bdvYsWMHBQoUoF27dphMpkzHJIQAbN6vXgiR64WEhCgnJyfl5eVlvb300kvpHrty5UpVpEgRa3nhwoXK19fXWvb29laLFi1K99w+ffqofv36panbtm2bMhqNKjExMd1z7r3+qVOnVIUKFVS9evWUUkoVL15cTZgwIc059evXVwMGDFBKKTV48GDVokULZbFY0r0+oH744QellFIREREKUAcOHEhzTEhIiHr22Wet5WeffVb17t3bWv7iiy9U8eLFldlsVkop1bJlSzVx4sQ011i6dKkKDAxMNwallAoLC1NGo1F5eXkpd3d3BShATZs2LcNzlFJq4MCB6sUXX8ww1tvPXbFixTTvQXJysvLw8FAbNmx44PWFEGnJGCEh8qmnnnqKzz//3Fr28vICtNaRSZMmcfLkSWJjY0lNTSUpKYmEhAQ8PT3vu05oaCivv/46S5cutXbvlCtXDtC6zQ4fPsyyZcusxyulsFgsREREULly5XRji4mJoUCBAlgsFpKSkmjatCnz588nNjaWf//9lyZNmqQ5vkmTJhw6dAjQurVat25NxYoVadeuHR07dqRNmzaP9F5169aNvn37Mnv2bNzc3Fi2bBmvvPIKRqPR+jp37NiRpgXIbDY/8H0DqFixImvWrCEpKYmvvvqKgwcPMnjw4DTHzJo1iwULFhAZGUliYiImk4latWo9MN5Dhw5x+vRpvL2909QnJSVx5syZLLwDQjguSYSEyKe8vLx47LHH0tSdO3eOjh070r9/fyZMmEDhwoXZvn07ffr0wWQypfuFPmbMGLp27cratWv55ZdfCAsLY8WKFTz//PPcunWLN954gyFDhtx3XqlSpTKMzdvbm/3792M0GgkMDMTDwwOA2NjYh76uOnXqEBERwS+//MKmTZvo3LkzrVq14rvvvnvouRnp1KkTSinWrl1L/fr12bZtG5988on18Vu3bjF27FheeOGF+851d3fP8Lqurq7Wz2Dy5Mk8/fTTjB07lvHjxwOwYsUK3nnnHaZOnUqjRo3w9vZmypQp7Nq164Hx3rp1i7p166ZJQG/LLQPihcgrJBESwoHs27cPi8XC1KlTra0dt8ejPEiFChWoUKECQ4cO5dVXX2XhwoU8//zz1KlTh+PHj9+XcD2M0WhM9xwfHx+KFy/Ojh07aN68ubV+x44dNGjQIM1xXbp0oUuXLrz00ku0a9eO69evU7hw4TTXuz0ex2w2PzAed3d3XnjhBZYtW8bp06epWLEiderUsT5ep04dwsPDbX6d9xo1ahQtWrSgf//+1tfZuHFjBgwYYD3m3hYdV1fX++KvU6cO33zzDcWKFcPHx+eRYhLC0clgaSEcyGOPPUZKSgozZszg7NmzLF26lDlz5mR4fGJiIoMGDWLLli38888/7Nixgz179li7vN5//33+/PNPBg0axMGDB/n777/58ccfbR4sfbd3332X//u//+Obb74hPDycYcOGcfDgQd58800Apk2bxtdff83Jkyc5deoUK1euJCAgIN1FIIsVK4aHhwfr16/n8uXLxMTEZPi83bp1Y+3atSxYsMA6SPq20aNHs2TJEsaOHcuxY8c4ceIEK1asYNSoUTa9tkaNGlGjRg0mTpwIQPny5dm7dy8bNmzg1KlTfPDBB+zZsyfNOcHBwRw+fJjw8HCio6NJSUmhW7du+Pn58eyzz7Jt2zYiIiLYsmULQ4YM4cKFCzbFJITD03uQkhDC/tIbYHvbtGnTVGBgoPLw8FBt27ZVS5YsUYC6ceOGUirtYObk5GT1yiuvqKCgIOXq6qqKFy+uBg0alGYg9O7du1Xr1q1VgQIFlJeXl6pRo8Z9g53vdu9g6XuZzWY1ZswYVaJECeXi4qJq1qypfvnlF+vjc+fOVbVq1VJeXl7Kx8dHtWzZUu3fv9/6OHcNllZKqXnz5qmgoCBlNBpV8+bNM3x/zGazCgwMVIA6c+bMfXGtX79eNW7cWHl4eCgfHx/VoEEDNXfu3AxfR1hYmKpZs+Z99V9//bVyc3NTkZGRKikpSfXs2VP5+vqqggULqv79+6thw4alOe/KlSvW9xdQv//+u1JKqUuXLqkePXooPz8/5ebmpsqWLav69u2rYmJiMoxJCHE/g1JK6ZuKCSGEEELoQ7rGhBBCCOGwJBESQgghhMOSREgIIYQQDksSISGEEEI4LEmEhBBCCOGwJBESQgghhMOSREgIIYQQDksSISGEEEI4LEmEhBBCCOGwJBESQgghhMOSREgIIYQQDuv/Ae26Ac1KhJuhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = extra_trees_randomized_search.predict(X_test)\n",
    "y_pred_proba = extra_trees_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. AdaBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.a Simple AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=ExtraTreesClassifier(random_state=2023),\n",
       "                   n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=ExtraTreesClassifier(random_state=2023),\n",
       "                   n_estimators=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(random_state=2023)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(random_state=2023)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=ExtraTreesClassifier(random_state=2023),\n",
       "                   n_estimators=100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_cls = AdaBoostClassifier(base_estimator=ExtraTreesClassifier(random_state=semilla), n_estimators=100)\n",
    "\n",
    "adaboost_cls.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910105\n",
      "Precision: 0.623585\n",
      "Recall: 0.965740\n",
      "F1 score: 0.757832\n",
      "AUC: 0.933181\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = adaboost_cls.predict(X_test)\n",
    "y_pred_proba = adaboost_cls.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. GradientBoosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.a Simple GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_cls = GradientBoostingClassifier()\n",
    "\n",
    "grad_boost_cls.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717547\n",
      "Precision: 0.312473\n",
      "Recall: 0.782574\n",
      "F1 score: 0.446617\n",
      "AUC: 0.744517\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = grad_boost_cls.predict(X_test)\n",
    "y_pred_proba = grad_boost_cls.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.a Simple XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=3,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=3,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=3,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_jobs=3, eval_metric=\"logloss\", use_label_encoder=False)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.899419\n",
      "Precision: 0.595887\n",
      "Recall: 0.961424\n",
      "F1 score: 0.735756\n",
      "AUC: 0.925136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.b XGBooost Hyperparameter opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_parameter = {\n",
    "    'max_depth':list(range(3,15))+[None],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_child_weight': range(1, 10, 1),\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 5],\n",
    "    'base_score': [0.2, 0.5, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[01:30:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=None, min_child_weight=6, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=1.0; total time=  11.0s\n",
      "[01:30:38] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=None, min_child_weight=6, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=1.0; total time=  10.6s\n",
      "[01:30:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=None, min_child_weight=6, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=1.0; total time=  10.4s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=None, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  49.1s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=None, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  50.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=None, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  50.6s\n",
      "[01:33:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.5, max_depth=9, min_child_weight=9, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  21.1s\n",
      "[01:33:52] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.5, max_depth=9, min_child_weight=9, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  22.0s\n",
      "[01:34:14] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.5, max_depth=9, min_child_weight=9, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  21.4s\n",
      "[01:34:35] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=13, min_child_weight=4, n_estimators=400, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=   8.4s\n",
      "[01:34:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=13, min_child_weight=4, n_estimators=400, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=   8.5s\n",
      "[01:34:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=13, min_child_weight=4, n_estimators=400, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=   9.1s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=3, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  49.4s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=3, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  49.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=14, min_child_weight=3, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  49.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.9, gamma=1, learning_rate=0.3, max_depth=7, min_child_weight=6, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=0.8; total time= 1.3min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.9, gamma=1, learning_rate=0.3, max_depth=7, min_child_weight=6, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=0.8; total time= 1.3min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.9, gamma=1, learning_rate=0.3, max_depth=7, min_child_weight=6, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=0.8; total time= 1.3min\n",
      "[01:41:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.5, gamma=1, learning_rate=0.5, max_depth=12, min_child_weight=9, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  11.2s\n",
      "[01:41:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.5, gamma=1, learning_rate=0.5, max_depth=12, min_child_weight=9, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  10.9s\n",
      "[01:41:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.5, gamma=1, learning_rate=0.5, max_depth=12, min_child_weight=9, n_estimators=500, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=  10.5s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=13, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.5; total time= 3.0min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=13, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.5; total time= 3.0min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=13, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.5; total time= 3.0min\n",
      "[01:51:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   3.3s\n",
      "[01:51:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   3.3s\n",
      "[01:51:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   3.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=13, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=13, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=13, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.5; total time= 1.2min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.5; total time= 1.2min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.5; total time= 1.2min\n",
      "[01:54:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=400, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   9.5s\n",
      "[01:54:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=400, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   8.5s\n",
      "[01:55:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=400, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time=   8.9s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.7, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.7, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.7, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=   0.3s\n",
      "[01:55:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=14, min_child_weight=3, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.8; total time=  10.4s\n",
      "[01:55:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=14, min_child_weight=3, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.8; total time=  10.5s\n",
      "[01:55:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=14, min_child_weight=3, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.8; total time=  10.4s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.6; total time= 1.1min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.6; total time= 1.1min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=8, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.6; total time= 1.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=6, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.6; total time= 1.0min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=6, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.6; total time= 1.0min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=6, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.6; total time= 1.0min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time= 1.1min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time= 1.1min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=1.0; total time= 1.1min\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=3, min_child_weight=9, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=3, min_child_weight=9, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.5; total time=   0.2s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=3, min_child_weight=9, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=6, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=6, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.2s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=6, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, min_child_weight=8, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[02:05:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=  19.0s\n",
      "[02:05:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=  18.6s\n",
      "[02:06:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.01, max_depth=8, min_child_weight=4, n_estimators=900, reg_alpha=0.5, reg_lambda=5, subsample=0.7; total time=  18.2s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=11, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  52.1s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=11, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  51.9s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=11, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=  54.8s\n",
      "[02:09:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  15.4s\n",
      "[02:09:31] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  14.5s\n",
      "[02:09:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  14.5s\n",
      "[02:10:00] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  28.4s\n",
      "[02:10:29] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  26.7s\n",
      "[02:10:55] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  26.2s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  20.4s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  20.5s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=12, min_child_weight=6, n_estimators=200, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  20.0s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.5, max_depth=14, min_child_weight=1, n_estimators=1000, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time= 4.9min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.5, max_depth=14, min_child_weight=1, n_estimators=1000, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time= 4.9min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.5, max_depth=14, min_child_weight=1, n_estimators=1000, reg_alpha=0.5, reg_lambda=1, subsample=0.7; total time= 4.9min\n",
      "[02:27:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=11, min_child_weight=5, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  18.4s\n",
      "[02:27:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=11, min_child_weight=5, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  18.2s\n",
      "[02:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=0.5, learning_rate=0.7, max_depth=11, min_child_weight=5, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  18.9s\n",
      "[02:28:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=14, min_child_weight=2, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  13.1s\n",
      "[02:28:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=14, min_child_weight=2, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  12.4s\n",
      "[02:28:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=14, min_child_weight=2, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=  12.4s\n",
      "[02:28:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.5; total time=  12.4s\n",
      "[02:28:57] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.5; total time=  13.3s\n",
      "[02:29:10] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=1, reg_lambda=5, subsample=0.5; total time=  12.9s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   0.3s\n",
      "[02:29:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=2, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.8; total time=  17.7s\n",
      "[02:29:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=2, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.8; total time=  16.3s\n",
      "[02:29:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=6, min_child_weight=2, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.8; total time=  17.1s\n",
      "[02:30:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   8.5s\n",
      "[02:30:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   8.8s\n",
      "[02:30:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.7; total time=   8.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=  19.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=  19.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=  19.5s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.9; total time= 1.4min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.9; total time= 1.4min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.9; total time= 1.4min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  43.7s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  44.1s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  43.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=2, n_estimators=500, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.6s\n",
      "[02:40:27] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=14, min_child_weight=7, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  21.4s\n",
      "[02:40:49] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=14, min_child_weight=7, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  21.7s\n",
      "[02:41:11] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=14, min_child_weight=7, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time=  21.7s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  51.1s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  51.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=500, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  51.3s\n",
      "[02:44:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  16.7s\n",
      "[02:44:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  17.4s\n",
      "[02:44:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  16.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  47.1s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  46.7s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.7, max_depth=9, min_child_weight=5, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.6; total time=  47.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   8.5s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   8.5s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=None, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   9.4s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[02:47:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=1000, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  20.7s\n",
      "[02:48:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=1000, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  20.6s\n",
      "[02:48:30] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=0.9, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=1000, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  20.4s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=1, learning_rate=0.3, max_depth=None, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time= 1.2min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=1, learning_rate=0.3, max_depth=None, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time= 1.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=1, learning_rate=0.3, max_depth=None, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.7; total time= 1.1min\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=9, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=9, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=9, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=1.0; total time=   0.3s\n",
      "[02:52:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=6, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.6s\n",
      "[02:52:34] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=6, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.8s\n",
      "[02:52:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=6, n_estimators=600, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  12.4s\n",
      "[02:52:59] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=3, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time=   3.3s\n",
      "[02:53:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=3, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time=   3.3s\n",
      "[02:53:06] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.3, max_depth=14, min_child_weight=3, n_estimators=100, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time=   3.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=None, min_child_weight=6, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=  16.1s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=None, min_child_weight=6, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=  16.0s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=None, min_child_weight=6, n_estimators=100, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=  16.0s\n",
      "[02:53:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=1, learning_rate=0.3, max_depth=13, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6; total time=   2.6s\n",
      "[02:54:01] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=1, learning_rate=0.3, max_depth=13, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6; total time=   2.6s\n",
      "[02:54:03] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=1, learning_rate=0.3, max_depth=13, min_child_weight=1, n_estimators=100, reg_alpha=0.5, reg_lambda=1, subsample=0.6; total time=   2.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=14, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 2.0min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=14, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 2.0min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=14, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 2.0min\n",
      "[03:00:12] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=  11.4s\n",
      "[03:00:24] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=  11.0s\n",
      "[03:00:35] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=  11.0s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=8, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.5; total time=  25.5s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=8, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.5; total time=  25.6s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=8, min_child_weight=5, n_estimators=200, reg_alpha=1, reg_lambda=1, subsample=0.5; total time=  25.4s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  17.4s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  17.2s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0, learning_rate=0.5, max_depth=12, min_child_weight=5, n_estimators=100, reg_alpha=1, reg_lambda=0.5, subsample=0.7; total time=  17.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.5, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.5, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.4s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0, learning_rate=0.5, max_depth=14, min_child_weight=8, n_estimators=600, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time=  45.6s\n",
      "[03:05:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=4, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  18.9s\n",
      "[03:05:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=4, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  18.9s\n",
      "[03:05:51] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=10, min_child_weight=4, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  18.4s\n",
      "[03:06:09] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   6.7s\n",
      "[03:06:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   6.6s\n",
      "[03:06:23] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=9, n_estimators=300, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   6.9s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=6, n_estimators=1000, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=6, n_estimators=1000, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=6, n_estimators=1000, reg_alpha=1, reg_lambda=0.5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=0.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900, reg_alpha=1, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=11, min_child_weight=3, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.9; total time= 3.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=11, min_child_weight=3, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.9; total time= 3.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=11, min_child_weight=3, n_estimators=600, reg_alpha=0, reg_lambda=5, subsample=0.9; total time= 3.1min\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.6, gamma=1, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=3, min_child_weight=8, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  41.7s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=3, min_child_weight=8, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  41.6s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.8, gamma=0.5, learning_rate=0.5, max_depth=3, min_child_weight=8, n_estimators=700, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  41.6s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=9, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=9, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=0.5, learning_rate=0.05, max_depth=9, min_child_weight=6, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.7, gamma=1, learning_rate=0.1, max_depth=8, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.7, gamma=1, learning_rate=0.1, max_depth=8, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.7, gamma=1, learning_rate=0.1, max_depth=8, min_child_weight=1, n_estimators=1000, reg_alpha=0, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.5, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0.5, reg_lambda=0.5, subsample=0.7; total time= 1.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.5, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0.5, reg_lambda=0.5, subsample=0.7; total time= 1.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.5, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0.5, reg_lambda=0.5, subsample=0.7; total time= 1.1min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.5; total time= 1.6min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.5; total time= 1.6min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=13, min_child_weight=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.5; total time= 1.6min\n",
      "[03:26:07] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  14.7s\n",
      "[03:26:21] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  14.7s\n",
      "[03:26:36] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=700, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  14.8s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=11, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=11, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=11, min_child_weight=7, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  21.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  22.1s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=2, n_estimators=400, reg_alpha=1, reg_lambda=1, subsample=0.7; total time=  22.2s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=13, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=  59.0s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=13, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=  59.6s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.6, gamma=0, learning_rate=0.5, max_depth=13, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=1, subsample=1.0; total time=  58.9s\n",
      "[03:30:57] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=1, learning_rate=0.05, max_depth=11, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  19.2s\n",
      "[03:31:16] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=1, learning_rate=0.05, max_depth=11, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  18.7s\n",
      "[03:31:35] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=1, learning_rate=0.05, max_depth=11, min_child_weight=2, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=  19.0s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=11, min_child_weight=5, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=11, min_child_weight=5, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=11, min_child_weight=5, n_estimators=1000, reg_alpha=0.5, reg_lambda=0.5, subsample=0.6; total time=   0.3s\n",
      "[03:31:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   8.5s\n",
      "[03:32:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   8.6s\n",
      "[03:32:13] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=1, learning_rate=0.01, max_depth=None, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   8.7s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time= 1.4min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time= 1.4min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=3, min_child_weight=6, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time= 1.4min\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=8, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=8, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.6, colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=8, n_estimators=900, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=   0.3s\n",
      "[03:36:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  19.0s\n",
      "[03:36:56] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  19.1s\n",
      "[03:37:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.8, gamma=1, learning_rate=0.5, max_depth=4, min_child_weight=9, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  22.5s\n",
      "[03:37:37] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.8; total time=   8.2s\n",
      "[03:37:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.8; total time=   8.3s\n",
      "[03:37:54] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=300, reg_alpha=0.5, reg_lambda=1, subsample=0.8; total time=   8.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.5; total time=   0.4s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=7, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.5; total time=   0.3s\n",
      "[03:38:04] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  10.7s\n",
      "[03:38:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  10.5s\n",
      "[03:38:26] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.5, booster=gblinear, colsample_bylevel=0.7, colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=0.7; total time=  10.7s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=4, min_child_weight=9, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=4, min_child_weight=9, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.6, colsample_bytree=0.7, gamma=0, learning_rate=0.7, max_depth=4, min_child_weight=9, n_estimators=800, reg_alpha=1, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  51.0s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  49.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.8, colsample_bytree=0.5, gamma=0.5, learning_rate=0.7, max_depth=7, min_child_weight=6, n_estimators=600, reg_alpha=0, reg_lambda=0.5, subsample=0.8; total time=  52.9s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=200, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=200, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=200, reg_alpha=0.5, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=3, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=3, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7, gamma=1, learning_rate=0.3, max_depth=4, min_child_weight=3, n_estimators=200, reg_alpha=0, reg_lambda=5, subsample=0.8; total time=   0.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=400, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  41.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=400, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  39.3s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.6, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=400, reg_alpha=1, reg_lambda=0.5, subsample=0.9; total time=  37.8s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.7, max_depth=7, min_child_weight=5, n_estimators=600, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gblinear, colsample_bylevel=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=13, min_child_weight=4, n_estimators=700, reg_alpha=0, reg_lambda=5, subsample=0.9; total time=   0.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  59.4s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  59.4s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=0.5, learning_rate=0.1, max_depth=None, min_child_weight=1, n_estimators=800, reg_alpha=0.5, reg_lambda=0.5, subsample=0.8; total time=  59.7s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.7, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time= 1.4min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.7, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time= 1.4min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.7, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0, reg_lambda=0.5, subsample=0.9; total time= 1.3min\n",
      "[03:50:19] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  16.7s\n",
      "[03:50:36] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  16.6s\n",
      "[03:50:53] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.5, colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=5, subsample=1.0; total time=  16.9s\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time= 3.9min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time= 3.9min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=13, min_child_weight=5, n_estimators=800, reg_alpha=0.5, reg_lambda=1, subsample=0.9; total time= 3.9min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=None, min_child_weight=2, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time= 1.6min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=None, min_child_weight=2, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time= 1.6min\n",
      "[CV] END base_score=0.2, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=None, min_child_weight=2, n_estimators=1000, reg_alpha=0, reg_lambda=0.5, subsample=0.7; total time= 1.6min\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, gamma=0.5, learning_rate=0.01, max_depth=8, min_child_weight=6, n_estimators=700, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=1, booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.5; total time=   0.3s\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time= 1.5min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time= 1.5min\n",
      "[CV] END base_score=0.5, booster=gbtree, colsample_bylevel=0.7, colsample_bytree=0.5, gamma=1, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=800, reg_alpha=0, reg_lambda=5, subsample=0.5; total time= 1.5min\n",
      "[04:12:18] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=13, min_child_weight=7, n_estimators=300, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   7.1s\n",
      "[04:12:25] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=13, min_child_weight=7, n_estimators=300, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   6.7s\n",
      "[04:12:32] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\" } are not used.\n",
      "\n",
      "[CV] END base_score=0.2, booster=gblinear, colsample_bylevel=0.8, colsample_bytree=0.7, gamma=0.5, learning_rate=0.3, max_depth=13, min_child_weight=7, n_estimators=300, reg_alpha=0.5, reg_lambda=5, subsample=0.9; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "90 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:30:59] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:31:00] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:42:03] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:42:04] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:42:05] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:51:13] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:51:14] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:55:15] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:55:16] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [01:55:17] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:05:36] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:05:37] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:05:38] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:05:39] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:29:23] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:29:24] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:31:41] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:31:42] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:47:47] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:47:48] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:52:18] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:52:19] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [02:52:20] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:06:30] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:06:31] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:06:32] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:15:45] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:15:46] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:17:51] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:17:52] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:17:53] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:26:51] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:26:52] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:31:54] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:31:55] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:36:35] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:36:36] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:38:03] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:38:04] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:38:36] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:38:37] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:41:11] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:41:12] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:41:13] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:41:14] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:43:13] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:43:14] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [03:43:15] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [04:07:40] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [04:07:41] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [04:07:42] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1\\xgboost\\xgboost-ci-windows\\src\\objective\\./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.87514342 0.55362084 0.5        0.94749274\n",
      " 0.91435513 0.5               nan        nan 0.93220625 0.54731052\n",
      "        nan 0.88091382 0.5               nan        nan 0.5\n",
      " 0.86933927 0.86582979 0.93740298        nan        nan        nan\n",
      " 0.5        0.93922521 0.5        0.54731052 0.88084633 0.88617804\n",
      " 0.5        0.5        0.5               nan 0.5        0.55463319\n",
      " 0.69329149        nan 0.91914693 0.88546939 0.90490653 0.54731052\n",
      " 0.91519876 0.5        0.85044206 0.86147668        nan 0.5\n",
      " 0.89397314        nan        nan 0.5        0.54731052 0.81598839\n",
      " 0.5        0.95174462 0.54920024 0.82766417 0.88061011 0.91317406\n",
      " 0.5        0.5               nan        nan 0.93281366        nan\n",
      " 0.8711615         nan        nan 0.87949652 0.8982925  0.5\n",
      "        nan 0.78244584 0.91688601 0.55362084        nan 0.54896403\n",
      " 0.75467369        nan 0.55362084 0.5               nan 0.5\n",
      "        nan 0.86670716        nan        nan 0.92727948        nan\n",
      "        nan 0.92798812 0.88027266 0.5        0.94310589 0.9213741\n",
      "        nan        nan 0.91364649 0.5       ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.5, 0.6, 0.7, 0.8,\n",
       "                                                             0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.5, 1],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.3,\n",
       "                                                          0.5, 0.7],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                      11, 12, 13, 14, None],\n",
       "                                        &#x27;min_child_weight&#x27;: range(1, 10),\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0, 0.5, 1],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.5, 1, 5],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.5, 0.6, 0.7, 0.8,\n",
       "                                                             0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.5, 1],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.3,\n",
       "                                                          0.5, 0.7],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                      11, 12, 13, 14, None],\n",
       "                                        &#x27;min_child_weight&#x27;: range(1, 10),\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0, 0.5, 1],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.5, 1, 5],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                        'colsample_bytree': [0.5, 0.6, 0.7, 0.8,\n",
       "                                                             0.9, 1.0],\n",
       "                                        'gamma': [0, 0.5, 1],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.1, 0.3,\n",
       "                                                          0.5, 0.7],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                      11, 12, 13, 14, None],\n",
       "                                        'min_child_weight': range(1, 10),\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000],\n",
       "                                        'reg_alpha': [0, 0.5, 1],\n",
       "                                        'reg_lambda': [0.5, 1, 5],\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 100\n",
    "cv = 3\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_randomized_search = RandomizedSearchCV(estimator=xgb, \n",
    "                                         param_distributions=xgboost_parameter, n_iter=n_iter, cv=cv, scoring='accuracy', verbose=2)\n",
    "\n",
    "xgb_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961889\n",
      "Precision: 0.796662\n",
      "Recall: 0.991368\n",
      "F1 score: 0.883413\n",
      "AUC: 0.974116\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = xgb_randomized_search.predict(X_test)\n",
    "y_pred_proba = xgb_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(xgb_randomized_search, 'lda_xgb_randomized_search.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGdCAYAAAD+C94iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8sUlEQVR4nO3dfVzN5/8H8Ncpur+TKSdUulGhEplyZtnWpDBhIl+6UcSkfJmwiVIq+5W7fc1avtNs2eQ+ljSGESI6fKmFNvcZ31FNhOr8/nA6X2fdnZBKr+fj8Xk8zufzuT7X9f5c52zeXef6XEcgkUgkICIiIiIiKDV3AERERERELQWTYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISKpdcwdA1NpUVVXh5s2b0NbWhkAgaO5wiIiISAESiQR//fUXjIyMoKRU9/gwk2OiRrp58ya6devW3GEQERHRc7h27Rq6du1a53kmx0SNpK2tDeDpf1w6OjrNHA0REREporS0FN26dZP9O14XJsdEjVQ9lUJHR4fJMRERUSvT0JRIPpBHRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFJMjomIiIiIpJgcExERERFJMTkmIiIiIpJickxEREREJMXkmIiIiIhIiskxEREREZEUk2MiIiIiIikmx0REREREUu2aOwCi1qr34r1QUtVo7jCIiIheG5fjhjV3CBw5JiIiIiKqxuSYiIiIiEiKyTERERERkRSTYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSajHJsUQiwdSpU6Gvrw+BQAA9PT3MmjWrucNCREQE+vTp09xhvJCmuAc/Pz94enrK9gcPHtwi3i8iIiKiF9FikuOMjAwkJydj9+7dKCoqwoULFxAVFfVCdQoEAuzYsePlBEj12rZt2wu/Xw2RSCSIj49Hjx49oKqqii5dumDp0qVyZdasWQMbGxuoq6vDysoKGzZskDuflJSEQYMGoUOHDujQoQNcXV1x4sSJJo2biIiIWo8W8/PRhYWFEAqFGDhwoELlHz9+DBUVlSaOihSlr6/f5G2EhoYiMzMT8fHxsLW1xd27d3H37l3Z+bVr12LBggVISkpC//79ceLECUyZMgUdOnTAiBEjAAAHDx6Et7c3Bg4cCDU1NSxbtgxDhgzB+fPn0aVLlya/ByIiImrZWsTIsZ+fH2bOnImrV69CIBDA1NS0xtf0pqamiIqKgo+PD3R0dDB16lQ8fvwYwcHBEAqFUFNTg4mJCWJjY2XlAWDUqFGyOhURFxcHQ0NDaGtrIyAgAOXl5XLnq6qqsGTJEnTt2hWqqqro06cPMjIy5Mpcv34d3t7e0NfXh6amJhwdHZGdna1Q+zt37kTfvn2hpqYGMzMzREZGoqKiQnZeIBAgMTERw4cPh4aGBmxsbHDs2DFcunQJgwcPhqamJgYOHIjCwsIadScmJqJbt27Q0NCAl5cXSkpKFIqpsrISs2fPhp6eHjp27IiwsDBIJBK5MrW9X9HR0fDx8YGWlhZMTEyQlpaGO3fuYOTIkdDS0oKdnR1ycnIUiiE/Px9r167Fzp078cEHH6B79+7o168f3n//fVmZb7/9FkFBQRg3bhzMzMwwfvx4TJ06FcuWLZOVSUlJwUcffYQ+ffrA2toa69atQ1VVFfbv369QHERERPR6axHJ8apVq2QJZ1FREU6ePFlrufj4eNjb2yM3Nxfh4eFYvXo10tLSkJqaioKCAqSkpMiS4Oo61q9fX2+dz0pNTUVERARiYmKQk5MDoVCIL774okasCQkJiI+Px9mzZ+Hm5oYPPvgAFy9eBADcv38fLi4uuHHjBtLS0nDmzBmEhYWhqqqqwfYPHz4MHx8fhIaGIi8vD4mJiUhOTq4xdaD6jwSxWAxra2tMmDABQUFBWLBgAXJyciCRSBAcHCx3zaVLl5Camopdu3YhIyMDubm5+OijjxqMCQASEhKQnJyMr7/+GkeOHMHdu3exffv2Bq9bsWIFRCIRcnNzMWzYMEyaNAk+Pj6YOHEiTp8+DXNzc/j4+NRItGuza9cumJmZYffu3ejevTtMTU0RGBgoN3L86NEjqKmpyV2nrq6OEydO4MmTJ7XW++DBAzx58qTeke9Hjx6htLRUbiMiIqLXU4uYVqGrqwttbW0oKyujc+fOdZZ79913MWfOHNn+1atXYWlpibfeegsCgQAmJiayc506dQIA6Onp1Vvns1auXImAgAAEBAQAAKKjo7Fv3z650eP4+HjMmzcP48ePBwAsW7YMBw4cwMqVK7FmzRps3LgRd+7cwcmTJ2UJl4WFhULtR0ZGYv78+fD19QUAmJmZISoqCmFhYVi8eLGsnL+/P7y8vAAA8+bNg7OzM8LDw+Hm5gbg6fQDf39/ubrLy8uxYcMG2dSBzz//HMOGDUNCQkKD/bNy5UosWLAAo0ePBgB8+eWX2Lt3b4P34+HhgaCgIADAokWLsHbtWvTv3x9jx46Vi/2PP/5oMIbffvsNV65cwebNm7FhwwZUVlbin//8Jz788EP8/PPPAAA3NzesW7cOnp6e6Nu3L06dOoV169bhyZMn+O9//wuhUFij3nnz5sHIyAiurq51th0bG4vIyMgG75eIiIhavxYxcqwoR0dHuX0/Pz+IxWJYWVkhJCQEmZmZL1R/fn4+BgwYIHfM2dlZ9rq0tBQ3b96ESCSSKyMSiZCfnw8AEIvFcHBweK45uGfOnMGSJUugpaUl26ZMmYKioiI8ePBAVs7Ozk722tDQEABga2srd6y8vFxuhNPY2FhuTq2zszOqqqpQUFBQb0wlJSUoKiqS65d27drVeC9qo0icAHD79u0G66qqqsKjR4+wYcMGDBo0CIMHD8a///1vHDhwQHYP4eHhcHd3h5OTE9q3b4+RI0fK/tBQUqr5UY+Li8MPP/yA7du31xhxftaCBQtQUlIi265du9ZgvERERNQ6tarkWFNTU26/b9+++P333xEVFYWHDx/Cy8sLH374YTNF95S6uvpzX3v//n1ERkZCLBbLtv/85z+4ePGiXPLWvn172WuBQFDnMUWmcjSllxmnUChEu3bt0KNHD9kxGxsbAE+/QQCe9v3XX3+NBw8e4PLly7h69SpMTU2hra0t+yahWnx8POLi4pCZmSmXxNdGVVUVOjo6chsRERG9nlpVclwbHR0djBs3DklJSdi0aRO2bt0qm4favn17VFZWKlyXjY1NjQfnjh8/LteWkZERsrKy5MpkZWWhZ8+eAJ6OlorFYrm5sIrq27cvCgoKYGFhUWOrbeSzMa5evYqbN2/K9o8fPw4lJSVYWVnVe52uri6EQqFcv1RUVODUqVMvFE9jiUQiVFRUyD1oeOHCBQCQm04DPH3fu3btCmVlZfzwww8YPny4XP999tlniIqKQkZGhkIj4ERERNR2tIg5x89r+fLlEAqFcHBwgJKSEjZv3ozOnTtDT08PwNMVE/bv3w+RSARVVVV06NCh3vpCQ0Ph5+cHR0dHiEQipKSk4Pz58zAzM5OVmTt3LhYvXgxzc3P06dMH69evh1gsRkpKCgDA29sbMTEx8PT0RGxsLIRCIXJzc2FkZCQ3RaM2ixYtwvDhw2FsbIwPP/wQSkpKOHPmDM6dO4fo6OgX6is1NTX4+voiPj4epaWlCAkJgZeXl0LzsUNDQxEXFwdLS0tYW1tj+fLlKC4ufqF4GsvV1RV9+/bF5MmTsXLlSlRVVWHGjBl4//33ZaPJFy5cwIkTJzBgwADcu3cPy5cvx7lz5/DNN9/I6lm2bBkWLVqEjRs3wtTUFLdu3QIA2TQWIiIiatta9cixtrY2PvvsMzg6OqJ///64fPky0tPTZaOECQkJ+Omnn9CtWzc4ODg0WN+4ceMQHh6OsLAw9OvXD1euXMH06dPlyoSEhGD27NmYM2cObG1tkZGRgbS0NFhaWgIAVFRUkJmZCQMDA3h4eMDW1hZxcXFQVlZusH03Nzfs3r0bmZmZ6N+/P5ycnLBixYoaI6PPw8LCAqNHj4aHhweGDBkCOzu7Gitx1GXOnDmYNGkSfH194ezsDG1tbYwaNeqFY2oMJSUl7Nq1C2+88QbefvttDBs2DDY2Nvjhhx9kZSorK5GQkAB7e3u8//77KC8vx9GjR+WW8Vu7di0eP36MDz/8EEKhULbFx8e/0vshIiKilkkgUWQdLSKSKS0tha6uLrrNSoWSqkZzh0NERPTauBw3rMnqrv73u6SkpN7nh1r1yDERERER0cvUppLjXr16yS2T9uxWPWf4dW6/LnXFpKWlhcOHD7+SGNzd3euMISYm5pXEQERERNSqH8hrrPT09Dp/Ka16zd3Xuf26iMXiOs89uzZyU1q3bh0ePnxY67nnWTOaiIiI6Hm0qeT4ZTzY1prbr4uiv+DXlF5VEk5ERERUnzY1rYKIiIiIqD5MjomIiIiIpJgcExERERFJtak5x0Qv07lIt3rXSSQiIqLWhyPHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIpLuRE9p96L90JJVaO5wyAiIlLI5bhhzR1Cq8CRYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISKrFJMcSiQRTp06Fvr4+BAIB9PT0MGvWrOYOCxEREejTp09zh/FCmuIe/Pz84OnpKdsfPHhwi3i/iIiIiF5Ei0mOMzIykJycjN27d6OoqAgXLlxAVFTUC9UpEAiwY8eOlxMg1Wvbtm0v/H7V5+DBgxg5ciSEQiE0NTXRp08fpKSk1Ci3cuVKWFlZQV1dHd26dcM///lPlJeXy85HRERAIBDIbdbW1k0WNxEREbUuLeYX8goLCyEUCjFw4ECFyj9+/BgqKipNHBUpSl9fv0nrP3r0KOzs7DBv3jwYGhpi9+7d8PHxga6uLoYPHw4A2LhxI+bPn4+vv/4aAwcOxIULF+Dn5weBQIDly5fL6urVqxf27dsn22/XrsX8Z0BERETNrEWMHPv5+WHmzJm4evUqBAIBTE1Na3xNb2pqiqioKPj4+EBHRwdTp07F48ePERwcDKFQCDU1NZiYmCA2NlZWHgBGjRolq1MRcXFxMDQ0hLa2NgICAuRGHQGgqqoKS5YsQdeuXaGqqoo+ffogIyNDrsz169fh7e0NfX19aGpqwtHREdnZ2Qq1v3PnTvTt2xdqamowMzNDZGQkKioqZOcFAgESExMxfPhwaGhowMbGBseOHcOlS5cwePBgaGpqYuDAgSgsLKxRd2JiIrp16wYNDQ14eXmhpKREoZgqKysxe/Zs6OnpoWPHjggLC4NEIpErU9v7FR0dDR8fH2hpacHExARpaWm4c+cORo4cCS0tLdjZ2SEnJ0ehGD755BNERUVh4MCBMDc3R2hoKIYOHYpt27bJyhw9ehQikQgTJkyAqakphgwZAm9vb5w4cUKurnbt2qFz586y7Y033lAoBiIiInr9tYjkeNWqVbKEs6ioCCdPnqy1XHx8POzt7ZGbm4vw8HCsXr0aaWlpSE1NRUFBAVJSUmRJcHUd69evr7fOZ6WmpiIiIgIxMTHIycmBUCjEF198USPWhIQExMfH4+zZs3Bzc8MHH3yAixcvAgDu378PFxcX3LhxA2lpaThz5gzCwsJQVVXVYPuHDx+Gj48PQkNDkZeXh8TERCQnJ2Pp0qVy5ar/SBCLxbC2tsaECRMQFBSEBQsWICcnBxKJBMHBwXLXXLp0Campqdi1axcyMjKQm5uLjz76qMGYACAhIQHJycn4+uuvceTIEdy9exfbt29v8LoVK1ZAJBIhNzcXw4YNw6RJk+Dj44OJEyfi9OnTMDc3h4+PT41EW1ElJSVyI9YDBw7EqVOnZMnwb7/9hvT0dHh4eMhdd/HiRRgZGcHMzAz/+Mc/cPXq1XrbefToEUpLS+U2IiIiej21iO+TdXV1oa2tDWVlZXTu3LnOcu+++y7mzJkj27969SosLS3x1ltvQSAQwMTERHauU6dOAAA9Pb1663zWypUrERAQgICAAABAdHQ09u3bJzd6HB8fj3nz5mH8+PEAgGXLluHAgQNYuXIl1qxZg40bN+LOnTs4efKkLHGzsLBQqP3IyEjMnz8fvr6+AAAzMzNERUUhLCwMixcvlpXz9/eHl5cXAGDevHlwdnZGeHg43NzcAAChoaHw9/eXq7u8vBwbNmxAly5dAACff/45hg0bhoSEhAb7Z+XKlViwYAFGjx4NAPjyyy+xd+/eBu/Hw8MDQUFBAIBFixZh7dq16N+/P8aOHSsX+x9//KHwe1QtNTUVJ0+eRGJiouzYhAkT8N///hdvvfUWJBIJKioqMG3aNHzyySeyMgMGDEBycjKsrKxQVFSEyMhIDBo0COfOnYO2tnatbcXGxiIyMrJR8REREVHr1CJGjhXl6Ogot+/n5wexWAwrKyuEhIQgMzPzherPz8/HgAED5I45OzvLXpeWluLmzZsQiURyZUQiEfLz8wEAYrEYDg4OzzUH98yZM1iyZAm0tLRk25QpU1BUVIQHDx7IytnZ2cleGxoaAgBsbW3ljpWXl8uNcBobG8sS4+r7qqqqQkFBQb0xlZSUoKioSK5f2rVrV+O9qI0icQLA7du3G6zrWQcOHIC/vz+SkpLQq1cv2fGDBw8iJiYGX3zxBU6fPo1t27bhxx9/lHtQ0N3dHWPHjoWdnR3c3NyQnp6O4uJipKam1tneggULUFJSItuuXbvWqHiJiIio9WgRI8eK0tTUlNvv27cvfv/9d+zZswf79u2Dl5cXXF1dsWXLlmaKEFBXV3/ua+/fv4/IyEjZCO2z1NTUZK/bt28vey0QCOo8pshUjqbUFHEeOnQII0aMwIoVK+Dj4yN3Ljw8HJMmTUJgYCCAp4l4WVkZpk6dik8//RRKSjX/FtTT00OPHj1w6dKlOttUVVWFqqqqwjESERFR69WqRo5ro6Ojg3HjxiEpKQmbNm3C1q1bcffuXQBPE7HKykqF67Kxsanx4Nzx48fl2jIyMkJWVpZcmaysLPTs2RPA09FSsVgsi6Ex+vbti4KCAlhYWNTYakvsGuPq1au4efOmbP/48eNQUlKClZVVvdfp6upCKBTK9UtFRQVOnTr1QvE8j4MHD2LYsGFYtmwZpk6dWuP8gwcPavSTsrIyANQ5r/n+/fuylVKIiIiIWtXI8d8tX74cQqEQDg4OUFJSwubNm9G5c2fo6ekBeLpiwv79+yESiaCqqooOHTrUW19oaCj8/Pzg6OgIkUiElJQUnD9/HmZmZrIyc+fOxeLFi2Fubo4+ffpg/fr1EIvFsjV3vb29ERMTA09PT8TGxkIoFCI3NxdGRkZyUzRqs2jRIgwfPhzGxsb48MMPoaSkhDNnzuDcuXOIjo5+ob5SU1ODr68v4uPjUVpaipCQEHh5eSk01zc0NBRxcXGwtLSEtbU1li9fjuLi4heKp7EOHDiA4cOHIzQ0FGPGjMGtW7cAACoqKrIpLCNGjMDy5cvh4OCAAQMG4NKlSwgPD8eIESNkSfLHH3+MESNGwMTEBDdv3sTixYuhrKwMb2/vV3o/RERE1DK16uRYW1sbn332GS5evAhlZWX0798f6enpstHDhIQEzJ49G0lJSejSpQsuX75cb33jxo1DYWEhwsLCUF5ejjFjxmD69OlyD5+FhISgpKQEc+bMwe3bt9GzZ0+kpaXB0tISwNNkLTMzE3PmzIGHhwcqKirQs2dPrFmzpsH7cXNzw+7du7FkyRIsW7YM7du3h7W1tWyawIuwsLDA6NGj4eHhgbt372L48OE1VuKoy5w5c1BUVARfX18oKSlh8uTJGDVqlMJLwb0M33zzDR48eIDY2FjZcn0A4OLigoMHDwIAFi5cCIFAgIULF+LGjRvo1KkTRowYIbfaR/Uye3/++Sc6deqEt956C8ePH5c9wElERERtm0DyvOtoEbVRpaWl0NXVRbdZqVBS1WjucIiIiBRyOW5Yc4fQrKr//S4pKYGOjk6d5Vr9nGMiIiIiopelTSXHvXr1klsm7dmtes7w69x+XeqKSUtLC4cPH34lMbi7u9cZQ0xMzCuJgYiIiKhVzzlurPT0dDx58qTWc9Vr7r7O7ddFLBbXee7ZtZGb0rp16/Dw4cNazz3PmtFEREREz6NNJcfP/oJeW2y/Lor+gl9TelVJOBEREVF92tS0CiIiIiKi+jA5JiIiIiKSYnJMRERERCTVpuYcE71M5yLd6l0nkYiIiFofjhwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKyTERERERkRSTYyIiIiIiKS7lRvScei/eCyVVjeYOg4iI6nE5blhzh0CtDEeOiYiIiIikmBwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKyTERERERkRSTYyIiIiIiKSbHRERERERSLSY5lkgkmDp1KvT19SEQCKCnp4dZs2Y1d1iIiIhAnz59mjuMF9IU9+Dn5wdPT0/Z/uDBg1vE+0VERET0IlpMcpyRkYHk5GTs3r0bRUVFuHDhAqKiol6oToFAgB07drycAKle27Zte+H3S1GXLl2CtrY29PT05I6fP38eY8aMgampKQQCAVauXFnr9WvWrIGpqSnU1NQwYMAAnDhxoumDJiIiolahxSTHhYWFEAqFGDhwIDp37gwDAwNoa2vXWf7x48evMDpqiL6+fr3v18vy5MkTeHt7Y9CgQTXOPXjwAGZmZoiLi0Pnzp1rvX7Tpk2YPXs2Fi9ejNOnT8Pe3h5ubm64fft2U4dORERErUCLSI79/Pwwc+ZMXL16FQKBAKampjW+pjc1NUVUVBR8fHygo6ODqVOn4vHjxwgODoZQKISamhpMTEwQGxsrKw8Ao0aNktWpiLi4OBgaGkJbWxsBAQEoLy+XO19VVYUlS5aga9euUFVVRZ8+fZCRkSFX5vr16/D29oa+vj40NTXh6OiI7OxshdrfuXMn+vbtCzU1NZiZmSEyMhIVFRWy8wKBAImJiRg+fDg0NDRgY2ODY8eO4dKlSxg8eDA0NTUxcOBAFBYW1qg7MTER3bp1g4aGBry8vFBSUqJQTJWVlZg9ezb09PTQsWNHhIWFQSKRyJWp7f2Kjo6Gj48PtLS0YGJigrS0NNy5cwcjR46ElpYW7OzskJOTo1AM1RYuXAhra2t4eXnVONe/f3/83//9H8aPHw9VVdVar1++fDmmTJkCf39/9OzZE19++SU0NDTw9ddfNyoOIiIiej21iOR41apVsoSzqKgIJ0+erLVcfHw87O3tkZubi/DwcKxevRppaWlITU1FQUEBUlJSZElwdR3r16+vt85npaamIiIiAjExMcjJyYFQKMQXX3xRI9aEhATEx8fj7NmzcHNzwwcffICLFy8CAO7fvw8XFxfcuHEDaWlpOHPmDMLCwlBVVdVg+4cPH4aPjw9CQ0ORl5eHxMREJCcnY+nSpXLlqv9IEIvFsLa2xoQJExAUFIQFCxYgJycHEokEwcHBctdcunQJqamp2LVrFzIyMpCbm4uPPvqowZgAICEhAcnJyfj6669x5MgR3L17F9u3b2/wuhUrVkAkEiE3NxfDhg3DpEmT4OPjg4kTJ+L06dMwNzeHj49PjUS7Lj///DM2b96MNWvWKFT+7x4/foxTp07B1dVVdkxJSQmurq44duxYndc9evQIpaWlchsRERG9nto1dwAAoKurC21tbSgrK9f5dTgAvPvuu5gzZ45s/+rVq7C0tMRbb70FgUAAExMT2blOnToBAPT09Oqt81krV65EQEAAAgICAADR0dHYt2+f3OhxfHw85s2bh/HjxwMAli1bhgMHDmDlypVYs2YNNm7ciDt37uDkyZPQ19cHAFhYWCjUfmRkJObPnw9fX18AgJmZGaKiohAWFobFixfLyvn7+8tGTufNmwdnZ2eEh4fDzc0NABAaGgp/f3+5usvLy7FhwwZ06dIFAPD5559j2LBhSEhIaLB/Vq5ciQULFmD06NEAgC+//BJ79+5t8H48PDwQFBQEAFi0aBHWrl2L/v37Y+zYsXKx//HHHw3G8Oeff8LPzw/fffcddHR0Gmy7Nv/9739RWVkJQ0NDueOGhob49ddf67wuNjYWkZGRz9UmERERtS4tYuRYUY6OjnL7fn5+EIvFsLKyQkhICDIzM1+o/vz8fAwYMEDumLOzs+x1aWkpbt68CZFIJFdGJBIhPz8fACAWi+Hg4CBLjBvjzJkzWLJkCbS0tGTblClTUFRUhAcPHsjK2dnZyV5XJ3q2trZyx8rLy+VGOI2NjWWJcfV9VVVVoaCgoN6YSkpKUFRUJNcv7dq1q/Fe1EaROAEoNN93ypQpmDBhAt5+++0Gy75sCxYsQElJiWy7du3aK4+BiIiIXo0WMXKsKE1NTbn9vn374vfff8eePXuwb98+eHl5wdXVFVu2bGmmCAF1dfXnvvb+/fuIjIyUjdA+S01NTfa6ffv2stcCgaDOY4pM5WhKLzPOn3/+GWlpaYiPjwfwdOm/qqoqtGvXDl999RUmT57cYB1vvPEGlJWV8ccff8gdb2jkWlVVtc45zERERPR6aVUjx7XR0dHBuHHjkJSUhE2bNmHr1q24e/cugKeJWGVlpcJ12djY1Hhw7vjx43JtGRkZISsrS65MVlYWevbsCeDpaKlYLJbF0Bh9+/ZFQUEBLCwsamxKSi/2Vl29ehU3b96U7R8/fhxKSkqwsrKq9zpdXV0IhUK5fqmoqMCpU6deKJ7GOnbsGMRisWxbsmQJtLW1IRaLMWrUKIXqUFFRQb9+/bB//37ZsaqqKuzfv1/uGwIiIiJqu1rVyPHfLV++HEKhEA4ODlBSUsLmzZvRuXNn2fq3pqam2L9/P0QiEVRVVdGhQ4d66wsNDYWfnx8cHR0hEomQkpKC8+fPw8zMTFZm7ty5WLx4MczNzdGnTx+sX78eYrEYKSkpAABvb2/ExMTA09MTsbGxEAqFyM3NhZGRUYMJ2KJFizB8+HAYGxvjww8/hJKSEs6cOYNz584hOjr6hfpKTU0Nvr6+iI+PR2lpKUJCQuDl5aXQfOzQ0FDExcXB0tIS1tbWWL58OYqLi18onsaysbGR28/JyYGSkhJ69+4tO/b48WPk5eXJXt+4cQNisRhaWlqyed+zZ8+Gr68vHB0d8eabb2LlypUoKyurMUebiIiI2qZWnRxra2vjs88+w8WLF6GsrIz+/fsjPT1dNsqakJCA2bNnIykpCV26dMHly5frrW/cuHEoLCxEWFgYysvLMWbMGEyfPl3u4bOQkBCUlJRgzpw5uH37Nnr27Im0tDRYWloCeDo6mZmZiTlz5sDDwwMVFRXo2bOnQissuLm5Yffu3ViyZAmWLVuG9u3bw9raGoGBgc/fSVIWFhYYPXo0PDw8cPfuXQwfPrzGShx1mTNnDoqKiuDr6wslJSVMnjwZo0aNUngpuFfl5s2bcHBwkO3Hx8cjPj4eLi4uOHjwIICn7/GdO3ewaNEi3Lp1S7YU398f0iMiIqK2SSBRdB0tIgLw9MFMXV1ddJuVCiVVjeYOh4iI6nE5blhzh0AtRPW/3yUlJfWufNXq5xwTEREREb0sbSo57tWrl9wyac9u1XOGX+f261JXTFpaWjh8+PAricHd3b3OGGJiYl5JDEREREStes5xY6Wnp+PJkye1nnsVc06bu/26iMXiOs89uzZyU1q3bh0ePnxY67nnWTOaiIiI6Hm0qeT42V/Qa4vt10XRX/BrSq8qCSciIiKqT5uaVkFEREREVB8mx0REREREUm1qWgXRy3Qu0q3epWCIiIio9eHIMRERERGRFJNjIiIiIiIpJsdERERERFJMjomIiIiIpJgcExERERFJMTkmIiIiIpLiUm5Ez6n34r1QUtVo7jCIiF6Jy3HDmjsEoleCI8dERERERFJMjomIiIiIpJgcExERERFJMTkmIiIiIpJickxEREREJMXkmIiIiIhIiskxEREREZEUk2MiIiIiIqnXPjk+ePAgBAIBiouLn+v65ORk6OnpvdSYXrWmuIeIiAj06dNHtu/n5wdPT8+X2gYRERHRq/baJ8f0aqxatQrJycmvpK0///wTXbt2rfWPnpSUFNjb20NDQwNCoRCTJ0/Gn3/+KTu/bds2ODo6Qk9PD5qamujTpw++/fbbVxI3ERERtXxMjuml0NXVfWUj7AEBAbCzs6txPCsrCz4+PggICMD58+exefNmnDhxAlOmTJGV0dfXx6effopjx47h7Nmz8Pf3h7+/P/bu3ftKYiciIqKWrdHJ8ZYtW2Brawt1dXV07NgRrq6uKCsrAwCsW7cONjY2UFNTg7W1Nb744gu5a69fvw5vb2/o6+tDU1MTjo6OyM7Olp1fu3YtzM3NoaKiAisrqxojegKBAOvWrcOoUaOgoaEBS0tLpKWlyZVJT09Hjx49oK6ujnfeeQeXL19u1P0lJyfD2NgYGhoaGDVqlNyoo6JxFhcXIygoCIaGhlBTU0Pv3r2xe/duhdo/cuQIBg0aBHV1dXTr1g0hISGy/gUAU1NTREdHw8fHB1paWjAxMUFaWhru3LmDkSNHQktLC3Z2dsjJyalR944dO2BpaQk1NTW4ubnh2rVrCvdLXFwcDA0Noa2tjYCAAJSXl8ud//u0isGDB2PmzJmYNWsWOnToAENDQyQlJaGsrAz+/v7Q1taGhYUF9uzZo3AMwNO+Ly4uxscff1zj3LFjx2BqaoqQkBB0794db731FoKCgnDixAm5uEaNGgUbGxuYm5sjNDQUdnZ2OHLkSKPiICIiotdTo5LjoqIieHt7Y/LkycjPz8fBgwcxevRoSCQSpKSkYNGiRVi6dCny8/MRExOD8PBwfPPNNwCA+/fvw8XFBTdu3EBaWhrOnDmDsLAwVFVVAQC2b9+O0NBQzJkzB+fOnUNQUBD8/f1x4MABuRgiIyPh5eWFs2fPwsPDA//4xz9w9+5dAMC1a9cwevRojBgxAmKxGIGBgZg/f77C95ednY2AgAAEBwdDLBbjnXfeQXR0tFyZhuKsqqqCu7s7srKy8N133yEvLw9xcXFQVlZusP3CwkIMHToUY8aMwdmzZ7Fp0yYcOXIEwcHBcuVWrFgBkUiE3NxcDBs2DJMmTYKPjw8mTpyI06dPw9zcHD4+PpBIJLJrHjx4gKVLl2LDhg3IyspCcXExxo8fr1C/pKamIiIiAjExMcjJyYFQKKzxh09tvvnmG7zxxhs4ceIEZs6cienTp2Ps2LEYOHAgTp8+jSFDhmDSpEl48OCBQnHk5eVhyZIl2LBhA5SUan50nZ2dce3aNaSnp0MikeCPP/7Ali1b4OHhUWt9EokE+/fvR0FBAd5+++0623306BFKS0vlNiIiIno9CSTPZlANOH36NPr164fLly/DxMRE7pyFhQWioqLg7e0tOxYdHY309HQcPXoUX331FT7++GNcvnwZ+vr6NeoWiUTo1asXvvrqK9kxLy8vlJWV4ccff3warECAhQsXIioqCgBQVlYGLS0t7NmzB0OHDsUnn3yCnTt34vz587I65s+fj2XLluHevXsNfu0/YcIElJSUyNoDgPHjxyMjI0M2t7WhODMzM+Hu7o78/Hz06NGjgR6VFxgYCGVlZSQmJsqOHTlyBC4uLigrK4OamhpMTU0xaNAg2Wj1rVu3IBQKER4ejiVLlgAAjh8/DmdnZxQVFaFz585ITk6Gv78/jh8/jgEDBgAAfv31V9jY2CA7OxtvvvlmvXENHDgQDg4OWLNmjeyYk5MTysvLIRaLATwdOS4uLsaOHTsAPB2hraysxOHDhwEAlZWV0NXVxejRo7Fhwwa52I8dOwYnJ6d6Y3j06BHefPNNzJ07FxMnTsTBgwfxzjvv1HhfN2/ejMmTJ6O8vBwVFRUYMWIEtm7divbt28vKlJSUoEuXLnj06BGUlZXxxRdfYPLkyXW2HRERgcjIyBrHu81KhZKqRr1xExG9Li7HDWvuEIheSGlpKXR1dVFSUgIdHZ06yzVq5Nje3h7vvfcebG1tMXbsWCQlJeHevXsoKytDYWEhAgICoKWlJduio6NRWFgIABCLxXBwcKg1MQaA/Px8iEQiuWMikQj5+flyx56da6qpqQkdHR3cvn1bVkd18lfN2dlZ4ftT5PqG4hSLxejatWujE2MAOHPmDJKTk+X60M3NDVVVVfj9999l5Z7tA0NDQwCAra1tjWPV/QIA7dq1Q//+/WX71tbW0NPTq9G/tXnefn02TmVlZXTs2LHBOOuyYMEC2NjYYOLEiXWWycvLQ2hoKBYtWoRTp04hIyMDly9fxrRp0+TKaWtrQywW4+TJk1i6dClmz56NgwcP1tt2SUmJbGvMdBQiIiJqXdo1prCysjJ++uknHD16FJmZmfj888/x6aefYteuXQCApKSkGklU9XQCdXX1lxLwsyOAwNPR5OqpGS3Bi9zn/fv3ERQUhJCQkBrnjI2NZa+f7QOBQFDnsebul9req+eN8+eff8Z//vMfbNmyBQBkU0beeOMNfPrpp4iMjERsbCxEIhHmzp0L4GlyrqmpiUGDBiE6OhpCoRAAoKSkBAsLCwBAnz59kJ+fj9jYWAwePLjWtlVVVaGqqtqIOyciIqLWqtEP5AkEAohEIkRGRiI3NxcqKirIysqCkZERfvvtN1hYWMht3bt3B/A0URGLxbL5wX9nY2ODrKwsuWNZWVno2bOnwrHZ2NjIPXwFPJ1i0Jjrn31AsLbrG4rTzs4O169fx4ULFxRut1rfvn2Rl5dXow8tLCygoqLS6PqeVVFRIfeQXkFBAYqLi2FjY9PgtYr0S1PbunUrzpw5A7FYDLFYjHXr1gEADh8+jBkzZgB4Oq/673ORq/84q2/2UFVVFR49etREkRMREVFr0qiR4+zsbOzfvx9DhgyBgYEBsrOzcefOHdjY2CAyMhIhISHQ1dXF0KFD8ejRI+Tk5ODevXuYPXs2vL29ERMTA09PT8TGxkIoFCI3NxdGRkZwdnbG3Llz4eXlBQcHB7i6umLXrl3Ytm0b9u3bp3B806ZNQ0JCAubOnYvAwECcOnWqUWvvhoSEQCQSIT4+HiNHjsTevXuRkZEhV6ahOF1cXPD2229jzJgxWL58OSwsLPDrr79CIBBg6NCh9bY/b948ODk5ITg4GIGBgdDU1EReXh5++ukn/Otf/1L4PmrTvn17zJw5E6tXr0a7du0QHBwMJyenBucbA0BoaCj8/Pzg6OgIkUiElJQUnD9/HmZmZi8UU2OYm5vL7f/3v/8F8DRxr55zPGLECEyZMgVr166Fm5sbioqKMGvWLLz55pswMjICAMTGxsLR0RHm5uZ49OgR0tPT8e2332Lt2rWv7F6IiIio5WrUyLGOjg5++eUXeHh4oEePHli4cCESEhLg7u6OwMBArFu3DuvXr4etrS1cXFyQnJwsGzlWUVFBZmYmDAwM4OHhAVtbW7lVHDw9PbFq1SrEx8ejV69eSExMxPr16+v8qrs2xsbG2Lp1K3bs2AF7e3t8+eWXiImJUfh6JycnJCUlYdWqVbC3t0dmZiYWLlwoV0aROLdu3Yr+/fvD29sbPXv2RFhYGCorKxts387ODocOHcKFCxcwaNAgODg4YNGiRbLE7kVoaGhg3rx5mDBhAkQiEbS0tLBp0yaFrh03bhzCw8MRFhaGfv364cqVK5g+ffoLx/Sy+fn5Yfny5fjXv/6F3r17Y+zYsbCyssK2bdtkZcrKyvDRRx+hV69eEIlE2Lp1K7777jsEBgY2Y+RERETUUjRqtQoi+t/TrlytgojaEq5WQa1dk6xWQURERET0OmtTybG7u7vcMmnPbo2ZftFa269Lr1696owrJSXllcQwbdq0OmP4+1JsRERERE2lTU2ruHHjBh4+fFjrOX19/TrXYH5d2q/LlStX8OTJk1rPVf9kdFO7fft2nb88p6OjAwMDgyaPQVGcVkFEbRGnVVBrp+i0ikatVtHadenSpU23X5e//9phczAwMGhRCTARERG1TW1qWgURERERUX2YHBMRERERSTE5JiIiIiKSalNzjolepnORbvVO6CciIqLWhyPHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIpLuRE9p96L90JJVaO5wyAiwuW4Yc0dAtFrgyPHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGR1GufHB88eBACgQDFxcXPdX1ycjL09PReakyvWlPcQ0REBPr06SPb9/Pzg6en50ttg4iIiOhVe+2TY3o1Vq1aheTk5Car/8yZM/D29ka3bt2grq4OGxsbrFq1Sq6Mn58fBAJBja1Xr16yMn/99RdmzZoFExMTqKurY+DAgTh58mSTxU1EREStC38hj14KXV3dJq3/1KlTMDAwwHfffYdu3brh6NGjmDp1KpSVlREcHAzgaYIeFxcnu6aiogL29vYYO3as7FhgYCDOnTuHb7/9FkZGRvjuu+/g6uqKvLw8dOnSpUnvgYiIiFq+Ro8cb9myBba2tlBXV0fHjh3h6uqKsrIyAMC6detgY2MDNTU1WFtb44svvpC79vr16/D29oa+vj40NTXh6OiI7Oxs2fm1a9fC3NwcKioqsLKywrfffit3vUAgwLp16zBq1ChoaGjA0tISaWlpcmXS09PRo0cPqKur45133sHly5cbdX/JyckwNjaGhoYGRo0ahT///LNGmYbiLC4uRlBQEAwNDaGmpobevXtj9+7dCrV/5MgRDBo0COrq6ujWrRtCQkJk/QsApqamiI6Oho+PD7S0tGBiYoK0tDTcuXMHI0eOhJaWFuzs7JCTk1Oj7h07dsDS0hJqampwc3PDtWvXFO6XuLg4GBoaQltbGwEBASgvL5c7//dpFYMHD8bMmTMxa9YsdOjQAYaGhkhKSkJZWRn8/f2hra0NCwsL7NmzR6H2J0+ejFWrVsHFxQVmZmaYOHEi/P39sW3bNlkZXV1ddO7cWbbl5OTg3r178Pf3BwA8fPgQW7duxWeffYa3334bFhYWiIiIgIWFBdauXatwXxAREdHrq1HJcVFREby9vTF58mTk5+fj4MGDGD16NCQSCVJSUrBo0SIsXboU+fn5iImJQXh4OL755hsAwP379+Hi4oIbN24gLS0NZ86cQVhYGKqqqgAA27dvR2hoKObMmYNz584hKCgI/v7+OHDggFwMkZGR8PLywtmzZ+Hh4YF//OMfuHv3LgDg2rVrGD16NEaMGAGxWIzAwEDMnz9f4fvLzs5GQEAAgoODIRaL8c477yA6OlquTENxVlVVwd3dHVlZWfjuu++Ql5eHuLg4KCsrN9h+YWEhhg4dijFjxuDs2bPYtGkTjhw5IhsZrbZixQqIRCLk5uZi2LBhmDRpEnx8fDBx4kScPn0a5ubm8PHxgUQikV3z4MEDLF26FBs2bEBWVhaKi4sxfvx4hfolNTUVERERiImJQU5ODoRCYY0/fGrzzTff4I033sCJEycwc+ZMTJ8+HWPHjsXAgQNx+vRpDBkyBJMmTcKDBw8UiuPvSkpKoK+vX+f5f//733B1dYWJiQmApyPJlZWVUFNTkyunrq6OI0eO1FnPo0ePUFpaKrcRERHR60kgeTaDasDp06fRr18/XL58WZZwVLOwsEBUVBS8vb1lx6Kjo5Geno6jR4/iq6++wscff4zLly/XmtCIRCL06tULX331leyYl5cXysrK8OOPPz4NViDAwoULERUVBQAoKyuDlpYW9uzZg6FDh+KTTz7Bzp07cf78eVkd8+fPx7Jly3Dv3r0GH0qbMGECSkpKZO0BwPjx45GRkSF7oK+hODMzM+Hu7o78/Hz06NGjgR6VFxgYCGVlZSQmJsqOHTlyBC4uLigrK4OamhpMTU0xaNAg2Wj1rVu3IBQKER4ejiVLlgAAjh8/DmdnZxQVFaFz585ITk6Gv78/jh8/jgEDBgAAfv31V9jY2CA7OxtvvvlmvXENHDgQDg4OWLNmjeyYk5MTysvLIRaLATwdOS4uLsaOHTsAPB05rqysxOHDhwEAlZWV0NXVxejRo7Fhwwa52I8dOwYnJ6dG9dXRo0fh4uKCH3/8EUOGDKlx/ubNmzA2NsbGjRvh5eUldy8qKirYuHEjDA0N8f3338PX1xcWFhYoKCiota2IiAhERkbWON5tViqUVDUaFTcRUVO4HDesuUMgavFKS0uhq6uLkpIS6Ojo1FmuUSPH9vb2eO+992Bra4uxY8ciKSkJ9+7dQ1lZGQoLCxEQEAAtLS3ZFh0djcLCQgCAWCyGg4NDnSN9+fn5EIlEcsdEIhHy8/PljtnZ2clea2pqQkdHB7dv35bVUZ38VXN2dlb4/hS5vqE4xWIxunbt2ujEGHj60FlycrJcH7q5uaGqqgq///67rNyzfWBoaAgAsLW1rXGsul8AoF27dujfv79s39raGnp6ejX6tzbP26/PxqmsrIyOHTs2GKcizp07h5EjR2Lx4sW1JsbA01FrPT29GitofPvtt5BIJOjSpQtUVVWxevVqeHt7Q0mp7v8UFixYgJKSEtnWmOkoRERE1Lo06oE8ZWVl/PTTTzh69CgyMzPx+eef49NPP8WuXbsAAElJSTWSqOrpBOrq6i8l4Pbt28vtCwQC2dSMluBF7vP+/fsICgpCSEhIjXPGxsay18/2gUAgqPNYc/dLbe/Vi8aZl5eH9957D1OnTsXChQtrLSORSPD1119j0qRJUFFRkTtnbm6OQ4cOoaysDKWlpRAKhRg3bhzMzMzqbFNVVRWqqqoKx0hEREStV6MfyBMIBBCJRIiMjERubi5UVFSQlZUFIyMj/Pbbb7CwsJDbunfvDuDpKKJYLJbND/47GxsbZGVlyR3LyspCz549FY7NxsYGJ06ckDt2/PjxRl3/7AOCtV3fUJx2dna4fv06Lly4oHC71fr27Yu8vLwafWhhYVEjyWusiooKuYf0CgoKUFxcDBsbmwavVaRfXoXz58/jnXfega+vL5YuXVpnuUOHDuHSpUsICAios4ympiaEQiHu3buHvXv3YuTIkU0RMhEREbUyjRo5zs7Oxv79+zFkyBAYGBggOzsbd+7cgY2NDSIjIxESEgJdXV0MHToUjx49kq0WMHv2bHh7eyMmJgaenp6IjY2FUChEbm4ujIyM4OzsjLlz58LLywsODg5wdXXFrl27sG3bNuzbt0/h+KZNm4aEhATMnTsXgYGBOHXqVKPW3g0JCYFIJEJ8fDxGjhyJvXv3IiMjQ65MQ3G6uLjg7bffxpgxY7B8+XJYWFjg119/hUAgwNChQ+ttf968eXByckJwcDACAwOhqamJvLw8/PTTT/jXv/6l8H3Upn379pg5cyZWr16Ndu3aITg4GE5OTg3ONwaA0NBQ+Pn5wdHRESKRCCkpKTh//ny9o60v27lz5/Duu+/Czc0Ns2fPxq1btwA8/WaiU6dOcmX//e9/Y8CAAejdu3eNevbu3QuJRAIrKytcunQJc+fOhbW1tWxFCyIiImrbGjVyrKOjg19++QUeHh7o0aMHFi5ciISEBLi7uyMwMBDr1q3D+vXrYWtrCxcXFyQnJ8tGjlVUVJCZmQkDAwN4eHjA1tZWbhUHT09PrFq1CvHx8ejVqxcSExOxfv16DB48WOH4jI2NsXXrVuzYsQP29vb48ssvERMTo/D1Tk5OSEpKwqpVq2Bvb4/MzMwaX90rEufWrVvRv39/eHt7o2fPnggLC0NlZWWD7dvZ2eHQoUO4cOECBg0aBAcHByxatAhGRkYK30NdNDQ0MG/ePEyYMAEikQhaWlrYtGmTQteOGzcO4eHhCAsLQ79+/XDlyhVMnz79hWNqjC1btuDOnTv47rvvIBQKZduz86iBpytYbN26tc5R45KSEsyYMQPW1tbw8fHBW2+9hb1799aYAkJERERtU6NWqyCi/z3tytUqiKil4GoVRA1rktUqiIiIiIheZ20qOXZ3d5dbJu3ZrTHTL1pr+3Xp1atXnXGlpKS8khimTZtWZwzTpk17JTEQERERtalpFTdu3MDDhw9rPaevr1/vr629Du3X5cqVK3jy5Emt56p/Mrqp3b59u85fntPR0YGBgUGTx6AoTqsgopaG0yqIGqbotIpGrVbR2nXp0qVNt1+Xv//aYXMwMDBoUQkwERERtU1taloFEREREVF9mBwTEREREUkxOSYiIiIikmpTc46JXqZzkW71TugnIiKi1ocjx0REREREUkyOiYiIiIikmBwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKS7kRPafei/dCSVWjucMgotfE5bhhzR0CEYEjx0REREREMkyOiYiIiIikmBwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKyTERERERkRSTYyIiIiIiqRaTHEskEkydOhX6+voQCATQ09PDrFmzmjssREREoE+fPs0dxgtpinvw8/ODp6enbH/w4MEt4v0iIiIiehEtJjnOyMhAcnIydu/ejaKiIly4cAFRUVEvVKdAIMCOHTteToBUr23btr3w+9UQiUSC+Ph49OjRA6qqqujSpQuWLl1aa9msrCy0a9euxh8Ff/31F2bNmgUTExOoq6tj4MCBOHnyZJPGTURERK1Hi/n56MLCQgiFQgwcOFCh8o8fP4aKikoTR0WK0tfXb/I2QkNDkZmZifj4eNja2uLu3bu4e/dujXLFxcXw8fHBe++9hz/++EPuXGBgIM6dO4dvv/0WRkZG+O677+Dq6oq8vDx06dKlye+BiIiIWrYWMXLs5+eHmTNn4urVqxAIBDA1Na3xNb2pqSmioqLg4+MDHR0dTJ06FY8fP0ZwcDCEQiHU1NRgYmKC2NhYWXkAGDVqlKxORcTFxcHQ0BDa2toICAhAeXm53PmqqiosWbIEXbt2haqqKvr06YOMjAy5MtevX4e3tzf09fWhqakJR0dHZGdnK9T+zp070bdvX6ipqcHMzAyRkZGoqKiQnRcIBEhMTMTw4cOhoaEBGxsbHDt2DJcuXcLgwYOhqamJgQMHorCwsEbdiYmJ6NatGzQ0NODl5YWSkhKFYqqsrMTs2bOhp6eHjh07IiwsDBKJRK5Mbe9XdHQ0fHx8oKWlBRMTE6SlpeHOnTsYOXIktLS0YGdnh5ycHIViyM/Px9q1a7Fz50588MEH6N69O/r164f333+/Rtlp06ZhwoQJcHZ2ljv+8OFDbN26FZ999hnefvttWFhYICIiAhYWFli7dq1CcRAREdHrrUUkx6tWrZIlnEVFRXV+zR0fHw97e3vk5uYiPDwcq1evRlpaGlJTU1FQUICUlBRZElxdx/r16+ut81mpqamIiIhATEwMcnJyIBQK8cUXX9SINSEhAfHx8Th79izc3NzwwQcf4OLFiwCA+/fvw8XFBTdu3EBaWhrOnDmDsLAwVFVVNdj+4cOH4ePjg9DQUOTl5SExMRHJyck1pg5U/5EgFothbW2NCRMmICgoCAsWLEBOTg4kEgmCg4Plrrl06RJSU1Oxa9cuZGRkIDc3Fx999FGDMQFAQkICkpOT8fXXX+PIkSO4e/cutm/f3uB1K1asgEgkQm5uLoYNG4ZJkybBx8cHEydOxOnTp2Fubg4fH58aiXZtdu3aBTMzM+zevRvdu3eHqakpAgMDa4wcr1+/Hr/99hsWL15co46KigpUVlZCTU1N7ri6ujqOHDlSZ9uPHj1CaWmp3EZERESvpxYxrUJXVxfa2tpQVlZG586d6yz37rvvYs6cObL9q1evwtLSEm+99RYEAgFMTExk5zp16gQA0NPTq7fOZ61cuRIBAQEICAgAAERHR2Pfvn1yo8fx8fGYN28exo8fDwBYtmwZDhw4gJUrV2LNmjXYuHEj7ty5g5MnT8qmGlhYWCjUfmRkJObPnw9fX18AgJmZGaKiohAWFiaX7Pn7+8PLywsAMG/ePDg7OyM8PBxubm4Ank4/8Pf3l6u7vLwcGzZskE0d+PzzzzFs2DAkJCQ02D8rV67EggULMHr0aADAl19+ib179zZ4Px4eHggKCgIALFq0CGvXrkX//v0xduxYudj/+OOPBmP47bffcOXKFWzevBkbNmxAZWUl/vnPf+LDDz/Ezz//DAC4ePEi5s+fj8OHD6Ndu5ofbW1tbTg7OyMqKgo2NjYwNDTE999/j2PHjtX7HsXGxiIyMrLB+yUiIqLWr0WMHCvK0dFRbt/Pzw9isRhWVlYICQlBZmbmC9Wfn5+PAQMGyB179qv50tJS3Lx5EyKRSK6MSCRCfn4+AEAsFsPBweG55uCeOXMGS5YsgZaWlmybMmUKioqK8ODBA1k5Ozs72WtDQ0MAgK2trdyx8vJyuRFOY2NjuTm1zs7OqKqqQkFBQb0xlZSUoKioSK5f2rVrV+O9qI0icQLA7du3G6yrqqoKjx49woYNGzBo0CAMHjwY//73v3HgwAEUFBSgsrISEyZMQGRkJHr06FFnPd9++y0kEgm6dOkCVVVVrF69Gt7e3lBSqvs/hQULFqCkpES2Xbt2rcF4iYiIqHVqESPHitLU1JTb79u3L37//Xfs2bMH+/btg5eXF1xdXbFly5ZmivDpV/TP6/79+4iMjJSN0D7r2akA7du3l70WCAR1HlNkKkdTeplxCoVCtGvXTi7xtbGxAfD0GwRDQ0Pk5OQgNzdXNqWkqqoKEokE7dq1Q2ZmJt59912Ym5vj0KFDKCsrQ2lpKYRCIcaNGwczM7M621ZVVYWqqmoj7pyIiIhaq1Y1clwbHR0djBs3DklJSdi0aRO2bt0qm4favn17VFZWKlyXjY1NjQfnjh8/LteWkZERsrKy5MpkZWWhZ8+eAJ6OlorF4lpXUWhI3759UVBQAAsLixpbfSObirh69Spu3rwp2z9+/DiUlJRgZWVV73W6uroQCoVy/VJRUYFTp069UDyNJRKJUFFRIfeg4YULFwAAJiYm0NHRwX/+8x+IxWLZNm3aNFhZWUEsFtf4RkBTUxNCoRD37t3D3r17MXLkyFd6P0RERNQytaqR479bvnw5hEIhHBwcoKSkhM2bN6Nz587Q09MD8HTFhP3790MkEkFVVRUdOnSot77Q0FD4+fnB0dERIpEIKSkpOH/+vNyo4ty5c7F48WKYm5ujT58+WL9+PcRiMVJSUgAA3t7eiImJgaenJ2JjYyEUCpGbmwsjI6Maqyf83aJFizB8+HAYGxvjww8/hJKSEs6cOYNz584hOjr6hfpKTU0Nvr6+iI+PR2lpKUJCQuDl5aXQfOzQ0FDExcXB0tIS1tbWWL58OYqLi18onsZydXVF3759MXnyZKxcuRJVVVWYMWMG3n//fdlocu/eveWuMTAwgJqamtzxvXv3QiKRwMrKCpcuXcLcuXNhbW1dY442ERERtU2teuRYW1sbn332GRwdHdG/f39cvnwZ6enpslHWhIQE/PTTT+jWrRscHBwarG/cuHEIDw9HWFgY+vXrhytXrmD69OlyZUJCQjB79mzMmTMHtra2yMjIQFpaGiwtLQEAKioqyMzMhIGBATw8PGBra4u4uDgoKys32L6bmxt2796NzMxM9O/fH05OTlixYoXcg4bPy8LCAqNHj4aHhweGDBkCOzu7Gitx1GXOnDmYNGkSfH194ezsDG1tbYwaNeqFY2oMJSUl7Nq1C2+88QbefvttDBs2DDY2Nvjhhx8aVU9JSQlmzJgBa2tr+Pj44K233sLevXvlpnsQERFR2yWQKLKOFhHJlJaWQldXF91mpUJJVaO5wyGi18TluGHNHQLRa6363++SkhLo6OjUWa5VjxwTEREREb1MbSo57tWrl9wyac9u1XOGX+f261JXTFpaWjh8+PAricHd3b3OGGJiYl5JDERERESt+oG8xkpPT8eTJ09qPVe95u7r3H5dxGJxneeeXRu5Ka1btw4PHz6s9dzzrBlNRERE9DzaVHL8Mh5sa83t10XRX/BrSq8qCSciIiKqT5uaVkFEREREVB8mx0REREREUm1qWgXRy3Qu0q3epWCIiIio9eHIMRERERGRFJNjIiIiIiIpJsdERERERFJMjomIiIiIpJgcExERERFJMTkmIiIiIpLiUm5Ez6n34r1QUtVo7jCIqJlcjhvW3CEQURPgyDERERERkRSTYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISOq1T44PHjwIgUCA4uLi57o+OTkZenp6LzWmV60p7iEiIgJ9+vSR7fv5+cHT0/OltkFERET0qr32yTG9GqtWrUJycnKT1X/mzBl4e3ujW7duUFdXh42NDVatWlWjXEpKCuzt7aGhoQGhUIjJkyfjzz//lJ1PTk6GQCCQ29TU1JosbiIiImpd+PPR9FLo6uo2af2nTp2CgYEBvvvuO3Tr1g1Hjx7F1KlToaysjODgYABAVlYWfHx8sGLFCowYMQI3btzAtGnTMGXKFGzbtk1Wl46ODgoKCmT7AoGgSWMnIiKi1qPRI8dbtmyBra0t1NXV0bFjR7i6uqKsrAwAsG7dOtjY2EBNTQ3W1tb44osv5K69fv06vL29oa+vD01NTTg6OiI7O1t2fu3atTA3N4eKigqsrKzw7bffyl0vEAiwbt06jBo1ChoaGrC0tERaWppcmfT0dPTo0QPq6up45513cPny5UbdX3JyMoyNjaGhoYFRo0bJjToqGmdxcTGCgoJgaGgINTU19O7dG7t371ao/SNHjmDQoEFQV1dHt27dEBISIutfADA1NUV0dDR8fHygpaUFExMTpKWl4c6dOxg5ciS0tLRgZ2eHnJycGnXv2LEDlpaWUFNTg5ubG65du6Zwv8TFxcHQ0BDa2toICAhAeXm53Pm/T6sYPHgwZs6ciVmzZqFDhw4wNDREUlISysrK4O/vD21tbVhYWGDPnj0KtT958mSsWrUKLi4uMDMzw8SJE+Hv7y+X9B47dgympqYICQlB9+7d8dZbbyEoKAgnTpyQq0sgEKBz586yzdDQUOF+ICIiotdbo5LjoqIieHt7Y/LkycjPz8fBgwcxevRoSCQSpKSkYNGiRVi6dCny8/MRExOD8PBwfPPNNwCA+/fvw8XFBTdu3EBaWhrOnDmDsLAwVFVVAQC2b9+O0NBQzJkzB+fOnUNQUBD8/f1x4MABuRgiIyPh5eWFs2fPwsPDA//4xz9w9+5dAMC1a9cwevRojBgxAmKxGIGBgZg/f77C95ednY2AgAAEBwdDLBbjnXfeQXR0tFyZhuKsqqqCu7s7srKy8N133yEvLw9xcXFQVlZusP3CwkIMHToUY8aMwdmzZ7Fp0yYcOXJENjJabcWKFRCJRMjNzcWwYcMwadIk+Pj4YOLEiTh9+jTMzc3h4+MDiUQiu+bBgwdYunQpNmzYgKysLBQXF2P8+PEK9UtqaioiIiIQExODnJwcCIXCGn/41Oabb77BG2+8gRMnTmDmzJmYPn06xo4di4EDB+L06dMYMmQIJk2ahAcPHigUx9+VlJRAX19ftu/s7Ixr164hPT0dEokEf/zxB7Zs2QIPDw+56+7fvw8TExN069YNI0eOxPnz5+tt59GjRygtLZXbiIiI6PUkkDybQTXg9OnT6NevHy5fvgwTExO5cxYWFoiKioK3t7fsWHR0NNLT03H06FF89dVX+Pjjj3H58mW5hKaaSCRCr1698NVXX8mOeXl5oaysDD/++OPTYAUCLFy4EFFRUQCAsrIyaGlpYc+ePRg6dCg++eQT7Ny5Uy7ZmT9/PpYtW4Z79+41+FDahAkTUFJSImsPAMaPH4+MjAzZA30NxZmZmQl3d3fk5+ejR48eDfSovMDAQCgrKyMxMVF27MiRI3BxcUFZWRnU1NRgamqKQYMGyUarb926BaFQiPDwcCxZsgQAcPz4cTg7O6OoqAidO3dGcnIy/P39cfz4cQwYMAAA8Ouvv8LGxgbZ2dl48803641r4MCBcHBwwJo1a2THnJycUF5eDrFYDODpyHFxcTF27NgB4OnIcWVlJQ4fPgwAqKyshK6uLkaPHo0NGzbIxX7s2DE4OTk1qq+OHj0KFxcX/PjjjxgyZIjs+ObNmzF58mSUl5ejoqICI0aMwNatW9G+fXsAT0eXL168CDs7O5SUlCA+Ph6//PILzp8/j65du9baVkREBCIjI2sc7zYrFUqqGo2Km4heH5fjhjV3CETUCKWlpdDV1UVJSQl0dHTqLNeokWN7e3u89957sLW1xdixY5GUlIR79+6hrKwMhYWFCAgIgJaWlmyLjo5GYWEhAEAsFsPBwaHWxBgA8vPzIRKJ5I6JRCLk5+fLHbOzs5O91tTUhI6ODm7fvi2rozr5q+bs7Kzw/SlyfUNxisVidO3atdGJMfD0obPk5GS5PnRzc0NVVRV+//13Wbln+6B6SoCtrW2NY9X9AgDt2rVD//79ZfvW1tbQ09Or0b+1ed5+fTZOZWVldOzYscE4FXHu3DmMHDkSixcvlkuM8/LyEBoaikWLFuHUqVPIyMjA5cuXMW3aNLm4fXx80KdPH7i4uGDbtm3o1KmT3B8kf7dgwQKUlJTItsZMRyEiIqLWpVEP5CkrK+Onn37C0aNHkZmZic8//xyffvopdu3aBQBISkqqkURVTydQV1d/KQFXjwBWEwgEsqkZLcGL3Of9+/cRFBSEkJCQGueMjY1lr5/tg+qHyWo71tz9Utt79aJx5uXl4b333sPUqVOxcOFCuXOxsbEQiUSYO3cugKfJuaamJgYNGoTo6GgIhcJaY3RwcMClS5fqbFNVVRWqqqoKx0hEREStV6MfyBMIBBCJRIiMjERubi5UVFSQlZUFIyMj/Pbbb7CwsJDbunfvDuBpoiIWi2Xzg//OxsYGWVlZcseysrLQs2dPhWOzsbGp8fDV8ePHG3X9sw8I1nZ9Q3Ha2dnh+vXruHDhgsLtVuvbty/y8vJq9KGFhQVUVFQaXd+zKioq5B7SKygoQHFxMWxsbBq8VpF+eRXOnz+Pd955B76+vli6dGmN8w8ePICSkvxHuvqPs7pmD1VWVuI///lPrYkzERERtT2NGjnOzs7G/v37MWTIEBgYGCA7Oxt37tyBjY0NIiMjERISAl1dXQwdOhSPHj1CTk4O7t27h9mzZ8Pb2xsxMTHw9PREbGwshEIhcnNzYWRkBGdnZ8ydOxdeXl5wcHCAq6srdu3ahW3btmHfvn0Kxzdt2jQkJCRg7ty5CAwMxKlTpxq19m5ISAhEIhHi4+MxcuRI7N27FxkZGXJlGorTxcUFb7/9NsaMGYPly5fDwsICv/76KwQCAYYOHVpv+/PmzYOTkxOCg4MRGBgITU1N5OXl4aeffsK//vUvhe+jNu3bt8fMmTOxevVqtGvXDsHBwXBycmpwvjEAhIaGws/PD46OjhCJREhJScH58+dhZmb2QjE1xrlz5/Duu+/Czc0Ns2fPxq1btwA8TX47deoEABgxYgSmTJmCtWvXws3NDUVFRZg1axbefPNNGBkZAQCWLFkCJycnWFhYoLi4GP/3f/+HK1euIDAw8JXdCxEREbVcjRo51tHRwS+//AIPDw/06NEDCxcuREJCAtzd3REYGIh169Zh/fr1sLW1hYuLC5KTk2UjxyoqKsjMzISBgQE8PDxga2srt4qDp6cnVq1ahfj4ePTq1QuJiYlYv349Bg8erHB8xsbG2Lp1K3bs2AF7e3t8+eWXiImJUfh6JycnJCUlYdWqVbC3t0dmZmaNr+4ViXPr1q3o378/vL290bNnT4SFhaGysrLB9u3s7HDo0CFcuHABgwYNgoODAxYtWiRL7F6EhoYG5s2bhwkTJkAkEkFLSwubNm1S6Npx48YhPDwcYWFh6NevH65cuYLp06e/cEyNsWXLFty5cwffffcdhEKhbHt2HrWfnx+WL1+Of/3rX+jduzfGjh0LKysrueXe7t27hylTpsDGxgYeHh4oLS3F0aNHG/UNBREREb2+GrVaBRH972lXrlZB1LZxtQqi1qVJVqsgIiIiInqdtank2N3dXW6ZtGe3xky/aK3t16VXr151xpWSkvJKYpg2bVqdMTy7FBsRERFRU2pT0ypu3LiBhw8f1npOX1+/zjWYX5f263LlyhU8efKk1nPVPxnd1G7fvl3nL8/p6OjAwMCgyWNQFKdVEBHAaRVErY2i0yoatVpFa9elS5c23X5d/v5rh83BwMCgRSXARERE1Da1qWkVRERERET1YXJMRERERCTF5JiIiIiISKpNzTkmepnORbrVO6GfiIiIWh+OHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGRFFerIHpOvRfv5c9HE7Vh/PlootcTR46JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFItJjmWSCSYOnUq9PX1IRAIoKenh1mzZjV3WIiIiECfPn2aO4wX0hT34OfnB09PT9n+4MGDW8T7RURERPQiWkxynJGRgeTkZOzevRtFRUW4cOECoqKiXqhOgUCAHTt2vJwAqV7btm174ferPuXl5fDz84OtrS3atWsnl5g/G8P777+PTp06QUdHB87Ozti7d69cmdjYWPTv3x/a2towMDCAp6cnCgoKmixuIiIial1aTHJcWFgIoVCIgQMHonPnzjAwMIC2tnad5R8/fvwKo6OG6Ovr1/t+vajKykqoq6sjJCQErq6utZb55Zdf8P777yM9PR2nTp3CO++8gxEjRiA3N1dW5tChQ5gxYwaOHz+On376CU+ePMGQIUNQVlbWZLETERFR69EikmM/Pz/MnDkTV69ehUAggKmpaY2v6U1NTREVFQUfHx/o6Ohg6tSpePz4MYKDgyEUCqGmpgYTExPExsbKygPAqFGjZHUqIi4uDoaGhtDW1kZAQADKy8vlzldVVWHJkiXo2rUrVFVV0adPH2RkZMiVuX79Ory9vaGvrw9NTU04OjoiOztbofZ37tyJvn37Qk1NDWZmZoiMjERFRYXsvEAgQGJiIoYPHw4NDQ3Y2Njg2LFjuHTpEgYPHgxNTU0MHDgQhYWFNepOTExEt27doKGhAS8vL5SUlCgUU2VlJWbPng09PT107NgRYWFhkEgkcmVqe7+io6Ph4+MDLS0tmJiYIC0tDXfu3MHIkSOhpaUFOzs75OTkKBSDpqYm1q5diylTpqBz5861llm5ciXCwsLQv39/WFpaIiYmBpaWlti1a5esTEZGBvz8/NCrVy/Y29sjOTkZV69exalTpxSKg4iIiF5vLSI5XrVqlSzhLCoqwsmTJ2stFx8fD3t7e+Tm5iI8PByrV69GWloaUlNTUVBQgJSUFFkSXF3H+vXr663zWampqYiIiEBMTAxycnIgFArxxRdf1Ig1ISEB8fHxOHv2LNzc3PDBBx/g4sWLAID79+/DxcUFN27cQFpaGs6cOYOwsDBUVVU12P7hw4fh4+OD0NBQ5OXlITExEcnJyVi6dKlcueo/EsRiMaytrTFhwgQEBQVhwYIFyMnJgUQiQXBwsNw1ly5dQmpqKnbt2oWMjAzk5ubio48+ajAmAEhISEBycjK+/vprHDlyBHfv3sX27dsbvG7FihUQiUTIzc3FsGHDMGnSJPj4+GDixIk4ffo0zM3N4ePjUyPRflmqqqrw119/QV9fv84y1X8g1Ffm0aNHKC0tlduIiIjo9dSuuQMAAF1dXWhra0NZWbnOUUEAePfddzFnzhzZ/tWrV2FpaYm33noLAoEAJiYmsnOdOnUCAOjp6dVb57NWrlyJgIAABAQEAACio6Oxb98+udHj+Ph4zJs3D+PHjwcALFu2DAcOHMDKlSuxZs0abNy4EXfu3MHJkydlCZeFhYVC7UdGRmL+/Pnw9fUFAJiZmSEqKgphYWFYvHixrJy/vz+8vLwAAPPmzYOzszPCw8Ph5uYGAAgNDYW/v79c3eXl5diwYQO6dOkCAPj8888xbNgwJCQkNNg/K1euxIIFCzB69GgAwJdfflljLm9tPDw8EBQUBABYtGgR1q5di/79+2Ps2LFysf/xxx8Kv0eNER8fj/v378v66u+qqqowa9YsiEQi9O7du856YmNjERkZ+dLjIyIiopanRYwcK8rR0VFu38/PD2KxGFZWVggJCUFmZuYL1Z+fn48BAwbIHXN2dpa9Li0txc2bNyESieTKiEQi5OfnAwDEYjEcHBzqHYmsy5kzZ7BkyRJoaWnJtilTpqCoqAgPHjyQlbOzs5O9NjQ0BADY2trKHSsvL5cb4TQ2NpYlxtX3VVVV1eDDaCUlJSgqKpLrl3bt2tV4L2qjSJwAcPv27QbraqyNGzciMjISqampMDAwqLXMjBkzcO7cOfzwww/11rVgwQKUlJTItmvXrr30eImIiKhlaBEjx4rS1NSU2+/bty9+//137NmzB/v27YOXlxdcXV2xZcuWZooQUFdXf+5r79+/j8jISNkI7bPU1NRkr9u3by97LRAI6jymyFSOptRccf7www8IDAzE5s2b63x4Lzg4GLt378Yvv/yCrl271lufqqoqVFVVX2qMRERE1DK1qpHj2ujo6GDcuHFISkrCpk2bsHXrVty9exfA00SssrJS4bpsbGxqPDh3/PhxubaMjIyQlZUlVyYrKws9e/YE8HS0VCwWy2JojL59+6KgoAAWFhY1NiWlF3urrl69ips3b8r2jx8/DiUlJVhZWdV7na6uLoRCoVy/VFRUtNgH2L7//nv4+/vj+++/x7Bhw2qcr56PvX37dvz888/o3r17M0RJRERELVWrGjn+u+XLl0MoFMLBwQFKSkrYvHkzOnfuDD09PQBPV0zYv38/RCIRVFVV0aFDh3rrCw0NhZ+fHxwdHSESiZCSkoLz58/DzMxMVmbu3LlYvHgxzM3N0adPH6xfvx5isRgpKSkAAG9vb8TExMDT0xOxsbEQCoXIzc2FkZGR3BSN2ixatAjDhw+HsbExPvzwQygpKeHMmTM4d+4coqOjX6iv1NTU4Ovri/j4eJSWliIkJAReXl4KzfUNDQ1FXFwcLC0tYW1tjeXLl6O4uPiF4nkeeXl5ePz4Me7evYu//voLYrEYAGQ/cLJx40b4+vpi1apVGDBgAG7dugXg6Wi+rq4ugKdTKTZu3IidO3dCW1tbVkZXV/eFRv2JiIjo9dCqk2NtbW189tlnuHjxIpSVldG/f3+kp6fLRlkTEhIwe/ZsJCUloUuXLrh8+XK99Y0bNw6FhYUICwtDeXk5xowZg+nTp8s9fBYSEoKSkhLMmTMHt2/fRs+ePZGWlgZLS0sAgIqKCjIzMzFnzhx4eHigoqICPXv2xJo1axq8Hzc3N+zevRtLlizBsmXL0L59e1hbWyMwMPD5O0nKwsICo0ePhoeHB+7evYvhw4fXWImjLnPmzEFRURF8fX2hpKSEyZMnY9SoUQovBfeyeHh44MqVK7J9BwcHAJCtdvHVV1+hoqICM2bMwIwZM2TlfH19kZycDABYu3YtgKdLzz1r/fr18PPza7rgiYiIqFUQSJpqHS2i11RpaSl0dXXRbVYqlFQ1mjscImoml+NqTt0iopar+t/vkpIS6Ojo1Fmu1c85JiIiIiJ6WdpUctyrVy+5ZdKe3arnDL/O7delrpi0tLRw+PDhVxKDu7t7nTHExMS8khiIiIiIWvWc48ZKT0/HkydPaj1Xvebu69x+XaofbKvNs2sjN6V169bh4cOHtZ57njWjiYiIiJ5Hm0qOn/0FvbbYfl0U/QW/pvSqknAiIiKi+rSpaRVERERERPVhckxEREREJMXkmIiIiIhIqk3NOSZ6mc5FutW7TiIRERG1Phw5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFJcyo3oOfVevBdKqhrNHQYRKehy3LDmDoGIWgGOHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFKtKjmWSCSYOnUq9PX1IRAIoKenh1mzZjV3WIiIiECfPn2aO4wX0hT34OfnB09PT9n+4MGDW8T7RURERFSXVpUcZ2RkIDk5Gbt370ZRUREuXLiAqKioF6pTIBBgx44dLydAqte2bdte+P2qT3l5Ofz8/GBra4t27drJJebPxvD++++jU6dO0NHRgbOzM/bu3dtkMREREVHr0qqS48LCQgiFQgwcOBCdO3eGgYEBtLW16yz/+PHjVxgdNURfX7/e9+tFVVZWQl1dHSEhIXB1da21zC+//IL3338f6enpOHXqFN555x2MGDECubm5TRYXERERtR6tJjn28/PDzJkzcfXqVQgEApiamtb4mt7U1BRRUVHw8fGBjo4Opk6disePHyM4OBhCoRBqamowMTFBbGysrDwAjBo1SlanIuLi4mBoaAhtbW0EBASgvLxc7nxVVRWWLFmCrl27QlVVFX369EFGRoZcmevXr8Pb2xv6+vrQ1NSEo6MjsrOzFWp/586d6Nu3L9TU1GBmZobIyEhUVFTIzgsEAiQmJmL48OHQ0NCAjY0Njh07hkuXLmHw4MHQ1NTEwIEDUVhYWKPuxMREdOvWDRoaGvDy8kJJSYlCMVVWVmL27NnQ09NDx44dERYWBolEIlemtvcrOjoaPj4+0NLSgomJCdLS0nDnzh2MHDkSWlpasLOzQ05OjkIxaGpqYu3atZgyZQo6d+5ca5mVK1ciLCwM/fv3h6WlJWJiYmBpaYldu3Yp1AYRERG93lpNcrxq1SpZwllUVISTJ0/WWi4+Ph729vbIzc1FeHg4Vq9ejbS0NKSmpqKgoAApKSmyJLi6jvXr19db57NSU1MRERGBmJgY5OTkQCgU4osvvqgRa0JCAuLj43H27Fm4ubnhgw8+wMWLFwEA9+/fh4uLC27cuIG0tDScOXMGYWFhqKqqarD9w4cPw8fHB6GhocjLy0NiYiKSk5OxdOlSuXLVfySIxWJYW1tjwoQJCAoKwoIFC5CTkwOJRILg4GC5ay5duoTU1FTs2rULGRkZyM3NxUcffdRgTACQkJCA5ORkfP311zhy5Aju3r2L7du3N3jdihUrIBKJkJubi2HDhmHSpEnw8fHBxIkTcfr0aZibm8PHx6dGov2yVFVV4a+//oK+vn6dZR49eoTS0lK5jYiIiF5P7Zo7AEXp6upCW1sbysrKdY4KAsC7776LOXPmyPavXr0KS0tLvPXWWxAIBDAxMZGd69SpEwBAT0+v3jqftXLlSgQEBCAgIAAAEB0djX379smNHsfHx2PevHkYP348AGDZsmU4cOAAVq5ciTVr1mDjxo24c+cOTp48KUvKLCwsFGo/MjIS8+fPh6+vLwDAzMwMUVFRCAsLw+LFi2Xl/P394eXlBQCYN28enJ2dER4eDjc3NwBAaGgo/P395eouLy/Hhg0b0KVLFwDA559/jmHDhiEhIaHB/lm5ciUWLFiA0aNHAwC+/PJLhebyenh4ICgoCACwaNEirF27Fv3798fYsWPlYv/jjz8Ufo8aIz4+Hvfv35f1VW1iY2MRGRn50tsmIiKilqfVjBwrytHRUW7fz88PYrEYVlZWCAkJQWZm5gvVn5+fjwEDBsgdc3Z2lr0uLS3FzZs3IRKJ5MqIRCLk5+cDAMRiMRwcHOodrazLmTNnsGTJEmhpacm2KVOmoKioCA8ePJCVs7Ozk702NDQEANja2sodKy8vlxsFNTY2liXG1fdVVVWFgoKCemMqKSlBUVGRXL+0a9euxntRG0XiBIDbt283WFdjbdy4EZGRkUhNTYWBgUGd5RYsWICSkhLZdu3atZceCxEREbUMrWbkWFGamppy+3379sXvv/+OPXv2YN++ffDy8oKrqyu2bNnSTBEC6urqz33t/fv3ERkZKRuhfZaamprsdfv27WWvBQJBnccUmcrRlJorzh9++AGBgYHYvHlznQ/vVVNVVYWqqupLbZ+IiIhaptdu5Lg2Ojo6GDduHJKSkrBp0yZs3boVd+/eBfA0EausrFS4LhsbmxoPzh0/flyuLSMjI2RlZcmVycrKQs+ePQE8HS0Vi8WyGBqjb9++KCgogIWFRY1NSenF3s6rV6/i5s2bsv3jx49DSUkJVlZW9V6nq6sLoVAo1y8VFRU4derUC8XTVL7//nv4+/vj+++/x7Bhw5o7HCIiImpBXruR479bvnw5hEIhHBwcoKSkhM2bN6Nz587Q09MD8HTFhP3790MkEkFVVRUdOnSot77Q0FD4+fnB0dERIpEIKSkpOH/+PMzMzGRl5s6di8WLF8Pc3Bx9+vTB+vXrIRaLkZKSAgDw9vZGTEwMPD09ERsbC6FQiNzcXBgZGclN0ajNokWLMHz4cBgbG+PDDz+EkpISzpw5g3PnziE6OvqF+kpNTQ2+vr6Ij49HaWkpQkJC4OXlpdBc39DQUMTFxcHS0hLW1tZYvnw5iouLXyie55GXl4fHjx/j7t27+OuvvyAWiwFA9gMnGzduhK+vL1atWoUBAwbg1q1bAJ6O5uvq6r7yeImIiKhlee2TY21tbXz22We4ePEilJWV0b9/f6Snp8tGWRMSEjB79mwkJSWhS5cuuHz5cr31jRs3DoWFhQgLC0N5eTnGjBmD6dOnyz18FhISgpKSEsyZMwe3b99Gz549kZaWBktLSwCAiooKMjMzMWfOHHh4eKCiogI9e/bEmjVrGrwfNzc37N69G0uWLMGyZcvQvn17WFtbIzAw8Pk7ScrCwgKjR4+Gh4cH7t69i+HDh9dYiaMuc+bMQVFREXx9faGkpITJkydj1KhRCi8F97J4eHjgypUrsn0HBwcAkK128dVXX6GiogIzZszAjBkzZOV8fX2RnJz8SmMlIiKilkcgaao1soheU6WlpdDV1UW3WalQUtVo7nCISEGX4ziNiqgtq/73u6SkBDo6OnWWaxNzjomIiIiIFMHk+G969eolt0zas1v1nOHXuf261BWTlpYWDh8+/EpicHd3rzOGmJiYVxIDERERvd5e+znHjZWeno4nT57Ueq56zd3Xuf26VD/YVptn10ZuSuvWrcPDhw9rPfc8a0YTERER/R2T47959hf02mL7dVH0F/ya0qtKwomIiKjt4rQKIiIiIiIpJsdERERERFJMjomIiIiIpDjnmOg5nYt0q3edRCIiImp9OHJMRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFJMjomIiIiIpLiUG9Fz6r14L5RUNZo7DCKSuhw3rLlDIKLXAEeOiYiIiIikmBwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKyTERERERkRSTYyIiIiIiKSbHRERERERSr31yfPDgQQgEAhQXFz/X9cnJydDT03upMb1qTXEPERER6NOnj2zfz88Pnp6eL7UNIiIiolfttU+O6dVYtWoVkpOTm7SNkJAQ9OvXD6qqqnKJ+bP27t0LJycnaGtro1OnThgzZgwuX74sV2bNmjWwsbGBuro6rKyssGHDhiaNm4iIiFoPJsf0Uujq6r6SEfbJkydj3LhxtZ77/fffMXLkSLz77rsQi8XYu3cv/vvf/2L06NGyMmvXrsWCBQsQERGB8+fPIzIyEjNmzMCuXbuaPHYiIiJq+RqdHG/ZsgW2trZQV1dHx44d4erqirKyMgDAunXrYGNjAzU1NVhbW+OLL76Qu/b69evw9vaGvr4+NDU14ejoiOzsbNn5tWvXwtzcHCoqKrCyssK3334rd71AIMC6deswatQoaGhowNLSEmlpaXJl0tPT0aNHD6irq+Odd96pMWrYkOTkZBgbG0NDQwOjRo3Cn3/+WaNMQ3EWFxcjKCgIhoaGUFNTQ+/evbF7926F2j9y5AgGDRoEdXV1dOvWDSEhIbL+BQBTU1NER0fDx8cHWlpaMDExQVpaGu7cuYORI0dCS0sLdnZ2yMnJqVH3jh07YGlpCTU1Nbi5ueHatWsK90tcXBwMDQ2hra2NgIAAlJeXy53/+7SKwYMHY+bMmZg1axY6dOgAQ0NDJCUloaysDP7+/tDW1oaFhQX27NmjcAyrV6/GjBkzYGZmVuv5U6dOobKyEtHR0TA3N0ffvn3x8ccfQywW48mTJwCAb7/9FkFBQRg3bhzMzMwwfvx4TJ06FcuWLVM4DiIiInp9NSo5Lioqgre3NyZPnoz8/HwcPHgQo0ePhkQiQUpKChYtWoSlS5ciPz8fMTExCA8PxzfffAMAuH//PlxcXHDjxg2kpaXhzJkzCAsLQ1VVFQBg+/btCA0NxZw5c3Du3DkEBQXB398fBw4ckIshMjISXl5eOHv2LDw8PPCPf/wDd+/eBQBcu3YNo0ePxogRIyAWixEYGIj58+crfH/Z2dkICAhAcHAwxGIx3nnnHURHR8uVaSjOqqoquLu7IysrC9999x3y8vIQFxcHZWXlBtsvLCzE0KFDMWbMGJw9exabNm3CkSNHEBwcLFduxYoVEIlEyM3NxbBhwzBp0iT4+Phg4sSJOH36NMzNzeHj4wOJRCK75sGDB1i6dCk2bNiArKwsFBcXY/z48Qr1S2pqKiIiIhATE4OcnBwIhcIaf/jU5ptvvsEbb7yBEydOYObMmZg+fTrGjh2LgQMH4vTp0xgyZAgmTZqEBw8eKBRHQ/r16wclJSWsX78elZWVKCkpwbfffgtXV1e0b98eAPDo0SOoqanJXaeuro4TJ07IEui/e/ToEUpLS+U2IiIiej0JJM9mUA04ffo0+vXrh8uXL8PExETunIWFBaKiouDt7S07Fh0djfT0dBw9ehRfffUVPv74Y1y+fBn6+vo16haJROjVqxe++uor2TEvLy+UlZXhxx9/fBqsQICFCxciKioKAFBWVgYtLS3s2bMHQ4cOxSeffIKdO3fi/Pnzsjrmz5+PZcuW4d69ew1+7T9hwgSUlJTI2gOA8ePHIyMjQ/ZAX0NxZmZmwt3dHfn5+ejRo0cDPSovMDAQysrKSExMlB07cuQIXFxcUFZWBjU1NZiammLQoEGy0epbt25BKBQiPDwcS5YsAQAcP34czs7OKCoqQufOnZGcnAx/f38cP34cAwYMAAD8+uuvsLGxQXZ2Nt5888164xo4cCAcHBywZs0a2TEnJyeUl5dDLBYDeDpyXFxcjB07dgB4OnJcWVmJw4cPAwAqKyuhq6uL0aNHy+b4Vsd+7NgxODk5KdxPERER2LFjh6ztZx06dAheXl74888/UVlZCWdnZ6Snp8ve+08++QTr16/H7t270bdvX5w6dQrDhw/HH3/8gZs3b0IoFNbaXmRkZI3j3WalQklVQ+G4iahpXY4b1twhEFELVlpaCl1dXZSUlEBHR6fOco0aOba3t8d7770HW1tbjB07FklJSbh37x7KyspQWFiIgIAAaGlpybbo6GgUFhYCAMRiMRwcHGpNjAEgPz8fIpFI7phIJEJ+fr7cMTs7O9lrTU1N6Ojo4Pbt27I6qpO/as7OzgrfnyLXNxSnWCxG165dG50YA8CZM2eQnJws14dubm6oqqrC77//Liv3bB8YGhoCAGxtbWscq+4XAGjXrh369+8v27e2toaenl6N/q3N8/brs3EqKyujY8eODcb5Im7duoUpU6bA19cXJ0+exKFDh6CiooIPP/xQNooeHh4Od3d3ODk5oX379hg5ciR8fX0BAEpKtf/nsGDBApSUlMi2xkxHISIiotalXWMKKysr46effsLRo0eRmZmJzz//HJ9++qnsYaakpKQaSVT1dAJ1dfWXEnD11+PVBAKBbGpGS/Ai93n//n0EBQUhJCSkxjljY2PZ62f7QCAQ1HmsufultveqKeNcs2YNdHV18dlnn8mOfffdd+jWrRuys7Ph5OQEdXV1fP3110hMTMQff/wBoVCIr776Sra6RW1UVVWhqqr6UmIkIiKilq3RD+QJBAKIRCJERkYiNzcXKioqyMrKgpGREX777TdYWFjIbd27dwfwdBRRLBbL5gf/nY2NDbKysuSOZWVloWfPngrHZmNjgxMnTsgdO378eKOuf/YBwdqubyhOOzs7XL9+HRcuXFC43Wp9+/ZFXl5ejT60sLCAiopKo+t7VkVFhdxDegUFBSguLoaNjU2D1yrSLy3BgwcPaoz+Vv9x9vcEvH379ujatSuUlZXxww8/YPjw4XWOHBMREVHb0aiR4+zsbOzfvx9DhgyBgYEBsrOzcefOHdjY2CAyMhIhISHQ1dXF0KFD8ejRI+Tk5ODevXuYPXs2vL29ERMTA09PT8TGxkIoFCI3NxdGRkZwdnbG3Llz4eXlBQcHB7i6umLXrl3Ytm0b9u3bp3B806ZNQ0JCAubOnYvAwECcOnWqUWvvhoSEQCQSIT4+HiNHjsTevXuRkZEhV6ahOF1cXPD2229jzJgxWL58OSwsLPDrr79CIBBg6NCh9bY/b948ODk5ITg4GIGBgdDU1EReXh5++ukn/Otf/1L4PmrTvn17zJw5E6tXr0a7du0QHBwMJyenBucbA0BoaCj8/Pzg6OgIkUiElJQUnD9/vs5VI5rKpUuXcP/+fdy6dQsPHz6UzTnu2bMnVFRUMGzYMKxYsQJLliyBt7c3/vrrL3zyyScwMTGBg4MDAODChQs4ceIEBgwYgHv37mH58uU4d+6c7MFRIiIiatsaNVSmo6ODX375BR4eHujRowcWLlyIhIQEuLu7IzAwEOvWrcP69etha2sLFxcXJCcny0aOVVRUkJmZCQMDA3h4eMDW1lZuFQdPT0+sWrUK8fHx6NWrFxITE7F+/XoMHjxY4fiMjY2xdetW7NixA/b29vjyyy8RExOj8PVOTk5ISkrCqlWrYG9vj8zMTCxcuFCujCJxbt26Ff3794e3tzd69uyJsLAwVFZWNti+nZ0dDh06hAsXLmDQoEFwcHDAokWLYGRkpPA91EVDQwPz5s3DhAkTIBKJoKWlhU2bNil07bhx4xAeHo6wsDD069cPV65cwfTp0184psYKDAyEg4MDEhMTceHCBTg4OMDBwQE3b94EALz77rvYuHEjduzYAQcHBwwdOhSqqqrIyMiQTXeprKxEQkIC7O3t8f7776O8vBxHjx6FqanpK78fIiIiankatVoFEf3vaVeuVkHUsnC1CiKqT5OsVkFERERE9DprU8mxu7u73DJpz26NmX7RWtuvS69eveqMKyUl5ZXEMG3atDpjmDZt2iuJgYiIiKhNTau4ceMGHj58WOs5fX39Otdgfl3ar8uVK1fq/HW46p+Mbmq3b9+u85fndHR0YGBg0OQxKIrTKohaJk6rIKL6KDqtolGrVbR2Xbp0adPt1+Xvv3bYHAwMDFpUAkxERERtU5uaVkFEREREVB8mx0REREREUm1qWgXRy3Qu0q3eOUtERETU+nDkmIiIiIhIiskxEREREZEUk2MiIiIiIikmx0REREREUkyOiYiIiIikmBwTEREREUkxOSYiIiIikmJyTEREREQkxeSYiIiIiEiKyTERERERkRSTYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSatfcARC1NhKJBABQWlrazJEQERGRoqr/3a7+d7wuTI6JGunPP/8EAHTr1q2ZIyEiIqLG+uuvv6Crq1vneSbHRI2kr68PALh69Wq9/3G97kpLS9GtWzdcu3YNOjo6zR1Os2JfPMV++B/2xf+wL55iP/xPc/WFRCLBX3/9BSMjo3rLMTkmaiQlpadT9XV1ddv8/+AAQEdHh/0gxb54iv3wP+yL/2FfPMV++J/m6AtFBrX4QB4RERERkRSTYyIiIiIiKSbHRI2kqqqKxYsXQ1VVtblDaVbsh/9hXzzFfvgf9sX/sC+eYj/8T0vvC4GkofUsiIiIiIjaCI4cExERERFJMTkmIiIiIpJickxEREREJMXkmIiIiIhIiskxUSOsWbMGpqamUFNTw4ABA3DixInmDumVi4iIgEAgkNusra2bO6xX4pdffsGIESNgZGQEgUCAHTt2yJ2XSCRYtGgRhEIh1NXV4erqiosXLzZPsE2ooX7w8/Or8RkZOnRo8wTbhGJjY9G/f39oa2vDwMAAnp6eKCgokCtTXl6OGTNmoGPHjtDS0sKYMWPwxx9/NFPETUeRvhg8eHCNz8W0adOaKeKmsXbtWtjZ2cl+3MLZ2Rl79uyRnW8rnweg4b5oyZ8HJsdECtq0aRNmz56NxYsX4/Tp07C3t4ebmxtu377d3KG9cr169UJRUZFsO3LkSHOH9EqUlZXB3t4ea9asqfX8Z599htWrV+PLL79EdnY2NDU14ebmhvLy8lccadNqqB8AYOjQoXKfke+///4VRvhqHDp0CDNmzMDx48fx008/4cmTJxgyZAjKyspkZf75z39i165d2Lx5Mw4dOoSbN29i9OjRzRh101CkLwBgypQpcp+Lzz77rJkibhpdu3ZFXFwcTp06hZycHLz77rsYOXIkzp8/D6DtfB6AhvsCaMGfBwkRKeTNN9+UzJgxQ7ZfWVkpMTIyksTGxjZjVK/e4sWLJfb29s0dRrMDINm+fbtsv6qqStK5c2fJ//3f/8mOFRcXS1RVVSXff/99M0T4avy9HyQSicTX11cycuTIZomnOd2+fVsCQHLo0CGJRPL0/W/fvr1k8+bNsjL5+fkSAJJjx441V5ivxN/7QiKRSFxcXCShoaHNF1Qz6dChg2TdunVt+vNQrbovJJKW/XngyDGRAh4/foxTp07B1dVVdkxJSQmurq44duxYM0bWPC5evAgjIyOYmZnhH//4B65evdrcITW733//Hbdu3ZL7jOjq6mLAgAFt8jNy8OBBGBgYwMrKCtOnT8eff/7Z3CE1uZKSEgCAvr4+AODUqVN48uSJ3GfC2toaxsbGr/1n4u99US0lJQVvvPEGevfujQULFuDBgwfNEd4rUVlZiR9++AFlZWVwdnZu05+Hv/dFtZb6eWjX3AEQtQb//e9/UVlZCUNDQ7njhoaG+PXXX5spquYxYMAAJCcnw8rKCkVFRYiMjMSgQYNw7tw5aGtrN3d4zebWrVsAUOtnpPpcWzF06FCMHj0a3bt3R2FhIT755BO4u7vj2LFjUFZWbu7wmkRVVRVmzZoFkUiE3r17A3j6mVBRUYGenp5c2df9M1FbXwDAhAkTYGJiAiMjI5w9exbz5s1DQUEBtm3b1ozRvnz/+c9/4OzsjPLycmhpaWH79u3o2bMnxGJxm/s81NUXQMv+PDA5JqJGcXd3l722s7PDgAEDYGJigtTUVAQEBDRjZNRSjB8/Xvba1tYWdnZ2MDc3x8GDB/Hee+81Y2RNZ8aMGTh37lybmX9fn7r6YurUqbLXtra2EAqFeO+991BYWAhzc/NXHWaTsbKyglgsRklJCbZs2QJfX18cOnSoucNqFnX1Rc+ePVv054HTKogU8MYbb0BZWbnGU8V//PEHOnfu3ExRtQx6enro0aMHLl261NyhNKvqzwE/IzWZmZnhjTfeeG0/I8HBwdi9ezcOHDiArl27yo537twZjx8/RnFxsVz51/kzUVdf1GbAgAEA8Np9LlRUVGBhYYF+/fohNjYW9vb2WLVqVZv8PNTVF7VpSZ8HJsdEClBRUUG/fv2wf/9+2bGqqirs379fbv5UW3T//n0UFhZCKBQ2dyjNqnv37ujcubPcZ6S0tBTZ2dlt/jNy/fp1/Pnnn6/dZ0QikSA4OBjbt2/Hzz//jO7du8ud79evH9q3by/3mSgoKMDVq1dfu89EQ31RG7FYDACv3efi76qqqvDo0aM29XmoS3Vf1KYlfR44rYJIQbNnz4avry8cHR3x5ptvYuXKlSgrK4O/v39zh/ZKffzxxxgxYgRMTExw8+ZNLF68GMrKyvD29m7u0Jrc/fv35UY1fv/9d4jFYujr68PY2BizZs1CdHQ0LC0t0b17d4SHh8PIyAienp7NF3QTqK8f9PX1ERkZiTFjxqBz584oLCxEWFgYLCws4Obm1oxRv3wzZszAxo0bsXPnTmhra8vmjerq6kJdXR26uroICAjA7Nmzoa+vDx0dHcycORPOzs5wcnJq5uhfrob6orCwEBs3boSHhwc6duyIs2fP4p///Cfefvtt2NnZNXP0L8+CBQvg7u4OY2Nj/PXXX9i4cSMOHjyIvXv3tqnPA1B/X7T4z0NzL5dB1Jp8/vnnEmNjY4mKiorkzTfflBw/fry5Q3rlxo0bJxEKhRIVFRVJly5dJOPGjZNcunSpucN6JQ4cOCABUGPz9fWVSCRPl3MLDw+XGBoaSlRVVSXvvfeepKCgoHmDbgL19cODBw8kQ4YMkXTq1EnSvn17iYmJiWTKlCmSW7duNXfYL11tfQBAsn79elmZhw8fSj766CNJhw4dJBoaGpJRo0ZJioqKmi/oJtJQX1y9elXy9ttvS/T19SWqqqoSCwsLydy5cyUlJSXNG/hLNnnyZImJiYlERUVF0qlTJ8l7770nyczMlJ1vK58HiaT+vmjpnweBRCKRvMpknIiIiIiopeKcYyIiIiIiKSbHRERERERSTI6JiIiIiKSYHBMRERERSTE5JiIiIiKSYnJMRERERCTF5JiIiIiISIrJMRERERGRFJNjIiIiIiIpJsdERERERFJMjomIiIiIpJgcExERERFJ/T8ky7puWdVTDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = xgb_randomized_search.best_estimator_.get_booster().get_score(importance_type='gain') # Importance: gain\n",
    "sorted_importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)) # Sort by descending importance\n",
    "\n",
    "top_n = dict(list(sorted_importance.items())[:10]) # Keep top N\n",
    "\n",
    "# Plot\n",
    "plt.barh(range(len(top_n)), list(top_n.values())[::-1], align='center')\n",
    "plt.yticks(range(len(top_n)), list(top_n.keys())[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.a Simple LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(n_jobs=3, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(n_jobs=3, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(n_jobs=3, verbose=-1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(n_jobs=3, verbose=-1)\n",
    "lgbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850385\n",
      "Precision: 0.492938\n",
      "Recall: 0.950904\n",
      "F1 score: 0.649291\n",
      "AUC: 0.892076\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = lgbm.predict(X_test)\n",
    "y_pred_proba = lgbm.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. CatBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.a Simple CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x22205675ee0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb = CatBoostClassifier(thread_count=3, verbose=False)\n",
    "catb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901501\n",
      "Precision: 0.600402\n",
      "Recall: 0.967899\n",
      "F1 score: 0.741093\n",
      "AUC: 0.929040\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = catb.predict(X_test)\n",
    "y_pred_proba = catb.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.b CatBoost hyperparameter opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb_parameters = {\n",
    "    'iterations': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7],\n",
    "    'depth': range(3, 15, 1),\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 96, 128, 160],\n",
    "    'bagging_temperature': [0, 0.1, 0.5, 1, 2, 5],\n",
    "    'random_strength': [0, 0.1, 0.5, 1, 2, 5],\n",
    "    'auto_class_weights': ['None', 'Balanced', 'SqrtBalanced'],\n",
    "    'leaf_estimation_method': ['Newton', 'Gradient', 'Exact'],\n",
    "    'eval_metric': ['Logloss', 'AUC', 'F1', 'Accuracy', 'Precision', 'Recall']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=64, depth=12, eval_metric=AUC, iterations=400, l2_leaf_reg=3, leaf_estimation_method=Exact, learning_rate=0.01, random_strength=0.1; total time=   0.1s\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=64, depth=12, eval_metric=AUC, iterations=400, l2_leaf_reg=3, leaf_estimation_method=Exact, learning_rate=0.01, random_strength=0.1; total time=   0.0s\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=64, depth=12, eval_metric=AUC, iterations=400, l2_leaf_reg=3, leaf_estimation_method=Exact, learning_rate=0.01, random_strength=0.1; total time=   0.2s\n",
      "0:\tlearn: 0.5622647\ttotal: 654ms\tremaining: 2m 10s\n",
      "1:\tlearn: 0.4898489\ttotal: 1.32s\tremaining: 2m 10s\n",
      "2:\tlearn: 0.4332490\ttotal: 1.98s\tremaining: 2m 9s\n",
      "3:\tlearn: 0.3902622\ttotal: 2.66s\tremaining: 2m 10s\n",
      "4:\tlearn: 0.3566695\ttotal: 3.33s\tremaining: 2m 9s\n",
      "5:\tlearn: 0.3265951\ttotal: 3.99s\tremaining: 2m 8s\n",
      "6:\tlearn: 0.3061504\ttotal: 4.65s\tremaining: 2m 8s\n",
      "7:\tlearn: 0.2826523\ttotal: 5.31s\tremaining: 2m 7s\n",
      "8:\tlearn: 0.2603606\ttotal: 5.98s\tremaining: 2m 6s\n",
      "9:\tlearn: 0.2466195\ttotal: 6.64s\tremaining: 2m 6s\n",
      "10:\tlearn: 0.2294939\ttotal: 7.32s\tremaining: 2m 5s\n",
      "11:\tlearn: 0.2137950\ttotal: 7.97s\tremaining: 2m 4s\n",
      "12:\tlearn: 0.2012782\ttotal: 8.64s\tremaining: 2m 4s\n",
      "13:\tlearn: 0.1852937\ttotal: 9.3s\tremaining: 2m 3s\n",
      "14:\tlearn: 0.1717622\ttotal: 9.96s\tremaining: 2m 2s\n",
      "15:\tlearn: 0.1610263\ttotal: 10.6s\tremaining: 2m 2s\n",
      "16:\tlearn: 0.1485300\ttotal: 11.3s\tremaining: 2m 1s\n",
      "17:\tlearn: 0.1377684\ttotal: 11.9s\tremaining: 2m\n",
      "18:\tlearn: 0.1287348\ttotal: 12.6s\tremaining: 2m\n",
      "19:\tlearn: 0.1189121\ttotal: 13.3s\tremaining: 1m 59s\n",
      "20:\tlearn: 0.1104137\ttotal: 13.9s\tremaining: 1m 58s\n",
      "21:\tlearn: 0.1044201\ttotal: 14.6s\tremaining: 1m 58s\n",
      "22:\tlearn: 0.0967510\ttotal: 15.3s\tremaining: 1m 57s\n",
      "23:\tlearn: 0.0904073\ttotal: 16s\tremaining: 1m 57s\n",
      "24:\tlearn: 0.0848356\ttotal: 16.6s\tremaining: 1m 56s\n",
      "25:\tlearn: 0.0807886\ttotal: 17.3s\tremaining: 1m 55s\n",
      "26:\tlearn: 0.0759915\ttotal: 18s\tremaining: 1m 55s\n",
      "27:\tlearn: 0.0713129\ttotal: 18.7s\tremaining: 1m 54s\n",
      "28:\tlearn: 0.0673970\ttotal: 19.4s\tremaining: 1m 54s\n",
      "29:\tlearn: 0.0628298\ttotal: 20s\tremaining: 1m 53s\n",
      "30:\tlearn: 0.0586848\ttotal: 20.7s\tremaining: 1m 53s\n",
      "31:\tlearn: 0.0557921\ttotal: 21.4s\tremaining: 1m 52s\n",
      "32:\tlearn: 0.0531604\ttotal: 22.1s\tremaining: 1m 51s\n",
      "33:\tlearn: 0.0517723\ttotal: 22.8s\tremaining: 1m 51s\n",
      "34:\tlearn: 0.0506927\ttotal: 23.4s\tremaining: 1m 50s\n",
      "35:\tlearn: 0.0488845\ttotal: 24.1s\tremaining: 1m 49s\n",
      "36:\tlearn: 0.0464070\ttotal: 24.8s\tremaining: 1m 49s\n",
      "37:\tlearn: 0.0447579\ttotal: 25.5s\tremaining: 1m 48s\n",
      "38:\tlearn: 0.0431920\ttotal: 26.1s\tremaining: 1m 47s\n",
      "39:\tlearn: 0.0413494\ttotal: 26.8s\tremaining: 1m 47s\n",
      "40:\tlearn: 0.0397115\ttotal: 27.5s\tremaining: 1m 46s\n",
      "41:\tlearn: 0.0383977\ttotal: 28.1s\tremaining: 1m 45s\n",
      "42:\tlearn: 0.0374785\ttotal: 28.8s\tremaining: 1m 45s\n",
      "43:\tlearn: 0.0358184\ttotal: 29.5s\tremaining: 1m 44s\n",
      "44:\tlearn: 0.0345954\ttotal: 30.1s\tremaining: 1m 43s\n",
      "45:\tlearn: 0.0335209\ttotal: 30.8s\tremaining: 1m 43s\n",
      "46:\tlearn: 0.0317801\ttotal: 31.5s\tremaining: 1m 42s\n",
      "47:\tlearn: 0.0301245\ttotal: 32.2s\tremaining: 1m 41s\n",
      "48:\tlearn: 0.0293068\ttotal: 32.9s\tremaining: 1m 41s\n",
      "49:\tlearn: 0.0282119\ttotal: 33.6s\tremaining: 1m 40s\n",
      "50:\tlearn: 0.0271104\ttotal: 34.2s\tremaining: 1m 40s\n",
      "51:\tlearn: 0.0262070\ttotal: 34.9s\tremaining: 1m 39s\n",
      "52:\tlearn: 0.0254518\ttotal: 35.6s\tremaining: 1m 38s\n",
      "53:\tlearn: 0.0246569\ttotal: 36.3s\tremaining: 1m 38s\n",
      "54:\tlearn: 0.0237975\ttotal: 36.9s\tremaining: 1m 37s\n",
      "55:\tlearn: 0.0229210\ttotal: 37.6s\tremaining: 1m 36s\n",
      "56:\tlearn: 0.0222493\ttotal: 38.3s\tremaining: 1m 36s\n",
      "57:\tlearn: 0.0217780\ttotal: 39s\tremaining: 1m 35s\n",
      "58:\tlearn: 0.0211404\ttotal: 39.6s\tremaining: 1m 34s\n",
      "59:\tlearn: 0.0204716\ttotal: 40.3s\tremaining: 1m 34s\n",
      "60:\tlearn: 0.0199038\ttotal: 41s\tremaining: 1m 33s\n",
      "61:\tlearn: 0.0193086\ttotal: 41.7s\tremaining: 1m 32s\n",
      "62:\tlearn: 0.0187128\ttotal: 42.3s\tremaining: 1m 32s\n",
      "63:\tlearn: 0.0182999\ttotal: 43s\tremaining: 1m 31s\n",
      "64:\tlearn: 0.0178404\ttotal: 43.7s\tremaining: 1m 30s\n",
      "65:\tlearn: 0.0173754\ttotal: 44.4s\tremaining: 1m 30s\n",
      "66:\tlearn: 0.0170314\ttotal: 45s\tremaining: 1m 29s\n",
      "67:\tlearn: 0.0164322\ttotal: 45.7s\tremaining: 1m 28s\n",
      "68:\tlearn: 0.0159213\ttotal: 46.4s\tremaining: 1m 28s\n",
      "69:\tlearn: 0.0155329\ttotal: 47.1s\tremaining: 1m 27s\n",
      "70:\tlearn: 0.0150222\ttotal: 47.8s\tremaining: 1m 26s\n",
      "71:\tlearn: 0.0146111\ttotal: 48.5s\tremaining: 1m 26s\n",
      "72:\tlearn: 0.0142095\ttotal: 49.2s\tremaining: 1m 25s\n",
      "73:\tlearn: 0.0138726\ttotal: 49.9s\tremaining: 1m 24s\n",
      "74:\tlearn: 0.0137009\ttotal: 50.6s\tremaining: 1m 24s\n",
      "75:\tlearn: 0.0133452\ttotal: 51.3s\tremaining: 1m 23s\n",
      "76:\tlearn: 0.0130336\ttotal: 52s\tremaining: 1m 23s\n",
      "77:\tlearn: 0.0127548\ttotal: 52.7s\tremaining: 1m 22s\n",
      "78:\tlearn: 0.0125024\ttotal: 53.3s\tremaining: 1m 21s\n",
      "79:\tlearn: 0.0122456\ttotal: 54s\tremaining: 1m 20s\n",
      "80:\tlearn: 0.0119852\ttotal: 54.7s\tremaining: 1m 20s\n",
      "81:\tlearn: 0.0117234\ttotal: 55.4s\tremaining: 1m 19s\n",
      "82:\tlearn: 0.0114383\ttotal: 56.1s\tremaining: 1m 19s\n",
      "83:\tlearn: 0.0112191\ttotal: 56.8s\tremaining: 1m 18s\n",
      "84:\tlearn: 0.0109878\ttotal: 57.4s\tremaining: 1m 17s\n",
      "85:\tlearn: 0.0108077\ttotal: 58.1s\tremaining: 1m 17s\n",
      "86:\tlearn: 0.0105825\ttotal: 58.8s\tremaining: 1m 16s\n",
      "87:\tlearn: 0.0104359\ttotal: 59.5s\tremaining: 1m 15s\n",
      "88:\tlearn: 0.0103049\ttotal: 1m\tremaining: 1m 15s\n",
      "89:\tlearn: 0.0101681\ttotal: 1m\tremaining: 1m 14s\n",
      "90:\tlearn: 0.0100225\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "91:\tlearn: 0.0098892\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "92:\tlearn: 0.0096967\ttotal: 1m 2s\tremaining: 1m 12s\n",
      "93:\tlearn: 0.0095662\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "94:\tlearn: 0.0094181\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "95:\tlearn: 0.0093060\ttotal: 1m 4s\tremaining: 1m 10s\n",
      "96:\tlearn: 0.0091574\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "97:\tlearn: 0.0090328\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "98:\tlearn: 0.0088721\ttotal: 1m 6s\tremaining: 1m 8s\n",
      "99:\tlearn: 0.0087321\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "100:\tlearn: 0.0085914\ttotal: 1m 8s\tremaining: 1m 6s\n",
      "101:\tlearn: 0.0084560\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "102:\tlearn: 0.0082820\ttotal: 1m 9s\tremaining: 1m 5s\n",
      "103:\tlearn: 0.0081683\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "104:\tlearn: 0.0080320\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "105:\tlearn: 0.0078865\ttotal: 1m 11s\tremaining: 1m 3s\n",
      "106:\tlearn: 0.0077586\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "107:\tlearn: 0.0076373\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "108:\tlearn: 0.0075554\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "109:\tlearn: 0.0074436\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "110:\tlearn: 0.0073442\ttotal: 1m 15s\tremaining: 1m\n",
      "111:\tlearn: 0.0072455\ttotal: 1m 16s\tremaining: 59.8s\n",
      "112:\tlearn: 0.0071616\ttotal: 1m 16s\tremaining: 59.2s\n",
      "113:\tlearn: 0.0070708\ttotal: 1m 17s\tremaining: 58.6s\n",
      "114:\tlearn: 0.0069989\ttotal: 1m 18s\tremaining: 58s\n",
      "115:\tlearn: 0.0069176\ttotal: 1m 19s\tremaining: 57.4s\n",
      "116:\tlearn: 0.0068286\ttotal: 1m 20s\tremaining: 56.8s\n",
      "117:\tlearn: 0.0067620\ttotal: 1m 20s\tremaining: 56.2s\n",
      "118:\tlearn: 0.0066861\ttotal: 1m 21s\tremaining: 55.5s\n",
      "119:\tlearn: 0.0066201\ttotal: 1m 22s\tremaining: 54.9s\n",
      "120:\tlearn: 0.0065489\ttotal: 1m 23s\tremaining: 54.2s\n",
      "121:\tlearn: 0.0064686\ttotal: 1m 23s\tremaining: 53.6s\n",
      "122:\tlearn: 0.0063837\ttotal: 1m 24s\tremaining: 53s\n",
      "123:\tlearn: 0.0063199\ttotal: 1m 25s\tremaining: 52.4s\n",
      "124:\tlearn: 0.0062490\ttotal: 1m 26s\tremaining: 51.7s\n",
      "125:\tlearn: 0.0061618\ttotal: 1m 26s\tremaining: 51.1s\n",
      "126:\tlearn: 0.0061012\ttotal: 1m 27s\tremaining: 50.4s\n",
      "127:\tlearn: 0.0060442\ttotal: 1m 28s\tremaining: 49.7s\n",
      "128:\tlearn: 0.0059581\ttotal: 1m 29s\tremaining: 49.2s\n",
      "129:\tlearn: 0.0058997\ttotal: 1m 30s\tremaining: 48.5s\n",
      "130:\tlearn: 0.0058307\ttotal: 1m 30s\tremaining: 47.9s\n",
      "131:\tlearn: 0.0057632\ttotal: 1m 31s\tremaining: 47.2s\n",
      "132:\tlearn: 0.0057024\ttotal: 1m 32s\tremaining: 46.6s\n",
      "133:\tlearn: 0.0056480\ttotal: 1m 33s\tremaining: 45.9s\n",
      "134:\tlearn: 0.0055772\ttotal: 1m 33s\tremaining: 45.2s\n",
      "135:\tlearn: 0.0055076\ttotal: 1m 34s\tremaining: 44.5s\n",
      "136:\tlearn: 0.0054492\ttotal: 1m 35s\tremaining: 43.8s\n",
      "137:\tlearn: 0.0053804\ttotal: 1m 36s\tremaining: 43.1s\n",
      "138:\tlearn: 0.0053094\ttotal: 1m 36s\tremaining: 42.4s\n",
      "139:\tlearn: 0.0052664\ttotal: 1m 37s\tremaining: 41.7s\n",
      "140:\tlearn: 0.0052320\ttotal: 1m 38s\tremaining: 41s\n",
      "141:\tlearn: 0.0051783\ttotal: 1m 38s\tremaining: 40.3s\n",
      "142:\tlearn: 0.0051191\ttotal: 1m 39s\tremaining: 39.7s\n",
      "143:\tlearn: 0.0050530\ttotal: 1m 40s\tremaining: 39s\n",
      "144:\tlearn: 0.0049980\ttotal: 1m 41s\tremaining: 38.3s\n",
      "145:\tlearn: 0.0049518\ttotal: 1m 41s\tremaining: 37.6s\n",
      "146:\tlearn: 0.0049032\ttotal: 1m 42s\tremaining: 36.9s\n",
      "147:\tlearn: 0.0048634\ttotal: 1m 43s\tremaining: 36.2s\n",
      "148:\tlearn: 0.0048290\ttotal: 1m 43s\tremaining: 35.5s\n",
      "149:\tlearn: 0.0047901\ttotal: 1m 44s\tremaining: 34.8s\n",
      "150:\tlearn: 0.0047464\ttotal: 1m 45s\tremaining: 34.1s\n",
      "151:\tlearn: 0.0047027\ttotal: 1m 45s\tremaining: 33.4s\n",
      "152:\tlearn: 0.0046590\ttotal: 1m 46s\tremaining: 32.7s\n",
      "153:\tlearn: 0.0046230\ttotal: 1m 47s\tremaining: 32s\n",
      "154:\tlearn: 0.0045918\ttotal: 1m 47s\tremaining: 31.3s\n",
      "155:\tlearn: 0.0045556\ttotal: 1m 48s\tremaining: 30.6s\n",
      "156:\tlearn: 0.0045133\ttotal: 1m 49s\tremaining: 29.9s\n",
      "157:\tlearn: 0.0044693\ttotal: 1m 49s\tremaining: 29.2s\n",
      "158:\tlearn: 0.0044461\ttotal: 1m 50s\tremaining: 28.5s\n",
      "159:\tlearn: 0.0043997\ttotal: 1m 51s\tremaining: 27.8s\n",
      "160:\tlearn: 0.0043678\ttotal: 1m 52s\tremaining: 27.2s\n",
      "161:\tlearn: 0.0043310\ttotal: 1m 52s\tremaining: 26.5s\n",
      "162:\tlearn: 0.0042947\ttotal: 1m 53s\tremaining: 25.8s\n",
      "163:\tlearn: 0.0042653\ttotal: 1m 54s\tremaining: 25.1s\n",
      "164:\tlearn: 0.0042232\ttotal: 1m 54s\tremaining: 24.4s\n",
      "165:\tlearn: 0.0041853\ttotal: 1m 55s\tremaining: 23.7s\n",
      "166:\tlearn: 0.0041491\ttotal: 1m 56s\tremaining: 23s\n",
      "167:\tlearn: 0.0041217\ttotal: 1m 57s\tremaining: 22.3s\n",
      "168:\tlearn: 0.0040986\ttotal: 1m 57s\tremaining: 21.6s\n",
      "169:\tlearn: 0.0040688\ttotal: 1m 58s\tremaining: 20.9s\n",
      "170:\tlearn: 0.0040399\ttotal: 1m 59s\tremaining: 20.2s\n",
      "171:\tlearn: 0.0040070\ttotal: 1m 59s\tremaining: 19.5s\n",
      "172:\tlearn: 0.0039695\ttotal: 2m\tremaining: 18.8s\n",
      "173:\tlearn: 0.0039488\ttotal: 2m 1s\tremaining: 18.1s\n",
      "174:\tlearn: 0.0039222\ttotal: 2m 1s\tremaining: 17.4s\n",
      "175:\tlearn: 0.0038945\ttotal: 2m 2s\tremaining: 16.7s\n",
      "176:\tlearn: 0.0038713\ttotal: 2m 3s\tremaining: 16s\n",
      "177:\tlearn: 0.0038503\ttotal: 2m 4s\tremaining: 15.4s\n",
      "178:\tlearn: 0.0038188\ttotal: 2m 5s\tremaining: 14.7s\n",
      "179:\tlearn: 0.0037880\ttotal: 2m 5s\tremaining: 14s\n",
      "180:\tlearn: 0.0037606\ttotal: 2m 6s\tremaining: 13.3s\n",
      "181:\tlearn: 0.0037349\ttotal: 2m 7s\tremaining: 12.6s\n",
      "182:\tlearn: 0.0037119\ttotal: 2m 7s\tremaining: 11.9s\n",
      "183:\tlearn: 0.0036937\ttotal: 2m 8s\tremaining: 11.2s\n",
      "184:\tlearn: 0.0036683\ttotal: 2m 9s\tremaining: 10.5s\n",
      "185:\tlearn: 0.0036386\ttotal: 2m 10s\tremaining: 9.79s\n",
      "186:\tlearn: 0.0036162\ttotal: 2m 10s\tremaining: 9.09s\n",
      "187:\tlearn: 0.0035956\ttotal: 2m 11s\tremaining: 8.39s\n",
      "188:\tlearn: 0.0035789\ttotal: 2m 12s\tremaining: 7.69s\n",
      "189:\tlearn: 0.0035585\ttotal: 2m 12s\tremaining: 6.99s\n",
      "190:\tlearn: 0.0035332\ttotal: 2m 13s\tremaining: 6.29s\n",
      "191:\tlearn: 0.0035091\ttotal: 2m 14s\tremaining: 5.59s\n",
      "192:\tlearn: 0.0034826\ttotal: 2m 15s\tremaining: 4.9s\n",
      "193:\tlearn: 0.0034661\ttotal: 2m 15s\tremaining: 4.2s\n",
      "194:\tlearn: 0.0034438\ttotal: 2m 16s\tremaining: 3.5s\n",
      "195:\tlearn: 0.0034225\ttotal: 2m 17s\tremaining: 2.8s\n",
      "196:\tlearn: 0.0033972\ttotal: 2m 18s\tremaining: 2.1s\n",
      "197:\tlearn: 0.0033795\ttotal: 2m 18s\tremaining: 1.4s\n",
      "198:\tlearn: 0.0033559\ttotal: 2m 19s\tremaining: 700ms\n",
      "199:\tlearn: 0.0033390\ttotal: 2m 20s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.5, border_count=96, depth=10, eval_metric=Logloss, iterations=200, l2_leaf_reg=7, leaf_estimation_method=Gradient, learning_rate=0.7, random_strength=0.1; total time= 2.3min\n",
      "0:\tlearn: 0.5485317\ttotal: 690ms\tremaining: 2m 17s\n",
      "1:\tlearn: 0.4783266\ttotal: 1.37s\tremaining: 2m 15s\n",
      "2:\tlearn: 0.4363534\ttotal: 2.03s\tremaining: 2m 13s\n",
      "3:\tlearn: 0.3867543\ttotal: 2.73s\tremaining: 2m 13s\n",
      "4:\tlearn: 0.3491536\ttotal: 3.4s\tremaining: 2m 12s\n",
      "5:\tlearn: 0.3178703\ttotal: 4.08s\tremaining: 2m 11s\n",
      "6:\tlearn: 0.2998851\ttotal: 4.76s\tremaining: 2m 11s\n",
      "7:\tlearn: 0.2775736\ttotal: 5.43s\tremaining: 2m 10s\n",
      "8:\tlearn: 0.2570490\ttotal: 6.12s\tremaining: 2m 9s\n",
      "9:\tlearn: 0.2419381\ttotal: 6.83s\tremaining: 2m 9s\n",
      "10:\tlearn: 0.2226507\ttotal: 7.51s\tremaining: 2m 9s\n",
      "11:\tlearn: 0.2078863\ttotal: 8.19s\tremaining: 2m 8s\n",
      "12:\tlearn: 0.1910632\ttotal: 8.91s\tremaining: 2m 8s\n",
      "13:\tlearn: 0.1766707\ttotal: 9.6s\tremaining: 2m 7s\n",
      "14:\tlearn: 0.1686450\ttotal: 10.4s\tremaining: 2m 7s\n",
      "15:\tlearn: 0.1584361\ttotal: 11.1s\tremaining: 2m 7s\n",
      "16:\tlearn: 0.1471780\ttotal: 11.8s\tremaining: 2m 7s\n",
      "17:\tlearn: 0.1388112\ttotal: 12.6s\tremaining: 2m 7s\n",
      "18:\tlearn: 0.1332455\ttotal: 13.3s\tremaining: 2m 6s\n",
      "19:\tlearn: 0.1253623\ttotal: 14s\tremaining: 2m 5s\n",
      "20:\tlearn: 0.1195760\ttotal: 14.7s\tremaining: 2m 5s\n",
      "21:\tlearn: 0.1093937\ttotal: 15.4s\tremaining: 2m 4s\n",
      "22:\tlearn: 0.1029190\ttotal: 16.1s\tremaining: 2m 3s\n",
      "23:\tlearn: 0.0976708\ttotal: 16.8s\tremaining: 2m 2s\n",
      "24:\tlearn: 0.0933490\ttotal: 17.5s\tremaining: 2m 2s\n",
      "25:\tlearn: 0.0886433\ttotal: 18.1s\tremaining: 2m 1s\n",
      "26:\tlearn: 0.0822033\ttotal: 18.8s\tremaining: 2m\n",
      "27:\tlearn: 0.0768153\ttotal: 19.5s\tremaining: 1m 59s\n",
      "28:\tlearn: 0.0743536\ttotal: 20.2s\tremaining: 1m 58s\n",
      "29:\tlearn: 0.0698735\ttotal: 20.9s\tremaining: 1m 58s\n",
      "30:\tlearn: 0.0671423\ttotal: 21.5s\tremaining: 1m 57s\n",
      "31:\tlearn: 0.0667166\ttotal: 22.2s\tremaining: 1m 56s\n",
      "32:\tlearn: 0.0635468\ttotal: 22.9s\tremaining: 1m 55s\n",
      "33:\tlearn: 0.0601293\ttotal: 23.5s\tremaining: 1m 54s\n",
      "34:\tlearn: 0.0573856\ttotal: 24.2s\tremaining: 1m 54s\n",
      "35:\tlearn: 0.0530435\ttotal: 24.9s\tremaining: 1m 53s\n",
      "36:\tlearn: 0.0506154\ttotal: 25.6s\tremaining: 1m 52s\n",
      "37:\tlearn: 0.0484806\ttotal: 26.3s\tremaining: 1m 52s\n",
      "38:\tlearn: 0.0459477\ttotal: 27s\tremaining: 1m 51s\n",
      "39:\tlearn: 0.0441755\ttotal: 27.7s\tremaining: 1m 50s\n",
      "40:\tlearn: 0.0421212\ttotal: 28.3s\tremaining: 1m 49s\n",
      "41:\tlearn: 0.0398326\ttotal: 29s\tremaining: 1m 49s\n",
      "42:\tlearn: 0.0385213\ttotal: 29.7s\tremaining: 1m 48s\n",
      "43:\tlearn: 0.0373259\ttotal: 30.4s\tremaining: 1m 47s\n",
      "44:\tlearn: 0.0364932\ttotal: 31.1s\tremaining: 1m 46s\n",
      "45:\tlearn: 0.0350725\ttotal: 31.7s\tremaining: 1m 46s\n",
      "46:\tlearn: 0.0339022\ttotal: 32.4s\tremaining: 1m 45s\n",
      "47:\tlearn: 0.0331923\ttotal: 33.1s\tremaining: 1m 44s\n",
      "48:\tlearn: 0.0317914\ttotal: 33.8s\tremaining: 1m 44s\n",
      "49:\tlearn: 0.0305391\ttotal: 34.4s\tremaining: 1m 43s\n",
      "50:\tlearn: 0.0292344\ttotal: 35.1s\tremaining: 1m 42s\n",
      "51:\tlearn: 0.0280653\ttotal: 35.8s\tremaining: 1m 41s\n",
      "52:\tlearn: 0.0266454\ttotal: 36.5s\tremaining: 1m 41s\n",
      "53:\tlearn: 0.0259881\ttotal: 37.1s\tremaining: 1m 40s\n",
      "54:\tlearn: 0.0251860\ttotal: 37.8s\tremaining: 1m 39s\n",
      "55:\tlearn: 0.0245719\ttotal: 38.5s\tremaining: 1m 39s\n",
      "56:\tlearn: 0.0239753\ttotal: 39.2s\tremaining: 1m 38s\n",
      "57:\tlearn: 0.0229885\ttotal: 39.9s\tremaining: 1m 37s\n",
      "58:\tlearn: 0.0223906\ttotal: 40.5s\tremaining: 1m 36s\n",
      "59:\tlearn: 0.0218484\ttotal: 41.2s\tremaining: 1m 36s\n",
      "60:\tlearn: 0.0212572\ttotal: 41.9s\tremaining: 1m 35s\n",
      "61:\tlearn: 0.0206445\ttotal: 42.5s\tremaining: 1m 34s\n",
      "62:\tlearn: 0.0200746\ttotal: 43.2s\tremaining: 1m 33s\n",
      "63:\tlearn: 0.0194092\ttotal: 43.9s\tremaining: 1m 33s\n",
      "64:\tlearn: 0.0189226\ttotal: 44.6s\tremaining: 1m 32s\n",
      "65:\tlearn: 0.0185591\ttotal: 45.2s\tremaining: 1m 31s\n",
      "66:\tlearn: 0.0181283\ttotal: 45.9s\tremaining: 1m 31s\n",
      "67:\tlearn: 0.0177450\ttotal: 46.6s\tremaining: 1m 30s\n",
      "68:\tlearn: 0.0173250\ttotal: 47.3s\tremaining: 1m 29s\n",
      "69:\tlearn: 0.0169305\ttotal: 47.9s\tremaining: 1m 29s\n",
      "70:\tlearn: 0.0165483\ttotal: 48.6s\tremaining: 1m 28s\n",
      "71:\tlearn: 0.0164301\ttotal: 49.3s\tremaining: 1m 27s\n",
      "72:\tlearn: 0.0158791\ttotal: 50s\tremaining: 1m 26s\n",
      "73:\tlearn: 0.0153315\ttotal: 50.6s\tremaining: 1m 26s\n",
      "74:\tlearn: 0.0149794\ttotal: 51.3s\tremaining: 1m 25s\n",
      "75:\tlearn: 0.0145669\ttotal: 52s\tremaining: 1m 24s\n",
      "76:\tlearn: 0.0140608\ttotal: 52.7s\tremaining: 1m 24s\n",
      "77:\tlearn: 0.0138427\ttotal: 53.4s\tremaining: 1m 23s\n",
      "78:\tlearn: 0.0135992\ttotal: 54s\tremaining: 1m 22s\n",
      "79:\tlearn: 0.0132757\ttotal: 54.7s\tremaining: 1m 22s\n",
      "80:\tlearn: 0.0129082\ttotal: 55.4s\tremaining: 1m 21s\n",
      "81:\tlearn: 0.0126774\ttotal: 56.1s\tremaining: 1m 20s\n",
      "82:\tlearn: 0.0123107\ttotal: 56.8s\tremaining: 1m 20s\n",
      "83:\tlearn: 0.0120832\ttotal: 57.5s\tremaining: 1m 19s\n",
      "84:\tlearn: 0.0118499\ttotal: 58.2s\tremaining: 1m 18s\n",
      "85:\tlearn: 0.0115262\ttotal: 58.9s\tremaining: 1m 18s\n",
      "86:\tlearn: 0.0113178\ttotal: 59.5s\tremaining: 1m 17s\n",
      "87:\tlearn: 0.0111007\ttotal: 1m\tremaining: 1m 16s\n",
      "88:\tlearn: 0.0109903\ttotal: 1m\tremaining: 1m 15s\n",
      "89:\tlearn: 0.0107715\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "90:\tlearn: 0.0105908\ttotal: 1m 2s\tremaining: 1m 14s\n",
      "91:\tlearn: 0.0103917\ttotal: 1m 2s\tremaining: 1m 13s\n",
      "92:\tlearn: 0.0101224\ttotal: 1m 3s\tremaining: 1m 13s\n",
      "93:\tlearn: 0.0099150\ttotal: 1m 4s\tremaining: 1m 12s\n",
      "94:\tlearn: 0.0097360\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "95:\tlearn: 0.0096058\ttotal: 1m 5s\tremaining: 1m 11s\n",
      "96:\tlearn: 0.0094782\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "97:\tlearn: 0.0093432\ttotal: 1m 6s\tremaining: 1m 9s\n",
      "98:\tlearn: 0.0092940\ttotal: 1m 7s\tremaining: 1m 9s\n",
      "99:\tlearn: 0.0091586\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "100:\tlearn: 0.0090290\ttotal: 1m 9s\tremaining: 1m 7s\n",
      "101:\tlearn: 0.0089261\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "102:\tlearn: 0.0087229\ttotal: 1m 10s\tremaining: 1m 6s\n",
      "103:\tlearn: 0.0085750\ttotal: 1m 11s\tremaining: 1m 5s\n",
      "104:\tlearn: 0.0084421\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "105:\tlearn: 0.0083270\ttotal: 1m 12s\tremaining: 1m 4s\n",
      "106:\tlearn: 0.0082221\ttotal: 1m 13s\tremaining: 1m 3s\n",
      "107:\tlearn: 0.0080918\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "108:\tlearn: 0.0080182\ttotal: 1m 14s\tremaining: 1m 2s\n",
      "109:\tlearn: 0.0079203\ttotal: 1m 15s\tremaining: 1m 1s\n",
      "110:\tlearn: 0.0077896\ttotal: 1m 15s\tremaining: 1m\n",
      "111:\tlearn: 0.0076944\ttotal: 1m 16s\tremaining: 1m\n",
      "112:\tlearn: 0.0075854\ttotal: 1m 17s\tremaining: 59.4s\n",
      "113:\tlearn: 0.0074609\ttotal: 1m 17s\tremaining: 58.8s\n",
      "114:\tlearn: 0.0073763\ttotal: 1m 18s\tremaining: 58.1s\n",
      "115:\tlearn: 0.0072550\ttotal: 1m 19s\tremaining: 57.4s\n",
      "116:\tlearn: 0.0071763\ttotal: 1m 19s\tremaining: 56.7s\n",
      "117:\tlearn: 0.0070936\ttotal: 1m 20s\tremaining: 56.1s\n",
      "118:\tlearn: 0.0070037\ttotal: 1m 21s\tremaining: 55.4s\n",
      "119:\tlearn: 0.0069295\ttotal: 1m 22s\tremaining: 54.7s\n",
      "120:\tlearn: 0.0068240\ttotal: 1m 22s\tremaining: 54s\n",
      "121:\tlearn: 0.0067320\ttotal: 1m 23s\tremaining: 53.3s\n",
      "122:\tlearn: 0.0066694\ttotal: 1m 24s\tremaining: 52.6s\n",
      "123:\tlearn: 0.0065860\ttotal: 1m 24s\tremaining: 52s\n",
      "124:\tlearn: 0.0065063\ttotal: 1m 25s\tremaining: 51.3s\n",
      "125:\tlearn: 0.0064371\ttotal: 1m 26s\tremaining: 50.6s\n",
      "126:\tlearn: 0.0063550\ttotal: 1m 26s\tremaining: 49.9s\n",
      "127:\tlearn: 0.0062705\ttotal: 1m 27s\tremaining: 49.2s\n",
      "128:\tlearn: 0.0062106\ttotal: 1m 28s\tremaining: 48.5s\n",
      "129:\tlearn: 0.0061532\ttotal: 1m 28s\tremaining: 47.8s\n",
      "130:\tlearn: 0.0060636\ttotal: 1m 29s\tremaining: 47.1s\n",
      "131:\tlearn: 0.0060036\ttotal: 1m 30s\tremaining: 46.5s\n",
      "132:\tlearn: 0.0059373\ttotal: 1m 30s\tremaining: 45.8s\n",
      "133:\tlearn: 0.0058842\ttotal: 1m 31s\tremaining: 45.1s\n",
      "134:\tlearn: 0.0058208\ttotal: 1m 32s\tremaining: 44.4s\n",
      "135:\tlearn: 0.0057769\ttotal: 1m 32s\tremaining: 43.7s\n",
      "136:\tlearn: 0.0057173\ttotal: 1m 33s\tremaining: 43.1s\n",
      "137:\tlearn: 0.0056597\ttotal: 1m 34s\tremaining: 42.4s\n",
      "138:\tlearn: 0.0056155\ttotal: 1m 35s\tremaining: 41.7s\n",
      "139:\tlearn: 0.0055714\ttotal: 1m 35s\tremaining: 41s\n",
      "140:\tlearn: 0.0055279\ttotal: 1m 36s\tremaining: 40.3s\n",
      "141:\tlearn: 0.0054649\ttotal: 1m 37s\tremaining: 39.6s\n",
      "142:\tlearn: 0.0053978\ttotal: 1m 37s\tremaining: 39s\n",
      "143:\tlearn: 0.0053439\ttotal: 1m 38s\tremaining: 38.3s\n",
      "144:\tlearn: 0.0052942\ttotal: 1m 39s\tremaining: 37.6s\n",
      "145:\tlearn: 0.0052454\ttotal: 1m 39s\tremaining: 36.9s\n",
      "146:\tlearn: 0.0051935\ttotal: 1m 40s\tremaining: 36.2s\n",
      "147:\tlearn: 0.0051406\ttotal: 1m 41s\tremaining: 35.5s\n",
      "148:\tlearn: 0.0050946\ttotal: 1m 41s\tremaining: 34.9s\n",
      "149:\tlearn: 0.0050446\ttotal: 1m 42s\tremaining: 34.2s\n",
      "150:\tlearn: 0.0050038\ttotal: 1m 43s\tremaining: 33.5s\n",
      "151:\tlearn: 0.0049695\ttotal: 1m 43s\tremaining: 32.8s\n",
      "152:\tlearn: 0.0049236\ttotal: 1m 44s\tremaining: 32.1s\n",
      "153:\tlearn: 0.0048827\ttotal: 1m 45s\tremaining: 31.4s\n",
      "154:\tlearn: 0.0048345\ttotal: 1m 45s\tremaining: 30.7s\n",
      "155:\tlearn: 0.0048024\ttotal: 1m 46s\tremaining: 30.1s\n",
      "156:\tlearn: 0.0047545\ttotal: 1m 47s\tremaining: 29.4s\n",
      "157:\tlearn: 0.0047152\ttotal: 1m 47s\tremaining: 28.7s\n",
      "158:\tlearn: 0.0046876\ttotal: 1m 48s\tremaining: 28s\n",
      "159:\tlearn: 0.0046536\ttotal: 1m 49s\tremaining: 27.3s\n",
      "160:\tlearn: 0.0046134\ttotal: 1m 49s\tremaining: 26.6s\n",
      "161:\tlearn: 0.0045727\ttotal: 1m 50s\tremaining: 25.9s\n",
      "162:\tlearn: 0.0045286\ttotal: 1m 51s\tremaining: 25.3s\n",
      "163:\tlearn: 0.0044966\ttotal: 1m 51s\tremaining: 24.6s\n",
      "164:\tlearn: 0.0044624\ttotal: 1m 52s\tremaining: 23.9s\n",
      "165:\tlearn: 0.0044184\ttotal: 1m 53s\tremaining: 23.2s\n",
      "166:\tlearn: 0.0043787\ttotal: 1m 53s\tremaining: 22.5s\n",
      "167:\tlearn: 0.0043462\ttotal: 1m 54s\tremaining: 21.8s\n",
      "168:\tlearn: 0.0043111\ttotal: 1m 55s\tremaining: 21.1s\n",
      "169:\tlearn: 0.0042762\ttotal: 1m 55s\tremaining: 20.5s\n",
      "170:\tlearn: 0.0042498\ttotal: 1m 56s\tremaining: 19.8s\n",
      "171:\tlearn: 0.0042121\ttotal: 1m 57s\tremaining: 19.1s\n",
      "172:\tlearn: 0.0041815\ttotal: 1m 57s\tremaining: 18.4s\n",
      "173:\tlearn: 0.0041389\ttotal: 1m 58s\tremaining: 17.7s\n",
      "174:\tlearn: 0.0041062\ttotal: 1m 59s\tremaining: 17.1s\n",
      "175:\tlearn: 0.0040666\ttotal: 2m\tremaining: 16.4s\n",
      "176:\tlearn: 0.0040338\ttotal: 2m\tremaining: 15.7s\n",
      "177:\tlearn: 0.0040136\ttotal: 2m 1s\tremaining: 15s\n",
      "178:\tlearn: 0.0039816\ttotal: 2m 2s\tremaining: 14.3s\n",
      "179:\tlearn: 0.0039396\ttotal: 2m 2s\tremaining: 13.6s\n",
      "180:\tlearn: 0.0039160\ttotal: 2m 3s\tremaining: 13s\n",
      "181:\tlearn: 0.0038836\ttotal: 2m 4s\tremaining: 12.3s\n",
      "182:\tlearn: 0.0038543\ttotal: 2m 4s\tremaining: 11.6s\n",
      "183:\tlearn: 0.0038254\ttotal: 2m 5s\tremaining: 10.9s\n",
      "184:\tlearn: 0.0037956\ttotal: 2m 6s\tremaining: 10.2s\n",
      "185:\tlearn: 0.0037666\ttotal: 2m 6s\tremaining: 9.55s\n",
      "186:\tlearn: 0.0037558\ttotal: 2m 7s\tremaining: 8.87s\n",
      "187:\tlearn: 0.0037253\ttotal: 2m 8s\tremaining: 8.18s\n",
      "188:\tlearn: 0.0037014\ttotal: 2m 8s\tremaining: 7.5s\n",
      "189:\tlearn: 0.0036776\ttotal: 2m 9s\tremaining: 6.82s\n",
      "190:\tlearn: 0.0036524\ttotal: 2m 10s\tremaining: 6.14s\n",
      "191:\tlearn: 0.0036306\ttotal: 2m 10s\tremaining: 5.45s\n",
      "192:\tlearn: 0.0036105\ttotal: 2m 11s\tremaining: 4.77s\n",
      "193:\tlearn: 0.0035881\ttotal: 2m 12s\tremaining: 4.09s\n",
      "194:\tlearn: 0.0035650\ttotal: 2m 12s\tremaining: 3.41s\n",
      "195:\tlearn: 0.0035433\ttotal: 2m 13s\tremaining: 2.73s\n",
      "196:\tlearn: 0.0035213\ttotal: 2m 14s\tremaining: 2.04s\n",
      "197:\tlearn: 0.0034999\ttotal: 2m 14s\tremaining: 1.36s\n",
      "198:\tlearn: 0.0034721\ttotal: 2m 15s\tremaining: 682ms\n",
      "199:\tlearn: 0.0034487\ttotal: 2m 16s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.5, border_count=96, depth=10, eval_metric=Logloss, iterations=200, l2_leaf_reg=7, leaf_estimation_method=Gradient, learning_rate=0.7, random_strength=0.1; total time= 2.3min\n",
      "0:\tlearn: 0.5573831\ttotal: 681ms\tremaining: 2m 15s\n",
      "1:\tlearn: 0.4912547\ttotal: 1.35s\tremaining: 2m 13s\n",
      "2:\tlearn: 0.4275479\ttotal: 2.02s\tremaining: 2m 12s\n",
      "3:\tlearn: 0.3736850\ttotal: 2.7s\tremaining: 2m 12s\n",
      "4:\tlearn: 0.3438980\ttotal: 3.36s\tremaining: 2m 11s\n",
      "5:\tlearn: 0.3164208\ttotal: 4.04s\tremaining: 2m 10s\n",
      "6:\tlearn: 0.2842656\ttotal: 4.74s\tremaining: 2m 10s\n",
      "7:\tlearn: 0.2660039\ttotal: 5.41s\tremaining: 2m 9s\n",
      "8:\tlearn: 0.2488417\ttotal: 6.11s\tremaining: 2m 9s\n",
      "9:\tlearn: 0.2385874\ttotal: 6.82s\tremaining: 2m 9s\n",
      "10:\tlearn: 0.2205405\ttotal: 7.52s\tremaining: 2m 9s\n",
      "11:\tlearn: 0.1998984\ttotal: 8.22s\tremaining: 2m 8s\n",
      "12:\tlearn: 0.1879445\ttotal: 8.92s\tremaining: 2m 8s\n",
      "13:\tlearn: 0.1757903\ttotal: 9.61s\tremaining: 2m 7s\n",
      "14:\tlearn: 0.1623393\ttotal: 10.3s\tremaining: 2m 7s\n",
      "15:\tlearn: 0.1519850\ttotal: 11s\tremaining: 2m 6s\n",
      "16:\tlearn: 0.1421647\ttotal: 11.7s\tremaining: 2m 5s\n",
      "17:\tlearn: 0.1356184\ttotal: 12.4s\tremaining: 2m 4s\n",
      "18:\tlearn: 0.1235843\ttotal: 13s\tremaining: 2m 4s\n",
      "19:\tlearn: 0.1158857\ttotal: 13.7s\tremaining: 2m 3s\n",
      "20:\tlearn: 0.1062533\ttotal: 14.4s\tremaining: 2m 2s\n",
      "21:\tlearn: 0.1013675\ttotal: 15.1s\tremaining: 2m 1s\n",
      "22:\tlearn: 0.0949522\ttotal: 15.7s\tremaining: 2m 1s\n",
      "23:\tlearn: 0.0878349\ttotal: 16.4s\tremaining: 2m\n",
      "24:\tlearn: 0.0798722\ttotal: 17.1s\tremaining: 1m 59s\n",
      "25:\tlearn: 0.0782160\ttotal: 17.8s\tremaining: 1m 58s\n",
      "26:\tlearn: 0.0740221\ttotal: 18.4s\tremaining: 1m 58s\n",
      "27:\tlearn: 0.0711950\ttotal: 19.1s\tremaining: 1m 57s\n",
      "28:\tlearn: 0.0682171\ttotal: 19.8s\tremaining: 1m 56s\n",
      "29:\tlearn: 0.0648559\ttotal: 20.4s\tremaining: 1m 55s\n",
      "30:\tlearn: 0.0618266\ttotal: 21.1s\tremaining: 1m 55s\n",
      "31:\tlearn: 0.0587971\ttotal: 21.8s\tremaining: 1m 54s\n",
      "32:\tlearn: 0.0560671\ttotal: 22.5s\tremaining: 1m 53s\n",
      "33:\tlearn: 0.0533896\ttotal: 23.2s\tremaining: 1m 53s\n",
      "34:\tlearn: 0.0511807\ttotal: 23.9s\tremaining: 1m 52s\n",
      "35:\tlearn: 0.0486469\ttotal: 24.6s\tremaining: 1m 51s\n",
      "36:\tlearn: 0.0462436\ttotal: 25.2s\tremaining: 1m 51s\n",
      "37:\tlearn: 0.0432654\ttotal: 25.9s\tremaining: 1m 50s\n",
      "38:\tlearn: 0.0409082\ttotal: 26.6s\tremaining: 1m 49s\n",
      "39:\tlearn: 0.0384033\ttotal: 27.3s\tremaining: 1m 49s\n",
      "40:\tlearn: 0.0372851\ttotal: 28s\tremaining: 1m 48s\n",
      "41:\tlearn: 0.0354302\ttotal: 28.6s\tremaining: 1m 47s\n",
      "42:\tlearn: 0.0342820\ttotal: 29.3s\tremaining: 1m 47s\n",
      "43:\tlearn: 0.0331394\ttotal: 30s\tremaining: 1m 46s\n",
      "44:\tlearn: 0.0322649\ttotal: 30.6s\tremaining: 1m 45s\n",
      "45:\tlearn: 0.0310710\ttotal: 31.3s\tremaining: 1m 44s\n",
      "46:\tlearn: 0.0294094\ttotal: 32s\tremaining: 1m 44s\n",
      "47:\tlearn: 0.0290746\ttotal: 32.6s\tremaining: 1m 43s\n",
      "48:\tlearn: 0.0278892\ttotal: 33.3s\tremaining: 1m 42s\n",
      "49:\tlearn: 0.0267785\ttotal: 34s\tremaining: 1m 42s\n",
      "50:\tlearn: 0.0257393\ttotal: 34.7s\tremaining: 1m 41s\n",
      "51:\tlearn: 0.0249738\ttotal: 35.4s\tremaining: 1m 40s\n",
      "52:\tlearn: 0.0242505\ttotal: 36s\tremaining: 1m 39s\n",
      "53:\tlearn: 0.0235299\ttotal: 36.7s\tremaining: 1m 39s\n",
      "54:\tlearn: 0.0226848\ttotal: 37.4s\tremaining: 1m 38s\n",
      "55:\tlearn: 0.0221282\ttotal: 38.1s\tremaining: 1m 37s\n",
      "56:\tlearn: 0.0214511\ttotal: 38.7s\tremaining: 1m 37s\n",
      "57:\tlearn: 0.0206432\ttotal: 39.4s\tremaining: 1m 36s\n",
      "58:\tlearn: 0.0199933\ttotal: 40.1s\tremaining: 1m 35s\n",
      "59:\tlearn: 0.0193903\ttotal: 40.8s\tremaining: 1m 35s\n",
      "60:\tlearn: 0.0188802\ttotal: 41.4s\tremaining: 1m 34s\n",
      "61:\tlearn: 0.0182751\ttotal: 42.1s\tremaining: 1m 33s\n",
      "62:\tlearn: 0.0181292\ttotal: 42.8s\tremaining: 1m 33s\n",
      "63:\tlearn: 0.0176057\ttotal: 43.5s\tremaining: 1m 32s\n",
      "64:\tlearn: 0.0172711\ttotal: 44.1s\tremaining: 1m 31s\n",
      "65:\tlearn: 0.0169332\ttotal: 44.8s\tremaining: 1m 30s\n",
      "66:\tlearn: 0.0165809\ttotal: 45.5s\tremaining: 1m 30s\n",
      "67:\tlearn: 0.0161976\ttotal: 46.2s\tremaining: 1m 29s\n",
      "68:\tlearn: 0.0158210\ttotal: 46.8s\tremaining: 1m 28s\n",
      "69:\tlearn: 0.0155415\ttotal: 47.5s\tremaining: 1m 28s\n",
      "70:\tlearn: 0.0152324\ttotal: 48.2s\tremaining: 1m 27s\n",
      "71:\tlearn: 0.0148270\ttotal: 48.9s\tremaining: 1m 26s\n",
      "72:\tlearn: 0.0145216\ttotal: 49.6s\tremaining: 1m 26s\n",
      "73:\tlearn: 0.0141295\ttotal: 50.2s\tremaining: 1m 25s\n",
      "74:\tlearn: 0.0138704\ttotal: 50.9s\tremaining: 1m 24s\n",
      "75:\tlearn: 0.0134750\ttotal: 51.6s\tremaining: 1m 24s\n",
      "76:\tlearn: 0.0131999\ttotal: 52.3s\tremaining: 1m 23s\n",
      "77:\tlearn: 0.0128895\ttotal: 52.9s\tremaining: 1m 22s\n",
      "78:\tlearn: 0.0126112\ttotal: 53.6s\tremaining: 1m 22s\n",
      "79:\tlearn: 0.0123150\ttotal: 54.3s\tremaining: 1m 21s\n",
      "80:\tlearn: 0.0120743\ttotal: 55s\tremaining: 1m 20s\n",
      "81:\tlearn: 0.0119045\ttotal: 55.6s\tremaining: 1m 20s\n",
      "82:\tlearn: 0.0116865\ttotal: 56.3s\tremaining: 1m 19s\n",
      "83:\tlearn: 0.0114312\ttotal: 57s\tremaining: 1m 18s\n",
      "84:\tlearn: 0.0112322\ttotal: 57.7s\tremaining: 1m 18s\n",
      "85:\tlearn: 0.0110050\ttotal: 58.3s\tremaining: 1m 17s\n",
      "86:\tlearn: 0.0109023\ttotal: 59s\tremaining: 1m 16s\n",
      "87:\tlearn: 0.0107348\ttotal: 59.7s\tremaining: 1m 15s\n",
      "88:\tlearn: 0.0105949\ttotal: 1m\tremaining: 1m 15s\n",
      "89:\tlearn: 0.0104140\ttotal: 1m 1s\tremaining: 1m 14s\n",
      "90:\tlearn: 0.0102631\ttotal: 1m 1s\tremaining: 1m 13s\n",
      "91:\tlearn: 0.0101222\ttotal: 1m 2s\tremaining: 1m 13s\n",
      "92:\tlearn: 0.0100094\ttotal: 1m 3s\tremaining: 1m 12s\n",
      "93:\tlearn: 0.0099091\ttotal: 1m 3s\tremaining: 1m 11s\n",
      "94:\tlearn: 0.0097562\ttotal: 1m 4s\tremaining: 1m 11s\n",
      "95:\tlearn: 0.0095340\ttotal: 1m 5s\tremaining: 1m 10s\n",
      "96:\tlearn: 0.0093538\ttotal: 1m 5s\tremaining: 1m 9s\n",
      "97:\tlearn: 0.0092503\ttotal: 1m 6s\tremaining: 1m 9s\n",
      "98:\tlearn: 0.0091424\ttotal: 1m 7s\tremaining: 1m 8s\n",
      "99:\tlearn: 0.0089810\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "100:\tlearn: 0.0088380\ttotal: 1m 8s\tremaining: 1m 7s\n",
      "101:\tlearn: 0.0087229\ttotal: 1m 9s\tremaining: 1m 6s\n",
      "102:\tlearn: 0.0085486\ttotal: 1m 9s\tremaining: 1m 5s\n",
      "103:\tlearn: 0.0083943\ttotal: 1m 10s\tremaining: 1m 5s\n",
      "104:\tlearn: 0.0082694\ttotal: 1m 11s\tremaining: 1m 4s\n",
      "105:\tlearn: 0.0081874\ttotal: 1m 11s\tremaining: 1m 3s\n",
      "106:\tlearn: 0.0080512\ttotal: 1m 12s\tremaining: 1m 3s\n",
      "107:\tlearn: 0.0079284\ttotal: 1m 13s\tremaining: 1m 2s\n",
      "108:\tlearn: 0.0078001\ttotal: 1m 13s\tremaining: 1m 1s\n",
      "109:\tlearn: 0.0077026\ttotal: 1m 14s\tremaining: 1m 1s\n",
      "110:\tlearn: 0.0076092\ttotal: 1m 15s\tremaining: 1m\n",
      "111:\tlearn: 0.0075397\ttotal: 1m 16s\tremaining: 59.8s\n",
      "112:\tlearn: 0.0074373\ttotal: 1m 16s\tremaining: 59.1s\n",
      "113:\tlearn: 0.0073409\ttotal: 1m 17s\tremaining: 58.4s\n",
      "114:\tlearn: 0.0072613\ttotal: 1m 18s\tremaining: 57.7s\n",
      "115:\tlearn: 0.0071868\ttotal: 1m 18s\tremaining: 57s\n",
      "116:\tlearn: 0.0071003\ttotal: 1m 19s\tremaining: 56.4s\n",
      "117:\tlearn: 0.0069998\ttotal: 1m 20s\tremaining: 55.7s\n",
      "118:\tlearn: 0.0069162\ttotal: 1m 20s\tremaining: 55s\n",
      "119:\tlearn: 0.0067846\ttotal: 1m 21s\tremaining: 54.3s\n",
      "120:\tlearn: 0.0067190\ttotal: 1m 22s\tremaining: 53.7s\n",
      "121:\tlearn: 0.0066399\ttotal: 1m 22s\tremaining: 53s\n",
      "122:\tlearn: 0.0065604\ttotal: 1m 23s\tremaining: 52.3s\n",
      "123:\tlearn: 0.0064832\ttotal: 1m 24s\tremaining: 51.6s\n",
      "124:\tlearn: 0.0064260\ttotal: 1m 24s\tremaining: 51s\n",
      "125:\tlearn: 0.0063715\ttotal: 1m 25s\tremaining: 50.3s\n",
      "126:\tlearn: 0.0062946\ttotal: 1m 26s\tremaining: 49.6s\n",
      "127:\tlearn: 0.0062151\ttotal: 1m 26s\tremaining: 48.9s\n",
      "128:\tlearn: 0.0061436\ttotal: 1m 27s\tremaining: 48.3s\n",
      "129:\tlearn: 0.0060747\ttotal: 1m 28s\tremaining: 47.6s\n",
      "130:\tlearn: 0.0059970\ttotal: 1m 29s\tremaining: 46.9s\n",
      "131:\tlearn: 0.0059228\ttotal: 1m 29s\tremaining: 46.2s\n",
      "132:\tlearn: 0.0058706\ttotal: 1m 30s\tremaining: 45.5s\n",
      "133:\tlearn: 0.0058104\ttotal: 1m 31s\tremaining: 44.9s\n",
      "134:\tlearn: 0.0057690\ttotal: 1m 31s\tremaining: 44.2s\n",
      "135:\tlearn: 0.0057149\ttotal: 1m 32s\tremaining: 43.5s\n",
      "136:\tlearn: 0.0056572\ttotal: 1m 33s\tremaining: 42.8s\n",
      "137:\tlearn: 0.0055945\ttotal: 1m 33s\tremaining: 42.1s\n",
      "138:\tlearn: 0.0055297\ttotal: 1m 34s\tremaining: 41.5s\n",
      "139:\tlearn: 0.0054693\ttotal: 1m 35s\tremaining: 40.8s\n",
      "140:\tlearn: 0.0054232\ttotal: 1m 35s\tremaining: 40.1s\n",
      "141:\tlearn: 0.0053732\ttotal: 1m 36s\tremaining: 39.4s\n",
      "142:\tlearn: 0.0053195\ttotal: 1m 37s\tremaining: 38.7s\n",
      "143:\tlearn: 0.0052831\ttotal: 1m 37s\tremaining: 38.1s\n",
      "144:\tlearn: 0.0052214\ttotal: 1m 38s\tremaining: 37.4s\n",
      "145:\tlearn: 0.0051858\ttotal: 1m 39s\tremaining: 36.7s\n",
      "146:\tlearn: 0.0051466\ttotal: 1m 39s\tremaining: 36s\n",
      "147:\tlearn: 0.0051096\ttotal: 1m 40s\tremaining: 35.3s\n",
      "148:\tlearn: 0.0050625\ttotal: 1m 41s\tremaining: 34.6s\n",
      "149:\tlearn: 0.0050170\ttotal: 1m 41s\tremaining: 34s\n",
      "150:\tlearn: 0.0049783\ttotal: 1m 42s\tremaining: 33.3s\n",
      "151:\tlearn: 0.0049386\ttotal: 1m 43s\tremaining: 32.6s\n",
      "152:\tlearn: 0.0049028\ttotal: 1m 43s\tremaining: 31.9s\n",
      "153:\tlearn: 0.0048592\ttotal: 1m 44s\tremaining: 31.2s\n",
      "154:\tlearn: 0.0048160\ttotal: 1m 45s\tremaining: 30.6s\n",
      "155:\tlearn: 0.0047657\ttotal: 1m 45s\tremaining: 29.9s\n",
      "156:\tlearn: 0.0047133\ttotal: 1m 46s\tremaining: 29.2s\n",
      "157:\tlearn: 0.0046707\ttotal: 1m 47s\tremaining: 28.5s\n",
      "158:\tlearn: 0.0046312\ttotal: 1m 48s\tremaining: 27.9s\n",
      "159:\tlearn: 0.0045925\ttotal: 1m 48s\tremaining: 27.2s\n",
      "160:\tlearn: 0.0045680\ttotal: 1m 49s\tremaining: 26.5s\n",
      "161:\tlearn: 0.0045484\ttotal: 1m 50s\tremaining: 25.8s\n",
      "162:\tlearn: 0.0045027\ttotal: 1m 50s\tremaining: 25.1s\n",
      "163:\tlearn: 0.0044638\ttotal: 1m 51s\tremaining: 24.5s\n",
      "164:\tlearn: 0.0044198\ttotal: 1m 52s\tremaining: 23.8s\n",
      "165:\tlearn: 0.0043740\ttotal: 1m 52s\tremaining: 23.1s\n",
      "166:\tlearn: 0.0043396\ttotal: 1m 53s\tremaining: 22.4s\n",
      "167:\tlearn: 0.0042982\ttotal: 1m 54s\tremaining: 21.7s\n",
      "168:\tlearn: 0.0042658\ttotal: 1m 54s\tremaining: 21.1s\n",
      "169:\tlearn: 0.0042422\ttotal: 1m 55s\tremaining: 20.4s\n",
      "170:\tlearn: 0.0042029\ttotal: 1m 56s\tremaining: 19.7s\n",
      "171:\tlearn: 0.0041698\ttotal: 1m 56s\tremaining: 19s\n",
      "172:\tlearn: 0.0041644\ttotal: 1m 57s\tremaining: 18.3s\n",
      "173:\tlearn: 0.0041390\ttotal: 1m 58s\tremaining: 17.7s\n",
      "174:\tlearn: 0.0041005\ttotal: 1m 58s\tremaining: 17s\n",
      "175:\tlearn: 0.0040681\ttotal: 1m 59s\tremaining: 16.3s\n",
      "176:\tlearn: 0.0040363\ttotal: 2m\tremaining: 15.6s\n",
      "177:\tlearn: 0.0040150\ttotal: 2m\tremaining: 14.9s\n",
      "178:\tlearn: 0.0039836\ttotal: 2m 1s\tremaining: 14.3s\n",
      "179:\tlearn: 0.0039531\ttotal: 2m 2s\tremaining: 13.6s\n",
      "180:\tlearn: 0.0039239\ttotal: 2m 3s\tremaining: 12.9s\n",
      "181:\tlearn: 0.0038940\ttotal: 2m 3s\tremaining: 12.2s\n",
      "182:\tlearn: 0.0038682\ttotal: 2m 4s\tremaining: 11.6s\n",
      "183:\tlearn: 0.0038335\ttotal: 2m 5s\tremaining: 10.9s\n",
      "184:\tlearn: 0.0038130\ttotal: 2m 5s\tremaining: 10.2s\n",
      "185:\tlearn: 0.0038062\ttotal: 2m 6s\tremaining: 9.51s\n",
      "186:\tlearn: 0.0037700\ttotal: 2m 7s\tremaining: 8.83s\n",
      "187:\tlearn: 0.0037434\ttotal: 2m 7s\tremaining: 8.15s\n",
      "188:\tlearn: 0.0037167\ttotal: 2m 8s\tremaining: 7.47s\n",
      "189:\tlearn: 0.0036885\ttotal: 2m 9s\tremaining: 6.79s\n",
      "190:\tlearn: 0.0036609\ttotal: 2m 9s\tremaining: 6.12s\n",
      "191:\tlearn: 0.0036332\ttotal: 2m 10s\tremaining: 5.43s\n",
      "192:\tlearn: 0.0036025\ttotal: 2m 11s\tremaining: 4.76s\n",
      "193:\tlearn: 0.0035829\ttotal: 2m 11s\tremaining: 4.08s\n",
      "194:\tlearn: 0.0035546\ttotal: 2m 12s\tremaining: 3.4s\n",
      "195:\tlearn: 0.0035314\ttotal: 2m 13s\tremaining: 2.72s\n",
      "196:\tlearn: 0.0035152\ttotal: 2m 13s\tremaining: 2.04s\n",
      "197:\tlearn: 0.0034879\ttotal: 2m 14s\tremaining: 1.36s\n",
      "198:\tlearn: 0.0034677\ttotal: 2m 15s\tremaining: 679ms\n",
      "199:\tlearn: 0.0034517\ttotal: 2m 15s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.5, border_count=96, depth=10, eval_metric=Logloss, iterations=200, l2_leaf_reg=7, leaf_estimation_method=Gradient, learning_rate=0.7, random_strength=0.1; total time= 2.3min\n",
      "0:\tlearn: 0.6794807\ttotal: 25.7ms\tremaining: 12.8s\n",
      "1:\tlearn: 0.6756869\ttotal: 53.6ms\tremaining: 13.3s\n",
      "2:\tlearn: 0.6766518\ttotal: 80.3ms\tremaining: 13.3s\n",
      "3:\tlearn: 0.6874574\ttotal: 105ms\tremaining: 13s\n",
      "4:\tlearn: 0.6956185\ttotal: 128ms\tremaining: 12.7s\n",
      "5:\tlearn: 0.6997267\ttotal: 152ms\tremaining: 12.5s\n",
      "6:\tlearn: 0.7113468\ttotal: 178ms\tremaining: 12.5s\n",
      "7:\tlearn: 0.7195417\ttotal: 202ms\tremaining: 12.4s\n",
      "8:\tlearn: 0.7243644\ttotal: 227ms\tremaining: 12.4s\n",
      "9:\tlearn: 0.7327484\ttotal: 251ms\tremaining: 12.3s\n",
      "10:\tlearn: 0.7396963\ttotal: 278ms\tremaining: 12.3s\n",
      "11:\tlearn: 0.7440758\ttotal: 305ms\tremaining: 12.4s\n",
      "12:\tlearn: 0.7523371\ttotal: 327ms\tremaining: 12.3s\n",
      "13:\tlearn: 0.7559913\ttotal: 351ms\tremaining: 12.2s\n",
      "14:\tlearn: 0.7611793\ttotal: 374ms\tremaining: 12.1s\n",
      "15:\tlearn: 0.7669404\ttotal: 398ms\tremaining: 12s\n",
      "16:\tlearn: 0.7702422\ttotal: 420ms\tremaining: 11.9s\n",
      "17:\tlearn: 0.7735074\ttotal: 444ms\tremaining: 11.9s\n",
      "18:\tlearn: 0.7782823\ttotal: 468ms\tremaining: 11.9s\n",
      "19:\tlearn: 0.7814733\ttotal: 492ms\tremaining: 11.8s\n",
      "20:\tlearn: 0.7870942\ttotal: 518ms\tremaining: 11.8s\n",
      "21:\tlearn: 0.7884255\ttotal: 543ms\tremaining: 11.8s\n",
      "22:\tlearn: 0.7926444\ttotal: 570ms\tremaining: 11.8s\n",
      "23:\tlearn: 0.7954041\ttotal: 594ms\tremaining: 11.8s\n",
      "24:\tlearn: 0.7974264\ttotal: 623ms\tremaining: 11.8s\n",
      "25:\tlearn: 0.8003170\ttotal: 653ms\tremaining: 11.9s\n",
      "26:\tlearn: 0.8025541\ttotal: 681ms\tremaining: 11.9s\n",
      "27:\tlearn: 0.8046980\ttotal: 706ms\tremaining: 11.9s\n",
      "28:\tlearn: 0.8059967\ttotal: 734ms\tremaining: 11.9s\n",
      "29:\tlearn: 0.8095663\ttotal: 764ms\tremaining: 12s\n",
      "30:\tlearn: 0.8129614\ttotal: 790ms\tremaining: 11.9s\n",
      "31:\tlearn: 0.8154166\ttotal: 812ms\tremaining: 11.9s\n",
      "32:\tlearn: 0.8152417\ttotal: 839ms\tremaining: 11.9s\n",
      "33:\tlearn: 0.8177223\ttotal: 862ms\tremaining: 11.8s\n",
      "34:\tlearn: 0.8216393\ttotal: 887ms\tremaining: 11.8s\n",
      "35:\tlearn: 0.8223335\ttotal: 914ms\tremaining: 11.8s\n",
      "36:\tlearn: 0.8232611\ttotal: 938ms\tremaining: 11.7s\n",
      "37:\tlearn: 0.8253795\ttotal: 960ms\tremaining: 11.7s\n",
      "38:\tlearn: 0.8268428\ttotal: 982ms\tremaining: 11.6s\n",
      "39:\tlearn: 0.8288351\ttotal: 1.01s\tremaining: 11.6s\n",
      "40:\tlearn: 0.8310734\ttotal: 1.04s\tremaining: 11.6s\n",
      "41:\tlearn: 0.8337137\ttotal: 1.06s\tremaining: 11.6s\n",
      "42:\tlearn: 0.8347489\ttotal: 1.08s\tremaining: 11.5s\n",
      "43:\tlearn: 0.8359988\ttotal: 1.11s\tremaining: 11.6s\n",
      "44:\tlearn: 0.8374448\ttotal: 1.14s\tremaining: 11.6s\n",
      "45:\tlearn: 0.8385207\ttotal: 1.17s\tremaining: 11.6s\n",
      "46:\tlearn: 0.8400476\ttotal: 1.2s\tremaining: 11.5s\n",
      "47:\tlearn: 0.8428047\ttotal: 1.22s\tremaining: 11.5s\n",
      "48:\tlearn: 0.8446823\ttotal: 1.25s\tremaining: 11.5s\n",
      "49:\tlearn: 0.8470950\ttotal: 1.28s\tremaining: 11.5s\n",
      "50:\tlearn: 0.8471521\ttotal: 1.3s\tremaining: 11.5s\n",
      "51:\tlearn: 0.8487253\ttotal: 1.32s\tremaining: 11.4s\n",
      "52:\tlearn: 0.8503226\ttotal: 1.35s\tremaining: 11.4s\n",
      "53:\tlearn: 0.8531919\ttotal: 1.38s\tremaining: 11.4s\n",
      "54:\tlearn: 0.8545680\ttotal: 1.4s\tremaining: 11.3s\n",
      "55:\tlearn: 0.8560400\ttotal: 1.42s\tremaining: 11.3s\n",
      "56:\tlearn: 0.8573551\ttotal: 1.45s\tremaining: 11.2s\n",
      "57:\tlearn: 0.8599455\ttotal: 1.47s\tremaining: 11.2s\n",
      "58:\tlearn: 0.8605262\ttotal: 1.49s\tremaining: 11.2s\n",
      "59:\tlearn: 0.8608247\ttotal: 1.52s\tremaining: 11.1s\n",
      "60:\tlearn: 0.8632673\ttotal: 1.54s\tremaining: 11.1s\n",
      "61:\tlearn: 0.8646777\ttotal: 1.56s\tremaining: 11s\n",
      "62:\tlearn: 0.8654293\ttotal: 1.59s\tremaining: 11s\n",
      "63:\tlearn: 0.8667955\ttotal: 1.61s\tremaining: 11s\n",
      "64:\tlearn: 0.8677039\ttotal: 1.64s\tremaining: 11s\n",
      "65:\tlearn: 0.8686598\ttotal: 1.66s\tremaining: 10.9s\n",
      "66:\tlearn: 0.8690954\ttotal: 1.69s\tremaining: 10.9s\n",
      "67:\tlearn: 0.8702638\ttotal: 1.72s\tremaining: 10.9s\n",
      "68:\tlearn: 0.8715123\ttotal: 1.75s\tremaining: 10.9s\n",
      "69:\tlearn: 0.8732632\ttotal: 1.77s\tremaining: 10.9s\n",
      "70:\tlearn: 0.8741005\ttotal: 1.79s\tremaining: 10.8s\n",
      "71:\tlearn: 0.8748884\ttotal: 1.81s\tremaining: 10.8s\n",
      "72:\tlearn: 0.8762953\ttotal: 1.84s\tremaining: 10.8s\n",
      "73:\tlearn: 0.8777299\ttotal: 1.86s\tremaining: 10.7s\n",
      "74:\tlearn: 0.8778917\ttotal: 1.89s\tremaining: 10.7s\n",
      "75:\tlearn: 0.8795682\ttotal: 1.92s\tremaining: 10.7s\n",
      "76:\tlearn: 0.8797305\ttotal: 1.94s\tremaining: 10.7s\n",
      "77:\tlearn: 0.8808167\ttotal: 1.97s\tremaining: 10.7s\n",
      "78:\tlearn: 0.8824346\ttotal: 1.99s\tremaining: 10.6s\n",
      "79:\tlearn: 0.8854363\ttotal: 2.02s\tremaining: 10.6s\n",
      "80:\tlearn: 0.8862204\ttotal: 2.04s\tremaining: 10.6s\n",
      "81:\tlearn: 0.8865294\ttotal: 2.07s\tremaining: 10.5s\n",
      "82:\tlearn: 0.8882823\ttotal: 2.09s\tremaining: 10.5s\n",
      "83:\tlearn: 0.8888558\ttotal: 2.11s\tremaining: 10.5s\n",
      "84:\tlearn: 0.8894290\ttotal: 2.14s\tremaining: 10.4s\n",
      "85:\tlearn: 0.8912277\ttotal: 2.17s\tremaining: 10.4s\n",
      "86:\tlearn: 0.8928235\ttotal: 2.19s\tremaining: 10.4s\n",
      "87:\tlearn: 0.8935917\ttotal: 2.21s\tremaining: 10.4s\n",
      "88:\tlearn: 0.8950084\ttotal: 2.24s\tremaining: 10.3s\n",
      "89:\tlearn: 0.8956379\ttotal: 2.26s\tremaining: 10.3s\n",
      "90:\tlearn: 0.8967812\ttotal: 2.28s\tremaining: 10.3s\n",
      "91:\tlearn: 0.8976041\ttotal: 2.31s\tremaining: 10.2s\n",
      "92:\tlearn: 0.8994036\ttotal: 2.33s\tremaining: 10.2s\n",
      "93:\tlearn: 0.9009439\ttotal: 2.36s\tremaining: 10.2s\n",
      "94:\tlearn: 0.9019530\ttotal: 2.38s\tremaining: 10.2s\n",
      "95:\tlearn: 0.9009842\ttotal: 2.41s\tremaining: 10.1s\n",
      "96:\tlearn: 0.9020621\ttotal: 2.43s\tremaining: 10.1s\n",
      "97:\tlearn: 0.9038538\ttotal: 2.46s\tremaining: 10.1s\n",
      "98:\tlearn: 0.9052537\ttotal: 2.49s\tremaining: 10.1s\n",
      "99:\tlearn: 0.9061289\ttotal: 2.51s\tremaining: 10.1s\n",
      "100:\tlearn: 0.9070588\ttotal: 2.54s\tremaining: 10s\n",
      "101:\tlearn: 0.9082327\ttotal: 2.57s\tremaining: 10s\n",
      "102:\tlearn: 0.9098043\ttotal: 2.59s\tremaining: 10s\n",
      "103:\tlearn: 0.9101202\ttotal: 2.62s\tremaining: 9.98s\n",
      "104:\tlearn: 0.9112214\ttotal: 2.65s\tremaining: 9.95s\n",
      "105:\tlearn: 0.9139539\ttotal: 2.67s\tremaining: 9.93s\n",
      "106:\tlearn: 0.9131558\ttotal: 2.7s\tremaining: 9.92s\n",
      "107:\tlearn: 0.9132638\ttotal: 2.73s\tremaining: 9.9s\n",
      "108:\tlearn: 0.9145329\ttotal: 2.75s\tremaining: 9.88s\n",
      "109:\tlearn: 0.9149963\ttotal: 2.78s\tremaining: 9.86s\n",
      "110:\tlearn: 0.9160207\ttotal: 2.81s\tremaining: 9.85s\n",
      "111:\tlearn: 0.9166708\ttotal: 2.83s\tremaining: 9.82s\n",
      "112:\tlearn: 0.9171013\ttotal: 2.86s\tremaining: 9.79s\n",
      "113:\tlearn: 0.9183765\ttotal: 2.88s\tremaining: 9.76s\n",
      "114:\tlearn: 0.9191418\ttotal: 2.91s\tremaining: 9.73s\n",
      "115:\tlearn: 0.9198291\ttotal: 2.93s\tremaining: 9.69s\n",
      "116:\tlearn: 0.9207311\ttotal: 2.95s\tremaining: 9.66s\n",
      "117:\tlearn: 0.9204692\ttotal: 2.97s\tremaining: 9.63s\n",
      "118:\tlearn: 0.9201612\ttotal: 3s\tremaining: 9.6s\n",
      "119:\tlearn: 0.9209557\ttotal: 3.03s\tremaining: 9.59s\n",
      "120:\tlearn: 0.9216915\ttotal: 3.06s\tremaining: 9.57s\n",
      "121:\tlearn: 0.9223799\ttotal: 3.08s\tremaining: 9.55s\n",
      "122:\tlearn: 0.9235976\ttotal: 3.11s\tremaining: 9.52s\n",
      "123:\tlearn: 0.9246401\ttotal: 3.13s\tremaining: 9.5s\n",
      "124:\tlearn: 0.9256494\ttotal: 3.16s\tremaining: 9.47s\n",
      "125:\tlearn: 0.9262854\ttotal: 3.18s\tremaining: 9.44s\n",
      "126:\tlearn: 0.9268220\ttotal: 3.2s\tremaining: 9.41s\n",
      "127:\tlearn: 0.9281762\ttotal: 3.23s\tremaining: 9.38s\n",
      "128:\tlearn: 0.9287528\ttotal: 3.25s\tremaining: 9.36s\n",
      "129:\tlearn: 0.9296910\ttotal: 3.27s\tremaining: 9.32s\n",
      "130:\tlearn: 0.9296280\ttotal: 3.3s\tremaining: 9.29s\n",
      "131:\tlearn: 0.9299686\ttotal: 3.32s\tremaining: 9.27s\n",
      "132:\tlearn: 0.9304387\ttotal: 3.35s\tremaining: 9.24s\n",
      "133:\tlearn: 0.9303924\ttotal: 3.37s\tremaining: 9.21s\n",
      "134:\tlearn: 0.9310431\ttotal: 3.4s\tremaining: 9.18s\n",
      "135:\tlearn: 0.9322709\ttotal: 3.42s\tremaining: 9.15s\n",
      "136:\tlearn: 0.9325971\ttotal: 3.44s\tremaining: 9.12s\n",
      "137:\tlearn: 0.9336387\ttotal: 3.46s\tremaining: 9.09s\n",
      "138:\tlearn: 0.9336653\ttotal: 3.49s\tremaining: 9.07s\n",
      "139:\tlearn: 0.9344156\ttotal: 3.52s\tremaining: 9.04s\n",
      "140:\tlearn: 0.9351529\ttotal: 3.54s\tremaining: 9.03s\n",
      "141:\tlearn: 0.9356912\ttotal: 3.57s\tremaining: 9s\n",
      "142:\tlearn: 0.9363016\ttotal: 3.59s\tremaining: 8.97s\n",
      "143:\tlearn: 0.9374160\ttotal: 3.62s\tremaining: 8.95s\n",
      "144:\tlearn: 0.9373973\ttotal: 3.65s\tremaining: 8.94s\n",
      "145:\tlearn: 0.9384991\ttotal: 3.68s\tremaining: 8.92s\n",
      "146:\tlearn: 0.9388914\ttotal: 3.7s\tremaining: 8.89s\n",
      "147:\tlearn: 0.9397830\ttotal: 3.73s\tremaining: 8.88s\n",
      "148:\tlearn: 0.9395960\ttotal: 3.75s\tremaining: 8.85s\n",
      "149:\tlearn: 0.9406266\ttotal: 3.78s\tremaining: 8.82s\n",
      "150:\tlearn: 0.9415277\ttotal: 3.81s\tremaining: 8.8s\n",
      "151:\tlearn: 0.9425573\ttotal: 3.83s\tremaining: 8.77s\n",
      "152:\tlearn: 0.9439164\ttotal: 3.85s\tremaining: 8.74s\n",
      "153:\tlearn: 0.9438638\ttotal: 3.88s\tremaining: 8.71s\n",
      "154:\tlearn: 0.9447822\ttotal: 3.9s\tremaining: 8.68s\n",
      "155:\tlearn: 0.9457426\ttotal: 3.92s\tremaining: 8.64s\n",
      "156:\tlearn: 0.9465086\ttotal: 3.94s\tremaining: 8.61s\n",
      "157:\tlearn: 0.9469489\ttotal: 3.96s\tremaining: 8.58s\n",
      "158:\tlearn: 0.9472215\ttotal: 3.99s\tremaining: 8.55s\n",
      "159:\tlearn: 0.9478720\ttotal: 4.01s\tremaining: 8.52s\n",
      "160:\tlearn: 0.9484125\ttotal: 4.03s\tremaining: 8.49s\n",
      "161:\tlearn: 0.9487333\ttotal: 4.06s\tremaining: 8.47s\n",
      "162:\tlearn: 0.9490798\ttotal: 4.09s\tremaining: 8.45s\n",
      "163:\tlearn: 0.9491999\ttotal: 4.11s\tremaining: 8.43s\n",
      "164:\tlearn: 0.9498204\ttotal: 4.14s\tremaining: 8.4s\n",
      "165:\tlearn: 0.9501621\ttotal: 4.16s\tremaining: 8.37s\n",
      "166:\tlearn: 0.9504891\ttotal: 4.18s\tremaining: 8.34s\n",
      "167:\tlearn: 0.9509359\ttotal: 4.21s\tremaining: 8.31s\n",
      "168:\tlearn: 0.9517627\ttotal: 4.24s\tremaining: 8.3s\n",
      "169:\tlearn: 0.9525853\ttotal: 4.26s\tremaining: 8.28s\n",
      "170:\tlearn: 0.9534466\ttotal: 4.29s\tremaining: 8.25s\n",
      "171:\tlearn: 0.9534698\ttotal: 4.31s\tremaining: 8.23s\n",
      "172:\tlearn: 0.9546294\ttotal: 4.34s\tremaining: 8.2s\n",
      "173:\tlearn: 0.9543958\ttotal: 4.36s\tremaining: 8.18s\n",
      "174:\tlearn: 0.9551493\ttotal: 4.39s\tremaining: 8.15s\n",
      "175:\tlearn: 0.9561395\ttotal: 4.42s\tremaining: 8.13s\n",
      "176:\tlearn: 0.9569258\ttotal: 4.44s\tremaining: 8.11s\n",
      "177:\tlearn: 0.9565652\ttotal: 4.47s\tremaining: 8.09s\n",
      "178:\tlearn: 0.9569560\ttotal: 4.5s\tremaining: 8.07s\n",
      "179:\tlearn: 0.9580193\ttotal: 4.53s\tremaining: 8.05s\n",
      "180:\tlearn: 0.9580151\ttotal: 4.55s\tremaining: 8.02s\n",
      "181:\tlearn: 0.9586496\ttotal: 4.58s\tremaining: 8s\n",
      "182:\tlearn: 0.9594925\ttotal: 4.6s\tremaining: 7.97s\n",
      "183:\tlearn: 0.9594446\ttotal: 4.63s\tremaining: 7.95s\n",
      "184:\tlearn: 0.9601558\ttotal: 4.65s\tremaining: 7.92s\n",
      "185:\tlearn: 0.9605473\ttotal: 4.67s\tremaining: 7.89s\n",
      "186:\tlearn: 0.9601120\ttotal: 4.7s\tremaining: 7.86s\n",
      "187:\tlearn: 0.9612752\ttotal: 4.72s\tremaining: 7.83s\n",
      "188:\tlearn: 0.9614943\ttotal: 4.74s\tremaining: 7.8s\n",
      "189:\tlearn: 0.9624488\ttotal: 4.77s\tremaining: 7.78s\n",
      "190:\tlearn: 0.9632368\ttotal: 4.79s\tremaining: 7.75s\n",
      "191:\tlearn: 0.9639289\ttotal: 4.82s\tremaining: 7.73s\n",
      "192:\tlearn: 0.9637772\ttotal: 4.84s\tremaining: 7.71s\n",
      "193:\tlearn: 0.9644660\ttotal: 4.87s\tremaining: 7.68s\n",
      "194:\tlearn: 0.9648412\ttotal: 4.89s\tremaining: 7.65s\n",
      "195:\tlearn: 0.9652722\ttotal: 4.92s\tremaining: 7.63s\n",
      "196:\tlearn: 0.9659279\ttotal: 4.95s\tremaining: 7.61s\n",
      "197:\tlearn: 0.9668152\ttotal: 4.98s\tremaining: 7.59s\n",
      "198:\tlearn: 0.9667284\ttotal: 5s\tremaining: 7.57s\n",
      "199:\tlearn: 0.9674837\ttotal: 5.03s\tremaining: 7.54s\n",
      "200:\tlearn: 0.9675838\ttotal: 5.05s\tremaining: 7.51s\n",
      "201:\tlearn: 0.9681841\ttotal: 5.07s\tremaining: 7.48s\n",
      "202:\tlearn: 0.9683715\ttotal: 5.1s\tremaining: 7.46s\n",
      "203:\tlearn: 0.9687391\ttotal: 5.12s\tremaining: 7.43s\n",
      "204:\tlearn: 0.9692300\ttotal: 5.14s\tremaining: 7.4s\n",
      "205:\tlearn: 0.9688595\ttotal: 5.16s\tremaining: 7.37s\n",
      "206:\tlearn: 0.9690598\ttotal: 5.19s\tremaining: 7.34s\n",
      "207:\tlearn: 0.9702980\ttotal: 5.21s\tremaining: 7.32s\n",
      "208:\tlearn: 0.9705529\ttotal: 5.24s\tremaining: 7.29s\n",
      "209:\tlearn: 0.9711654\ttotal: 5.26s\tremaining: 7.27s\n",
      "210:\tlearn: 0.9710566\ttotal: 5.29s\tremaining: 7.25s\n",
      "211:\tlearn: 0.9712540\ttotal: 5.32s\tremaining: 7.23s\n",
      "212:\tlearn: 0.9710225\ttotal: 5.35s\tremaining: 7.21s\n",
      "213:\tlearn: 0.9716632\ttotal: 5.38s\tremaining: 7.19s\n",
      "214:\tlearn: 0.9719036\ttotal: 5.4s\tremaining: 7.16s\n",
      "215:\tlearn: 0.9717520\ttotal: 5.42s\tremaining: 7.13s\n",
      "216:\tlearn: 0.9728457\ttotal: 5.45s\tremaining: 7.1s\n",
      "217:\tlearn: 0.9731490\ttotal: 5.48s\tremaining: 7.09s\n",
      "218:\tlearn: 0.9735879\ttotal: 5.51s\tremaining: 7.06s\n",
      "219:\tlearn: 0.9737831\ttotal: 5.53s\tremaining: 7.04s\n",
      "220:\tlearn: 0.9738782\ttotal: 5.55s\tremaining: 7.01s\n",
      "221:\tlearn: 0.9739270\ttotal: 5.58s\tremaining: 6.98s\n",
      "222:\tlearn: 0.9740377\ttotal: 5.6s\tremaining: 6.95s\n",
      "223:\tlearn: 0.9746829\ttotal: 5.62s\tremaining: 6.92s\n",
      "224:\tlearn: 0.9752356\ttotal: 5.64s\tremaining: 6.89s\n",
      "225:\tlearn: 0.9754460\ttotal: 5.67s\tremaining: 6.87s\n",
      "226:\tlearn: 0.9750915\ttotal: 5.69s\tremaining: 6.85s\n",
      "227:\tlearn: 0.9752795\ttotal: 5.72s\tremaining: 6.82s\n",
      "228:\tlearn: 0.9758275\ttotal: 5.74s\tremaining: 6.79s\n",
      "229:\tlearn: 0.9762729\ttotal: 5.76s\tremaining: 6.76s\n",
      "230:\tlearn: 0.9765414\ttotal: 5.78s\tremaining: 6.74s\n",
      "231:\tlearn: 0.9769890\ttotal: 5.81s\tremaining: 6.71s\n",
      "232:\tlearn: 0.9771827\ttotal: 5.84s\tremaining: 6.69s\n",
      "233:\tlearn: 0.9779851\ttotal: 5.86s\tremaining: 6.67s\n",
      "234:\tlearn: 0.9785804\ttotal: 5.88s\tremaining: 6.63s\n",
      "235:\tlearn: 0.9787853\ttotal: 5.91s\tremaining: 6.61s\n",
      "236:\tlearn: 0.9783350\ttotal: 5.93s\tremaining: 6.58s\n",
      "237:\tlearn: 0.9789241\ttotal: 5.96s\tremaining: 6.55s\n",
      "238:\tlearn: 0.9792702\ttotal: 5.98s\tremaining: 6.54s\n",
      "239:\tlearn: 0.9793664\ttotal: 6.01s\tremaining: 6.51s\n",
      "240:\tlearn: 0.9796123\ttotal: 6.04s\tremaining: 6.49s\n",
      "241:\tlearn: 0.9802701\ttotal: 6.06s\tremaining: 6.46s\n",
      "242:\tlearn: 0.9805674\ttotal: 6.09s\tremaining: 6.44s\n",
      "243:\tlearn: 0.9809122\ttotal: 6.11s\tremaining: 6.41s\n",
      "244:\tlearn: 0.9812060\ttotal: 6.13s\tremaining: 6.38s\n",
      "245:\tlearn: 0.9819132\ttotal: 6.16s\tremaining: 6.36s\n",
      "246:\tlearn: 0.9825143\ttotal: 6.18s\tremaining: 6.33s\n",
      "247:\tlearn: 0.9824650\ttotal: 6.21s\tremaining: 6.3s\n",
      "248:\tlearn: 0.9829657\ttotal: 6.23s\tremaining: 6.28s\n",
      "249:\tlearn: 0.9831139\ttotal: 6.25s\tremaining: 6.25s\n",
      "250:\tlearn: 0.9837582\ttotal: 6.28s\tremaining: 6.23s\n",
      "251:\tlearn: 0.9832571\ttotal: 6.3s\tremaining: 6.2s\n",
      "252:\tlearn: 0.9832998\ttotal: 6.33s\tremaining: 6.18s\n",
      "253:\tlearn: 0.9840551\ttotal: 6.35s\tremaining: 6.15s\n",
      "254:\tlearn: 0.9847036\ttotal: 6.38s\tremaining: 6.13s\n",
      "255:\tlearn: 0.9843043\ttotal: 6.41s\tremaining: 6.11s\n",
      "256:\tlearn: 0.9848073\ttotal: 6.43s\tremaining: 6.08s\n",
      "257:\tlearn: 0.9852638\ttotal: 6.46s\tremaining: 6.06s\n",
      "258:\tlearn: 0.9853600\ttotal: 6.49s\tremaining: 6.04s\n",
      "259:\tlearn: 0.9849079\ttotal: 6.52s\tremaining: 6.02s\n",
      "260:\tlearn: 0.9846123\ttotal: 6.55s\tremaining: 6s\n",
      "261:\tlearn: 0.9853148\ttotal: 6.57s\tremaining: 5.97s\n",
      "262:\tlearn: 0.9855699\ttotal: 6.6s\tremaining: 5.95s\n",
      "263:\tlearn: 0.9852246\ttotal: 6.62s\tremaining: 5.92s\n",
      "264:\tlearn: 0.9857229\ttotal: 6.65s\tremaining: 5.9s\n",
      "265:\tlearn: 0.9859736\ttotal: 6.67s\tremaining: 5.87s\n",
      "266:\tlearn: 0.9860259\ttotal: 6.7s\tremaining: 5.84s\n",
      "267:\tlearn: 0.9863785\ttotal: 6.72s\tremaining: 5.82s\n",
      "268:\tlearn: 0.9865286\ttotal: 6.75s\tremaining: 5.79s\n",
      "269:\tlearn: 0.9864749\ttotal: 6.78s\tremaining: 5.77s\n",
      "270:\tlearn: 0.9862242\ttotal: 6.8s\tremaining: 5.75s\n",
      "271:\tlearn: 0.9866801\ttotal: 6.82s\tremaining: 5.72s\n",
      "272:\tlearn: 0.9871331\ttotal: 6.85s\tremaining: 5.69s\n",
      "273:\tlearn: 0.9876320\ttotal: 6.87s\tremaining: 5.67s\n",
      "274:\tlearn: 0.9878827\ttotal: 6.9s\tremaining: 5.64s\n",
      "275:\tlearn: 0.9881324\ttotal: 6.92s\tremaining: 5.62s\n",
      "276:\tlearn: 0.9880839\ttotal: 6.95s\tremaining: 5.6s\n",
      "277:\tlearn: 0.9883370\ttotal: 6.97s\tremaining: 5.57s\n",
      "278:\tlearn: 0.9886849\ttotal: 7s\tremaining: 5.54s\n",
      "279:\tlearn: 0.9887889\ttotal: 7.02s\tremaining: 5.52s\n",
      "280:\tlearn: 0.9891359\ttotal: 7.05s\tremaining: 5.49s\n",
      "281:\tlearn: 0.9891348\ttotal: 7.07s\tremaining: 5.46s\n",
      "282:\tlearn: 0.9894334\ttotal: 7.1s\tremaining: 5.44s\n",
      "283:\tlearn: 0.9895870\ttotal: 7.12s\tremaining: 5.42s\n",
      "284:\tlearn: 0.9899356\ttotal: 7.15s\tremaining: 5.39s\n",
      "285:\tlearn: 0.9906853\ttotal: 7.17s\tremaining: 5.37s\n",
      "286:\tlearn: 0.9904858\ttotal: 7.2s\tremaining: 5.34s\n",
      "287:\tlearn: 0.9901847\ttotal: 7.22s\tremaining: 5.32s\n",
      "288:\tlearn: 0.9906900\ttotal: 7.25s\tremaining: 5.29s\n",
      "289:\tlearn: 0.9905395\ttotal: 7.28s\tremaining: 5.27s\n",
      "290:\tlearn: 0.9905893\ttotal: 7.3s\tremaining: 5.25s\n",
      "291:\tlearn: 0.9905893\ttotal: 7.33s\tremaining: 5.22s\n",
      "292:\tlearn: 0.9909393\ttotal: 7.35s\tremaining: 5.19s\n",
      "293:\tlearn: 0.9910382\ttotal: 7.38s\tremaining: 5.17s\n",
      "294:\tlearn: 0.9911861\ttotal: 7.4s\tremaining: 5.14s\n",
      "295:\tlearn: 0.9914874\ttotal: 7.43s\tremaining: 5.12s\n",
      "296:\tlearn: 0.9916364\ttotal: 7.45s\tremaining: 5.09s\n",
      "297:\tlearn: 0.9913376\ttotal: 7.48s\tremaining: 5.07s\n",
      "298:\tlearn: 0.9914866\ttotal: 7.5s\tremaining: 5.04s\n",
      "299:\tlearn: 0.9915399\ttotal: 7.54s\tremaining: 5.02s\n",
      "300:\tlearn: 0.9917380\ttotal: 7.56s\tremaining: 5s\n",
      "301:\tlearn: 0.9918363\ttotal: 7.59s\tremaining: 4.97s\n",
      "302:\tlearn: 0.9921387\ttotal: 7.61s\tremaining: 4.95s\n",
      "303:\tlearn: 0.9925911\ttotal: 7.64s\tremaining: 4.92s\n",
      "304:\tlearn: 0.9928435\ttotal: 7.66s\tremaining: 4.9s\n",
      "305:\tlearn: 0.9928427\ttotal: 7.68s\tremaining: 4.87s\n",
      "306:\tlearn: 0.9929908\ttotal: 7.71s\tremaining: 4.84s\n",
      "307:\tlearn: 0.9929908\ttotal: 7.73s\tremaining: 4.82s\n",
      "308:\tlearn: 0.9932954\ttotal: 7.76s\tremaining: 4.79s\n",
      "309:\tlearn: 0.9933448\ttotal: 7.78s\tremaining: 4.77s\n",
      "310:\tlearn: 0.9935445\ttotal: 7.8s\tremaining: 4.74s\n",
      "311:\tlearn: 0.9935959\ttotal: 7.83s\tremaining: 4.72s\n",
      "312:\tlearn: 0.9935965\ttotal: 7.86s\tremaining: 4.69s\n",
      "313:\tlearn: 0.9937450\ttotal: 7.88s\tremaining: 4.67s\n",
      "314:\tlearn: 0.9937945\ttotal: 7.91s\tremaining: 4.64s\n",
      "315:\tlearn: 0.9939455\ttotal: 7.93s\tremaining: 4.62s\n",
      "316:\tlearn: 0.9939461\ttotal: 7.96s\tremaining: 4.59s\n",
      "317:\tlearn: 0.9940464\ttotal: 7.99s\tremaining: 4.57s\n",
      "318:\tlearn: 0.9939449\ttotal: 8.01s\tremaining: 4.55s\n",
      "319:\tlearn: 0.9941951\ttotal: 8.04s\tremaining: 4.52s\n",
      "320:\tlearn: 0.9942972\ttotal: 8.07s\tremaining: 4.5s\n",
      "321:\tlearn: 0.9941957\ttotal: 8.09s\tremaining: 4.47s\n",
      "322:\tlearn: 0.9950535\ttotal: 8.12s\tremaining: 4.45s\n",
      "323:\tlearn: 0.9951032\ttotal: 8.14s\tremaining: 4.42s\n",
      "324:\tlearn: 0.9949541\ttotal: 8.17s\tremaining: 4.4s\n",
      "325:\tlearn: 0.9949034\ttotal: 8.19s\tremaining: 4.37s\n",
      "326:\tlearn: 0.9950540\ttotal: 8.23s\tremaining: 4.35s\n",
      "327:\tlearn: 0.9951545\ttotal: 8.26s\tremaining: 4.33s\n",
      "328:\tlearn: 0.9954071\ttotal: 8.28s\tremaining: 4.3s\n",
      "329:\tlearn: 0.9957601\ttotal: 8.31s\tremaining: 4.28s\n",
      "330:\tlearn: 0.9957597\ttotal: 8.33s\tremaining: 4.25s\n",
      "331:\tlearn: 0.9959616\ttotal: 8.36s\tremaining: 4.23s\n",
      "332:\tlearn: 0.9960626\ttotal: 8.38s\tremaining: 4.2s\n",
      "333:\tlearn: 0.9965150\ttotal: 8.41s\tremaining: 4.18s\n",
      "334:\tlearn: 0.9964646\ttotal: 8.43s\tremaining: 4.15s\n",
      "335:\tlearn: 0.9964140\ttotal: 8.46s\tremaining: 4.13s\n",
      "336:\tlearn: 0.9966663\ttotal: 8.48s\tremaining: 4.1s\n",
      "337:\tlearn: 0.9967667\ttotal: 8.51s\tremaining: 4.08s\n",
      "338:\tlearn: 0.9966660\ttotal: 8.54s\tremaining: 4.06s\n",
      "339:\tlearn: 0.9969181\ttotal: 8.57s\tremaining: 4.03s\n",
      "340:\tlearn: 0.9970698\ttotal: 8.59s\tremaining: 4s\n",
      "341:\tlearn: 0.9971202\ttotal: 8.62s\tremaining: 3.98s\n",
      "342:\tlearn: 0.9968684\ttotal: 8.64s\tremaining: 3.95s\n",
      "343:\tlearn: 0.9971199\ttotal: 8.66s\tremaining: 3.93s\n",
      "344:\tlearn: 0.9971196\ttotal: 8.69s\tremaining: 3.9s\n",
      "345:\tlearn: 0.9972212\ttotal: 8.71s\tremaining: 3.88s\n",
      "346:\tlearn: 0.9973217\ttotal: 8.74s\tremaining: 3.85s\n",
      "347:\tlearn: 0.9975239\ttotal: 8.76s\tremaining: 3.83s\n",
      "348:\tlearn: 0.9977260\ttotal: 8.78s\tremaining: 3.8s\n",
      "349:\tlearn: 0.9978773\ttotal: 8.81s\tremaining: 3.77s\n",
      "350:\tlearn: 0.9978773\ttotal: 8.83s\tremaining: 3.75s\n",
      "351:\tlearn: 0.9979277\ttotal: 8.86s\tremaining: 3.72s\n",
      "352:\tlearn: 0.9978266\ttotal: 8.88s\tremaining: 3.7s\n",
      "353:\tlearn: 0.9977762\ttotal: 8.9s\tremaining: 3.67s\n",
      "354:\tlearn: 0.9976751\ttotal: 8.92s\tremaining: 3.65s\n",
      "355:\tlearn: 0.9978769\ttotal: 8.95s\tremaining: 3.62s\n",
      "356:\tlearn: 0.9978769\ttotal: 8.97s\tremaining: 3.59s\n",
      "357:\tlearn: 0.9978769\ttotal: 8.99s\tremaining: 3.56s\n",
      "358:\tlearn: 0.9981295\ttotal: 9.01s\tremaining: 3.54s\n",
      "359:\tlearn: 0.9982806\ttotal: 9.04s\tremaining: 3.51s\n",
      "360:\tlearn: 0.9982299\ttotal: 9.06s\tremaining: 3.49s\n",
      "361:\tlearn: 0.9982804\ttotal: 9.08s\tremaining: 3.46s\n",
      "362:\tlearn: 0.9981794\ttotal: 9.1s\tremaining: 3.44s\n",
      "363:\tlearn: 0.9981796\ttotal: 9.13s\tremaining: 3.41s\n",
      "364:\tlearn: 0.9982804\ttotal: 9.15s\tremaining: 3.38s\n",
      "365:\tlearn: 0.9983815\ttotal: 9.18s\tremaining: 3.36s\n",
      "366:\tlearn: 0.9984322\ttotal: 9.2s\tremaining: 3.33s\n",
      "367:\tlearn: 0.9984320\ttotal: 9.22s\tremaining: 3.31s\n",
      "368:\tlearn: 0.9985839\ttotal: 9.24s\tremaining: 3.28s\n",
      "369:\tlearn: 0.9985335\ttotal: 9.26s\tremaining: 3.25s\n",
      "370:\tlearn: 0.9985840\ttotal: 9.29s\tremaining: 3.23s\n",
      "371:\tlearn: 0.9983314\ttotal: 9.32s\tremaining: 3.21s\n",
      "372:\tlearn: 0.9984324\ttotal: 9.34s\tremaining: 3.18s\n",
      "373:\tlearn: 0.9984324\ttotal: 9.36s\tremaining: 3.15s\n",
      "374:\tlearn: 0.9987356\ttotal: 9.38s\tremaining: 3.13s\n",
      "375:\tlearn: 0.9987863\ttotal: 9.4s\tremaining: 3.1s\n",
      "376:\tlearn: 0.9988368\ttotal: 9.43s\tremaining: 3.08s\n",
      "377:\tlearn: 0.9987863\ttotal: 9.45s\tremaining: 3.05s\n",
      "378:\tlearn: 0.9986346\ttotal: 9.48s\tremaining: 3.02s\n",
      "379:\tlearn: 0.9987356\ttotal: 9.5s\tremaining: 3s\n",
      "380:\tlearn: 0.9989883\ttotal: 9.53s\tremaining: 2.98s\n",
      "381:\tlearn: 0.9988872\ttotal: 9.55s\tremaining: 2.95s\n",
      "382:\tlearn: 0.9989884\ttotal: 9.57s\tremaining: 2.92s\n",
      "383:\tlearn: 0.9991399\ttotal: 9.6s\tremaining: 2.9s\n",
      "384:\tlearn: 0.9990893\ttotal: 9.62s\tremaining: 2.87s\n",
      "385:\tlearn: 0.9990893\ttotal: 9.65s\tremaining: 2.85s\n",
      "386:\tlearn: 0.9991400\ttotal: 9.67s\tremaining: 2.82s\n",
      "387:\tlearn: 0.9990388\ttotal: 9.7s\tremaining: 2.8s\n",
      "388:\tlearn: 0.9990894\ttotal: 9.72s\tremaining: 2.77s\n",
      "389:\tlearn: 0.9989884\ttotal: 9.74s\tremaining: 2.75s\n",
      "390:\tlearn: 0.9990391\ttotal: 9.77s\tremaining: 2.72s\n",
      "391:\tlearn: 0.9989886\ttotal: 9.8s\tremaining: 2.7s\n",
      "392:\tlearn: 0.9989886\ttotal: 9.82s\tremaining: 2.67s\n",
      "393:\tlearn: 0.9989381\ttotal: 9.84s\tremaining: 2.65s\n",
      "394:\tlearn: 0.9988875\ttotal: 9.87s\tremaining: 2.62s\n",
      "395:\tlearn: 0.9990391\ttotal: 9.9s\tremaining: 2.6s\n",
      "396:\tlearn: 0.9990391\ttotal: 9.93s\tremaining: 2.58s\n",
      "397:\tlearn: 0.9991402\ttotal: 9.95s\tremaining: 2.55s\n",
      "398:\tlearn: 0.9991402\ttotal: 9.97s\tremaining: 2.52s\n",
      "399:\tlearn: 0.9990896\ttotal: 9.99s\tremaining: 2.5s\n",
      "400:\tlearn: 0.9989885\ttotal: 10s\tremaining: 2.47s\n",
      "401:\tlearn: 0.9990896\ttotal: 10s\tremaining: 2.45s\n",
      "402:\tlearn: 0.9990896\ttotal: 10.1s\tremaining: 2.42s\n",
      "403:\tlearn: 0.9991907\ttotal: 10.1s\tremaining: 2.4s\n",
      "404:\tlearn: 0.9991907\ttotal: 10.1s\tremaining: 2.37s\n",
      "405:\tlearn: 0.9992412\ttotal: 10.1s\tremaining: 2.35s\n",
      "406:\tlearn: 0.9993424\ttotal: 10.2s\tremaining: 2.32s\n",
      "407:\tlearn: 0.9992412\ttotal: 10.2s\tremaining: 2.29s\n",
      "408:\tlearn: 0.9993424\ttotal: 10.2s\tremaining: 2.27s\n",
      "409:\tlearn: 0.9992918\ttotal: 10.2s\tremaining: 2.24s\n",
      "410:\tlearn: 0.9993423\ttotal: 10.2s\tremaining: 2.22s\n",
      "411:\tlearn: 0.9992917\ttotal: 10.3s\tremaining: 2.19s\n",
      "412:\tlearn: 0.9993928\ttotal: 10.3s\tremaining: 2.17s\n",
      "413:\tlearn: 0.9993928\ttotal: 10.3s\tremaining: 2.14s\n",
      "414:\tlearn: 0.9993423\ttotal: 10.3s\tremaining: 2.12s\n",
      "415:\tlearn: 0.9993928\ttotal: 10.4s\tremaining: 2.09s\n",
      "416:\tlearn: 0.9993928\ttotal: 10.4s\tremaining: 2.07s\n",
      "417:\tlearn: 0.9993928\ttotal: 10.4s\tremaining: 2.04s\n",
      "418:\tlearn: 0.9994434\ttotal: 10.4s\tremaining: 2.02s\n",
      "419:\tlearn: 0.9994940\ttotal: 10.5s\tremaining: 1.99s\n",
      "420:\tlearn: 0.9996458\ttotal: 10.5s\tremaining: 1.97s\n",
      "421:\tlearn: 0.9996458\ttotal: 10.5s\tremaining: 1.94s\n",
      "422:\tlearn: 0.9995952\ttotal: 10.5s\tremaining: 1.92s\n",
      "423:\tlearn: 0.9995952\ttotal: 10.5s\tremaining: 1.89s\n",
      "424:\tlearn: 0.9995446\ttotal: 10.6s\tremaining: 1.86s\n",
      "425:\tlearn: 0.9996458\ttotal: 10.6s\tremaining: 1.84s\n",
      "426:\tlearn: 0.9995951\ttotal: 10.6s\tremaining: 1.81s\n",
      "427:\tlearn: 0.9994940\ttotal: 10.6s\tremaining: 1.79s\n",
      "428:\tlearn: 0.9996458\ttotal: 10.7s\tremaining: 1.77s\n",
      "429:\tlearn: 0.9996458\ttotal: 10.7s\tremaining: 1.74s\n",
      "430:\tlearn: 0.9995952\ttotal: 10.7s\tremaining: 1.72s\n",
      "431:\tlearn: 0.9995446\ttotal: 10.8s\tremaining: 1.69s\n",
      "432:\tlearn: 0.9996458\ttotal: 10.8s\tremaining: 1.67s\n",
      "433:\tlearn: 0.9996458\ttotal: 10.8s\tremaining: 1.64s\n",
      "434:\tlearn: 0.9996458\ttotal: 10.8s\tremaining: 1.62s\n",
      "435:\tlearn: 0.9996458\ttotal: 10.9s\tremaining: 1.59s\n",
      "436:\tlearn: 0.9997470\ttotal: 10.9s\tremaining: 1.57s\n",
      "437:\tlearn: 0.9997470\ttotal: 10.9s\tremaining: 1.54s\n",
      "438:\tlearn: 0.9996458\ttotal: 10.9s\tremaining: 1.52s\n",
      "439:\tlearn: 0.9996964\ttotal: 11s\tremaining: 1.49s\n",
      "440:\tlearn: 0.9996458\ttotal: 11s\tremaining: 1.47s\n",
      "441:\tlearn: 0.9995952\ttotal: 11s\tremaining: 1.44s\n",
      "442:\tlearn: 0.9995952\ttotal: 11s\tremaining: 1.42s\n",
      "443:\tlearn: 0.9995952\ttotal: 11.1s\tremaining: 1.39s\n",
      "444:\tlearn: 0.9995952\ttotal: 11.1s\tremaining: 1.37s\n",
      "445:\tlearn: 0.9996458\ttotal: 11.1s\tremaining: 1.34s\n",
      "446:\tlearn: 0.9996458\ttotal: 11.1s\tremaining: 1.32s\n",
      "447:\tlearn: 0.9996458\ttotal: 11.2s\tremaining: 1.29s\n",
      "448:\tlearn: 0.9996458\ttotal: 11.2s\tremaining: 1.27s\n",
      "449:\tlearn: 0.9996458\ttotal: 11.2s\tremaining: 1.24s\n",
      "450:\tlearn: 0.9996964\ttotal: 11.2s\tremaining: 1.22s\n",
      "451:\tlearn: 0.9996964\ttotal: 11.3s\tremaining: 1.19s\n",
      "452:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 1.17s\n",
      "453:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 1.14s\n",
      "454:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 1.12s\n",
      "455:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 1.09s\n",
      "456:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 1.07s\n",
      "457:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 1.04s\n",
      "458:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 1.02s\n",
      "459:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 994ms\n",
      "460:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 969ms\n",
      "461:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 944ms\n",
      "462:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 919ms\n",
      "463:\tlearn: 0.9997976\ttotal: 11.5s\tremaining: 894ms\n",
      "464:\tlearn: 0.9997976\ttotal: 11.6s\tremaining: 869ms\n",
      "465:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 845ms\n",
      "466:\tlearn: 0.9997976\ttotal: 11.6s\tremaining: 820ms\n",
      "467:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 795ms\n",
      "468:\tlearn: 0.9997976\ttotal: 11.7s\tremaining: 770ms\n",
      "469:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 745ms\n",
      "470:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 720ms\n",
      "471:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 695ms\n",
      "472:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 670ms\n",
      "473:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 645ms\n",
      "474:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 620ms\n",
      "475:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 596ms\n",
      "476:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 571ms\n",
      "477:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 546ms\n",
      "478:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 521ms\n",
      "479:\tlearn: 0.9997470\ttotal: 11.9s\tremaining: 496ms\n",
      "480:\tlearn: 0.9997976\ttotal: 11.9s\tremaining: 471ms\n",
      "481:\tlearn: 0.9997976\ttotal: 12s\tremaining: 447ms\n",
      "482:\tlearn: 0.9997470\ttotal: 12s\tremaining: 422ms\n",
      "483:\tlearn: 0.9997976\ttotal: 12s\tremaining: 397ms\n",
      "484:\tlearn: 0.9997976\ttotal: 12s\tremaining: 372ms\n",
      "485:\tlearn: 0.9997976\ttotal: 12.1s\tremaining: 348ms\n",
      "486:\tlearn: 0.9997470\ttotal: 12.1s\tremaining: 323ms\n",
      "487:\tlearn: 0.9997470\ttotal: 12.1s\tremaining: 298ms\n",
      "488:\tlearn: 0.9997470\ttotal: 12.1s\tremaining: 273ms\n",
      "489:\tlearn: 0.9997976\ttotal: 12.2s\tremaining: 248ms\n",
      "490:\tlearn: 0.9998482\ttotal: 12.2s\tremaining: 223ms\n",
      "491:\tlearn: 0.9998482\ttotal: 12.2s\tremaining: 199ms\n",
      "492:\tlearn: 0.9998482\ttotal: 12.2s\tremaining: 174ms\n",
      "493:\tlearn: 0.9998482\ttotal: 12.3s\tremaining: 149ms\n",
      "494:\tlearn: 0.9998482\ttotal: 12.3s\tremaining: 124ms\n",
      "495:\tlearn: 0.9998482\ttotal: 12.3s\tremaining: 99.2ms\n",
      "496:\tlearn: 0.9997976\ttotal: 12.3s\tremaining: 74.4ms\n",
      "497:\tlearn: 0.9997976\ttotal: 12.4s\tremaining: 49.7ms\n",
      "498:\tlearn: 0.9997976\ttotal: 12.4s\tremaining: 24.8ms\n",
      "499:\tlearn: 0.9997976\ttotal: 12.4s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=32, depth=4, eval_metric=F1, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=0.1; total time=  13.1s\n",
      "0:\tlearn: 0.6531950\ttotal: 25.5ms\tremaining: 12.7s\n",
      "1:\tlearn: 0.6522578\ttotal: 49.8ms\tremaining: 12.4s\n",
      "2:\tlearn: 0.6669592\ttotal: 73.3ms\tremaining: 12.2s\n",
      "3:\tlearn: 0.6849859\ttotal: 96.8ms\tremaining: 12s\n",
      "4:\tlearn: 0.6919009\ttotal: 122ms\tremaining: 12s\n",
      "5:\tlearn: 0.7006963\ttotal: 144ms\tremaining: 11.9s\n",
      "6:\tlearn: 0.7050147\ttotal: 168ms\tremaining: 11.8s\n",
      "7:\tlearn: 0.7137123\ttotal: 194ms\tremaining: 11.9s\n",
      "8:\tlearn: 0.7230471\ttotal: 218ms\tremaining: 11.9s\n",
      "9:\tlearn: 0.7286197\ttotal: 246ms\tremaining: 12s\n",
      "10:\tlearn: 0.7357909\ttotal: 270ms\tremaining: 12s\n",
      "11:\tlearn: 0.7418362\ttotal: 298ms\tremaining: 12.1s\n",
      "12:\tlearn: 0.7436802\ttotal: 321ms\tremaining: 12s\n",
      "13:\tlearn: 0.7532816\ttotal: 346ms\tremaining: 12s\n",
      "14:\tlearn: 0.7577237\ttotal: 372ms\tremaining: 12s\n",
      "15:\tlearn: 0.7624534\ttotal: 395ms\tremaining: 11.9s\n",
      "16:\tlearn: 0.7686953\ttotal: 420ms\tremaining: 11.9s\n",
      "17:\tlearn: 0.7679833\ttotal: 447ms\tremaining: 12s\n",
      "18:\tlearn: 0.7724152\ttotal: 471ms\tremaining: 11.9s\n",
      "19:\tlearn: 0.7759161\ttotal: 496ms\tremaining: 11.9s\n",
      "20:\tlearn: 0.7771809\ttotal: 520ms\tremaining: 11.9s\n",
      "21:\tlearn: 0.7828032\ttotal: 546ms\tremaining: 11.9s\n",
      "22:\tlearn: 0.7857107\ttotal: 569ms\tremaining: 11.8s\n",
      "23:\tlearn: 0.7891318\ttotal: 594ms\tremaining: 11.8s\n",
      "24:\tlearn: 0.7913940\ttotal: 619ms\tremaining: 11.8s\n",
      "25:\tlearn: 0.7939908\ttotal: 645ms\tremaining: 11.8s\n",
      "26:\tlearn: 0.7969485\ttotal: 666ms\tremaining: 11.7s\n",
      "27:\tlearn: 0.7976764\ttotal: 692ms\tremaining: 11.7s\n",
      "28:\tlearn: 0.8010123\ttotal: 716ms\tremaining: 11.6s\n",
      "29:\tlearn: 0.8040470\ttotal: 743ms\tremaining: 11.6s\n",
      "30:\tlearn: 0.8079857\ttotal: 764ms\tremaining: 11.6s\n",
      "31:\tlearn: 0.8091044\ttotal: 786ms\tremaining: 11.5s\n",
      "32:\tlearn: 0.8118136\ttotal: 810ms\tremaining: 11.5s\n",
      "33:\tlearn: 0.8129639\ttotal: 835ms\tremaining: 11.4s\n",
      "34:\tlearn: 0.8138764\ttotal: 861ms\tremaining: 11.4s\n",
      "35:\tlearn: 0.8173853\ttotal: 891ms\tremaining: 11.5s\n",
      "36:\tlearn: 0.8193057\ttotal: 915ms\tremaining: 11.4s\n",
      "37:\tlearn: 0.8215628\ttotal: 942ms\tremaining: 11.4s\n",
      "38:\tlearn: 0.8235818\ttotal: 966ms\tremaining: 11.4s\n",
      "39:\tlearn: 0.8256182\ttotal: 992ms\tremaining: 11.4s\n",
      "40:\tlearn: 0.8278113\ttotal: 1.01s\tremaining: 11.3s\n",
      "41:\tlearn: 0.8301382\ttotal: 1.04s\tremaining: 11.3s\n",
      "42:\tlearn: 0.8324752\ttotal: 1.06s\tremaining: 11.3s\n",
      "43:\tlearn: 0.8332013\ttotal: 1.09s\tremaining: 11.3s\n",
      "44:\tlearn: 0.8350592\ttotal: 1.11s\tremaining: 11.2s\n",
      "45:\tlearn: 0.8367468\ttotal: 1.14s\tremaining: 11.3s\n",
      "46:\tlearn: 0.8398256\ttotal: 1.16s\tremaining: 11.2s\n",
      "47:\tlearn: 0.8396386\ttotal: 1.19s\tremaining: 11.2s\n",
      "48:\tlearn: 0.8433077\ttotal: 1.21s\tremaining: 11.1s\n",
      "49:\tlearn: 0.8432315\ttotal: 1.24s\tremaining: 11.1s\n",
      "50:\tlearn: 0.8446033\ttotal: 1.26s\tremaining: 11.1s\n",
      "51:\tlearn: 0.8466002\ttotal: 1.28s\tremaining: 11.1s\n",
      "52:\tlearn: 0.8499752\ttotal: 1.31s\tremaining: 11s\n",
      "53:\tlearn: 0.8520927\ttotal: 1.33s\tremaining: 11s\n",
      "54:\tlearn: 0.8530274\ttotal: 1.35s\tremaining: 11s\n",
      "55:\tlearn: 0.8548435\ttotal: 1.38s\tremaining: 10.9s\n",
      "56:\tlearn: 0.8553840\ttotal: 1.4s\tremaining: 10.9s\n",
      "57:\tlearn: 0.8572704\ttotal: 1.43s\tremaining: 10.9s\n",
      "58:\tlearn: 0.8572422\ttotal: 1.45s\tremaining: 10.9s\n",
      "59:\tlearn: 0.8596378\ttotal: 1.48s\tremaining: 10.9s\n",
      "60:\tlearn: 0.8605621\ttotal: 1.5s\tremaining: 10.8s\n",
      "61:\tlearn: 0.8627782\ttotal: 1.53s\tremaining: 10.8s\n",
      "62:\tlearn: 0.8624801\ttotal: 1.56s\tremaining: 10.8s\n",
      "63:\tlearn: 0.8647144\ttotal: 1.59s\tremaining: 10.8s\n",
      "64:\tlearn: 0.8660142\ttotal: 1.61s\tremaining: 10.8s\n",
      "65:\tlearn: 0.8670308\ttotal: 1.64s\tremaining: 10.8s\n",
      "66:\tlearn: 0.8681717\ttotal: 1.66s\tremaining: 10.7s\n",
      "67:\tlearn: 0.8697852\ttotal: 1.69s\tremaining: 10.7s\n",
      "68:\tlearn: 0.8711005\ttotal: 1.71s\tremaining: 10.7s\n",
      "69:\tlearn: 0.8712783\ttotal: 1.74s\tremaining: 10.7s\n",
      "70:\tlearn: 0.8732758\ttotal: 1.76s\tremaining: 10.6s\n",
      "71:\tlearn: 0.8749007\ttotal: 1.78s\tremaining: 10.6s\n",
      "72:\tlearn: 0.8748511\ttotal: 1.81s\tremaining: 10.6s\n",
      "73:\tlearn: 0.8762406\ttotal: 1.83s\tremaining: 10.6s\n",
      "74:\tlearn: 0.8772069\ttotal: 1.86s\tremaining: 10.5s\n",
      "75:\tlearn: 0.8786076\ttotal: 1.89s\tremaining: 10.5s\n",
      "76:\tlearn: 0.8805674\ttotal: 1.92s\tremaining: 10.5s\n",
      "77:\tlearn: 0.8806548\ttotal: 1.94s\tremaining: 10.5s\n",
      "78:\tlearn: 0.8819765\ttotal: 1.97s\tremaining: 10.5s\n",
      "79:\tlearn: 0.8828462\ttotal: 1.99s\tremaining: 10.5s\n",
      "80:\tlearn: 0.8826477\ttotal: 2.02s\tremaining: 10.5s\n",
      "81:\tlearn: 0.8836771\ttotal: 2.05s\tremaining: 10.5s\n",
      "82:\tlearn: 0.8850102\ttotal: 2.08s\tremaining: 10.4s\n",
      "83:\tlearn: 0.8864661\ttotal: 2.1s\tremaining: 10.4s\n",
      "84:\tlearn: 0.8867166\ttotal: 2.13s\tremaining: 10.4s\n",
      "85:\tlearn: 0.8865090\ttotal: 2.17s\tremaining: 10.4s\n",
      "86:\tlearn: 0.8870168\ttotal: 2.19s\tremaining: 10.4s\n",
      "87:\tlearn: 0.8888228\ttotal: 2.21s\tremaining: 10.4s\n",
      "88:\tlearn: 0.8910469\ttotal: 2.24s\tremaining: 10.3s\n",
      "89:\tlearn: 0.8910263\ttotal: 2.26s\tremaining: 10.3s\n",
      "90:\tlearn: 0.8916869\ttotal: 2.29s\tremaining: 10.3s\n",
      "91:\tlearn: 0.8936255\ttotal: 2.31s\tremaining: 10.3s\n",
      "92:\tlearn: 0.8951853\ttotal: 2.34s\tremaining: 10.2s\n",
      "93:\tlearn: 0.8945465\ttotal: 2.37s\tremaining: 10.2s\n",
      "94:\tlearn: 0.8954426\ttotal: 2.39s\tremaining: 10.2s\n",
      "95:\tlearn: 0.8973369\ttotal: 2.42s\tremaining: 10.2s\n",
      "96:\tlearn: 0.8982439\ttotal: 2.44s\tremaining: 10.2s\n",
      "97:\tlearn: 0.8993767\ttotal: 2.47s\tremaining: 10.1s\n",
      "98:\tlearn: 0.9005194\ttotal: 2.49s\tremaining: 10.1s\n",
      "99:\tlearn: 0.9011424\ttotal: 2.51s\tremaining: 10s\n",
      "100:\tlearn: 0.9020132\ttotal: 2.54s\tremaining: 10s\n",
      "101:\tlearn: 0.9037653\ttotal: 2.56s\tremaining: 10s\n",
      "102:\tlearn: 0.9038385\ttotal: 2.58s\tremaining: 9.96s\n",
      "103:\tlearn: 0.9054962\ttotal: 2.61s\tremaining: 9.94s\n",
      "104:\tlearn: 0.9066469\ttotal: 2.64s\tremaining: 9.94s\n",
      "105:\tlearn: 0.9080028\ttotal: 2.67s\tremaining: 9.91s\n",
      "106:\tlearn: 0.9076452\ttotal: 2.69s\tremaining: 9.88s\n",
      "107:\tlearn: 0.9087766\ttotal: 2.71s\tremaining: 9.84s\n",
      "108:\tlearn: 0.9092166\ttotal: 2.73s\tremaining: 9.8s\n",
      "109:\tlearn: 0.9097109\ttotal: 2.76s\tremaining: 9.78s\n",
      "110:\tlearn: 0.9101968\ttotal: 2.79s\tremaining: 9.77s\n",
      "111:\tlearn: 0.9115727\ttotal: 2.81s\tremaining: 9.74s\n",
      "112:\tlearn: 0.9123449\ttotal: 2.83s\tremaining: 9.71s\n",
      "113:\tlearn: 0.9133788\ttotal: 2.86s\tremaining: 9.67s\n",
      "114:\tlearn: 0.9148231\ttotal: 2.88s\tremaining: 9.65s\n",
      "115:\tlearn: 0.9145943\ttotal: 2.91s\tremaining: 9.62s\n",
      "116:\tlearn: 0.9166048\ttotal: 2.93s\tremaining: 9.59s\n",
      "117:\tlearn: 0.9167656\ttotal: 2.96s\tremaining: 9.57s\n",
      "118:\tlearn: 0.9173640\ttotal: 2.98s\tremaining: 9.55s\n",
      "119:\tlearn: 0.9174666\ttotal: 3.01s\tremaining: 9.52s\n",
      "120:\tlearn: 0.9182471\ttotal: 3.03s\tremaining: 9.49s\n",
      "121:\tlearn: 0.9187475\ttotal: 3.06s\tremaining: 9.47s\n",
      "122:\tlearn: 0.9198137\ttotal: 3.08s\tremaining: 9.44s\n",
      "123:\tlearn: 0.9194731\ttotal: 3.1s\tremaining: 9.41s\n",
      "124:\tlearn: 0.9206223\ttotal: 3.13s\tremaining: 9.39s\n",
      "125:\tlearn: 0.9226952\ttotal: 3.16s\tremaining: 9.37s\n",
      "126:\tlearn: 0.9236115\ttotal: 3.18s\tremaining: 9.34s\n",
      "127:\tlearn: 0.9240852\ttotal: 3.21s\tremaining: 9.33s\n",
      "128:\tlearn: 0.9250633\ttotal: 3.23s\tremaining: 9.29s\n",
      "129:\tlearn: 0.9253227\ttotal: 3.25s\tremaining: 9.26s\n",
      "130:\tlearn: 0.9266985\ttotal: 3.28s\tremaining: 9.23s\n",
      "131:\tlearn: 0.9271563\ttotal: 3.3s\tremaining: 9.2s\n",
      "132:\tlearn: 0.9272168\ttotal: 3.33s\tremaining: 9.18s\n",
      "133:\tlearn: 0.9283801\ttotal: 3.35s\tremaining: 9.16s\n",
      "134:\tlearn: 0.9297185\ttotal: 3.38s\tremaining: 9.14s\n",
      "135:\tlearn: 0.9295495\ttotal: 3.41s\tremaining: 9.12s\n",
      "136:\tlearn: 0.9293230\ttotal: 3.43s\tremaining: 9.09s\n",
      "137:\tlearn: 0.9302994\ttotal: 3.46s\tremaining: 9.07s\n",
      "138:\tlearn: 0.9317189\ttotal: 3.48s\tremaining: 9.04s\n",
      "139:\tlearn: 0.9317201\ttotal: 3.5s\tremaining: 9.01s\n",
      "140:\tlearn: 0.9316604\ttotal: 3.53s\tremaining: 8.99s\n",
      "141:\tlearn: 0.9334523\ttotal: 3.55s\tremaining: 8.96s\n",
      "142:\tlearn: 0.9340212\ttotal: 3.58s\tremaining: 8.94s\n",
      "143:\tlearn: 0.9347697\ttotal: 3.6s\tremaining: 8.91s\n",
      "144:\tlearn: 0.9347966\ttotal: 3.62s\tremaining: 8.87s\n",
      "145:\tlearn: 0.9356423\ttotal: 3.65s\tremaining: 8.85s\n",
      "146:\tlearn: 0.9362378\ttotal: 3.67s\tremaining: 8.82s\n",
      "147:\tlearn: 0.9363244\ttotal: 3.7s\tremaining: 8.79s\n",
      "148:\tlearn: 0.9378537\ttotal: 3.72s\tremaining: 8.77s\n",
      "149:\tlearn: 0.9391580\ttotal: 3.75s\tremaining: 8.75s\n",
      "150:\tlearn: 0.9398105\ttotal: 3.78s\tremaining: 8.73s\n",
      "151:\tlearn: 0.9407970\ttotal: 3.8s\tremaining: 8.7s\n",
      "152:\tlearn: 0.9412407\ttotal: 3.82s\tremaining: 8.67s\n",
      "153:\tlearn: 0.9412641\ttotal: 3.85s\tremaining: 8.64s\n",
      "154:\tlearn: 0.9416671\ttotal: 3.87s\tremaining: 8.62s\n",
      "155:\tlearn: 0.9422514\ttotal: 3.9s\tremaining: 8.6s\n",
      "156:\tlearn: 0.9430103\ttotal: 3.92s\tremaining: 8.57s\n",
      "157:\tlearn: 0.9434487\ttotal: 3.95s\tremaining: 8.54s\n",
      "158:\tlearn: 0.9437075\ttotal: 3.97s\tremaining: 8.52s\n",
      "159:\tlearn: 0.9441988\ttotal: 3.99s\tremaining: 8.49s\n",
      "160:\tlearn: 0.9449359\ttotal: 4.02s\tremaining: 8.47s\n",
      "161:\tlearn: 0.9452919\ttotal: 4.04s\tremaining: 8.44s\n",
      "162:\tlearn: 0.9461018\ttotal: 4.07s\tremaining: 8.42s\n",
      "163:\tlearn: 0.9474626\ttotal: 4.1s\tremaining: 8.41s\n",
      "164:\tlearn: 0.9472900\ttotal: 4.13s\tremaining: 8.38s\n",
      "165:\tlearn: 0.9476403\ttotal: 4.16s\tremaining: 8.36s\n",
      "166:\tlearn: 0.9476981\ttotal: 4.18s\tremaining: 8.33s\n",
      "167:\tlearn: 0.9478918\ttotal: 4.2s\tremaining: 8.3s\n",
      "168:\tlearn: 0.9481592\ttotal: 4.22s\tremaining: 8.27s\n",
      "169:\tlearn: 0.9488289\ttotal: 4.25s\tremaining: 8.25s\n",
      "170:\tlearn: 0.9494206\ttotal: 4.27s\tremaining: 8.22s\n",
      "171:\tlearn: 0.9501268\ttotal: 4.3s\tremaining: 8.19s\n",
      "172:\tlearn: 0.9501691\ttotal: 4.32s\tremaining: 8.16s\n",
      "173:\tlearn: 0.9502438\ttotal: 4.34s\tremaining: 8.14s\n",
      "174:\tlearn: 0.9507561\ttotal: 4.37s\tremaining: 8.12s\n",
      "175:\tlearn: 0.9516041\ttotal: 4.4s\tremaining: 8.09s\n",
      "176:\tlearn: 0.9520303\ttotal: 4.42s\tremaining: 8.06s\n",
      "177:\tlearn: 0.9524046\ttotal: 4.44s\tremaining: 8.04s\n",
      "178:\tlearn: 0.9534143\ttotal: 4.47s\tremaining: 8.02s\n",
      "179:\tlearn: 0.9538599\ttotal: 4.49s\tremaining: 7.99s\n",
      "180:\tlearn: 0.9540773\ttotal: 4.51s\tremaining: 7.96s\n",
      "181:\tlearn: 0.9543056\ttotal: 4.54s\tremaining: 7.94s\n",
      "182:\tlearn: 0.9544618\ttotal: 4.57s\tremaining: 7.91s\n",
      "183:\tlearn: 0.9557681\ttotal: 4.59s\tremaining: 7.89s\n",
      "184:\tlearn: 0.9564394\ttotal: 4.61s\tremaining: 7.86s\n",
      "185:\tlearn: 0.9573058\ttotal: 4.64s\tremaining: 7.83s\n",
      "186:\tlearn: 0.9570503\ttotal: 4.66s\tremaining: 7.8s\n",
      "187:\tlearn: 0.9571806\ttotal: 4.68s\tremaining: 7.78s\n",
      "188:\tlearn: 0.9576875\ttotal: 4.71s\tremaining: 7.74s\n",
      "189:\tlearn: 0.9585805\ttotal: 4.73s\tremaining: 7.72s\n",
      "190:\tlearn: 0.9588672\ttotal: 4.76s\tremaining: 7.71s\n",
      "191:\tlearn: 0.9594776\ttotal: 4.79s\tremaining: 7.68s\n",
      "192:\tlearn: 0.9599801\ttotal: 4.81s\tremaining: 7.66s\n",
      "193:\tlearn: 0.9609936\ttotal: 4.84s\tremaining: 7.63s\n",
      "194:\tlearn: 0.9609056\ttotal: 4.87s\tremaining: 7.61s\n",
      "195:\tlearn: 0.9609172\ttotal: 4.89s\tremaining: 7.59s\n",
      "196:\tlearn: 0.9618739\ttotal: 4.92s\tremaining: 7.57s\n",
      "197:\tlearn: 0.9620544\ttotal: 4.95s\tremaining: 7.55s\n",
      "198:\tlearn: 0.9621239\ttotal: 4.97s\tremaining: 7.52s\n",
      "199:\tlearn: 0.9623498\ttotal: 5s\tremaining: 7.5s\n",
      "200:\tlearn: 0.9627450\ttotal: 5.03s\tremaining: 7.48s\n",
      "201:\tlearn: 0.9634177\ttotal: 5.05s\tremaining: 7.45s\n",
      "202:\tlearn: 0.9637099\ttotal: 5.07s\tremaining: 7.42s\n",
      "203:\tlearn: 0.9645050\ttotal: 5.1s\tremaining: 7.4s\n",
      "204:\tlearn: 0.9644837\ttotal: 5.12s\tremaining: 7.37s\n",
      "205:\tlearn: 0.9648527\ttotal: 5.14s\tremaining: 7.34s\n",
      "206:\tlearn: 0.9657825\ttotal: 5.18s\tremaining: 7.33s\n",
      "207:\tlearn: 0.9663303\ttotal: 5.2s\tremaining: 7.3s\n",
      "208:\tlearn: 0.9666200\ttotal: 5.23s\tremaining: 7.28s\n",
      "209:\tlearn: 0.9673875\ttotal: 5.26s\tremaining: 7.26s\n",
      "210:\tlearn: 0.9671230\ttotal: 5.28s\tremaining: 7.23s\n",
      "211:\tlearn: 0.9673777\ttotal: 5.3s\tremaining: 7.21s\n",
      "212:\tlearn: 0.9683253\ttotal: 5.33s\tremaining: 7.18s\n",
      "213:\tlearn: 0.9681319\ttotal: 5.35s\tremaining: 7.15s\n",
      "214:\tlearn: 0.9686578\ttotal: 5.38s\tremaining: 7.13s\n",
      "215:\tlearn: 0.9691031\ttotal: 5.4s\tremaining: 7.1s\n",
      "216:\tlearn: 0.9697636\ttotal: 5.42s\tremaining: 7.07s\n",
      "217:\tlearn: 0.9698030\ttotal: 5.45s\tremaining: 7.05s\n",
      "218:\tlearn: 0.9701634\ttotal: 5.47s\tremaining: 7.02s\n",
      "219:\tlearn: 0.9707602\ttotal: 5.49s\tremaining: 6.99s\n",
      "220:\tlearn: 0.9710116\ttotal: 5.51s\tremaining: 6.96s\n",
      "221:\tlearn: 0.9716199\ttotal: 5.54s\tremaining: 6.94s\n",
      "222:\tlearn: 0.9719626\ttotal: 5.57s\tremaining: 6.92s\n",
      "223:\tlearn: 0.9726349\ttotal: 5.59s\tremaining: 6.89s\n",
      "224:\tlearn: 0.9729027\ttotal: 5.62s\tremaining: 6.86s\n",
      "225:\tlearn: 0.9735921\ttotal: 5.64s\tremaining: 6.83s\n",
      "226:\tlearn: 0.9739870\ttotal: 5.66s\tremaining: 6.8s\n",
      "227:\tlearn: 0.9744898\ttotal: 5.68s\tremaining: 6.78s\n",
      "228:\tlearn: 0.9745949\ttotal: 5.71s\tremaining: 6.76s\n",
      "229:\tlearn: 0.9752827\ttotal: 5.74s\tremaining: 6.73s\n",
      "230:\tlearn: 0.9754926\ttotal: 5.76s\tremaining: 6.7s\n",
      "231:\tlearn: 0.9758319\ttotal: 5.78s\tremaining: 6.67s\n",
      "232:\tlearn: 0.9754291\ttotal: 5.81s\tremaining: 6.65s\n",
      "233:\tlearn: 0.9758686\ttotal: 5.83s\tremaining: 6.63s\n",
      "234:\tlearn: 0.9766114\ttotal: 5.86s\tremaining: 6.6s\n",
      "235:\tlearn: 0.9769096\ttotal: 5.88s\tremaining: 6.58s\n",
      "236:\tlearn: 0.9769493\ttotal: 5.91s\tremaining: 6.55s\n",
      "237:\tlearn: 0.9773924\ttotal: 5.93s\tremaining: 6.53s\n",
      "238:\tlearn: 0.9772921\ttotal: 5.96s\tremaining: 6.5s\n",
      "239:\tlearn: 0.9775996\ttotal: 5.98s\tremaining: 6.47s\n",
      "240:\tlearn: 0.9779427\ttotal: 6s\tremaining: 6.45s\n",
      "241:\tlearn: 0.9780027\ttotal: 6.02s\tremaining: 6.42s\n",
      "242:\tlearn: 0.9783394\ttotal: 6.04s\tremaining: 6.39s\n",
      "243:\tlearn: 0.9782478\ttotal: 6.07s\tremaining: 6.37s\n",
      "244:\tlearn: 0.9786019\ttotal: 6.09s\tremaining: 6.34s\n",
      "245:\tlearn: 0.9789964\ttotal: 6.11s\tremaining: 6.31s\n",
      "246:\tlearn: 0.9791051\ttotal: 6.13s\tremaining: 6.28s\n",
      "247:\tlearn: 0.9794527\ttotal: 6.16s\tremaining: 6.26s\n",
      "248:\tlearn: 0.9799599\ttotal: 6.18s\tremaining: 6.23s\n",
      "249:\tlearn: 0.9807422\ttotal: 6.21s\tremaining: 6.21s\n",
      "250:\tlearn: 0.9811472\ttotal: 6.23s\tremaining: 6.18s\n",
      "251:\tlearn: 0.9815409\ttotal: 6.25s\tremaining: 6.15s\n",
      "252:\tlearn: 0.9817324\ttotal: 6.27s\tremaining: 6.12s\n",
      "253:\tlearn: 0.9820281\ttotal: 6.3s\tremaining: 6.1s\n",
      "254:\tlearn: 0.9822764\ttotal: 6.32s\tremaining: 6.07s\n",
      "255:\tlearn: 0.9825794\ttotal: 6.34s\tremaining: 6.05s\n",
      "256:\tlearn: 0.9825812\ttotal: 6.37s\tremaining: 6.02s\n",
      "257:\tlearn: 0.9827292\ttotal: 6.39s\tremaining: 6s\n",
      "258:\tlearn: 0.9830304\ttotal: 6.42s\tremaining: 5.97s\n",
      "259:\tlearn: 0.9832773\ttotal: 6.44s\tremaining: 5.95s\n",
      "260:\tlearn: 0.9832262\ttotal: 6.46s\tremaining: 5.92s\n",
      "261:\tlearn: 0.9834271\ttotal: 6.49s\tremaining: 5.89s\n",
      "262:\tlearn: 0.9838847\ttotal: 6.51s\tremaining: 5.87s\n",
      "263:\tlearn: 0.9842306\ttotal: 6.54s\tremaining: 5.84s\n",
      "264:\tlearn: 0.9840712\ttotal: 6.56s\tremaining: 5.82s\n",
      "265:\tlearn: 0.9842179\ttotal: 6.58s\tremaining: 5.79s\n",
      "266:\tlearn: 0.9849261\ttotal: 6.61s\tremaining: 5.77s\n",
      "267:\tlearn: 0.9852232\ttotal: 6.63s\tremaining: 5.74s\n",
      "268:\tlearn: 0.9855714\ttotal: 6.66s\tremaining: 5.72s\n",
      "269:\tlearn: 0.9855247\ttotal: 6.68s\tremaining: 5.69s\n",
      "270:\tlearn: 0.9857796\ttotal: 6.71s\tremaining: 5.67s\n",
      "271:\tlearn: 0.9858773\ttotal: 6.73s\tremaining: 5.64s\n",
      "272:\tlearn: 0.9857810\ttotal: 6.76s\tremaining: 5.62s\n",
      "273:\tlearn: 0.9860755\ttotal: 6.78s\tremaining: 5.59s\n",
      "274:\tlearn: 0.9867793\ttotal: 6.8s\tremaining: 5.57s\n",
      "275:\tlearn: 0.9866291\ttotal: 6.83s\tremaining: 5.54s\n",
      "276:\tlearn: 0.9869803\ttotal: 6.85s\tremaining: 5.52s\n",
      "277:\tlearn: 0.9869738\ttotal: 6.88s\tremaining: 5.49s\n",
      "278:\tlearn: 0.9870770\ttotal: 6.9s\tremaining: 5.47s\n",
      "279:\tlearn: 0.9873265\ttotal: 6.93s\tremaining: 5.45s\n",
      "280:\tlearn: 0.9877797\ttotal: 6.96s\tremaining: 5.42s\n",
      "281:\tlearn: 0.9878294\ttotal: 6.98s\tremaining: 5.39s\n",
      "282:\tlearn: 0.9882791\ttotal: 7s\tremaining: 5.37s\n",
      "283:\tlearn: 0.9882270\ttotal: 7.03s\tremaining: 5.34s\n",
      "284:\tlearn: 0.9885277\ttotal: 7.05s\tremaining: 5.32s\n",
      "285:\tlearn: 0.9887313\ttotal: 7.08s\tremaining: 5.29s\n",
      "286:\tlearn: 0.9888839\ttotal: 7.1s\tremaining: 5.27s\n",
      "287:\tlearn: 0.9889347\ttotal: 7.12s\tremaining: 5.24s\n",
      "288:\tlearn: 0.9893328\ttotal: 7.15s\tremaining: 5.22s\n",
      "289:\tlearn: 0.9895786\ttotal: 7.17s\tremaining: 5.2s\n",
      "290:\tlearn: 0.9895807\ttotal: 7.2s\tremaining: 5.17s\n",
      "291:\tlearn: 0.9896803\ttotal: 7.22s\tremaining: 5.14s\n",
      "292:\tlearn: 0.9898319\ttotal: 7.26s\tremaining: 5.13s\n",
      "293:\tlearn: 0.9902844\ttotal: 7.28s\tremaining: 5.1s\n",
      "294:\tlearn: 0.9906824\ttotal: 7.3s\tremaining: 5.08s\n",
      "295:\tlearn: 0.9905846\ttotal: 7.34s\tremaining: 5.06s\n",
      "296:\tlearn: 0.9906824\ttotal: 7.36s\tremaining: 5.03s\n",
      "297:\tlearn: 0.9908830\ttotal: 7.38s\tremaining: 5s\n",
      "298:\tlearn: 0.9907832\ttotal: 7.4s\tremaining: 4.98s\n",
      "299:\tlearn: 0.9912316\ttotal: 7.43s\tremaining: 4.95s\n",
      "300:\tlearn: 0.9913298\ttotal: 7.45s\tremaining: 4.93s\n",
      "301:\tlearn: 0.9915365\ttotal: 7.48s\tremaining: 4.9s\n",
      "302:\tlearn: 0.9914857\ttotal: 7.5s\tremaining: 4.88s\n",
      "303:\tlearn: 0.9916847\ttotal: 7.52s\tremaining: 4.85s\n",
      "304:\tlearn: 0.9919871\ttotal: 7.55s\tremaining: 4.83s\n",
      "305:\tlearn: 0.9918347\ttotal: 7.58s\tremaining: 4.8s\n",
      "306:\tlearn: 0.9918847\ttotal: 7.6s\tremaining: 4.78s\n",
      "307:\tlearn: 0.9921347\ttotal: 7.63s\tremaining: 4.76s\n",
      "308:\tlearn: 0.9924865\ttotal: 7.66s\tremaining: 4.73s\n",
      "309:\tlearn: 0.9924865\ttotal: 7.68s\tremaining: 4.71s\n",
      "310:\tlearn: 0.9928892\ttotal: 7.7s\tremaining: 4.68s\n",
      "311:\tlearn: 0.9927397\ttotal: 7.73s\tremaining: 4.66s\n",
      "312:\tlearn: 0.9925896\ttotal: 7.75s\tremaining: 4.63s\n",
      "313:\tlearn: 0.9929407\ttotal: 7.78s\tremaining: 4.61s\n",
      "314:\tlearn: 0.9929922\ttotal: 7.8s\tremaining: 4.58s\n",
      "315:\tlearn: 0.9934430\ttotal: 7.82s\tremaining: 4.55s\n",
      "316:\tlearn: 0.9935939\ttotal: 7.85s\tremaining: 4.53s\n",
      "317:\tlearn: 0.9935432\ttotal: 7.87s\tremaining: 4.5s\n",
      "318:\tlearn: 0.9937450\ttotal: 7.89s\tremaining: 4.48s\n",
      "319:\tlearn: 0.9936955\ttotal: 7.91s\tremaining: 4.45s\n",
      "320:\tlearn: 0.9939975\ttotal: 7.94s\tremaining: 4.43s\n",
      "321:\tlearn: 0.9940500\ttotal: 7.96s\tremaining: 4.4s\n",
      "322:\tlearn: 0.9942494\ttotal: 7.99s\tremaining: 4.38s\n",
      "323:\tlearn: 0.9941992\ttotal: 8.01s\tremaining: 4.35s\n",
      "324:\tlearn: 0.9942506\ttotal: 8.03s\tremaining: 4.33s\n",
      "325:\tlearn: 0.9945013\ttotal: 8.05s\tremaining: 4.3s\n",
      "326:\tlearn: 0.9946508\ttotal: 8.08s\tremaining: 4.27s\n",
      "327:\tlearn: 0.9945515\ttotal: 8.1s\tremaining: 4.25s\n",
      "328:\tlearn: 0.9947512\ttotal: 8.13s\tremaining: 4.23s\n",
      "329:\tlearn: 0.9945990\ttotal: 8.15s\tremaining: 4.2s\n",
      "330:\tlearn: 0.9945984\ttotal: 8.18s\tremaining: 4.17s\n",
      "331:\tlearn: 0.9951535\ttotal: 8.2s\tremaining: 4.15s\n",
      "332:\tlearn: 0.9950515\ttotal: 8.22s\tremaining: 4.12s\n",
      "333:\tlearn: 0.9949003\ttotal: 8.25s\tremaining: 4.1s\n",
      "334:\tlearn: 0.9950515\ttotal: 8.27s\tremaining: 4.07s\n",
      "335:\tlearn: 0.9950013\ttotal: 8.29s\tremaining: 4.05s\n",
      "336:\tlearn: 0.9952037\ttotal: 8.32s\tremaining: 4.02s\n",
      "337:\tlearn: 0.9952544\ttotal: 8.34s\tremaining: 4s\n",
      "338:\tlearn: 0.9954052\ttotal: 8.37s\tremaining: 3.98s\n",
      "339:\tlearn: 0.9954061\ttotal: 8.39s\tremaining: 3.95s\n",
      "340:\tlearn: 0.9956081\ttotal: 8.42s\tremaining: 3.92s\n",
      "341:\tlearn: 0.9956085\ttotal: 8.44s\tremaining: 3.9s\n",
      "342:\tlearn: 0.9960119\ttotal: 8.46s\tremaining: 3.87s\n",
      "343:\tlearn: 0.9958607\ttotal: 8.49s\tremaining: 3.85s\n",
      "344:\tlearn: 0.9958108\ttotal: 8.52s\tremaining: 3.83s\n",
      "345:\tlearn: 0.9960123\ttotal: 8.54s\tremaining: 3.8s\n",
      "346:\tlearn: 0.9959105\ttotal: 8.57s\tremaining: 3.78s\n",
      "347:\tlearn: 0.9960107\ttotal: 8.59s\tremaining: 3.75s\n",
      "348:\tlearn: 0.9964147\ttotal: 8.62s\tremaining: 3.73s\n",
      "349:\tlearn: 0.9964654\ttotal: 8.64s\tremaining: 3.7s\n",
      "350:\tlearn: 0.9967170\ttotal: 8.66s\tremaining: 3.68s\n",
      "351:\tlearn: 0.9968677\ttotal: 8.68s\tremaining: 3.65s\n",
      "352:\tlearn: 0.9968684\ttotal: 8.71s\tremaining: 3.63s\n",
      "353:\tlearn: 0.9968677\ttotal: 8.73s\tremaining: 3.6s\n",
      "354:\tlearn: 0.9969190\ttotal: 8.76s\tremaining: 3.58s\n",
      "355:\tlearn: 0.9969190\ttotal: 8.79s\tremaining: 3.55s\n",
      "356:\tlearn: 0.9968693\ttotal: 8.81s\tremaining: 3.53s\n",
      "357:\tlearn: 0.9968687\ttotal: 8.84s\tremaining: 3.5s\n",
      "358:\tlearn: 0.9969193\ttotal: 8.86s\tremaining: 3.48s\n",
      "359:\tlearn: 0.9969197\ttotal: 8.88s\tremaining: 3.45s\n",
      "360:\tlearn: 0.9969700\ttotal: 8.91s\tremaining: 3.43s\n",
      "361:\tlearn: 0.9971717\ttotal: 8.93s\tremaining: 3.4s\n",
      "362:\tlearn: 0.9972218\ttotal: 8.96s\tremaining: 3.38s\n",
      "363:\tlearn: 0.9973729\ttotal: 8.98s\tremaining: 3.35s\n",
      "364:\tlearn: 0.9974233\ttotal: 9s\tremaining: 3.33s\n",
      "365:\tlearn: 0.9975748\ttotal: 9.03s\tremaining: 3.3s\n",
      "366:\tlearn: 0.9976758\ttotal: 9.04s\tremaining: 3.28s\n",
      "367:\tlearn: 0.9978271\ttotal: 9.07s\tremaining: 3.25s\n",
      "368:\tlearn: 0.9978777\ttotal: 9.09s\tremaining: 3.23s\n",
      "369:\tlearn: 0.9979279\ttotal: 9.12s\tremaining: 3.2s\n",
      "370:\tlearn: 0.9979279\ttotal: 9.14s\tremaining: 3.18s\n",
      "371:\tlearn: 0.9979279\ttotal: 9.16s\tremaining: 3.15s\n",
      "372:\tlearn: 0.9980290\ttotal: 9.19s\tremaining: 3.13s\n",
      "373:\tlearn: 0.9979281\ttotal: 9.21s\tremaining: 3.1s\n",
      "374:\tlearn: 0.9980290\ttotal: 9.23s\tremaining: 3.08s\n",
      "375:\tlearn: 0.9980795\ttotal: 9.26s\tremaining: 3.05s\n",
      "376:\tlearn: 0.9981299\ttotal: 9.28s\tremaining: 3.03s\n",
      "377:\tlearn: 0.9981803\ttotal: 9.3s\tremaining: 3s\n",
      "378:\tlearn: 0.9980791\ttotal: 9.33s\tremaining: 2.98s\n",
      "379:\tlearn: 0.9981802\ttotal: 9.35s\tremaining: 2.95s\n",
      "380:\tlearn: 0.9981803\ttotal: 9.37s\tremaining: 2.93s\n",
      "381:\tlearn: 0.9981301\ttotal: 9.39s\tremaining: 2.9s\n",
      "382:\tlearn: 0.9981805\ttotal: 9.42s\tremaining: 2.88s\n",
      "383:\tlearn: 0.9981805\ttotal: 9.44s\tremaining: 2.85s\n",
      "384:\tlearn: 0.9982814\ttotal: 9.46s\tremaining: 2.83s\n",
      "385:\tlearn: 0.9984328\ttotal: 9.49s\tremaining: 2.8s\n",
      "386:\tlearn: 0.9984328\ttotal: 9.51s\tremaining: 2.78s\n",
      "387:\tlearn: 0.9985338\ttotal: 9.54s\tremaining: 2.75s\n",
      "388:\tlearn: 0.9985844\ttotal: 9.56s\tremaining: 2.73s\n",
      "389:\tlearn: 0.9985844\ttotal: 9.58s\tremaining: 2.7s\n",
      "390:\tlearn: 0.9986855\ttotal: 9.61s\tremaining: 2.68s\n",
      "391:\tlearn: 0.9987867\ttotal: 9.63s\tremaining: 2.65s\n",
      "392:\tlearn: 0.9989382\ttotal: 9.66s\tremaining: 2.63s\n",
      "393:\tlearn: 0.9988877\ttotal: 9.68s\tremaining: 2.6s\n",
      "394:\tlearn: 0.9988877\ttotal: 9.7s\tremaining: 2.58s\n",
      "395:\tlearn: 0.9990392\ttotal: 9.73s\tremaining: 2.55s\n",
      "396:\tlearn: 0.9990897\ttotal: 9.75s\tremaining: 2.53s\n",
      "397:\tlearn: 0.9989886\ttotal: 9.77s\tremaining: 2.5s\n",
      "398:\tlearn: 0.9989886\ttotal: 9.79s\tremaining: 2.48s\n",
      "399:\tlearn: 0.9990896\ttotal: 9.82s\tremaining: 2.45s\n",
      "400:\tlearn: 0.9990896\ttotal: 9.84s\tremaining: 2.43s\n",
      "401:\tlearn: 0.9990896\ttotal: 9.87s\tremaining: 2.4s\n",
      "402:\tlearn: 0.9990895\ttotal: 9.89s\tremaining: 2.38s\n",
      "403:\tlearn: 0.9991402\ttotal: 9.91s\tremaining: 2.35s\n",
      "404:\tlearn: 0.9991402\ttotal: 9.94s\tremaining: 2.33s\n",
      "405:\tlearn: 0.9991402\ttotal: 9.97s\tremaining: 2.31s\n",
      "406:\tlearn: 0.9992412\ttotal: 9.99s\tremaining: 2.28s\n",
      "407:\tlearn: 0.9992918\ttotal: 10s\tremaining: 2.26s\n",
      "408:\tlearn: 0.9991907\ttotal: 10s\tremaining: 2.23s\n",
      "409:\tlearn: 0.9990391\ttotal: 10.1s\tremaining: 2.21s\n",
      "410:\tlearn: 0.9990896\ttotal: 10.1s\tremaining: 2.18s\n",
      "411:\tlearn: 0.9992412\ttotal: 10.1s\tremaining: 2.16s\n",
      "412:\tlearn: 0.9990391\ttotal: 10.1s\tremaining: 2.13s\n",
      "413:\tlearn: 0.9990896\ttotal: 10.2s\tremaining: 2.11s\n",
      "414:\tlearn: 0.9991402\ttotal: 10.2s\tremaining: 2.09s\n",
      "415:\tlearn: 0.9991402\ttotal: 10.2s\tremaining: 2.06s\n",
      "416:\tlearn: 0.9991402\ttotal: 10.2s\tremaining: 2.04s\n",
      "417:\tlearn: 0.9991907\ttotal: 10.3s\tremaining: 2.01s\n",
      "418:\tlearn: 0.9992412\ttotal: 10.3s\tremaining: 1.99s\n",
      "419:\tlearn: 0.9992412\ttotal: 10.3s\tremaining: 1.96s\n",
      "420:\tlearn: 0.9992412\ttotal: 10.3s\tremaining: 1.94s\n",
      "421:\tlearn: 0.9992412\ttotal: 10.4s\tremaining: 1.91s\n",
      "422:\tlearn: 0.9991402\ttotal: 10.4s\tremaining: 1.89s\n",
      "423:\tlearn: 0.9991402\ttotal: 10.4s\tremaining: 1.86s\n",
      "424:\tlearn: 0.9992412\ttotal: 10.4s\tremaining: 1.84s\n",
      "425:\tlearn: 0.9992412\ttotal: 10.4s\tremaining: 1.81s\n",
      "426:\tlearn: 0.9992412\ttotal: 10.5s\tremaining: 1.79s\n",
      "427:\tlearn: 0.9992918\ttotal: 10.5s\tremaining: 1.77s\n",
      "428:\tlearn: 0.9992918\ttotal: 10.5s\tremaining: 1.74s\n",
      "429:\tlearn: 0.9992412\ttotal: 10.5s\tremaining: 1.72s\n",
      "430:\tlearn: 0.9992412\ttotal: 10.6s\tremaining: 1.69s\n",
      "431:\tlearn: 0.9993423\ttotal: 10.6s\tremaining: 1.67s\n",
      "432:\tlearn: 0.9994435\ttotal: 10.6s\tremaining: 1.64s\n",
      "433:\tlearn: 0.9993929\ttotal: 10.6s\tremaining: 1.62s\n",
      "434:\tlearn: 0.9994940\ttotal: 10.7s\tremaining: 1.59s\n",
      "435:\tlearn: 0.9995952\ttotal: 10.7s\tremaining: 1.57s\n",
      "436:\tlearn: 0.9996458\ttotal: 10.7s\tremaining: 1.54s\n",
      "437:\tlearn: 0.9995952\ttotal: 10.7s\tremaining: 1.52s\n",
      "438:\tlearn: 0.9995952\ttotal: 10.8s\tremaining: 1.5s\n",
      "439:\tlearn: 0.9995952\ttotal: 10.8s\tremaining: 1.47s\n",
      "440:\tlearn: 0.9995952\ttotal: 10.8s\tremaining: 1.45s\n",
      "441:\tlearn: 0.9996964\ttotal: 10.8s\tremaining: 1.42s\n",
      "442:\tlearn: 0.9997976\ttotal: 10.9s\tremaining: 1.4s\n",
      "443:\tlearn: 0.9997976\ttotal: 10.9s\tremaining: 1.37s\n",
      "444:\tlearn: 0.9997976\ttotal: 10.9s\tremaining: 1.35s\n",
      "445:\tlearn: 0.9997976\ttotal: 10.9s\tremaining: 1.32s\n",
      "446:\tlearn: 0.9997470\ttotal: 11s\tremaining: 1.3s\n",
      "447:\tlearn: 0.9997470\ttotal: 11s\tremaining: 1.27s\n",
      "448:\tlearn: 0.9996963\ttotal: 11s\tremaining: 1.25s\n",
      "449:\tlearn: 0.9996963\ttotal: 11s\tremaining: 1.23s\n",
      "450:\tlearn: 0.9996963\ttotal: 11.1s\tremaining: 1.2s\n",
      "451:\tlearn: 0.9997470\ttotal: 11.1s\tremaining: 1.18s\n",
      "452:\tlearn: 0.9997470\ttotal: 11.1s\tremaining: 1.15s\n",
      "453:\tlearn: 0.9997976\ttotal: 11.1s\tremaining: 1.13s\n",
      "454:\tlearn: 0.9997976\ttotal: 11.1s\tremaining: 1.1s\n",
      "455:\tlearn: 0.9997976\ttotal: 11.2s\tremaining: 1.08s\n",
      "456:\tlearn: 0.9997470\ttotal: 11.2s\tremaining: 1.05s\n",
      "457:\tlearn: 0.9997470\ttotal: 11.2s\tremaining: 1.03s\n",
      "458:\tlearn: 0.9998482\ttotal: 11.2s\tremaining: 1s\n",
      "459:\tlearn: 0.9998482\ttotal: 11.3s\tremaining: 980ms\n",
      "460:\tlearn: 0.9998482\ttotal: 11.3s\tremaining: 955ms\n",
      "461:\tlearn: 0.9998482\ttotal: 11.3s\tremaining: 930ms\n",
      "462:\tlearn: 0.9998482\ttotal: 11.3s\tremaining: 906ms\n",
      "463:\tlearn: 0.9998482\ttotal: 11.4s\tremaining: 881ms\n",
      "464:\tlearn: 0.9998988\ttotal: 11.4s\tremaining: 857ms\n",
      "465:\tlearn: 0.9998482\ttotal: 11.4s\tremaining: 833ms\n",
      "466:\tlearn: 0.9998482\ttotal: 11.4s\tremaining: 808ms\n",
      "467:\tlearn: 0.9998482\ttotal: 11.5s\tremaining: 783ms\n",
      "468:\tlearn: 0.9998482\ttotal: 11.5s\tremaining: 759ms\n",
      "469:\tlearn: 0.9998482\ttotal: 11.5s\tremaining: 734ms\n",
      "470:\tlearn: 0.9998482\ttotal: 11.5s\tremaining: 710ms\n",
      "471:\tlearn: 0.9997976\ttotal: 11.5s\tremaining: 685ms\n",
      "472:\tlearn: 0.9997976\ttotal: 11.6s\tremaining: 660ms\n",
      "473:\tlearn: 0.9998482\ttotal: 11.6s\tremaining: 636ms\n",
      "474:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 611ms\n",
      "475:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 587ms\n",
      "476:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 562ms\n",
      "477:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 538ms\n",
      "478:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 513ms\n",
      "479:\tlearn: 0.9998482\ttotal: 11.7s\tremaining: 489ms\n",
      "480:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 464ms\n",
      "481:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 440ms\n",
      "482:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 415ms\n",
      "483:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 391ms\n",
      "484:\tlearn: 0.9998482\ttotal: 11.8s\tremaining: 366ms\n",
      "485:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 342ms\n",
      "486:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 318ms\n",
      "487:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 293ms\n",
      "488:\tlearn: 0.9998482\ttotal: 11.9s\tremaining: 269ms\n",
      "489:\tlearn: 0.9998482\ttotal: 12s\tremaining: 244ms\n",
      "490:\tlearn: 0.9998482\ttotal: 12s\tremaining: 220ms\n",
      "491:\tlearn: 0.9998988\ttotal: 12s\tremaining: 195ms\n",
      "492:\tlearn: 0.9998988\ttotal: 12s\tremaining: 171ms\n",
      "493:\tlearn: 0.9998988\ttotal: 12.1s\tremaining: 147ms\n",
      "494:\tlearn: 0.9998988\ttotal: 12.1s\tremaining: 122ms\n",
      "495:\tlearn: 0.9998988\ttotal: 12.1s\tremaining: 97.7ms\n",
      "496:\tlearn: 0.9998988\ttotal: 12.1s\tremaining: 73.3ms\n",
      "497:\tlearn: 0.9998988\ttotal: 12.2s\tremaining: 48.8ms\n",
      "498:\tlearn: 0.9998988\ttotal: 12.2s\tremaining: 24.4ms\n",
      "499:\tlearn: 0.9998988\ttotal: 12.2s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=32, depth=4, eval_metric=F1, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=0.1; total time=  12.7s\n",
      "0:\tlearn: 0.6136033\ttotal: 27.7ms\tremaining: 13.8s\n",
      "1:\tlearn: 0.6546454\ttotal: 52.6ms\tremaining: 13.1s\n",
      "2:\tlearn: 0.6745517\ttotal: 76.1ms\tremaining: 12.6s\n",
      "3:\tlearn: 0.6891554\ttotal: 103ms\tremaining: 12.7s\n",
      "4:\tlearn: 0.6955147\ttotal: 127ms\tremaining: 12.6s\n",
      "5:\tlearn: 0.7062854\ttotal: 149ms\tremaining: 12.2s\n",
      "6:\tlearn: 0.7159221\ttotal: 171ms\tremaining: 12s\n",
      "7:\tlearn: 0.7199840\ttotal: 197ms\tremaining: 12.1s\n",
      "8:\tlearn: 0.7262894\ttotal: 224ms\tremaining: 12.2s\n",
      "9:\tlearn: 0.7331036\ttotal: 251ms\tremaining: 12.3s\n",
      "10:\tlearn: 0.7381785\ttotal: 273ms\tremaining: 12.1s\n",
      "11:\tlearn: 0.7456324\ttotal: 300ms\tremaining: 12.2s\n",
      "12:\tlearn: 0.7506978\ttotal: 325ms\tremaining: 12.2s\n",
      "13:\tlearn: 0.7537618\ttotal: 348ms\tremaining: 12.1s\n",
      "14:\tlearn: 0.7582280\ttotal: 372ms\tremaining: 12s\n",
      "15:\tlearn: 0.7616717\ttotal: 395ms\tremaining: 12s\n",
      "16:\tlearn: 0.7672259\ttotal: 421ms\tremaining: 12s\n",
      "17:\tlearn: 0.7710038\ttotal: 446ms\tremaining: 11.9s\n",
      "18:\tlearn: 0.7769461\ttotal: 469ms\tremaining: 11.9s\n",
      "19:\tlearn: 0.7805122\ttotal: 495ms\tremaining: 11.9s\n",
      "20:\tlearn: 0.7819751\ttotal: 520ms\tremaining: 11.9s\n",
      "21:\tlearn: 0.7854404\ttotal: 543ms\tremaining: 11.8s\n",
      "22:\tlearn: 0.7876706\ttotal: 570ms\tremaining: 11.8s\n",
      "23:\tlearn: 0.7913147\ttotal: 596ms\tremaining: 11.8s\n",
      "24:\tlearn: 0.7946796\ttotal: 619ms\tremaining: 11.8s\n",
      "25:\tlearn: 0.7979352\ttotal: 646ms\tremaining: 11.8s\n",
      "26:\tlearn: 0.8013314\ttotal: 671ms\tremaining: 11.8s\n",
      "27:\tlearn: 0.8021459\ttotal: 698ms\tremaining: 11.8s\n",
      "28:\tlearn: 0.8024741\ttotal: 725ms\tremaining: 11.8s\n",
      "29:\tlearn: 0.8064163\ttotal: 747ms\tremaining: 11.7s\n",
      "30:\tlearn: 0.8101543\ttotal: 772ms\tremaining: 11.7s\n",
      "31:\tlearn: 0.8132896\ttotal: 795ms\tremaining: 11.6s\n",
      "32:\tlearn: 0.8136334\ttotal: 816ms\tremaining: 11.6s\n",
      "33:\tlearn: 0.8162291\ttotal: 841ms\tremaining: 11.5s\n",
      "34:\tlearn: 0.8198368\ttotal: 862ms\tremaining: 11.5s\n",
      "35:\tlearn: 0.8226922\ttotal: 887ms\tremaining: 11.4s\n",
      "36:\tlearn: 0.8243263\ttotal: 914ms\tremaining: 11.4s\n",
      "37:\tlearn: 0.8260307\ttotal: 937ms\tremaining: 11.4s\n",
      "38:\tlearn: 0.8283682\ttotal: 962ms\tremaining: 11.4s\n",
      "39:\tlearn: 0.8310693\ttotal: 986ms\tremaining: 11.3s\n",
      "40:\tlearn: 0.8310489\ttotal: 1.01s\tremaining: 11.3s\n",
      "41:\tlearn: 0.8333416\ttotal: 1.03s\tremaining: 11.2s\n",
      "42:\tlearn: 0.8347584\ttotal: 1.06s\tremaining: 11.2s\n",
      "43:\tlearn: 0.8359557\ttotal: 1.08s\tremaining: 11.2s\n",
      "44:\tlearn: 0.8378365\ttotal: 1.1s\tremaining: 11.2s\n",
      "45:\tlearn: 0.8388790\ttotal: 1.13s\tremaining: 11.1s\n",
      "46:\tlearn: 0.8413171\ttotal: 1.15s\tremaining: 11.1s\n",
      "47:\tlearn: 0.8431489\ttotal: 1.17s\tremaining: 11.1s\n",
      "48:\tlearn: 0.8444555\ttotal: 1.2s\tremaining: 11s\n",
      "49:\tlearn: 0.8457115\ttotal: 1.22s\tremaining: 11s\n",
      "50:\tlearn: 0.8467522\ttotal: 1.24s\tremaining: 10.9s\n",
      "51:\tlearn: 0.8473180\ttotal: 1.27s\tremaining: 10.9s\n",
      "52:\tlearn: 0.8514204\ttotal: 1.29s\tremaining: 10.9s\n",
      "53:\tlearn: 0.8523696\ttotal: 1.32s\tremaining: 10.9s\n",
      "54:\tlearn: 0.8535594\ttotal: 1.35s\tremaining: 10.9s\n",
      "55:\tlearn: 0.8557978\ttotal: 1.38s\tremaining: 10.9s\n",
      "56:\tlearn: 0.8567888\ttotal: 1.4s\tremaining: 10.9s\n",
      "57:\tlearn: 0.8573980\ttotal: 1.43s\tremaining: 10.9s\n",
      "58:\tlearn: 0.8596953\ttotal: 1.45s\tremaining: 10.8s\n",
      "59:\tlearn: 0.8607118\ttotal: 1.47s\tremaining: 10.8s\n",
      "60:\tlearn: 0.8623343\ttotal: 1.5s\tremaining: 10.8s\n",
      "61:\tlearn: 0.8642502\ttotal: 1.52s\tremaining: 10.8s\n",
      "62:\tlearn: 0.8652137\ttotal: 1.55s\tremaining: 10.7s\n",
      "63:\tlearn: 0.8667262\ttotal: 1.57s\tremaining: 10.7s\n",
      "64:\tlearn: 0.8681532\ttotal: 1.6s\tremaining: 10.7s\n",
      "65:\tlearn: 0.8691292\ttotal: 1.62s\tremaining: 10.7s\n",
      "66:\tlearn: 0.8703290\ttotal: 1.64s\tremaining: 10.6s\n",
      "67:\tlearn: 0.8721663\ttotal: 1.67s\tremaining: 10.6s\n",
      "68:\tlearn: 0.8740653\ttotal: 1.69s\tremaining: 10.6s\n",
      "69:\tlearn: 0.8745537\ttotal: 1.72s\tremaining: 10.5s\n",
      "70:\tlearn: 0.8751860\ttotal: 1.74s\tremaining: 10.5s\n",
      "71:\tlearn: 0.8772556\ttotal: 1.76s\tremaining: 10.5s\n",
      "72:\tlearn: 0.8784407\ttotal: 1.78s\tremaining: 10.4s\n",
      "73:\tlearn: 0.8794129\ttotal: 1.81s\tremaining: 10.4s\n",
      "74:\tlearn: 0.8785427\ttotal: 1.83s\tremaining: 10.4s\n",
      "75:\tlearn: 0.8810162\ttotal: 1.86s\tremaining: 10.4s\n",
      "76:\tlearn: 0.8817460\ttotal: 1.88s\tremaining: 10.3s\n",
      "77:\tlearn: 0.8831530\ttotal: 1.91s\tremaining: 10.3s\n",
      "78:\tlearn: 0.8841802\ttotal: 1.93s\tremaining: 10.3s\n",
      "79:\tlearn: 0.8848899\ttotal: 1.95s\tremaining: 10.2s\n",
      "80:\tlearn: 0.8853468\ttotal: 1.97s\tremaining: 10.2s\n",
      "81:\tlearn: 0.8861438\ttotal: 2s\tremaining: 10.2s\n",
      "82:\tlearn: 0.8879960\ttotal: 2.02s\tremaining: 10.2s\n",
      "83:\tlearn: 0.8886464\ttotal: 2.04s\tremaining: 10.1s\n",
      "84:\tlearn: 0.8896165\ttotal: 2.07s\tremaining: 10.1s\n",
      "85:\tlearn: 0.8903437\ttotal: 2.09s\tremaining: 10.1s\n",
      "86:\tlearn: 0.8908423\ttotal: 2.12s\tremaining: 10.1s\n",
      "87:\tlearn: 0.8922771\ttotal: 2.14s\tremaining: 10s\n",
      "88:\tlearn: 0.8938154\ttotal: 2.16s\tremaining: 9.99s\n",
      "89:\tlearn: 0.8946638\ttotal: 2.19s\tremaining: 9.95s\n",
      "90:\tlearn: 0.8965346\ttotal: 2.21s\tremaining: 9.94s\n",
      "91:\tlearn: 0.8965072\ttotal: 2.23s\tremaining: 9.91s\n",
      "92:\tlearn: 0.8978639\ttotal: 2.26s\tremaining: 9.9s\n",
      "93:\tlearn: 0.8985680\ttotal: 2.29s\tremaining: 9.88s\n",
      "94:\tlearn: 0.8999751\ttotal: 2.31s\tremaining: 9.85s\n",
      "95:\tlearn: 0.9013567\ttotal: 2.33s\tremaining: 9.82s\n",
      "96:\tlearn: 0.9026039\ttotal: 2.36s\tremaining: 9.8s\n",
      "97:\tlearn: 0.9042008\ttotal: 2.38s\tremaining: 9.77s\n",
      "98:\tlearn: 0.9051596\ttotal: 2.41s\tremaining: 9.76s\n",
      "99:\tlearn: 0.9057748\ttotal: 2.44s\tremaining: 9.74s\n",
      "100:\tlearn: 0.9057841\ttotal: 2.46s\tremaining: 9.71s\n",
      "101:\tlearn: 0.9062174\ttotal: 2.48s\tremaining: 9.68s\n",
      "102:\tlearn: 0.9067038\ttotal: 2.5s\tremaining: 9.64s\n",
      "103:\tlearn: 0.9084945\ttotal: 2.52s\tremaining: 9.61s\n",
      "104:\tlearn: 0.9098857\ttotal: 2.55s\tremaining: 9.59s\n",
      "105:\tlearn: 0.9094881\ttotal: 2.57s\tremaining: 9.56s\n",
      "106:\tlearn: 0.9108773\ttotal: 2.6s\tremaining: 9.53s\n",
      "107:\tlearn: 0.9124882\ttotal: 2.62s\tremaining: 9.51s\n",
      "108:\tlearn: 0.9125385\ttotal: 2.64s\tremaining: 9.48s\n",
      "109:\tlearn: 0.9134319\ttotal: 2.67s\tremaining: 9.46s\n",
      "110:\tlearn: 0.9139934\ttotal: 2.69s\tremaining: 9.43s\n",
      "111:\tlearn: 0.9148133\ttotal: 2.71s\tremaining: 9.41s\n",
      "112:\tlearn: 0.9154510\ttotal: 2.74s\tremaining: 9.37s\n",
      "113:\tlearn: 0.9157942\ttotal: 2.76s\tremaining: 9.35s\n",
      "114:\tlearn: 0.9177090\ttotal: 2.79s\tremaining: 9.32s\n",
      "115:\tlearn: 0.9191147\ttotal: 2.81s\tremaining: 9.29s\n",
      "116:\tlearn: 0.9194228\ttotal: 2.83s\tremaining: 9.27s\n",
      "117:\tlearn: 0.9201827\ttotal: 2.85s\tremaining: 9.24s\n",
      "118:\tlearn: 0.9219626\ttotal: 2.88s\tremaining: 9.21s\n",
      "119:\tlearn: 0.9221224\ttotal: 2.9s\tremaining: 9.19s\n",
      "120:\tlearn: 0.9228634\ttotal: 2.93s\tremaining: 9.17s\n",
      "121:\tlearn: 0.9250769\ttotal: 2.95s\tremaining: 9.15s\n",
      "122:\tlearn: 0.9250769\ttotal: 2.98s\tremaining: 9.12s\n",
      "123:\tlearn: 0.9255657\ttotal: 3s\tremaining: 9.11s\n",
      "124:\tlearn: 0.9261832\ttotal: 3.03s\tremaining: 9.1s\n",
      "125:\tlearn: 0.9276714\ttotal: 3.06s\tremaining: 9.07s\n",
      "126:\tlearn: 0.9280222\ttotal: 3.08s\tremaining: 9.04s\n",
      "127:\tlearn: 0.9279016\ttotal: 3.1s\tremaining: 9.02s\n",
      "128:\tlearn: 0.9283341\ttotal: 3.13s\tremaining: 8.99s\n",
      "129:\tlearn: 0.9293551\ttotal: 3.15s\tremaining: 8.96s\n",
      "130:\tlearn: 0.9298446\ttotal: 3.17s\tremaining: 8.94s\n",
      "131:\tlearn: 0.9306252\ttotal: 3.2s\tremaining: 8.91s\n",
      "132:\tlearn: 0.9307658\ttotal: 3.22s\tremaining: 8.88s\n",
      "133:\tlearn: 0.9316443\ttotal: 3.24s\tremaining: 8.86s\n",
      "134:\tlearn: 0.9323338\ttotal: 3.27s\tremaining: 8.84s\n",
      "135:\tlearn: 0.9333929\ttotal: 3.29s\tremaining: 8.81s\n",
      "136:\tlearn: 0.9337439\ttotal: 3.31s\tremaining: 8.78s\n",
      "137:\tlearn: 0.9340086\ttotal: 3.34s\tremaining: 8.76s\n",
      "138:\tlearn: 0.9343928\ttotal: 3.38s\tremaining: 8.77s\n",
      "139:\tlearn: 0.9360203\ttotal: 3.4s\tremaining: 8.74s\n",
      "140:\tlearn: 0.9360286\ttotal: 3.42s\tremaining: 8.71s\n",
      "141:\tlearn: 0.9360835\ttotal: 3.45s\tremaining: 8.69s\n",
      "142:\tlearn: 0.9369781\ttotal: 3.47s\tremaining: 8.66s\n",
      "143:\tlearn: 0.9372514\ttotal: 3.49s\tremaining: 8.63s\n",
      "144:\tlearn: 0.9375559\ttotal: 3.52s\tremaining: 8.62s\n",
      "145:\tlearn: 0.9385442\ttotal: 3.54s\tremaining: 8.59s\n",
      "146:\tlearn: 0.9398440\ttotal: 3.57s\tremaining: 8.58s\n",
      "147:\tlearn: 0.9406855\ttotal: 3.59s\tremaining: 8.55s\n",
      "148:\tlearn: 0.9409484\ttotal: 3.62s\tremaining: 8.52s\n",
      "149:\tlearn: 0.9409249\ttotal: 3.64s\tremaining: 8.49s\n",
      "150:\tlearn: 0.9409249\ttotal: 3.66s\tremaining: 8.46s\n",
      "151:\tlearn: 0.9425219\ttotal: 3.69s\tremaining: 8.44s\n",
      "152:\tlearn: 0.9437755\ttotal: 3.71s\tremaining: 8.41s\n",
      "153:\tlearn: 0.9429594\ttotal: 3.74s\tremaining: 8.4s\n",
      "154:\tlearn: 0.9435332\ttotal: 3.77s\tremaining: 8.4s\n",
      "155:\tlearn: 0.9443174\ttotal: 3.8s\tremaining: 8.37s\n",
      "156:\tlearn: 0.9443836\ttotal: 3.82s\tremaining: 8.36s\n",
      "157:\tlearn: 0.9451687\ttotal: 3.85s\tremaining: 8.32s\n",
      "158:\tlearn: 0.9453930\ttotal: 3.87s\tremaining: 8.3s\n",
      "159:\tlearn: 0.9464206\ttotal: 3.9s\tremaining: 8.3s\n",
      "160:\tlearn: 0.9472061\ttotal: 3.93s\tremaining: 8.28s\n",
      "161:\tlearn: 0.9477300\ttotal: 3.95s\tremaining: 8.25s\n",
      "162:\tlearn: 0.9472427\ttotal: 3.98s\tremaining: 8.23s\n",
      "163:\tlearn: 0.9479711\ttotal: 4.01s\tremaining: 8.21s\n",
      "164:\tlearn: 0.9481179\ttotal: 4.03s\tremaining: 8.18s\n",
      "165:\tlearn: 0.9489720\ttotal: 4.05s\tremaining: 8.15s\n",
      "166:\tlearn: 0.9492909\ttotal: 4.08s\tremaining: 8.13s\n",
      "167:\tlearn: 0.9496317\ttotal: 4.1s\tremaining: 8.1s\n",
      "168:\tlearn: 0.9504428\ttotal: 4.13s\tremaining: 8.09s\n",
      "169:\tlearn: 0.9508882\ttotal: 4.16s\tremaining: 8.07s\n",
      "170:\tlearn: 0.9515326\ttotal: 4.18s\tremaining: 8.04s\n",
      "171:\tlearn: 0.9520064\ttotal: 4.2s\tremaining: 8.02s\n",
      "172:\tlearn: 0.9524616\ttotal: 4.23s\tremaining: 8s\n",
      "173:\tlearn: 0.9532021\ttotal: 4.25s\tremaining: 7.97s\n",
      "174:\tlearn: 0.9536714\ttotal: 4.27s\tremaining: 7.94s\n",
      "175:\tlearn: 0.9543076\ttotal: 4.29s\tremaining: 7.91s\n",
      "176:\tlearn: 0.9546632\ttotal: 4.32s\tremaining: 7.88s\n",
      "177:\tlearn: 0.9552655\ttotal: 4.34s\tremaining: 7.85s\n",
      "178:\tlearn: 0.9552045\ttotal: 4.37s\tremaining: 7.83s\n",
      "179:\tlearn: 0.9562659\ttotal: 4.4s\tremaining: 7.82s\n",
      "180:\tlearn: 0.9562790\ttotal: 4.42s\tremaining: 7.8s\n",
      "181:\tlearn: 0.9566735\ttotal: 4.45s\tremaining: 7.77s\n",
      "182:\tlearn: 0.9568209\ttotal: 4.47s\tremaining: 7.75s\n",
      "183:\tlearn: 0.9571243\ttotal: 4.49s\tremaining: 7.72s\n",
      "184:\tlearn: 0.9576833\ttotal: 4.52s\tremaining: 7.69s\n",
      "185:\tlearn: 0.9585079\ttotal: 4.54s\tremaining: 7.66s\n",
      "186:\tlearn: 0.9584789\ttotal: 4.56s\tremaining: 7.64s\n",
      "187:\tlearn: 0.9599840\ttotal: 4.59s\tremaining: 7.62s\n",
      "188:\tlearn: 0.9599840\ttotal: 4.62s\tremaining: 7.59s\n",
      "189:\tlearn: 0.9598882\ttotal: 4.64s\tremaining: 7.57s\n",
      "190:\tlearn: 0.9607706\ttotal: 4.66s\tremaining: 7.55s\n",
      "191:\tlearn: 0.9609508\ttotal: 4.69s\tremaining: 7.52s\n",
      "192:\tlearn: 0.9613618\ttotal: 4.71s\tremaining: 7.49s\n",
      "193:\tlearn: 0.9623084\ttotal: 4.74s\tremaining: 7.47s\n",
      "194:\tlearn: 0.9622971\ttotal: 4.76s\tremaining: 7.44s\n",
      "195:\tlearn: 0.9632812\ttotal: 4.79s\tremaining: 7.42s\n",
      "196:\tlearn: 0.9639397\ttotal: 4.81s\tremaining: 7.4s\n",
      "197:\tlearn: 0.9647377\ttotal: 4.84s\tremaining: 7.38s\n",
      "198:\tlearn: 0.9655000\ttotal: 4.87s\tremaining: 7.36s\n",
      "199:\tlearn: 0.9650105\ttotal: 4.89s\tremaining: 7.34s\n",
      "200:\tlearn: 0.9668901\ttotal: 4.92s\tremaining: 7.33s\n",
      "201:\tlearn: 0.9671484\ttotal: 4.95s\tremaining: 7.3s\n",
      "202:\tlearn: 0.9677710\ttotal: 4.97s\tremaining: 7.27s\n",
      "203:\tlearn: 0.9670385\ttotal: 5s\tremaining: 7.25s\n",
      "204:\tlearn: 0.9672385\ttotal: 5.02s\tremaining: 7.22s\n",
      "205:\tlearn: 0.9682905\ttotal: 5.05s\tremaining: 7.2s\n",
      "206:\tlearn: 0.9678679\ttotal: 5.07s\tremaining: 7.18s\n",
      "207:\tlearn: 0.9683874\ttotal: 5.1s\tremaining: 7.16s\n",
      "208:\tlearn: 0.9687969\ttotal: 5.12s\tremaining: 7.13s\n",
      "209:\tlearn: 0.9693694\ttotal: 5.15s\tremaining: 7.11s\n",
      "210:\tlearn: 0.9696211\ttotal: 5.17s\tremaining: 7.08s\n",
      "211:\tlearn: 0.9701366\ttotal: 5.19s\tremaining: 7.05s\n",
      "212:\tlearn: 0.9697152\ttotal: 5.21s\tremaining: 7.03s\n",
      "213:\tlearn: 0.9712569\ttotal: 5.24s\tremaining: 7.01s\n",
      "214:\tlearn: 0.9703704\ttotal: 5.27s\tremaining: 6.98s\n",
      "215:\tlearn: 0.9708621\ttotal: 5.29s\tremaining: 6.96s\n",
      "216:\tlearn: 0.9717175\ttotal: 5.31s\tremaining: 6.93s\n",
      "217:\tlearn: 0.9721638\ttotal: 5.34s\tremaining: 6.91s\n",
      "218:\tlearn: 0.9728539\ttotal: 5.36s\tremaining: 6.88s\n",
      "219:\tlearn: 0.9732545\ttotal: 5.38s\tremaining: 6.85s\n",
      "220:\tlearn: 0.9731029\ttotal: 5.42s\tremaining: 6.84s\n",
      "221:\tlearn: 0.9737119\ttotal: 5.44s\tremaining: 6.81s\n",
      "222:\tlearn: 0.9741612\ttotal: 5.46s\tremaining: 6.79s\n",
      "223:\tlearn: 0.9753018\ttotal: 5.49s\tremaining: 6.76s\n",
      "224:\tlearn: 0.9759423\ttotal: 5.51s\tremaining: 6.74s\n",
      "225:\tlearn: 0.9759960\ttotal: 5.53s\tremaining: 6.71s\n",
      "226:\tlearn: 0.9762036\ttotal: 5.56s\tremaining: 6.68s\n",
      "227:\tlearn: 0.9764505\ttotal: 5.58s\tremaining: 6.66s\n",
      "228:\tlearn: 0.9763527\ttotal: 5.61s\tremaining: 6.64s\n",
      "229:\tlearn: 0.9768375\ttotal: 5.63s\tremaining: 6.61s\n",
      "230:\tlearn: 0.9770893\ttotal: 5.66s\tremaining: 6.58s\n",
      "231:\tlearn: 0.9773855\ttotal: 5.68s\tremaining: 6.56s\n",
      "232:\tlearn: 0.9773365\ttotal: 5.7s\tremaining: 6.53s\n",
      "233:\tlearn: 0.9778892\ttotal: 5.72s\tremaining: 6.5s\n",
      "234:\tlearn: 0.9784887\ttotal: 5.74s\tremaining: 6.47s\n",
      "235:\tlearn: 0.9783884\ttotal: 5.76s\tremaining: 6.44s\n",
      "236:\tlearn: 0.9785954\ttotal: 5.78s\tremaining: 6.41s\n",
      "237:\tlearn: 0.9786466\ttotal: 5.8s\tremaining: 6.39s\n",
      "238:\tlearn: 0.9791823\ttotal: 5.83s\tremaining: 6.36s\n",
      "239:\tlearn: 0.9786957\ttotal: 5.85s\tremaining: 6.34s\n",
      "240:\tlearn: 0.9784995\ttotal: 5.87s\tremaining: 6.31s\n",
      "241:\tlearn: 0.9789516\ttotal: 5.9s\tremaining: 6.29s\n",
      "242:\tlearn: 0.9797494\ttotal: 5.93s\tremaining: 6.27s\n",
      "243:\tlearn: 0.9802015\ttotal: 5.95s\tremaining: 6.24s\n",
      "244:\tlearn: 0.9802899\ttotal: 5.97s\tremaining: 6.22s\n",
      "245:\tlearn: 0.9806419\ttotal: 6.01s\tremaining: 6.21s\n",
      "246:\tlearn: 0.9811832\ttotal: 6.04s\tremaining: 6.18s\n",
      "247:\tlearn: 0.9805869\ttotal: 6.06s\tremaining: 6.16s\n",
      "248:\tlearn: 0.9806342\ttotal: 6.08s\tremaining: 6.13s\n",
      "249:\tlearn: 0.9811813\ttotal: 6.11s\tremaining: 6.11s\n",
      "250:\tlearn: 0.9812817\ttotal: 6.14s\tremaining: 6.09s\n",
      "251:\tlearn: 0.9814843\ttotal: 6.16s\tremaining: 6.06s\n",
      "252:\tlearn: 0.9814332\ttotal: 6.19s\tremaining: 6.04s\n",
      "253:\tlearn: 0.9819897\ttotal: 6.21s\tremaining: 6.01s\n",
      "254:\tlearn: 0.9821375\ttotal: 6.23s\tremaining: 5.99s\n",
      "255:\tlearn: 0.9827768\ttotal: 6.26s\tremaining: 5.96s\n",
      "256:\tlearn: 0.9831751\ttotal: 6.29s\tremaining: 5.95s\n",
      "257:\tlearn: 0.9835242\ttotal: 6.31s\tremaining: 5.92s\n",
      "258:\tlearn: 0.9838685\ttotal: 6.33s\tremaining: 5.89s\n",
      "259:\tlearn: 0.9841701\ttotal: 6.35s\tremaining: 5.86s\n",
      "260:\tlearn: 0.9838158\ttotal: 6.38s\tremaining: 5.84s\n",
      "261:\tlearn: 0.9840615\ttotal: 6.4s\tremaining: 5.81s\n",
      "262:\tlearn: 0.9843664\ttotal: 6.42s\tremaining: 5.79s\n",
      "263:\tlearn: 0.9849155\ttotal: 6.45s\tremaining: 5.76s\n",
      "264:\tlearn: 0.9851107\ttotal: 6.47s\tremaining: 5.74s\n",
      "265:\tlearn: 0.9845566\ttotal: 6.5s\tremaining: 5.71s\n",
      "266:\tlearn: 0.9852023\ttotal: 6.52s\tremaining: 5.69s\n",
      "267:\tlearn: 0.9855102\ttotal: 6.54s\tremaining: 5.66s\n",
      "268:\tlearn: 0.9856690\ttotal: 6.57s\tremaining: 5.64s\n",
      "269:\tlearn: 0.9859070\ttotal: 6.59s\tremaining: 5.61s\n",
      "270:\tlearn: 0.9861607\ttotal: 6.61s\tremaining: 5.59s\n",
      "271:\tlearn: 0.9862614\ttotal: 6.63s\tremaining: 5.56s\n",
      "272:\tlearn: 0.9865110\ttotal: 6.65s\tremaining: 5.53s\n",
      "273:\tlearn: 0.9870130\ttotal: 6.68s\tremaining: 5.51s\n",
      "274:\tlearn: 0.9869567\ttotal: 6.7s\tremaining: 5.48s\n",
      "275:\tlearn: 0.9877687\ttotal: 6.72s\tremaining: 5.46s\n",
      "276:\tlearn: 0.9879203\ttotal: 6.75s\tremaining: 5.43s\n",
      "277:\tlearn: 0.9880173\ttotal: 6.78s\tremaining: 5.41s\n",
      "278:\tlearn: 0.9881678\ttotal: 6.8s\tremaining: 5.39s\n",
      "279:\tlearn: 0.9881725\ttotal: 6.83s\tremaining: 5.36s\n",
      "280:\tlearn: 0.9887754\ttotal: 6.85s\tremaining: 5.33s\n",
      "281:\tlearn: 0.9889247\ttotal: 6.87s\tremaining: 5.31s\n",
      "282:\tlearn: 0.9887222\ttotal: 6.89s\tremaining: 5.29s\n",
      "283:\tlearn: 0.9887199\ttotal: 6.92s\tremaining: 5.26s\n",
      "284:\tlearn: 0.9887697\ttotal: 6.94s\tremaining: 5.23s\n",
      "285:\tlearn: 0.9890686\ttotal: 6.96s\tremaining: 5.21s\n",
      "286:\tlearn: 0.9894217\ttotal: 6.99s\tremaining: 5.18s\n",
      "287:\tlearn: 0.9897250\ttotal: 7.01s\tremaining: 5.16s\n",
      "288:\tlearn: 0.9895765\ttotal: 7.04s\tremaining: 5.14s\n",
      "289:\tlearn: 0.9896803\ttotal: 7.07s\tremaining: 5.12s\n",
      "290:\tlearn: 0.9896772\ttotal: 7.09s\tremaining: 5.09s\n",
      "291:\tlearn: 0.9904800\ttotal: 7.13s\tremaining: 5.08s\n",
      "292:\tlearn: 0.9906297\ttotal: 7.16s\tremaining: 5.06s\n",
      "293:\tlearn: 0.9906787\ttotal: 7.18s\tremaining: 5.03s\n",
      "294:\tlearn: 0.9907305\ttotal: 7.21s\tremaining: 5.01s\n",
      "295:\tlearn: 0.9904772\ttotal: 7.23s\tremaining: 4.98s\n",
      "296:\tlearn: 0.9905299\ttotal: 7.25s\tremaining: 4.96s\n",
      "297:\tlearn: 0.9908322\ttotal: 7.28s\tremaining: 4.93s\n",
      "298:\tlearn: 0.9909819\ttotal: 7.3s\tremaining: 4.91s\n",
      "299:\tlearn: 0.9910809\ttotal: 7.32s\tremaining: 4.88s\n",
      "300:\tlearn: 0.9909320\ttotal: 7.35s\tremaining: 4.86s\n",
      "301:\tlearn: 0.9910327\ttotal: 7.37s\tremaining: 4.83s\n",
      "302:\tlearn: 0.9913333\ttotal: 7.4s\tremaining: 4.81s\n",
      "303:\tlearn: 0.9914823\ttotal: 7.42s\tremaining: 4.78s\n",
      "304:\tlearn: 0.9914315\ttotal: 7.45s\tremaining: 4.76s\n",
      "305:\tlearn: 0.9916331\ttotal: 7.47s\tremaining: 4.73s\n",
      "306:\tlearn: 0.9919847\ttotal: 7.49s\tremaining: 4.71s\n",
      "307:\tlearn: 0.9921371\ttotal: 7.51s\tremaining: 4.68s\n",
      "308:\tlearn: 0.9923872\ttotal: 7.54s\tremaining: 4.66s\n",
      "309:\tlearn: 0.9923364\ttotal: 7.56s\tremaining: 4.64s\n",
      "310:\tlearn: 0.9927876\ttotal: 7.59s\tremaining: 4.61s\n",
      "311:\tlearn: 0.9928878\ttotal: 7.61s\tremaining: 4.59s\n",
      "312:\tlearn: 0.9927898\ttotal: 7.64s\tremaining: 4.56s\n",
      "313:\tlearn: 0.9931925\ttotal: 7.66s\tremaining: 4.54s\n",
      "314:\tlearn: 0.9931918\ttotal: 7.68s\tremaining: 4.51s\n",
      "315:\tlearn: 0.9934436\ttotal: 7.7s\tremaining: 4.48s\n",
      "316:\tlearn: 0.9935933\ttotal: 7.72s\tremaining: 4.46s\n",
      "317:\tlearn: 0.9942482\ttotal: 7.75s\tremaining: 4.44s\n",
      "318:\tlearn: 0.9941467\ttotal: 7.78s\tremaining: 4.41s\n",
      "319:\tlearn: 0.9944495\ttotal: 7.8s\tremaining: 4.39s\n",
      "320:\tlearn: 0.9944489\ttotal: 7.82s\tremaining: 4.36s\n",
      "321:\tlearn: 0.9944506\ttotal: 7.85s\tremaining: 4.34s\n",
      "322:\tlearn: 0.9944506\ttotal: 7.87s\tremaining: 4.31s\n",
      "323:\tlearn: 0.9946017\ttotal: 7.89s\tremaining: 4.29s\n",
      "324:\tlearn: 0.9948035\ttotal: 7.92s\tremaining: 4.26s\n",
      "325:\tlearn: 0.9955587\ttotal: 7.94s\tremaining: 4.24s\n",
      "326:\tlearn: 0.9954568\ttotal: 7.97s\tremaining: 4.21s\n",
      "327:\tlearn: 0.9953080\ttotal: 7.99s\tremaining: 4.19s\n",
      "328:\tlearn: 0.9955098\ttotal: 8.02s\tremaining: 4.17s\n",
      "329:\tlearn: 0.9955605\ttotal: 8.04s\tremaining: 4.14s\n",
      "330:\tlearn: 0.9954591\ttotal: 8.06s\tremaining: 4.12s\n",
      "331:\tlearn: 0.9955596\ttotal: 8.09s\tremaining: 4.09s\n",
      "332:\tlearn: 0.9956103\ttotal: 8.11s\tremaining: 4.07s\n",
      "333:\tlearn: 0.9955596\ttotal: 8.14s\tremaining: 4.04s\n",
      "334:\tlearn: 0.9955605\ttotal: 8.16s\tremaining: 4.02s\n",
      "335:\tlearn: 0.9957112\ttotal: 8.19s\tremaining: 4s\n",
      "336:\tlearn: 0.9957108\ttotal: 8.21s\tremaining: 3.97s\n",
      "337:\tlearn: 0.9956107\ttotal: 8.24s\tremaining: 3.95s\n",
      "338:\tlearn: 0.9958121\ttotal: 8.26s\tremaining: 3.92s\n",
      "339:\tlearn: 0.9958623\ttotal: 8.29s\tremaining: 3.9s\n",
      "340:\tlearn: 0.9961141\ttotal: 8.31s\tremaining: 3.88s\n",
      "341:\tlearn: 0.9962146\ttotal: 8.34s\tremaining: 3.85s\n",
      "342:\tlearn: 0.9961636\ttotal: 8.36s\tremaining: 3.83s\n",
      "343:\tlearn: 0.9962645\ttotal: 8.38s\tremaining: 3.8s\n",
      "344:\tlearn: 0.9963651\ttotal: 8.41s\tremaining: 3.78s\n",
      "345:\tlearn: 0.9965667\ttotal: 8.43s\tremaining: 3.75s\n",
      "346:\tlearn: 0.9965667\ttotal: 8.45s\tremaining: 3.73s\n",
      "347:\tlearn: 0.9961141\ttotal: 8.47s\tremaining: 3.7s\n",
      "348:\tlearn: 0.9962146\ttotal: 8.5s\tremaining: 3.68s\n",
      "349:\tlearn: 0.9963647\ttotal: 8.52s\tremaining: 3.65s\n",
      "350:\tlearn: 0.9964657\ttotal: 8.55s\tremaining: 3.63s\n",
      "351:\tlearn: 0.9966167\ttotal: 8.57s\tremaining: 3.6s\n",
      "352:\tlearn: 0.9966174\ttotal: 8.59s\tremaining: 3.58s\n",
      "353:\tlearn: 0.9966170\ttotal: 8.62s\tremaining: 3.56s\n",
      "354:\tlearn: 0.9967683\ttotal: 8.64s\tremaining: 3.53s\n",
      "355:\tlearn: 0.9967680\ttotal: 8.67s\tremaining: 3.51s\n",
      "356:\tlearn: 0.9968187\ttotal: 8.69s\tremaining: 3.48s\n",
      "357:\tlearn: 0.9969697\ttotal: 8.71s\tremaining: 3.46s\n",
      "358:\tlearn: 0.9968187\ttotal: 8.74s\tremaining: 3.43s\n",
      "359:\tlearn: 0.9969697\ttotal: 8.76s\tremaining: 3.41s\n",
      "360:\tlearn: 0.9972215\ttotal: 8.79s\tremaining: 3.38s\n",
      "361:\tlearn: 0.9972719\ttotal: 8.81s\tremaining: 3.36s\n",
      "362:\tlearn: 0.9970194\ttotal: 8.83s\tremaining: 3.33s\n",
      "363:\tlearn: 0.9970191\ttotal: 8.85s\tremaining: 3.31s\n",
      "364:\tlearn: 0.9972212\ttotal: 8.88s\tremaining: 3.28s\n",
      "365:\tlearn: 0.9972722\ttotal: 8.9s\tremaining: 3.26s\n",
      "366:\tlearn: 0.9974233\ttotal: 8.92s\tremaining: 3.23s\n",
      "367:\tlearn: 0.9975745\ttotal: 8.95s\tremaining: 3.21s\n",
      "368:\tlearn: 0.9975241\ttotal: 8.97s\tremaining: 3.19s\n",
      "369:\tlearn: 0.9976249\ttotal: 8.99s\tremaining: 3.16s\n",
      "370:\tlearn: 0.9976754\ttotal: 9.02s\tremaining: 3.13s\n",
      "371:\tlearn: 0.9977258\ttotal: 9.04s\tremaining: 3.11s\n",
      "372:\tlearn: 0.9977258\ttotal: 9.07s\tremaining: 3.09s\n",
      "373:\tlearn: 0.9977762\ttotal: 9.09s\tremaining: 3.06s\n",
      "374:\tlearn: 0.9979277\ttotal: 9.11s\tremaining: 3.04s\n",
      "375:\tlearn: 0.9977764\ttotal: 9.14s\tremaining: 3.01s\n",
      "376:\tlearn: 0.9976751\ttotal: 9.16s\tremaining: 2.99s\n",
      "377:\tlearn: 0.9976247\ttotal: 9.18s\tremaining: 2.96s\n",
      "378:\tlearn: 0.9978271\ttotal: 9.21s\tremaining: 2.94s\n",
      "379:\tlearn: 0.9979279\ttotal: 9.24s\tremaining: 2.92s\n",
      "380:\tlearn: 0.9979279\ttotal: 9.26s\tremaining: 2.89s\n",
      "381:\tlearn: 0.9980793\ttotal: 9.29s\tremaining: 2.87s\n",
      "382:\tlearn: 0.9981802\ttotal: 9.31s\tremaining: 2.84s\n",
      "383:\tlearn: 0.9982813\ttotal: 9.33s\tremaining: 2.82s\n",
      "384:\tlearn: 0.9982813\ttotal: 9.36s\tremaining: 2.79s\n",
      "385:\tlearn: 0.9983824\ttotal: 9.38s\tremaining: 2.77s\n",
      "386:\tlearn: 0.9984833\ttotal: 9.4s\tremaining: 2.75s\n",
      "387:\tlearn: 0.9982308\ttotal: 9.43s\tremaining: 2.72s\n",
      "388:\tlearn: 0.9984328\ttotal: 9.45s\tremaining: 2.7s\n",
      "389:\tlearn: 0.9985338\ttotal: 9.48s\tremaining: 2.67s\n",
      "390:\tlearn: 0.9985337\ttotal: 9.5s\tremaining: 2.65s\n",
      "391:\tlearn: 0.9985843\ttotal: 9.52s\tremaining: 2.62s\n",
      "392:\tlearn: 0.9987359\ttotal: 9.55s\tremaining: 2.6s\n",
      "393:\tlearn: 0.9987359\ttotal: 9.57s\tremaining: 2.57s\n",
      "394:\tlearn: 0.9987864\ttotal: 9.59s\tremaining: 2.55s\n",
      "395:\tlearn: 0.9987864\ttotal: 9.62s\tremaining: 2.52s\n",
      "396:\tlearn: 0.9988369\ttotal: 9.64s\tremaining: 2.5s\n",
      "397:\tlearn: 0.9986854\ttotal: 9.66s\tremaining: 2.48s\n",
      "398:\tlearn: 0.9987359\ttotal: 9.69s\tremaining: 2.45s\n",
      "399:\tlearn: 0.9986854\ttotal: 9.71s\tremaining: 2.43s\n",
      "400:\tlearn: 0.9986854\ttotal: 9.74s\tremaining: 2.4s\n",
      "401:\tlearn: 0.9986854\ttotal: 9.76s\tremaining: 2.38s\n",
      "402:\tlearn: 0.9986349\ttotal: 9.78s\tremaining: 2.35s\n",
      "403:\tlearn: 0.9986349\ttotal: 9.8s\tremaining: 2.33s\n",
      "404:\tlearn: 0.9986854\ttotal: 9.82s\tremaining: 2.3s\n",
      "405:\tlearn: 0.9987359\ttotal: 9.85s\tremaining: 2.28s\n",
      "406:\tlearn: 0.9987359\ttotal: 9.87s\tremaining: 2.25s\n",
      "407:\tlearn: 0.9988369\ttotal: 9.89s\tremaining: 2.23s\n",
      "408:\tlearn: 0.9988874\ttotal: 9.92s\tremaining: 2.21s\n",
      "409:\tlearn: 0.9987359\ttotal: 9.95s\tremaining: 2.18s\n",
      "410:\tlearn: 0.9989885\ttotal: 9.97s\tremaining: 2.16s\n",
      "411:\tlearn: 0.9988874\ttotal: 9.99s\tremaining: 2.13s\n",
      "412:\tlearn: 0.9989379\ttotal: 10s\tremaining: 2.11s\n",
      "413:\tlearn: 0.9990390\ttotal: 10s\tremaining: 2.09s\n",
      "414:\tlearn: 0.9990390\ttotal: 10.1s\tremaining: 2.06s\n",
      "415:\tlearn: 0.9990389\ttotal: 10.1s\tremaining: 2.04s\n",
      "416:\tlearn: 0.9989884\ttotal: 10.1s\tremaining: 2.01s\n",
      "417:\tlearn: 0.9990894\ttotal: 10.1s\tremaining: 1.99s\n",
      "418:\tlearn: 0.9990894\ttotal: 10.2s\tremaining: 1.97s\n",
      "419:\tlearn: 0.9991400\ttotal: 10.2s\tremaining: 1.94s\n",
      "420:\tlearn: 0.9991905\ttotal: 10.2s\tremaining: 1.92s\n",
      "421:\tlearn: 0.9992411\ttotal: 10.2s\tremaining: 1.89s\n",
      "422:\tlearn: 0.9993422\ttotal: 10.3s\tremaining: 1.87s\n",
      "423:\tlearn: 0.9993422\ttotal: 10.3s\tremaining: 1.84s\n",
      "424:\tlearn: 0.9993422\ttotal: 10.3s\tremaining: 1.82s\n",
      "425:\tlearn: 0.9994940\ttotal: 10.3s\tremaining: 1.79s\n",
      "426:\tlearn: 0.9994940\ttotal: 10.4s\tremaining: 1.77s\n",
      "427:\tlearn: 0.9994939\ttotal: 10.4s\tremaining: 1.75s\n",
      "428:\tlearn: 0.9995445\ttotal: 10.4s\tremaining: 1.72s\n",
      "429:\tlearn: 0.9995951\ttotal: 10.4s\tremaining: 1.7s\n",
      "430:\tlearn: 0.9995951\ttotal: 10.5s\tremaining: 1.67s\n",
      "431:\tlearn: 0.9995951\ttotal: 10.5s\tremaining: 1.65s\n",
      "432:\tlearn: 0.9995951\ttotal: 10.5s\tremaining: 1.63s\n",
      "433:\tlearn: 0.9995445\ttotal: 10.5s\tremaining: 1.6s\n",
      "434:\tlearn: 0.9995445\ttotal: 10.6s\tremaining: 1.58s\n",
      "435:\tlearn: 0.9995445\ttotal: 10.6s\tremaining: 1.55s\n",
      "436:\tlearn: 0.9995951\ttotal: 10.6s\tremaining: 1.53s\n",
      "437:\tlearn: 0.9995951\ttotal: 10.6s\tremaining: 1.5s\n",
      "438:\tlearn: 0.9994434\ttotal: 10.7s\tremaining: 1.48s\n",
      "439:\tlearn: 0.9994434\ttotal: 10.7s\tremaining: 1.46s\n",
      "440:\tlearn: 0.9994940\ttotal: 10.7s\tremaining: 1.43s\n",
      "441:\tlearn: 0.9995446\ttotal: 10.7s\tremaining: 1.41s\n",
      "442:\tlearn: 0.9995446\ttotal: 10.7s\tremaining: 1.38s\n",
      "443:\tlearn: 0.9994940\ttotal: 10.8s\tremaining: 1.36s\n",
      "444:\tlearn: 0.9995952\ttotal: 10.8s\tremaining: 1.33s\n",
      "445:\tlearn: 0.9996458\ttotal: 10.8s\tremaining: 1.31s\n",
      "446:\tlearn: 0.9996458\ttotal: 10.8s\tremaining: 1.28s\n",
      "447:\tlearn: 0.9995446\ttotal: 10.9s\tremaining: 1.26s\n",
      "448:\tlearn: 0.9996458\ttotal: 10.9s\tremaining: 1.24s\n",
      "449:\tlearn: 0.9995952\ttotal: 10.9s\tremaining: 1.21s\n",
      "450:\tlearn: 0.9995952\ttotal: 10.9s\tremaining: 1.19s\n",
      "451:\tlearn: 0.9996964\ttotal: 11s\tremaining: 1.16s\n",
      "452:\tlearn: 0.9996964\ttotal: 11s\tremaining: 1.14s\n",
      "453:\tlearn: 0.9996458\ttotal: 11s\tremaining: 1.11s\n",
      "454:\tlearn: 0.9996458\ttotal: 11s\tremaining: 1.09s\n",
      "455:\tlearn: 0.9996458\ttotal: 11.1s\tremaining: 1.07s\n",
      "456:\tlearn: 0.9996458\ttotal: 11.1s\tremaining: 1.04s\n",
      "457:\tlearn: 0.9996964\ttotal: 11.1s\tremaining: 1.02s\n",
      "458:\tlearn: 0.9996458\ttotal: 11.1s\tremaining: 994ms\n",
      "459:\tlearn: 0.9996964\ttotal: 11.1s\tremaining: 969ms\n",
      "460:\tlearn: 0.9996964\ttotal: 11.2s\tremaining: 945ms\n",
      "461:\tlearn: 0.9996964\ttotal: 11.2s\tremaining: 921ms\n",
      "462:\tlearn: 0.9997470\ttotal: 11.2s\tremaining: 897ms\n",
      "463:\tlearn: 0.9997470\ttotal: 11.2s\tremaining: 872ms\n",
      "464:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 848ms\n",
      "465:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 824ms\n",
      "466:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 799ms\n",
      "467:\tlearn: 0.9997470\ttotal: 11.3s\tremaining: 775ms\n",
      "468:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 750ms\n",
      "469:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 726ms\n",
      "470:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 702ms\n",
      "471:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 678ms\n",
      "472:\tlearn: 0.9997470\ttotal: 11.4s\tremaining: 654ms\n",
      "473:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 629ms\n",
      "474:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 605ms\n",
      "475:\tlearn: 0.9997470\ttotal: 11.5s\tremaining: 581ms\n",
      "476:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 557ms\n",
      "477:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 533ms\n",
      "478:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 508ms\n",
      "479:\tlearn: 0.9997470\ttotal: 11.6s\tremaining: 484ms\n",
      "480:\tlearn: 0.9997976\ttotal: 11.6s\tremaining: 460ms\n",
      "481:\tlearn: 0.9997976\ttotal: 11.7s\tremaining: 436ms\n",
      "482:\tlearn: 0.9997976\ttotal: 11.7s\tremaining: 412ms\n",
      "483:\tlearn: 0.9997976\ttotal: 11.7s\tremaining: 387ms\n",
      "484:\tlearn: 0.9997976\ttotal: 11.7s\tremaining: 363ms\n",
      "485:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 339ms\n",
      "486:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 315ms\n",
      "487:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 290ms\n",
      "488:\tlearn: 0.9997976\ttotal: 11.8s\tremaining: 266ms\n",
      "489:\tlearn: 0.9997976\ttotal: 11.9s\tremaining: 242ms\n",
      "490:\tlearn: 0.9997976\ttotal: 11.9s\tremaining: 218ms\n",
      "491:\tlearn: 0.9997976\ttotal: 11.9s\tremaining: 194ms\n",
      "492:\tlearn: 0.9997976\ttotal: 11.9s\tremaining: 169ms\n",
      "493:\tlearn: 0.9997976\ttotal: 12s\tremaining: 145ms\n",
      "494:\tlearn: 0.9997976\ttotal: 12s\tremaining: 121ms\n",
      "495:\tlearn: 0.9997976\ttotal: 12s\tremaining: 96.8ms\n",
      "496:\tlearn: 0.9997976\ttotal: 12s\tremaining: 72.6ms\n",
      "497:\tlearn: 0.9997976\ttotal: 12s\tremaining: 48.4ms\n",
      "498:\tlearn: 0.9997976\ttotal: 12.1s\tremaining: 24.2ms\n",
      "499:\tlearn: 0.9997975\ttotal: 12.1s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=32, depth=4, eval_metric=F1, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=0.1; total time=  12.5s\n",
      "0:\tlearn: 0.6679638\ttotal: 319ms\tremaining: 2m 39s\n",
      "1:\tlearn: 0.7066385\ttotal: 578ms\tremaining: 2m 23s\n",
      "2:\tlearn: 0.7402910\ttotal: 835ms\tremaining: 2m 18s\n",
      "3:\tlearn: 0.7584383\ttotal: 1.1s\tremaining: 2m 16s\n",
      "4:\tlearn: 0.7687812\ttotal: 1.35s\tremaining: 2m 14s\n",
      "5:\tlearn: 0.7839277\ttotal: 1.61s\tremaining: 2m 12s\n",
      "6:\tlearn: 0.7877425\ttotal: 1.86s\tremaining: 2m 10s\n",
      "7:\tlearn: 0.7991842\ttotal: 2.11s\tremaining: 2m 9s\n",
      "8:\tlearn: 0.8075330\ttotal: 2.36s\tremaining: 2m 8s\n",
      "9:\tlearn: 0.8119554\ttotal: 2.62s\tremaining: 2m 8s\n",
      "10:\tlearn: 0.8148562\ttotal: 2.87s\tremaining: 2m 7s\n",
      "11:\tlearn: 0.8229517\ttotal: 3.12s\tremaining: 2m 7s\n",
      "12:\tlearn: 0.8293666\ttotal: 3.39s\tremaining: 2m 6s\n",
      "13:\tlearn: 0.8371831\ttotal: 3.65s\tremaining: 2m 6s\n",
      "14:\tlearn: 0.8423131\ttotal: 3.92s\tremaining: 2m 6s\n",
      "15:\tlearn: 0.8451710\ttotal: 4.18s\tremaining: 2m 6s\n",
      "16:\tlearn: 0.8472300\ttotal: 4.43s\tremaining: 2m 5s\n",
      "17:\tlearn: 0.8483687\ttotal: 4.68s\tremaining: 2m 5s\n",
      "18:\tlearn: 0.8521821\ttotal: 4.94s\tremaining: 2m 5s\n",
      "19:\tlearn: 0.8548297\ttotal: 5.2s\tremaining: 2m 4s\n",
      "20:\tlearn: 0.8576642\ttotal: 5.45s\tremaining: 2m 4s\n",
      "21:\tlearn: 0.8588917\ttotal: 5.71s\tremaining: 2m 4s\n",
      "22:\tlearn: 0.8615026\ttotal: 5.97s\tremaining: 2m 3s\n",
      "23:\tlearn: 0.8638993\ttotal: 6.22s\tremaining: 2m 3s\n",
      "24:\tlearn: 0.8669344\ttotal: 6.47s\tremaining: 2m 2s\n",
      "25:\tlearn: 0.8689687\ttotal: 6.73s\tremaining: 2m 2s\n",
      "26:\tlearn: 0.8695328\ttotal: 6.97s\tremaining: 2m 2s\n",
      "27:\tlearn: 0.8720082\ttotal: 7.23s\tremaining: 2m 1s\n",
      "28:\tlearn: 0.8733894\ttotal: 7.49s\tremaining: 2m 1s\n",
      "29:\tlearn: 0.8737864\ttotal: 7.73s\tremaining: 2m 1s\n",
      "30:\tlearn: 0.8757816\ttotal: 7.98s\tremaining: 2m\n",
      "31:\tlearn: 0.8795057\ttotal: 8.24s\tremaining: 2m\n",
      "32:\tlearn: 0.8799325\ttotal: 8.49s\tremaining: 2m\n",
      "33:\tlearn: 0.8824081\ttotal: 8.75s\tremaining: 1m 59s\n",
      "34:\tlearn: 0.8843735\ttotal: 9.01s\tremaining: 1m 59s\n",
      "35:\tlearn: 0.8863401\ttotal: 9.26s\tremaining: 1m 59s\n",
      "36:\tlearn: 0.8890979\ttotal: 9.51s\tremaining: 1m 58s\n",
      "37:\tlearn: 0.8901832\ttotal: 9.76s\tremaining: 1m 58s\n",
      "38:\tlearn: 0.8907689\ttotal: 10s\tremaining: 1m 58s\n",
      "39:\tlearn: 0.8928168\ttotal: 10.3s\tremaining: 1m 58s\n",
      "40:\tlearn: 0.8924550\ttotal: 10.5s\tremaining: 1m 57s\n",
      "41:\tlearn: 0.8938910\ttotal: 10.8s\tremaining: 1m 57s\n",
      "42:\tlearn: 0.8953947\ttotal: 11s\tremaining: 1m 57s\n",
      "43:\tlearn: 0.8965128\ttotal: 11.3s\tremaining: 1m 56s\n",
      "44:\tlearn: 0.8962893\ttotal: 11.5s\tremaining: 1m 56s\n",
      "45:\tlearn: 0.8980610\ttotal: 11.8s\tremaining: 1m 56s\n",
      "46:\tlearn: 0.8986461\ttotal: 12s\tremaining: 1m 55s\n",
      "47:\tlearn: 0.8995678\ttotal: 12.3s\tremaining: 1m 55s\n",
      "48:\tlearn: 0.9018059\ttotal: 12.5s\tremaining: 1m 55s\n",
      "49:\tlearn: 0.9029373\ttotal: 12.8s\tremaining: 1m 55s\n",
      "50:\tlearn: 0.9046003\ttotal: 13s\tremaining: 1m 54s\n",
      "51:\tlearn: 0.9055786\ttotal: 13.3s\tremaining: 1m 54s\n",
      "52:\tlearn: 0.9067069\ttotal: 13.6s\tremaining: 1m 54s\n",
      "53:\tlearn: 0.9071718\ttotal: 13.8s\tremaining: 1m 54s\n",
      "54:\tlearn: 0.9075068\ttotal: 14.1s\tremaining: 1m 53s\n",
      "55:\tlearn: 0.9085515\ttotal: 14.3s\tremaining: 1m 53s\n",
      "56:\tlearn: 0.9095278\ttotal: 14.6s\tremaining: 1m 53s\n",
      "57:\tlearn: 0.9106335\ttotal: 14.8s\tremaining: 1m 52s\n",
      "58:\tlearn: 0.9115595\ttotal: 15.1s\tremaining: 1m 52s\n",
      "59:\tlearn: 0.9134870\ttotal: 15.3s\tremaining: 1m 52s\n",
      "60:\tlearn: 0.9138729\ttotal: 15.6s\tremaining: 1m 52s\n",
      "61:\tlearn: 0.9145097\ttotal: 15.8s\tremaining: 1m 51s\n",
      "62:\tlearn: 0.9162333\ttotal: 16.1s\tremaining: 1m 51s\n",
      "63:\tlearn: 0.9158402\ttotal: 16.3s\tremaining: 1m 51s\n",
      "64:\tlearn: 0.9171860\ttotal: 16.6s\tremaining: 1m 51s\n",
      "65:\tlearn: 0.9180452\ttotal: 16.9s\tremaining: 1m 50s\n",
      "66:\tlearn: 0.9186761\ttotal: 17.1s\tremaining: 1m 50s\n",
      "67:\tlearn: 0.9194434\ttotal: 17.4s\tremaining: 1m 50s\n",
      "68:\tlearn: 0.9211524\ttotal: 17.6s\tremaining: 1m 49s\n",
      "69:\tlearn: 0.9225806\ttotal: 17.9s\tremaining: 1m 49s\n",
      "70:\tlearn: 0.9230623\ttotal: 18.1s\tremaining: 1m 49s\n",
      "71:\tlearn: 0.9238068\ttotal: 18.4s\tremaining: 1m 49s\n",
      "72:\tlearn: 0.9245516\ttotal: 18.6s\tremaining: 1m 48s\n",
      "73:\tlearn: 0.9258555\ttotal: 18.9s\tremaining: 1m 48s\n",
      "74:\tlearn: 0.9260667\ttotal: 19.1s\tremaining: 1m 48s\n",
      "75:\tlearn: 0.9262848\ttotal: 19.4s\tremaining: 1m 48s\n",
      "76:\tlearn: 0.9264776\ttotal: 19.7s\tremaining: 1m 47s\n",
      "77:\tlearn: 0.9282183\ttotal: 19.9s\tremaining: 1m 47s\n",
      "78:\tlearn: 0.9292035\ttotal: 20.2s\tremaining: 1m 47s\n",
      "79:\tlearn: 0.9295708\ttotal: 20.4s\tremaining: 1m 47s\n",
      "80:\tlearn: 0.9298012\ttotal: 20.7s\tremaining: 1m 46s\n",
      "81:\tlearn: 0.9325575\ttotal: 20.9s\tremaining: 1m 46s\n",
      "82:\tlearn: 0.9325200\ttotal: 21.2s\tremaining: 1m 46s\n",
      "83:\tlearn: 0.9341477\ttotal: 21.4s\tremaining: 1m 46s\n",
      "84:\tlearn: 0.9350587\ttotal: 21.7s\tremaining: 1m 45s\n",
      "85:\tlearn: 0.9355670\ttotal: 21.9s\tremaining: 1m 45s\n",
      "86:\tlearn: 0.9352408\ttotal: 22.2s\tremaining: 1m 45s\n",
      "87:\tlearn: 0.9362230\ttotal: 22.4s\tremaining: 1m 45s\n",
      "88:\tlearn: 0.9368431\ttotal: 22.7s\tremaining: 1m 44s\n",
      "89:\tlearn: 0.9375896\ttotal: 22.9s\tremaining: 1m 44s\n",
      "90:\tlearn: 0.9376852\ttotal: 23.2s\tremaining: 1m 44s\n",
      "91:\tlearn: 0.9390489\ttotal: 23.4s\tremaining: 1m 43s\n",
      "92:\tlearn: 0.9396898\ttotal: 23.7s\tremaining: 1m 43s\n",
      "93:\tlearn: 0.9410524\ttotal: 23.9s\tremaining: 1m 43s\n",
      "94:\tlearn: 0.9417969\ttotal: 24.2s\tremaining: 1m 43s\n",
      "95:\tlearn: 0.9421527\ttotal: 24.4s\tremaining: 1m 42s\n",
      "96:\tlearn: 0.9446207\ttotal: 24.7s\tremaining: 1m 42s\n",
      "97:\tlearn: 0.9450000\ttotal: 25s\tremaining: 1m 42s\n",
      "98:\tlearn: 0.9460916\ttotal: 25.2s\tremaining: 1m 42s\n",
      "99:\tlearn: 0.9472062\ttotal: 25.5s\tremaining: 1m 41s\n",
      "100:\tlearn: 0.9472214\ttotal: 25.7s\tremaining: 1m 41s\n",
      "101:\tlearn: 0.9483274\ttotal: 26s\tremaining: 1m 41s\n",
      "102:\tlearn: 0.9500676\ttotal: 26.3s\tremaining: 1m 41s\n",
      "103:\tlearn: 0.9507927\ttotal: 26.5s\tremaining: 1m 40s\n",
      "104:\tlearn: 0.9507151\ttotal: 26.8s\tremaining: 1m 40s\n",
      "105:\tlearn: 0.9523026\ttotal: 27s\tremaining: 1m 40s\n",
      "106:\tlearn: 0.9523856\ttotal: 27.3s\tremaining: 1m 40s\n",
      "107:\tlearn: 0.9530357\ttotal: 27.5s\tremaining: 1m 39s\n",
      "108:\tlearn: 0.9539907\ttotal: 27.8s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.9544485\ttotal: 28.1s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.9545455\ttotal: 28.3s\tremaining: 1m 39s\n",
      "111:\tlearn: 0.9549113\ttotal: 28.6s\tremaining: 1m 38s\n",
      "112:\tlearn: 0.9554931\ttotal: 28.8s\tremaining: 1m 38s\n",
      "113:\tlearn: 0.9572483\ttotal: 29.1s\tremaining: 1m 38s\n",
      "114:\tlearn: 0.9587468\ttotal: 29.4s\tremaining: 1m 38s\n",
      "115:\tlearn: 0.9600585\ttotal: 29.6s\tremaining: 1m 38s\n",
      "116:\tlearn: 0.9611897\ttotal: 29.9s\tremaining: 1m 37s\n",
      "117:\tlearn: 0.9614747\ttotal: 30.1s\tremaining: 1m 37s\n",
      "118:\tlearn: 0.9626013\ttotal: 30.4s\tremaining: 1m 37s\n",
      "119:\tlearn: 0.9659024\ttotal: 30.6s\tremaining: 1m 37s\n",
      "120:\tlearn: 0.9661897\ttotal: 30.9s\tremaining: 1m 36s\n",
      "121:\tlearn: 0.9669478\ttotal: 31.2s\tremaining: 1m 36s\n",
      "122:\tlearn: 0.9677039\ttotal: 31.4s\tremaining: 1m 36s\n",
      "123:\tlearn: 0.9684645\ttotal: 31.7s\tremaining: 1m 36s\n",
      "124:\tlearn: 0.9687531\ttotal: 31.9s\tremaining: 1m 35s\n",
      "125:\tlearn: 0.9696105\ttotal: 32.2s\tremaining: 1m 35s\n",
      "126:\tlearn: 0.9703769\ttotal: 32.5s\tremaining: 1m 35s\n",
      "127:\tlearn: 0.9722962\ttotal: 32.7s\tremaining: 1m 35s\n",
      "128:\tlearn: 0.9734531\ttotal: 33s\tremaining: 1m 34s\n",
      "129:\tlearn: 0.9734583\ttotal: 33.2s\tremaining: 1m 34s\n",
      "130:\tlearn: 0.9748049\ttotal: 33.5s\tremaining: 1m 34s\n",
      "131:\tlearn: 0.9754820\ttotal: 33.7s\tremaining: 1m 34s\n",
      "132:\tlearn: 0.9750964\ttotal: 34s\tremaining: 1m 33s\n",
      "133:\tlearn: 0.9752916\ttotal: 34.2s\tremaining: 1m 33s\n",
      "134:\tlearn: 0.9760633\ttotal: 34.5s\tremaining: 1m 33s\n",
      "135:\tlearn: 0.9758750\ttotal: 34.7s\tremaining: 1m 32s\n",
      "136:\tlearn: 0.9765486\ttotal: 35s\tremaining: 1m 32s\n",
      "137:\tlearn: 0.9770365\ttotal: 35.2s\tremaining: 1m 32s\n",
      "138:\tlearn: 0.9787846\ttotal: 35.5s\tremaining: 1m 32s\n",
      "139:\tlearn: 0.9782996\ttotal: 35.7s\tremaining: 1m 31s\n",
      "140:\tlearn: 0.9797539\ttotal: 36s\tremaining: 1m 31s\n",
      "141:\tlearn: 0.9804369\ttotal: 36.3s\tremaining: 1m 31s\n",
      "142:\tlearn: 0.9810215\ttotal: 36.5s\tremaining: 1m 31s\n",
      "143:\tlearn: 0.9816067\ttotal: 36.8s\tremaining: 1m 30s\n",
      "144:\tlearn: 0.9825836\ttotal: 37s\tremaining: 1m 30s\n",
      "145:\tlearn: 0.9832703\ttotal: 37.3s\tremaining: 1m 30s\n",
      "146:\tlearn: 0.9834661\ttotal: 37.5s\tremaining: 1m 30s\n",
      "147:\tlearn: 0.9846445\ttotal: 37.8s\tremaining: 1m 29s\n",
      "148:\tlearn: 0.9852340\ttotal: 38s\tremaining: 1m 29s\n",
      "149:\tlearn: 0.9858227\ttotal: 38.3s\tremaining: 1m 29s\n",
      "150:\tlearn: 0.9860210\ttotal: 38.5s\tremaining: 1m 29s\n",
      "151:\tlearn: 0.9873025\ttotal: 38.8s\tremaining: 1m 28s\n",
      "152:\tlearn: 0.9873025\ttotal: 39s\tremaining: 1m 28s\n",
      "153:\tlearn: 0.9875000\ttotal: 39.3s\tremaining: 1m 28s\n",
      "154:\tlearn: 0.9880940\ttotal: 39.5s\tremaining: 1m 28s\n",
      "155:\tlearn: 0.9890847\ttotal: 39.8s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.9891838\ttotal: 40.1s\tremaining: 1m 27s\n",
      "157:\tlearn: 0.9896794\ttotal: 40.3s\tremaining: 1m 27s\n",
      "158:\tlearn: 0.9901754\ttotal: 40.6s\tremaining: 1m 26s\n",
      "159:\tlearn: 0.9901754\ttotal: 40.8s\tremaining: 1m 26s\n",
      "160:\tlearn: 0.9901754\ttotal: 41.1s\tremaining: 1m 26s\n",
      "161:\tlearn: 0.9905727\ttotal: 41.3s\tremaining: 1m 26s\n",
      "162:\tlearn: 0.9908708\ttotal: 41.6s\tremaining: 1m 25s\n",
      "163:\tlearn: 0.9913681\ttotal: 41.8s\tremaining: 1m 25s\n",
      "164:\tlearn: 0.9915680\ttotal: 42.1s\tremaining: 1m 25s\n",
      "165:\tlearn: 0.9918667\ttotal: 42.3s\tremaining: 1m 25s\n",
      "166:\tlearn: 0.9923649\ttotal: 42.6s\tremaining: 1m 24s\n",
      "167:\tlearn: 0.9928629\ttotal: 42.8s\tremaining: 1m 24s\n",
      "168:\tlearn: 0.9932623\ttotal: 43.1s\tremaining: 1m 24s\n",
      "169:\tlearn: 0.9931624\ttotal: 43.4s\tremaining: 1m 24s\n",
      "170:\tlearn: 0.9935620\ttotal: 43.6s\tremaining: 1m 23s\n",
      "171:\tlearn: 0.9937619\ttotal: 43.9s\tremaining: 1m 23s\n",
      "172:\tlearn: 0.9937619\ttotal: 44.1s\tremaining: 1m 23s\n",
      "173:\tlearn: 0.9938619\ttotal: 44.4s\tremaining: 1m 23s\n",
      "174:\tlearn: 0.9939620\ttotal: 44.7s\tremaining: 1m 22s\n",
      "175:\tlearn: 0.9941621\ttotal: 44.9s\tremaining: 1m 22s\n",
      "176:\tlearn: 0.9944623\ttotal: 45.2s\tremaining: 1m 22s\n",
      "177:\tlearn: 0.9948630\ttotal: 45.4s\tremaining: 1m 22s\n",
      "178:\tlearn: 0.9946626\ttotal: 45.7s\tremaining: 1m 21s\n",
      "179:\tlearn: 0.9949632\ttotal: 46s\tremaining: 1m 21s\n",
      "180:\tlearn: 0.9953643\ttotal: 46.2s\tremaining: 1m 21s\n",
      "181:\tlearn: 0.9953643\ttotal: 46.5s\tremaining: 1m 21s\n",
      "182:\tlearn: 0.9953643\ttotal: 46.7s\tremaining: 1m 20s\n",
      "183:\tlearn: 0.9954646\ttotal: 47s\tremaining: 1m 20s\n",
      "184:\tlearn: 0.9954646\ttotal: 47.3s\tremaining: 1m 20s\n",
      "185:\tlearn: 0.9955650\ttotal: 47.5s\tremaining: 1m 20s\n",
      "186:\tlearn: 0.9957657\ttotal: 47.8s\tremaining: 1m 19s\n",
      "187:\tlearn: 0.9957657\ttotal: 48s\tremaining: 1m 19s\n",
      "188:\tlearn: 0.9957653\ttotal: 48.3s\tremaining: 1m 19s\n",
      "189:\tlearn: 0.9957657\ttotal: 48.6s\tremaining: 1m 19s\n",
      "190:\tlearn: 0.9958661\ttotal: 48.8s\tremaining: 1m 18s\n",
      "191:\tlearn: 0.9959669\ttotal: 49.1s\tremaining: 1m 18s\n",
      "192:\tlearn: 0.9960674\ttotal: 49.3s\tremaining: 1m 18s\n",
      "193:\tlearn: 0.9963688\ttotal: 49.6s\tremaining: 1m 18s\n",
      "194:\tlearn: 0.9966704\ttotal: 49.8s\tremaining: 1m 17s\n",
      "195:\tlearn: 0.9965698\ttotal: 50.1s\tremaining: 1m 17s\n",
      "196:\tlearn: 0.9966704\ttotal: 50.4s\tremaining: 1m 17s\n",
      "197:\tlearn: 0.9968715\ttotal: 50.6s\tremaining: 1m 17s\n",
      "198:\tlearn: 0.9967709\ttotal: 50.9s\tremaining: 1m 16s\n",
      "199:\tlearn: 0.9967709\ttotal: 51.1s\tremaining: 1m 16s\n",
      "200:\tlearn: 0.9968715\ttotal: 51.4s\tremaining: 1m 16s\n",
      "201:\tlearn: 0.9967709\ttotal: 51.6s\tremaining: 1m 16s\n",
      "202:\tlearn: 0.9969721\ttotal: 51.9s\tremaining: 1m 15s\n",
      "203:\tlearn: 0.9970725\ttotal: 52.1s\tremaining: 1m 15s\n",
      "204:\tlearn: 0.9970725\ttotal: 52.4s\tremaining: 1m 15s\n",
      "205:\tlearn: 0.9973745\ttotal: 52.6s\tremaining: 1m 15s\n",
      "206:\tlearn: 0.9972738\ttotal: 52.9s\tremaining: 1m 14s\n",
      "207:\tlearn: 0.9973745\ttotal: 53.1s\tremaining: 1m 14s\n",
      "208:\tlearn: 0.9973745\ttotal: 53.4s\tremaining: 1m 14s\n",
      "209:\tlearn: 0.9972738\ttotal: 53.6s\tremaining: 1m 14s\n",
      "210:\tlearn: 0.9973745\ttotal: 53.9s\tremaining: 1m 13s\n",
      "211:\tlearn: 0.9972741\ttotal: 54.1s\tremaining: 1m 13s\n",
      "212:\tlearn: 0.9973748\ttotal: 54.4s\tremaining: 1m 13s\n",
      "213:\tlearn: 0.9977778\ttotal: 54.7s\tremaining: 1m 13s\n",
      "214:\tlearn: 0.9977778\ttotal: 54.9s\tremaining: 1m 12s\n",
      "215:\tlearn: 0.9976770\ttotal: 55.2s\tremaining: 1m 12s\n",
      "216:\tlearn: 0.9976770\ttotal: 55.4s\tremaining: 1m 12s\n",
      "217:\tlearn: 0.9976770\ttotal: 55.7s\tremaining: 1m 12s\n",
      "218:\tlearn: 0.9976770\ttotal: 55.9s\tremaining: 1m 11s\n",
      "219:\tlearn: 0.9976770\ttotal: 56.2s\tremaining: 1m 11s\n",
      "220:\tlearn: 0.9976770\ttotal: 56.4s\tremaining: 1m 11s\n",
      "221:\tlearn: 0.9976770\ttotal: 56.7s\tremaining: 1m 10s\n",
      "222:\tlearn: 0.9978786\ttotal: 56.9s\tremaining: 1m 10s\n",
      "223:\tlearn: 0.9979794\ttotal: 57.2s\tremaining: 1m 10s\n",
      "224:\tlearn: 0.9980802\ttotal: 57.4s\tremaining: 1m 10s\n",
      "225:\tlearn: 0.9981811\ttotal: 57.7s\tremaining: 1m 9s\n",
      "226:\tlearn: 0.9981811\ttotal: 57.9s\tremaining: 1m 9s\n",
      "227:\tlearn: 0.9981811\ttotal: 58.2s\tremaining: 1m 9s\n",
      "228:\tlearn: 0.9982820\ttotal: 58.4s\tremaining: 1m 9s\n",
      "229:\tlearn: 0.9982820\ttotal: 58.7s\tremaining: 1m 8s\n",
      "230:\tlearn: 0.9983829\ttotal: 58.9s\tremaining: 1m 8s\n",
      "231:\tlearn: 0.9984838\ttotal: 59.2s\tremaining: 1m 8s\n",
      "232:\tlearn: 0.9984838\ttotal: 59.5s\tremaining: 1m 8s\n",
      "233:\tlearn: 0.9986857\ttotal: 59.7s\tremaining: 1m 7s\n",
      "234:\tlearn: 0.9986857\ttotal: 60s\tremaining: 1m 7s\n",
      "235:\tlearn: 0.9986857\ttotal: 1m\tremaining: 1m 7s\n",
      "236:\tlearn: 0.9983829\ttotal: 1m\tremaining: 1m 7s\n",
      "237:\tlearn: 0.9984838\ttotal: 1m\tremaining: 1m 6s\n",
      "238:\tlearn: 0.9985847\ttotal: 1m\tremaining: 1m 6s\n",
      "239:\tlearn: 0.9986857\ttotal: 1m 1s\tremaining: 1m 6s\n",
      "240:\tlearn: 0.9988877\ttotal: 1m 1s\tremaining: 1m 6s\n",
      "241:\tlearn: 0.9988877\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "242:\tlearn: 0.9988877\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "243:\tlearn: 0.9990897\ttotal: 1m 2s\tremaining: 1m 5s\n",
      "244:\tlearn: 0.9990897\ttotal: 1m 2s\tremaining: 1m 5s\n",
      "245:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "246:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "247:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 4s\n",
      "248:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "249:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "250:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "251:\tlearn: 0.9991908\ttotal: 1m 4s\tremaining: 1m 3s\n",
      "252:\tlearn: 0.9991908\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "253:\tlearn: 0.9991908\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "254:\tlearn: 0.9992919\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "255:\tlearn: 0.9992919\ttotal: 1m 5s\tremaining: 1m 2s\n",
      "256:\tlearn: 0.9992919\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "257:\tlearn: 0.9992919\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "258:\tlearn: 0.9992919\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "259:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 1s\n",
      "260:\tlearn: 0.9991908\ttotal: 1m 6s\tremaining: 1m\n",
      "261:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m\n",
      "262:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m\n",
      "263:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m\n",
      "264:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 59.8s\n",
      "265:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 59.6s\n",
      "266:\tlearn: 0.9993930\ttotal: 1m 7s\tremaining: 59.3s\n",
      "267:\tlearn: 0.9993930\ttotal: 1m 8s\tremaining: 59.1s\n",
      "268:\tlearn: 0.9994941\ttotal: 1m 8s\tremaining: 58.8s\n",
      "269:\tlearn: 0.9993930\ttotal: 1m 8s\tremaining: 58.5s\n",
      "270:\tlearn: 0.9993930\ttotal: 1m 8s\tremaining: 58.3s\n",
      "271:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 58s\n",
      "272:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 57.8s\n",
      "273:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 57.5s\n",
      "274:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 57.2s\n",
      "275:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 57s\n",
      "276:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 56.7s\n",
      "277:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.5s\n",
      "278:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.2s\n",
      "279:\tlearn: 0.9994941\ttotal: 1m 11s\tremaining: 56s\n",
      "280:\tlearn: 0.9994941\ttotal: 1m 11s\tremaining: 55.7s\n",
      "281:\tlearn: 0.9995952\ttotal: 1m 11s\tremaining: 55.5s\n",
      "282:\tlearn: 0.9995952\ttotal: 1m 11s\tremaining: 55.2s\n",
      "283:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 54.9s\n",
      "284:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 54.7s\n",
      "285:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 54.4s\n",
      "286:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 54.2s\n",
      "287:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 53.9s\n",
      "288:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 53.7s\n",
      "289:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 53.4s\n",
      "290:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 53.2s\n",
      "291:\tlearn: 0.9997976\ttotal: 1m 14s\tremaining: 52.9s\n",
      "292:\tlearn: 0.9997976\ttotal: 1m 14s\tremaining: 52.6s\n",
      "293:\tlearn: 0.9997976\ttotal: 1m 14s\tremaining: 52.4s\n",
      "294:\tlearn: 0.9997976\ttotal: 1m 15s\tremaining: 52.1s\n",
      "295:\tlearn: 0.9997976\ttotal: 1m 15s\tremaining: 51.9s\n",
      "296:\tlearn: 0.9997976\ttotal: 1m 15s\tremaining: 51.6s\n",
      "297:\tlearn: 0.9997976\ttotal: 1m 15s\tremaining: 51.4s\n",
      "298:\tlearn: 0.9997976\ttotal: 1m 16s\tremaining: 51.1s\n",
      "299:\tlearn: 0.9997976\ttotal: 1m 16s\tremaining: 50.9s\n",
      "300:\tlearn: 0.9997976\ttotal: 1m 16s\tremaining: 50.6s\n",
      "301:\tlearn: 0.9997976\ttotal: 1m 16s\tremaining: 50.4s\n",
      "302:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 50.1s\n",
      "303:\tlearn: 0.9998988\ttotal: 1m 17s\tremaining: 49.9s\n",
      "304:\tlearn: 0.9998988\ttotal: 1m 17s\tremaining: 49.6s\n",
      "305:\tlearn: 0.9998988\ttotal: 1m 17s\tremaining: 49.3s\n",
      "306:\tlearn: 0.9998988\ttotal: 1m 18s\tremaining: 49.1s\n",
      "307:\tlearn: 0.9998988\ttotal: 1m 18s\tremaining: 48.8s\n",
      "308:\tlearn: 0.9998988\ttotal: 1m 18s\tremaining: 48.6s\n",
      "309:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 48.3s\n",
      "310:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 48.1s\n",
      "311:\tlearn: 0.9998988\ttotal: 1m 19s\tremaining: 47.8s\n",
      "312:\tlearn: 0.9998988\ttotal: 1m 19s\tremaining: 47.6s\n",
      "313:\tlearn: 0.9998988\ttotal: 1m 19s\tremaining: 47.3s\n",
      "314:\tlearn: 0.9998988\ttotal: 1m 20s\tremaining: 47s\n",
      "315:\tlearn: 0.9998988\ttotal: 1m 20s\tremaining: 46.8s\n",
      "316:\tlearn: 0.9998988\ttotal: 1m 20s\tremaining: 46.5s\n",
      "317:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 46.3s\n",
      "318:\tlearn: 0.9998988\ttotal: 1m 21s\tremaining: 46s\n",
      "319:\tlearn: 0.9998988\ttotal: 1m 21s\tremaining: 45.8s\n",
      "320:\tlearn: 0.9998988\ttotal: 1m 21s\tremaining: 45.5s\n",
      "321:\tlearn: 0.9998988\ttotal: 1m 21s\tremaining: 45.3s\n",
      "322:\tlearn: 0.9998988\ttotal: 1m 22s\tremaining: 45s\n",
      "323:\tlearn: 0.9998988\ttotal: 1m 22s\tremaining: 44.7s\n",
      "324:\tlearn: 0.9998988\ttotal: 1m 22s\tremaining: 44.5s\n",
      "325:\tlearn: 0.9998988\ttotal: 1m 22s\tremaining: 44.2s\n",
      "326:\tlearn: 0.9998988\ttotal: 1m 23s\tremaining: 44s\n",
      "327:\tlearn: 0.9998988\ttotal: 1m 23s\tremaining: 43.7s\n",
      "328:\tlearn: 0.9998988\ttotal: 1m 23s\tremaining: 43.5s\n",
      "329:\tlearn: 0.9998988\ttotal: 1m 23s\tremaining: 43.2s\n",
      "330:\tlearn: 0.9998988\ttotal: 1m 24s\tremaining: 43s\n",
      "331:\tlearn: 0.9998988\ttotal: 1m 24s\tremaining: 42.7s\n",
      "332:\tlearn: 0.9998988\ttotal: 1m 24s\tremaining: 42.5s\n",
      "333:\tlearn: 0.9998988\ttotal: 1m 24s\tremaining: 42.2s\n",
      "334:\tlearn: 0.9998988\ttotal: 1m 25s\tremaining: 42s\n",
      "335:\tlearn: 0.9998988\ttotal: 1m 25s\tremaining: 41.7s\n",
      "336:\tlearn: 0.9998988\ttotal: 1m 25s\tremaining: 41.4s\n",
      "337:\tlearn: 0.9998988\ttotal: 1m 25s\tremaining: 41.2s\n",
      "338:\tlearn: 0.9998988\ttotal: 1m 26s\tremaining: 40.9s\n",
      "339:\tlearn: 0.9998988\ttotal: 1m 26s\tremaining: 40.7s\n",
      "340:\tlearn: 0.9998988\ttotal: 1m 26s\tremaining: 40.4s\n",
      "341:\tlearn: 0.9998988\ttotal: 1m 26s\tremaining: 40.2s\n",
      "342:\tlearn: 0.9998988\ttotal: 1m 27s\tremaining: 39.9s\n",
      "343:\tlearn: 0.9998988\ttotal: 1m 27s\tremaining: 39.7s\n",
      "344:\tlearn: 0.9998988\ttotal: 1m 27s\tremaining: 39.4s\n",
      "345:\tlearn: 0.9998988\ttotal: 1m 27s\tremaining: 39.1s\n",
      "346:\tlearn: 0.9998988\ttotal: 1m 28s\tremaining: 38.9s\n",
      "347:\tlearn: 0.9998988\ttotal: 1m 28s\tremaining: 38.6s\n",
      "348:\tlearn: 0.9998988\ttotal: 1m 28s\tremaining: 38.4s\n",
      "349:\tlearn: 1.0000000\ttotal: 1m 28s\tremaining: 38.1s\n",
      "350:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.9s\n",
      "351:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.6s\n",
      "352:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.4s\n",
      "353:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.1s\n",
      "354:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 36.9s\n",
      "355:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 36.6s\n",
      "356:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 36.4s\n",
      "357:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 36.1s\n",
      "358:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.8s\n",
      "359:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.6s\n",
      "360:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.3s\n",
      "361:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.1s\n",
      "362:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 34.8s\n",
      "363:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 34.6s\n",
      "364:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 34.3s\n",
      "365:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 34.1s\n",
      "366:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 33.8s\n",
      "367:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 33.5s\n",
      "368:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 33.3s\n",
      "369:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 33s\n",
      "370:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 32.8s\n",
      "371:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 32.5s\n",
      "372:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 32.3s\n",
      "373:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 32s\n",
      "374:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 31.8s\n",
      "375:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 31.5s\n",
      "376:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 31.3s\n",
      "377:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 31s\n",
      "378:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 30.8s\n",
      "379:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 30.5s\n",
      "380:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 30.3s\n",
      "381:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 30s\n",
      "382:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.8s\n",
      "383:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.5s\n",
      "384:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.3s\n",
      "385:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 29s\n",
      "386:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.7s\n",
      "387:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.5s\n",
      "388:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.2s\n",
      "389:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 28s\n",
      "390:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.7s\n",
      "391:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.5s\n",
      "392:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.2s\n",
      "393:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 27s\n",
      "394:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 26.7s\n",
      "395:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 26.4s\n",
      "396:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 26.2s\n",
      "397:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.9s\n",
      "398:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.7s\n",
      "399:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.4s\n",
      "400:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.2s\n",
      "401:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.9s\n",
      "402:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.7s\n",
      "403:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.4s\n",
      "404:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.2s\n",
      "405:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.9s\n",
      "406:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.6s\n",
      "407:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.4s\n",
      "408:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.1s\n",
      "409:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.9s\n",
      "410:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.6s\n",
      "411:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.4s\n",
      "412:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 22.1s\n",
      "413:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.9s\n",
      "414:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.6s\n",
      "415:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.4s\n",
      "416:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 21.1s\n",
      "417:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.8s\n",
      "418:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.6s\n",
      "419:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.3s\n",
      "420:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 20.1s\n",
      "421:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.8s\n",
      "422:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.6s\n",
      "423:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.3s\n",
      "424:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 19.1s\n",
      "425:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.8s\n",
      "426:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.6s\n",
      "427:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.3s\n",
      "428:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 18s\n",
      "429:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.8s\n",
      "430:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.5s\n",
      "431:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.3s\n",
      "432:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 17s\n",
      "433:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.8s\n",
      "434:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.5s\n",
      "435:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.3s\n",
      "436:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 16s\n",
      "437:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.8s\n",
      "438:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.5s\n",
      "439:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.2s\n",
      "440:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 15s\n",
      "441:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.7s\n",
      "442:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.5s\n",
      "443:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.2s\n",
      "444:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 14s\n",
      "445:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.7s\n",
      "446:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.5s\n",
      "447:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.2s\n",
      "448:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 13s\n",
      "449:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.7s\n",
      "450:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.5s\n",
      "451:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.2s\n",
      "452:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.9s\n",
      "453:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.7s\n",
      "454:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.4s\n",
      "455:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.2s\n",
      "456:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.9s\n",
      "457:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.7s\n",
      "458:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.4s\n",
      "459:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.2s\n",
      "460:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.91s\n",
      "461:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.66s\n",
      "462:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.4s\n",
      "463:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.15s\n",
      "464:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.89s\n",
      "465:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.64s\n",
      "466:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.38s\n",
      "467:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.13s\n",
      "468:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.88s\n",
      "469:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.62s\n",
      "470:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.37s\n",
      "471:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.11s\n",
      "472:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.86s\n",
      "473:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.61s\n",
      "474:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.35s\n",
      "475:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.1s\n",
      "476:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.84s\n",
      "477:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.59s\n",
      "478:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.33s\n",
      "479:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.08s\n",
      "480:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.83s\n",
      "481:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.57s\n",
      "482:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.32s\n",
      "483:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.07s\n",
      "484:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.81s\n",
      "485:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.56s\n",
      "486:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.3s\n",
      "487:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.05s\n",
      "488:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.79s\n",
      "489:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.54s\n",
      "490:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.29s\n",
      "491:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.03s\n",
      "492:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.78s\n",
      "493:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.52s\n",
      "494:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.27s\n",
      "495:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.02s\n",
      "496:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 762ms\n",
      "497:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 508ms\n",
      "498:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 254ms\n",
      "499:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=96, depth=9, eval_metric=Precision, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=1; total time= 2.1min\n",
      "0:\tlearn: 0.6595549\ttotal: 266ms\tremaining: 2m 12s\n",
      "1:\tlearn: 0.6759806\ttotal: 526ms\tremaining: 2m 10s\n",
      "2:\tlearn: 0.7185602\ttotal: 778ms\tremaining: 2m 8s\n",
      "3:\tlearn: 0.7621875\ttotal: 1.03s\tremaining: 2m 7s\n",
      "4:\tlearn: 0.7661223\ttotal: 1.28s\tremaining: 2m 6s\n",
      "5:\tlearn: 0.7858567\ttotal: 1.54s\tremaining: 2m 6s\n",
      "6:\tlearn: 0.7947985\ttotal: 1.79s\tremaining: 2m 6s\n",
      "7:\tlearn: 0.8011774\ttotal: 2.05s\tremaining: 2m 6s\n",
      "8:\tlearn: 0.8061147\ttotal: 2.3s\tremaining: 2m 5s\n",
      "9:\tlearn: 0.8114940\ttotal: 2.55s\tremaining: 2m 4s\n",
      "10:\tlearn: 0.8112446\ttotal: 2.8s\tremaining: 2m 4s\n",
      "11:\tlearn: 0.8156712\ttotal: 3.06s\tremaining: 2m 4s\n",
      "12:\tlearn: 0.8178508\ttotal: 3.31s\tremaining: 2m 4s\n",
      "13:\tlearn: 0.8242180\ttotal: 3.58s\tremaining: 2m 4s\n",
      "14:\tlearn: 0.8262573\ttotal: 3.82s\tremaining: 2m 3s\n",
      "15:\tlearn: 0.8329449\ttotal: 4.07s\tremaining: 2m 3s\n",
      "16:\tlearn: 0.8360350\ttotal: 4.33s\tremaining: 2m 3s\n",
      "17:\tlearn: 0.8387757\ttotal: 4.59s\tremaining: 2m 2s\n",
      "18:\tlearn: 0.8411825\ttotal: 4.84s\tremaining: 2m 2s\n",
      "19:\tlearn: 0.8428265\ttotal: 5.09s\tremaining: 2m 2s\n",
      "20:\tlearn: 0.8457526\ttotal: 5.35s\tremaining: 2m 2s\n",
      "21:\tlearn: 0.8499580\ttotal: 5.6s\tremaining: 2m 1s\n",
      "22:\tlearn: 0.8530566\ttotal: 5.86s\tremaining: 2m 1s\n",
      "23:\tlearn: 0.8556230\ttotal: 6.12s\tremaining: 2m 1s\n",
      "24:\tlearn: 0.8598768\ttotal: 6.38s\tremaining: 2m 1s\n",
      "25:\tlearn: 0.8613751\ttotal: 6.64s\tremaining: 2m 1s\n",
      "26:\tlearn: 0.8628784\ttotal: 6.89s\tremaining: 2m\n",
      "27:\tlearn: 0.8645173\ttotal: 7.15s\tremaining: 2m\n",
      "28:\tlearn: 0.8657912\ttotal: 7.4s\tremaining: 2m\n",
      "29:\tlearn: 0.8680982\ttotal: 7.65s\tremaining: 1m 59s\n",
      "30:\tlearn: 0.8704788\ttotal: 7.91s\tremaining: 1m 59s\n",
      "31:\tlearn: 0.8738831\ttotal: 8.17s\tremaining: 1m 59s\n",
      "32:\tlearn: 0.8744883\ttotal: 8.42s\tremaining: 1m 59s\n",
      "33:\tlearn: 0.8775852\ttotal: 8.67s\tremaining: 1m 58s\n",
      "34:\tlearn: 0.8799553\ttotal: 8.92s\tremaining: 1m 58s\n",
      "35:\tlearn: 0.8801118\ttotal: 9.18s\tremaining: 1m 58s\n",
      "36:\tlearn: 0.8815153\ttotal: 9.44s\tremaining: 1m 58s\n",
      "37:\tlearn: 0.8832076\ttotal: 9.69s\tremaining: 1m 57s\n",
      "38:\tlearn: 0.8843291\ttotal: 9.95s\tremaining: 1m 57s\n",
      "39:\tlearn: 0.8863191\ttotal: 10.2s\tremaining: 1m 57s\n",
      "40:\tlearn: 0.8890238\ttotal: 10.5s\tremaining: 1m 57s\n",
      "41:\tlearn: 0.8908428\ttotal: 10.7s\tremaining: 1m 56s\n",
      "42:\tlearn: 0.8919626\ttotal: 11s\tremaining: 1m 56s\n",
      "43:\tlearn: 0.8937623\ttotal: 11.2s\tremaining: 1m 56s\n",
      "44:\tlearn: 0.8945302\ttotal: 11.5s\tremaining: 1m 56s\n",
      "45:\tlearn: 0.8951598\ttotal: 11.7s\tremaining: 1m 55s\n",
      "46:\tlearn: 0.8964389\ttotal: 12s\tremaining: 1m 55s\n",
      "47:\tlearn: 0.8978027\ttotal: 12.3s\tremaining: 1m 55s\n",
      "48:\tlearn: 0.8983463\ttotal: 12.5s\tremaining: 1m 55s\n",
      "49:\tlearn: 0.8989257\ttotal: 12.8s\tremaining: 1m 54s\n",
      "50:\tlearn: 0.9007762\ttotal: 13s\tremaining: 1m 54s\n",
      "51:\tlearn: 0.9010753\ttotal: 13.3s\tremaining: 1m 54s\n",
      "52:\tlearn: 0.9024413\ttotal: 13.5s\tremaining: 1m 54s\n",
      "53:\tlearn: 0.9034735\ttotal: 13.8s\tremaining: 1m 53s\n",
      "54:\tlearn: 0.9064377\ttotal: 14.1s\tremaining: 1m 53s\n",
      "55:\tlearn: 0.9072581\ttotal: 14.3s\tremaining: 1m 53s\n",
      "56:\tlearn: 0.9070552\ttotal: 14.5s\tremaining: 1m 53s\n",
      "57:\tlearn: 0.9072600\ttotal: 14.8s\tremaining: 1m 52s\n",
      "58:\tlearn: 0.9081958\ttotal: 15.1s\tremaining: 1m 52s\n",
      "59:\tlearn: 0.9097653\ttotal: 15.3s\tremaining: 1m 52s\n",
      "60:\tlearn: 0.9113449\ttotal: 15.6s\tremaining: 1m 51s\n",
      "61:\tlearn: 0.9118835\ttotal: 15.8s\tremaining: 1m 51s\n",
      "62:\tlearn: 0.9134118\ttotal: 16.1s\tremaining: 1m 51s\n",
      "63:\tlearn: 0.9129454\ttotal: 16.3s\tremaining: 1m 51s\n",
      "64:\tlearn: 0.9145034\ttotal: 16.6s\tremaining: 1m 50s\n",
      "65:\tlearn: 0.9155380\ttotal: 16.8s\tremaining: 1m 50s\n",
      "66:\tlearn: 0.9161570\ttotal: 17.1s\tremaining: 1m 50s\n",
      "67:\tlearn: 0.9169179\ttotal: 17.3s\tremaining: 1m 50s\n",
      "68:\tlearn: 0.9180251\ttotal: 17.6s\tremaining: 1m 49s\n",
      "69:\tlearn: 0.9174986\ttotal: 17.8s\tremaining: 1m 49s\n",
      "70:\tlearn: 0.9191176\ttotal: 18.1s\tremaining: 1m 49s\n",
      "71:\tlearn: 0.9198905\ttotal: 18.3s\tremaining: 1m 48s\n",
      "72:\tlearn: 0.9207024\ttotal: 18.6s\tremaining: 1m 48s\n",
      "73:\tlearn: 0.9210651\ttotal: 18.8s\tremaining: 1m 48s\n",
      "74:\tlearn: 0.9219355\ttotal: 19.1s\tremaining: 1m 48s\n",
      "75:\tlearn: 0.9234699\ttotal: 19.3s\tremaining: 1m 47s\n",
      "76:\tlearn: 0.9240518\ttotal: 19.6s\tremaining: 1m 47s\n",
      "77:\tlearn: 0.9259996\ttotal: 19.8s\tremaining: 1m 47s\n",
      "78:\tlearn: 0.9259575\ttotal: 20.1s\tremaining: 1m 47s\n",
      "79:\tlearn: 0.9269380\ttotal: 20.3s\tremaining: 1m 46s\n",
      "80:\tlearn: 0.9283205\ttotal: 20.6s\tremaining: 1m 46s\n",
      "81:\tlearn: 0.9287885\ttotal: 20.9s\tremaining: 1m 46s\n",
      "82:\tlearn: 0.9294129\ttotal: 21.1s\tremaining: 1m 46s\n",
      "83:\tlearn: 0.9296979\ttotal: 21.4s\tremaining: 1m 45s\n",
      "84:\tlearn: 0.9307363\ttotal: 21.6s\tremaining: 1m 45s\n",
      "85:\tlearn: 0.9321340\ttotal: 21.9s\tremaining: 1m 45s\n",
      "86:\tlearn: 0.9323179\ttotal: 22.1s\tremaining: 1m 45s\n",
      "87:\tlearn: 0.9328891\ttotal: 22.4s\tremaining: 1m 44s\n",
      "88:\tlearn: 0.9335938\ttotal: 22.6s\tremaining: 1m 44s\n",
      "89:\tlearn: 0.9350439\ttotal: 22.9s\tremaining: 1m 44s\n",
      "90:\tlearn: 0.9369387\ttotal: 23.1s\tremaining: 1m 43s\n",
      "91:\tlearn: 0.9377570\ttotal: 23.4s\tremaining: 1m 43s\n",
      "92:\tlearn: 0.9382527\ttotal: 23.6s\tremaining: 1m 43s\n",
      "93:\tlearn: 0.9401628\ttotal: 23.9s\tremaining: 1m 43s\n",
      "94:\tlearn: 0.9406016\ttotal: 24.1s\tremaining: 1m 42s\n",
      "95:\tlearn: 0.9408103\ttotal: 24.4s\tremaining: 1m 42s\n",
      "96:\tlearn: 0.9411089\ttotal: 24.7s\tremaining: 1m 42s\n",
      "97:\tlearn: 0.9419318\ttotal: 24.9s\tremaining: 1m 42s\n",
      "98:\tlearn: 0.9430902\ttotal: 25.2s\tremaining: 1m 41s\n",
      "99:\tlearn: 0.9432134\ttotal: 25.4s\tremaining: 1m 41s\n",
      "100:\tlearn: 0.9434904\ttotal: 25.7s\tremaining: 1m 41s\n",
      "101:\tlearn: 0.9436984\ttotal: 25.9s\tremaining: 1m 41s\n",
      "102:\tlearn: 0.9455174\ttotal: 26.2s\tremaining: 1m 40s\n",
      "103:\tlearn: 0.9470747\ttotal: 26.4s\tremaining: 1m 40s\n",
      "104:\tlearn: 0.9500145\ttotal: 26.7s\tremaining: 1m 40s\n",
      "105:\tlearn: 0.9495563\ttotal: 26.9s\tremaining: 1m 40s\n",
      "106:\tlearn: 0.9503861\ttotal: 27.2s\tremaining: 1m 39s\n",
      "107:\tlearn: 0.9506423\ttotal: 27.4s\tremaining: 1m 39s\n",
      "108:\tlearn: 0.9525837\ttotal: 27.7s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.9525099\ttotal: 28s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.9530675\ttotal: 28.2s\tremaining: 1m 38s\n",
      "111:\tlearn: 0.9540920\ttotal: 28.5s\tremaining: 1m 38s\n",
      "112:\tlearn: 0.9542857\ttotal: 28.7s\tremaining: 1m 38s\n",
      "113:\tlearn: 0.9556870\ttotal: 29s\tremaining: 1m 38s\n",
      "114:\tlearn: 0.9570832\ttotal: 29.2s\tremaining: 1m 37s\n",
      "115:\tlearn: 0.9572898\ttotal: 29.5s\tremaining: 1m 37s\n",
      "116:\tlearn: 0.9581187\ttotal: 29.7s\tremaining: 1m 37s\n",
      "117:\tlearn: 0.9593385\ttotal: 30s\tremaining: 1m 37s\n",
      "118:\tlearn: 0.9595291\ttotal: 30.2s\tremaining: 1m 36s\n",
      "119:\tlearn: 0.9609314\ttotal: 30.5s\tremaining: 1m 36s\n",
      "120:\tlearn: 0.9617822\ttotal: 30.7s\tremaining: 1m 36s\n",
      "121:\tlearn: 0.9631004\ttotal: 31s\tremaining: 1m 35s\n",
      "122:\tlearn: 0.9643241\ttotal: 31.2s\tremaining: 1m 35s\n",
      "123:\tlearn: 0.9640414\ttotal: 31.5s\tremaining: 1m 35s\n",
      "124:\tlearn: 0.9647956\ttotal: 31.8s\tremaining: 1m 35s\n",
      "125:\tlearn: 0.9669673\ttotal: 32s\tremaining: 1m 35s\n",
      "126:\tlearn: 0.9682991\ttotal: 32.3s\tremaining: 1m 34s\n",
      "127:\tlearn: 0.9685936\ttotal: 32.5s\tremaining: 1m 34s\n",
      "128:\tlearn: 0.9687899\ttotal: 32.8s\tremaining: 1m 34s\n",
      "129:\tlearn: 0.9693577\ttotal: 33s\tremaining: 1m 34s\n",
      "130:\tlearn: 0.9706027\ttotal: 33.3s\tremaining: 1m 33s\n",
      "131:\tlearn: 0.9713752\ttotal: 33.5s\tremaining: 1m 33s\n",
      "132:\tlearn: 0.9724247\ttotal: 33.8s\tremaining: 1m 33s\n",
      "133:\tlearn: 0.9734792\ttotal: 34.1s\tremaining: 1m 33s\n",
      "134:\tlearn: 0.9740554\ttotal: 34.3s\tremaining: 1m 32s\n",
      "135:\tlearn: 0.9753086\ttotal: 34.6s\tremaining: 1m 32s\n",
      "136:\tlearn: 0.9757905\ttotal: 34.9s\tremaining: 1m 32s\n",
      "137:\tlearn: 0.9764683\ttotal: 35.1s\tremaining: 1m 32s\n",
      "138:\tlearn: 0.9778218\ttotal: 35.4s\tremaining: 1m 31s\n",
      "139:\tlearn: 0.9782070\ttotal: 35.6s\tremaining: 1m 31s\n",
      "140:\tlearn: 0.9785927\ttotal: 35.9s\tremaining: 1m 31s\n",
      "141:\tlearn: 0.9791770\ttotal: 36.1s\tremaining: 1m 31s\n",
      "142:\tlearn: 0.9789828\ttotal: 36.4s\tremaining: 1m 30s\n",
      "143:\tlearn: 0.9793712\ttotal: 36.6s\tremaining: 1m 30s\n",
      "144:\tlearn: 0.9797639\ttotal: 36.9s\tremaining: 1m 30s\n",
      "145:\tlearn: 0.9803454\ttotal: 37.2s\tremaining: 1m 30s\n",
      "146:\tlearn: 0.9814189\ttotal: 37.4s\tremaining: 1m 29s\n",
      "147:\tlearn: 0.9818110\ttotal: 37.7s\tremaining: 1m 29s\n",
      "148:\tlearn: 0.9820062\ttotal: 37.9s\tremaining: 1m 29s\n",
      "149:\tlearn: 0.9822015\ttotal: 38.2s\tremaining: 1m 29s\n",
      "150:\tlearn: 0.9824928\ttotal: 38.4s\tremaining: 1m 28s\n",
      "151:\tlearn: 0.9828839\ttotal: 38.7s\tremaining: 1m 28s\n",
      "152:\tlearn: 0.9836670\ttotal: 38.9s\tremaining: 1m 28s\n",
      "153:\tlearn: 0.9837649\ttotal: 39.2s\tremaining: 1m 28s\n",
      "154:\tlearn: 0.9839625\ttotal: 39.4s\tremaining: 1m 27s\n",
      "155:\tlearn: 0.9853367\ttotal: 39.7s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.9870104\ttotal: 39.9s\tremaining: 1m 27s\n",
      "157:\tlearn: 0.9872077\ttotal: 40.2s\tremaining: 1m 26s\n",
      "158:\tlearn: 0.9870104\ttotal: 40.4s\tremaining: 1m 26s\n",
      "159:\tlearn: 0.9877012\ttotal: 40.7s\tremaining: 1m 26s\n",
      "160:\tlearn: 0.9881953\ttotal: 40.9s\tremaining: 1m 26s\n",
      "161:\tlearn: 0.9882941\ttotal: 41.2s\tremaining: 1m 25s\n",
      "162:\tlearn: 0.9887888\ttotal: 41.4s\tremaining: 1m 25s\n",
      "163:\tlearn: 0.9887888\ttotal: 41.7s\tremaining: 1m 25s\n",
      "164:\tlearn: 0.9892839\ttotal: 41.9s\tremaining: 1m 25s\n",
      "165:\tlearn: 0.9899780\ttotal: 42.2s\tremaining: 1m 24s\n",
      "166:\tlearn: 0.9905736\ttotal: 42.4s\tremaining: 1m 24s\n",
      "167:\tlearn: 0.9908717\ttotal: 42.7s\tremaining: 1m 24s\n",
      "168:\tlearn: 0.9912694\ttotal: 42.9s\tremaining: 1m 24s\n",
      "169:\tlearn: 0.9915680\ttotal: 43.2s\tremaining: 1m 23s\n",
      "170:\tlearn: 0.9917671\ttotal: 43.4s\tremaining: 1m 23s\n",
      "171:\tlearn: 0.9919663\ttotal: 43.7s\tremaining: 1m 23s\n",
      "172:\tlearn: 0.9923649\ttotal: 43.9s\tremaining: 1m 23s\n",
      "173:\tlearn: 0.9931631\ttotal: 44.2s\tremaining: 1m 22s\n",
      "174:\tlearn: 0.9931631\ttotal: 44.5s\tremaining: 1m 22s\n",
      "175:\tlearn: 0.9934627\ttotal: 44.7s\tremaining: 1m 22s\n",
      "176:\tlearn: 0.9934627\ttotal: 45s\tremaining: 1m 22s\n",
      "177:\tlearn: 0.9934627\ttotal: 45.2s\tremaining: 1m 21s\n",
      "178:\tlearn: 0.9936626\ttotal: 45.5s\tremaining: 1m 21s\n",
      "179:\tlearn: 0.9936626\ttotal: 45.7s\tremaining: 1m 21s\n",
      "180:\tlearn: 0.9938626\ttotal: 46s\tremaining: 1m 21s\n",
      "181:\tlearn: 0.9942627\ttotal: 46.2s\tremaining: 1m 20s\n",
      "182:\tlearn: 0.9940626\ttotal: 46.5s\tremaining: 1m 20s\n",
      "183:\tlearn: 0.9942627\ttotal: 46.7s\tremaining: 1m 20s\n",
      "184:\tlearn: 0.9945630\ttotal: 47s\tremaining: 1m 20s\n",
      "185:\tlearn: 0.9948635\ttotal: 47.2s\tremaining: 1m 19s\n",
      "186:\tlearn: 0.9954651\ttotal: 47.5s\tremaining: 1m 19s\n",
      "187:\tlearn: 0.9953648\ttotal: 47.8s\tremaining: 1m 19s\n",
      "188:\tlearn: 0.9956658\ttotal: 48s\tremaining: 1m 19s\n",
      "189:\tlearn: 0.9957661\ttotal: 48.3s\tremaining: 1m 18s\n",
      "190:\tlearn: 0.9960674\ttotal: 48.5s\tremaining: 1m 18s\n",
      "191:\tlearn: 0.9961678\ttotal: 48.8s\tremaining: 1m 18s\n",
      "192:\tlearn: 0.9961678\ttotal: 49s\tremaining: 1m 17s\n",
      "193:\tlearn: 0.9964693\ttotal: 49.3s\tremaining: 1m 17s\n",
      "194:\tlearn: 0.9965698\ttotal: 49.5s\tremaining: 1m 17s\n",
      "195:\tlearn: 0.9965698\ttotal: 49.8s\tremaining: 1m 17s\n",
      "196:\tlearn: 0.9965698\ttotal: 50s\tremaining: 1m 16s\n",
      "197:\tlearn: 0.9967709\ttotal: 50.3s\tremaining: 1m 16s\n",
      "198:\tlearn: 0.9969721\ttotal: 50.5s\tremaining: 1m 16s\n",
      "199:\tlearn: 0.9970728\ttotal: 50.8s\tremaining: 1m 16s\n",
      "200:\tlearn: 0.9970728\ttotal: 51.1s\tremaining: 1m 15s\n",
      "201:\tlearn: 0.9971734\ttotal: 51.3s\tremaining: 1m 15s\n",
      "202:\tlearn: 0.9969721\ttotal: 51.5s\tremaining: 1m 15s\n",
      "203:\tlearn: 0.9970728\ttotal: 51.8s\tremaining: 1m 15s\n",
      "204:\tlearn: 0.9971734\ttotal: 52.1s\tremaining: 1m 14s\n",
      "205:\tlearn: 0.9975762\ttotal: 52.3s\tremaining: 1m 14s\n",
      "206:\tlearn: 0.9976770\ttotal: 52.6s\tremaining: 1m 14s\n",
      "207:\tlearn: 0.9977778\ttotal: 52.8s\tremaining: 1m 14s\n",
      "208:\tlearn: 0.9977778\ttotal: 53.1s\tremaining: 1m 13s\n",
      "209:\tlearn: 0.9978786\ttotal: 53.3s\tremaining: 1m 13s\n",
      "210:\tlearn: 0.9977778\ttotal: 53.6s\tremaining: 1m 13s\n",
      "211:\tlearn: 0.9981811\ttotal: 53.8s\tremaining: 1m 13s\n",
      "212:\tlearn: 0.9981811\ttotal: 54.1s\tremaining: 1m 12s\n",
      "213:\tlearn: 0.9982820\ttotal: 54.3s\tremaining: 1m 12s\n",
      "214:\tlearn: 0.9982820\ttotal: 54.6s\tremaining: 1m 12s\n",
      "215:\tlearn: 0.9983829\ttotal: 54.8s\tremaining: 1m 12s\n",
      "216:\tlearn: 0.9983829\ttotal: 55.1s\tremaining: 1m 11s\n",
      "217:\tlearn: 0.9982820\ttotal: 55.3s\tremaining: 1m 11s\n",
      "218:\tlearn: 0.9983829\ttotal: 55.6s\tremaining: 1m 11s\n",
      "219:\tlearn: 0.9984838\ttotal: 55.9s\tremaining: 1m 11s\n",
      "220:\tlearn: 0.9983829\ttotal: 56.1s\tremaining: 1m 10s\n",
      "221:\tlearn: 0.9984838\ttotal: 56.4s\tremaining: 1m 10s\n",
      "222:\tlearn: 0.9984838\ttotal: 56.6s\tremaining: 1m 10s\n",
      "223:\tlearn: 0.9984838\ttotal: 56.9s\tremaining: 1m 10s\n",
      "224:\tlearn: 0.9984838\ttotal: 57.1s\tremaining: 1m 9s\n",
      "225:\tlearn: 0.9984838\ttotal: 57.4s\tremaining: 1m 9s\n",
      "226:\tlearn: 0.9985847\ttotal: 57.6s\tremaining: 1m 9s\n",
      "227:\tlearn: 0.9985847\ttotal: 57.9s\tremaining: 1m 9s\n",
      "228:\tlearn: 0.9985847\ttotal: 58.1s\tremaining: 1m 8s\n",
      "229:\tlearn: 0.9985847\ttotal: 58.4s\tremaining: 1m 8s\n",
      "230:\tlearn: 0.9986857\ttotal: 58.6s\tremaining: 1m 8s\n",
      "231:\tlearn: 0.9986857\ttotal: 58.9s\tremaining: 1m 8s\n",
      "232:\tlearn: 0.9986857\ttotal: 59.1s\tremaining: 1m 7s\n",
      "233:\tlearn: 0.9987867\ttotal: 59.4s\tremaining: 1m 7s\n",
      "234:\tlearn: 0.9988877\ttotal: 59.6s\tremaining: 1m 7s\n",
      "235:\tlearn: 0.9988877\ttotal: 59.9s\tremaining: 1m 6s\n",
      "236:\tlearn: 0.9988877\ttotal: 1m\tremaining: 1m 6s\n",
      "237:\tlearn: 0.9988877\ttotal: 1m\tremaining: 1m 6s\n",
      "238:\tlearn: 0.9989887\ttotal: 1m\tremaining: 1m 6s\n",
      "239:\tlearn: 0.9989887\ttotal: 1m\tremaining: 1m 5s\n",
      "240:\tlearn: 0.9989887\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "241:\tlearn: 0.9989887\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "242:\tlearn: 0.9989887\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "243:\tlearn: 0.9990897\ttotal: 1m 1s\tremaining: 1m 4s\n",
      "244:\tlearn: 0.9990897\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "245:\tlearn: 0.9992919\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "246:\tlearn: 0.9993930\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "247:\tlearn: 0.9995952\ttotal: 1m 2s\tremaining: 1m 3s\n",
      "248:\tlearn: 0.9995952\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "249:\tlearn: 0.9995952\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "250:\tlearn: 0.9995952\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "251:\tlearn: 0.9995952\ttotal: 1m 3s\tremaining: 1m 2s\n",
      "252:\tlearn: 0.9995952\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "253:\tlearn: 0.9995952\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "254:\tlearn: 0.9995952\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "255:\tlearn: 0.9995952\ttotal: 1m 4s\tremaining: 1m 1s\n",
      "256:\tlearn: 0.9995952\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "257:\tlearn: 0.9995952\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "258:\tlearn: 0.9995952\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "259:\tlearn: 0.9995952\ttotal: 1m 5s\tremaining: 1m\n",
      "260:\tlearn: 0.9995952\ttotal: 1m 6s\tremaining: 1m\n",
      "261:\tlearn: 0.9995952\ttotal: 1m 6s\tremaining: 1m\n",
      "262:\tlearn: 0.9995952\ttotal: 1m 6s\tremaining: 1m\n",
      "263:\tlearn: 0.9995952\ttotal: 1m 6s\tremaining: 59.8s\n",
      "264:\tlearn: 0.9995952\ttotal: 1m 7s\tremaining: 59.6s\n",
      "265:\tlearn: 0.9995952\ttotal: 1m 7s\tremaining: 59.3s\n",
      "266:\tlearn: 0.9995952\ttotal: 1m 7s\tremaining: 59s\n",
      "267:\tlearn: 0.9995952\ttotal: 1m 7s\tremaining: 58.8s\n",
      "268:\tlearn: 0.9995952\ttotal: 1m 8s\tremaining: 58.5s\n",
      "269:\tlearn: 0.9995952\ttotal: 1m 8s\tremaining: 58.3s\n",
      "270:\tlearn: 0.9995952\ttotal: 1m 8s\tremaining: 58s\n",
      "271:\tlearn: 0.9995952\ttotal: 1m 8s\tremaining: 57.8s\n",
      "272:\tlearn: 0.9995952\ttotal: 1m 9s\tremaining: 57.5s\n",
      "273:\tlearn: 0.9996964\ttotal: 1m 9s\tremaining: 57.3s\n",
      "274:\tlearn: 0.9996964\ttotal: 1m 9s\tremaining: 57s\n",
      "275:\tlearn: 0.9996964\ttotal: 1m 9s\tremaining: 56.7s\n",
      "276:\tlearn: 0.9995952\ttotal: 1m 10s\tremaining: 56.5s\n",
      "277:\tlearn: 0.9995952\ttotal: 1m 10s\tremaining: 56.2s\n",
      "278:\tlearn: 0.9995952\ttotal: 1m 10s\tremaining: 56s\n",
      "279:\tlearn: 0.9996964\ttotal: 1m 10s\tremaining: 55.7s\n",
      "280:\tlearn: 0.9996964\ttotal: 1m 11s\tremaining: 55.5s\n",
      "281:\tlearn: 0.9996964\ttotal: 1m 11s\tremaining: 55.2s\n",
      "282:\tlearn: 0.9996964\ttotal: 1m 11s\tremaining: 54.9s\n",
      "283:\tlearn: 0.9996964\ttotal: 1m 11s\tremaining: 54.7s\n",
      "284:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 54.4s\n",
      "285:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 54.2s\n",
      "286:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 53.9s\n",
      "287:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 53.7s\n",
      "288:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.4s\n",
      "289:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.2s\n",
      "290:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 52.9s\n",
      "291:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 52.7s\n",
      "292:\tlearn: 0.9997976\ttotal: 1m 14s\tremaining: 52.4s\n",
      "293:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 52.1s\n",
      "294:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 51.9s\n",
      "295:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 51.6s\n",
      "296:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51.4s\n",
      "297:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51.1s\n",
      "298:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 50.9s\n",
      "299:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 50.6s\n",
      "300:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50.4s\n",
      "301:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50.1s\n",
      "302:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 49.8s\n",
      "303:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 49.6s\n",
      "304:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49.3s\n",
      "305:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49.1s\n",
      "306:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 48.8s\n",
      "307:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 48.6s\n",
      "308:\tlearn: 1.0000000\ttotal: 1m 18s\tremaining: 48.3s\n",
      "309:\tlearn: 1.0000000\ttotal: 1m 18s\tremaining: 48.1s\n",
      "310:\tlearn: 1.0000000\ttotal: 1m 18s\tremaining: 47.8s\n",
      "311:\tlearn: 1.0000000\ttotal: 1m 18s\tremaining: 47.6s\n",
      "312:\tlearn: 1.0000000\ttotal: 1m 19s\tremaining: 47.3s\n",
      "313:\tlearn: 1.0000000\ttotal: 1m 19s\tremaining: 47.1s\n",
      "314:\tlearn: 1.0000000\ttotal: 1m 19s\tremaining: 46.8s\n",
      "315:\tlearn: 1.0000000\ttotal: 1m 19s\tremaining: 46.6s\n",
      "316:\tlearn: 1.0000000\ttotal: 1m 20s\tremaining: 46.3s\n",
      "317:\tlearn: 1.0000000\ttotal: 1m 20s\tremaining: 46.1s\n",
      "318:\tlearn: 1.0000000\ttotal: 1m 20s\tremaining: 45.8s\n",
      "319:\tlearn: 1.0000000\ttotal: 1m 20s\tremaining: 45.5s\n",
      "320:\tlearn: 1.0000000\ttotal: 1m 21s\tremaining: 45.3s\n",
      "321:\tlearn: 1.0000000\ttotal: 1m 21s\tremaining: 45s\n",
      "322:\tlearn: 1.0000000\ttotal: 1m 21s\tremaining: 44.8s\n",
      "323:\tlearn: 1.0000000\ttotal: 1m 21s\tremaining: 44.5s\n",
      "324:\tlearn: 1.0000000\ttotal: 1m 22s\tremaining: 44.3s\n",
      "325:\tlearn: 1.0000000\ttotal: 1m 22s\tremaining: 44s\n",
      "326:\tlearn: 1.0000000\ttotal: 1m 22s\tremaining: 43.8s\n",
      "327:\tlearn: 1.0000000\ttotal: 1m 22s\tremaining: 43.5s\n",
      "328:\tlearn: 1.0000000\ttotal: 1m 23s\tremaining: 43.3s\n",
      "329:\tlearn: 1.0000000\ttotal: 1m 23s\tremaining: 43s\n",
      "330:\tlearn: 1.0000000\ttotal: 1m 23s\tremaining: 42.8s\n",
      "331:\tlearn: 1.0000000\ttotal: 1m 23s\tremaining: 42.5s\n",
      "332:\tlearn: 1.0000000\ttotal: 1m 24s\tremaining: 42.2s\n",
      "333:\tlearn: 1.0000000\ttotal: 1m 24s\tremaining: 42s\n",
      "334:\tlearn: 1.0000000\ttotal: 1m 24s\tremaining: 41.7s\n",
      "335:\tlearn: 1.0000000\ttotal: 1m 25s\tremaining: 41.5s\n",
      "336:\tlearn: 1.0000000\ttotal: 1m 25s\tremaining: 41.2s\n",
      "337:\tlearn: 1.0000000\ttotal: 1m 25s\tremaining: 41s\n",
      "338:\tlearn: 1.0000000\ttotal: 1m 25s\tremaining: 40.7s\n",
      "339:\tlearn: 1.0000000\ttotal: 1m 26s\tremaining: 40.5s\n",
      "340:\tlearn: 1.0000000\ttotal: 1m 26s\tremaining: 40.2s\n",
      "341:\tlearn: 1.0000000\ttotal: 1m 26s\tremaining: 40s\n",
      "342:\tlearn: 1.0000000\ttotal: 1m 26s\tremaining: 39.7s\n",
      "343:\tlearn: 1.0000000\ttotal: 1m 27s\tremaining: 39.5s\n",
      "344:\tlearn: 1.0000000\ttotal: 1m 27s\tremaining: 39.2s\n",
      "345:\tlearn: 1.0000000\ttotal: 1m 27s\tremaining: 38.9s\n",
      "346:\tlearn: 1.0000000\ttotal: 1m 27s\tremaining: 38.7s\n",
      "347:\tlearn: 1.0000000\ttotal: 1m 28s\tremaining: 38.4s\n",
      "348:\tlearn: 1.0000000\ttotal: 1m 28s\tremaining: 38.2s\n",
      "349:\tlearn: 1.0000000\ttotal: 1m 28s\tremaining: 37.9s\n",
      "350:\tlearn: 1.0000000\ttotal: 1m 28s\tremaining: 37.7s\n",
      "351:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.4s\n",
      "352:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 37.2s\n",
      "353:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 36.9s\n",
      "354:\tlearn: 1.0000000\ttotal: 1m 29s\tremaining: 36.7s\n",
      "355:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 36.4s\n",
      "356:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 36.2s\n",
      "357:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 35.9s\n",
      "358:\tlearn: 1.0000000\ttotal: 1m 30s\tremaining: 35.7s\n",
      "359:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.4s\n",
      "360:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 35.2s\n",
      "361:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 34.9s\n",
      "362:\tlearn: 1.0000000\ttotal: 1m 31s\tremaining: 34.6s\n",
      "363:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 34.4s\n",
      "364:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 34.1s\n",
      "365:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 33.9s\n",
      "366:\tlearn: 1.0000000\ttotal: 1m 32s\tremaining: 33.6s\n",
      "367:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 33.4s\n",
      "368:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 33.1s\n",
      "369:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 32.9s\n",
      "370:\tlearn: 1.0000000\ttotal: 1m 33s\tremaining: 32.6s\n",
      "371:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 32.4s\n",
      "372:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 32.1s\n",
      "373:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 31.9s\n",
      "374:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 31.6s\n",
      "375:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 31.3s\n",
      "376:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 31.1s\n",
      "377:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 30.8s\n",
      "378:\tlearn: 1.0000000\ttotal: 1m 35s\tremaining: 30.6s\n",
      "379:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 30.3s\n",
      "380:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 30.1s\n",
      "381:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 29.8s\n",
      "382:\tlearn: 1.0000000\ttotal: 1m 36s\tremaining: 29.6s\n",
      "383:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.3s\n",
      "384:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.1s\n",
      "385:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 28.8s\n",
      "386:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 28.6s\n",
      "387:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.3s\n",
      "388:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.1s\n",
      "389:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 27.8s\n",
      "390:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 27.6s\n",
      "391:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.3s\n",
      "392:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.1s\n",
      "393:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 26.8s\n",
      "394:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 26.6s\n",
      "395:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 26.3s\n",
      "396:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 26.1s\n",
      "397:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 25.8s\n",
      "398:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 25.5s\n",
      "399:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.3s\n",
      "400:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25s\n",
      "401:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 24.8s\n",
      "402:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 24.5s\n",
      "403:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.3s\n",
      "404:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24s\n",
      "405:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 23.8s\n",
      "406:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.5s\n",
      "407:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.3s\n",
      "408:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23s\n",
      "409:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 22.8s\n",
      "410:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.5s\n",
      "411:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.3s\n",
      "412:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22s\n",
      "413:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 21.8s\n",
      "414:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.5s\n",
      "415:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.3s\n",
      "416:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21s\n",
      "417:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 20.8s\n",
      "418:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.5s\n",
      "419:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.2s\n",
      "420:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20s\n",
      "421:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 19.7s\n",
      "422:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.5s\n",
      "423:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.2s\n",
      "424:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19s\n",
      "425:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 18.7s\n",
      "426:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.5s\n",
      "427:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.2s\n",
      "428:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18s\n",
      "429:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 17.7s\n",
      "430:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.5s\n",
      "431:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.2s\n",
      "432:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17s\n",
      "433:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 16.7s\n",
      "434:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.4s\n",
      "435:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.2s\n",
      "436:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 15.9s\n",
      "437:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 15.7s\n",
      "438:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.4s\n",
      "439:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.2s\n",
      "440:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 14.9s\n",
      "441:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 14.7s\n",
      "442:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.4s\n",
      "443:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.2s\n",
      "444:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 13.9s\n",
      "445:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 13.7s\n",
      "446:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.4s\n",
      "447:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.2s\n",
      "448:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 12.9s\n",
      "449:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 12.7s\n",
      "450:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.4s\n",
      "451:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.1s\n",
      "452:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 11.9s\n",
      "453:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 11.6s\n",
      "454:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.4s\n",
      "455:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.1s\n",
      "456:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 10.9s\n",
      "457:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 10.6s\n",
      "458:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.4s\n",
      "459:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.1s\n",
      "460:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 9.87s\n",
      "461:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 9.62s\n",
      "462:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.37s\n",
      "463:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.11s\n",
      "464:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 8.86s\n",
      "465:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 8.61s\n",
      "466:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.35s\n",
      "467:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.1s\n",
      "468:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 7.85s\n",
      "469:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 7.59s\n",
      "470:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.34s\n",
      "471:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.09s\n",
      "472:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 6.83s\n",
      "473:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 6.58s\n",
      "474:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.33s\n",
      "475:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.07s\n",
      "476:\tlearn: 1.0000000\ttotal: 2m\tremaining: 5.82s\n",
      "477:\tlearn: 1.0000000\ttotal: 2m\tremaining: 5.57s\n",
      "478:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.31s\n",
      "479:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.06s\n",
      "480:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 4.81s\n",
      "481:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 4.55s\n",
      "482:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.3s\n",
      "483:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.05s\n",
      "484:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 3.8s\n",
      "485:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 3.54s\n",
      "486:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.29s\n",
      "487:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.04s\n",
      "488:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 2.78s\n",
      "489:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 2.53s\n",
      "490:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.28s\n",
      "491:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.02s\n",
      "492:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 1.77s\n",
      "493:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.52s\n",
      "494:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.26s\n",
      "495:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.01s\n",
      "496:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 759ms\n",
      "497:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 506ms\n",
      "498:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 253ms\n",
      "499:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=96, depth=9, eval_metric=Precision, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=1; total time= 2.1min\n",
      "0:\tlearn: 0.6436093\ttotal: 269ms\tremaining: 2m 14s\n",
      "1:\tlearn: 0.7007513\ttotal: 521ms\tremaining: 2m 9s\n",
      "2:\tlearn: 0.7230857\ttotal: 784ms\tremaining: 2m 9s\n",
      "3:\tlearn: 0.7475029\ttotal: 1.04s\tremaining: 2m 8s\n",
      "4:\tlearn: 0.7700530\ttotal: 1.3s\tremaining: 2m 8s\n",
      "5:\tlearn: 0.7802177\ttotal: 1.55s\tremaining: 2m 7s\n",
      "6:\tlearn: 0.7912663\ttotal: 1.81s\tremaining: 2m 7s\n",
      "7:\tlearn: 0.7949616\ttotal: 2.06s\tremaining: 2m 7s\n",
      "8:\tlearn: 0.7983217\ttotal: 2.32s\tremaining: 2m 6s\n",
      "9:\tlearn: 0.8047237\ttotal: 2.57s\tremaining: 2m 5s\n",
      "10:\tlearn: 0.8146777\ttotal: 2.83s\tremaining: 2m 5s\n",
      "11:\tlearn: 0.8210966\ttotal: 3.09s\tremaining: 2m 5s\n",
      "12:\tlearn: 0.8240478\ttotal: 3.34s\tremaining: 2m 5s\n",
      "13:\tlearn: 0.8286281\ttotal: 3.6s\tremaining: 2m 4s\n",
      "14:\tlearn: 0.8280810\ttotal: 3.85s\tremaining: 2m 4s\n",
      "15:\tlearn: 0.8313039\ttotal: 4.11s\tremaining: 2m 4s\n",
      "16:\tlearn: 0.8382739\ttotal: 4.37s\tremaining: 2m 4s\n",
      "17:\tlearn: 0.8386916\ttotal: 4.62s\tremaining: 2m 3s\n",
      "18:\tlearn: 0.8461106\ttotal: 4.88s\tremaining: 2m 3s\n",
      "19:\tlearn: 0.8472883\ttotal: 5.13s\tremaining: 2m 3s\n",
      "20:\tlearn: 0.8534305\ttotal: 5.39s\tremaining: 2m 2s\n",
      "21:\tlearn: 0.8581062\ttotal: 5.65s\tremaining: 2m 2s\n",
      "22:\tlearn: 0.8600487\ttotal: 5.92s\tremaining: 2m 2s\n",
      "23:\tlearn: 0.8612539\ttotal: 6.17s\tremaining: 2m 2s\n",
      "24:\tlearn: 0.8632630\ttotal: 6.43s\tremaining: 2m 2s\n",
      "25:\tlearn: 0.8643277\ttotal: 6.68s\tremaining: 2m 1s\n",
      "26:\tlearn: 0.8679263\ttotal: 6.94s\tremaining: 2m 1s\n",
      "27:\tlearn: 0.8715957\ttotal: 7.19s\tremaining: 2m 1s\n",
      "28:\tlearn: 0.8735589\ttotal: 7.46s\tremaining: 2m 1s\n",
      "29:\tlearn: 0.8751757\ttotal: 7.71s\tremaining: 2m\n",
      "30:\tlearn: 0.8756200\ttotal: 7.96s\tremaining: 2m\n",
      "31:\tlearn: 0.8773161\ttotal: 8.23s\tremaining: 2m\n",
      "32:\tlearn: 0.8788474\ttotal: 8.48s\tremaining: 2m\n",
      "33:\tlearn: 0.8792555\ttotal: 8.74s\tremaining: 1m 59s\n",
      "34:\tlearn: 0.8849117\ttotal: 8.99s\tremaining: 1m 59s\n",
      "35:\tlearn: 0.8843990\ttotal: 9.24s\tremaining: 1m 59s\n",
      "36:\tlearn: 0.8869940\ttotal: 9.48s\tremaining: 1m 58s\n",
      "37:\tlearn: 0.8886180\ttotal: 9.74s\tremaining: 1m 58s\n",
      "38:\tlearn: 0.8901274\ttotal: 10s\tremaining: 1m 58s\n",
      "39:\tlearn: 0.8916159\ttotal: 10.3s\tremaining: 1m 57s\n",
      "40:\tlearn: 0.8942723\ttotal: 10.5s\tremaining: 1m 57s\n",
      "41:\tlearn: 0.8947566\ttotal: 10.8s\tremaining: 1m 57s\n",
      "42:\tlearn: 0.8964158\ttotal: 11s\tremaining: 1m 57s\n",
      "43:\tlearn: 0.8974191\ttotal: 11.3s\tremaining: 1m 56s\n",
      "44:\tlearn: 0.8979343\ttotal: 11.5s\tremaining: 1m 56s\n",
      "45:\tlearn: 0.8995863\ttotal: 11.8s\tremaining: 1m 56s\n",
      "46:\tlearn: 0.9003759\ttotal: 12s\tremaining: 1m 55s\n",
      "47:\tlearn: 0.9003662\ttotal: 12.3s\tremaining: 1m 55s\n",
      "48:\tlearn: 0.9031621\ttotal: 12.5s\tremaining: 1m 55s\n",
      "49:\tlearn: 0.9038263\ttotal: 12.8s\tremaining: 1m 55s\n",
      "50:\tlearn: 0.9050978\ttotal: 13s\tremaining: 1m 54s\n",
      "51:\tlearn: 0.9066918\ttotal: 13.3s\tremaining: 1m 54s\n",
      "52:\tlearn: 0.9071213\ttotal: 13.6s\tremaining: 1m 54s\n",
      "53:\tlearn: 0.9091081\ttotal: 13.8s\tremaining: 1m 54s\n",
      "54:\tlearn: 0.9103156\ttotal: 14.1s\tremaining: 1m 53s\n",
      "55:\tlearn: 0.9110881\ttotal: 14.3s\tremaining: 1m 53s\n",
      "56:\tlearn: 0.9126003\ttotal: 14.6s\tremaining: 1m 53s\n",
      "57:\tlearn: 0.9134742\ttotal: 14.8s\tremaining: 1m 53s\n",
      "58:\tlearn: 0.9138760\ttotal: 15.1s\tremaining: 1m 52s\n",
      "59:\tlearn: 0.9150703\ttotal: 15.3s\tremaining: 1m 52s\n",
      "60:\tlearn: 0.9163441\ttotal: 15.6s\tremaining: 1m 52s\n",
      "61:\tlearn: 0.9186530\ttotal: 15.8s\tremaining: 1m 51s\n",
      "62:\tlearn: 0.9193487\ttotal: 16.1s\tremaining: 1m 51s\n",
      "63:\tlearn: 0.9199319\ttotal: 16.4s\tremaining: 1m 51s\n",
      "64:\tlearn: 0.9205913\ttotal: 16.6s\tremaining: 1m 51s\n",
      "65:\tlearn: 0.9222011\ttotal: 16.9s\tremaining: 1m 50s\n",
      "66:\tlearn: 0.9233982\ttotal: 17.1s\tremaining: 1m 50s\n",
      "67:\tlearn: 0.9233982\ttotal: 17.4s\tremaining: 1m 50s\n",
      "68:\tlearn: 0.9234859\ttotal: 17.6s\tremaining: 1m 50s\n",
      "69:\tlearn: 0.9248313\ttotal: 17.9s\tremaining: 1m 49s\n",
      "70:\tlearn: 0.9252114\ttotal: 18.1s\tremaining: 1m 49s\n",
      "71:\tlearn: 0.9267852\ttotal: 18.4s\tremaining: 1m 49s\n",
      "72:\tlearn: 0.9276879\ttotal: 18.6s\tremaining: 1m 48s\n",
      "73:\tlearn: 0.9284355\ttotal: 18.9s\tremaining: 1m 48s\n",
      "74:\tlearn: 0.9293333\ttotal: 19.1s\tremaining: 1m 48s\n",
      "75:\tlearn: 0.9304431\ttotal: 19.4s\tremaining: 1m 48s\n",
      "76:\tlearn: 0.9312548\ttotal: 19.6s\tremaining: 1m 47s\n",
      "77:\tlearn: 0.9316060\ttotal: 19.9s\tremaining: 1m 47s\n",
      "78:\tlearn: 0.9321323\ttotal: 20.2s\tremaining: 1m 47s\n",
      "79:\tlearn: 0.9324878\ttotal: 20.4s\tremaining: 1m 47s\n",
      "80:\tlearn: 0.9326153\ttotal: 20.7s\tremaining: 1m 46s\n",
      "81:\tlearn: 0.9331936\ttotal: 20.9s\tremaining: 1m 46s\n",
      "82:\tlearn: 0.9341917\ttotal: 21.2s\tremaining: 1m 46s\n",
      "83:\tlearn: 0.9358227\ttotal: 21.4s\tremaining: 1m 46s\n",
      "84:\tlearn: 0.9367596\ttotal: 21.7s\tremaining: 1m 45s\n",
      "85:\tlearn: 0.9378288\ttotal: 21.9s\tremaining: 1m 45s\n",
      "86:\tlearn: 0.9399923\ttotal: 22.2s\tremaining: 1m 45s\n",
      "87:\tlearn: 0.9396667\ttotal: 22.4s\tremaining: 1m 45s\n",
      "88:\tlearn: 0.9407422\ttotal: 22.7s\tremaining: 1m 44s\n",
      "89:\tlearn: 0.9410242\ttotal: 23s\tremaining: 1m 44s\n",
      "90:\tlearn: 0.9418761\ttotal: 23.2s\tremaining: 1m 44s\n",
      "91:\tlearn: 0.9428434\ttotal: 23.5s\tremaining: 1m 44s\n",
      "92:\tlearn: 0.9432113\ttotal: 23.7s\tremaining: 1m 43s\n",
      "93:\tlearn: 0.9443376\ttotal: 24s\tremaining: 1m 43s\n",
      "94:\tlearn: 0.9441615\ttotal: 24.2s\tremaining: 1m 43s\n",
      "95:\tlearn: 0.9453321\ttotal: 24.5s\tremaining: 1m 42s\n",
      "96:\tlearn: 0.9460916\ttotal: 24.7s\tremaining: 1m 42s\n",
      "97:\tlearn: 0.9475511\ttotal: 25s\tremaining: 1m 42s\n",
      "98:\tlearn: 0.9482875\ttotal: 25.2s\tremaining: 1m 42s\n",
      "99:\tlearn: 0.9496716\ttotal: 25.5s\tremaining: 1m 41s\n",
      "100:\tlearn: 0.9510733\ttotal: 25.7s\tremaining: 1m 41s\n",
      "101:\tlearn: 0.9521781\ttotal: 26s\tremaining: 1m 41s\n",
      "102:\tlearn: 0.9533689\ttotal: 26.2s\tremaining: 1m 41s\n",
      "103:\tlearn: 0.9536552\ttotal: 26.5s\tremaining: 1m 40s\n",
      "104:\tlearn: 0.9536687\ttotal: 26.7s\tremaining: 1m 40s\n",
      "105:\tlearn: 0.9543999\ttotal: 27s\tremaining: 1m 40s\n",
      "106:\tlearn: 0.9551413\ttotal: 27.2s\tremaining: 1m 40s\n",
      "107:\tlearn: 0.9553441\ttotal: 27.5s\tremaining: 1m 39s\n",
      "108:\tlearn: 0.9569359\ttotal: 27.7s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.9575917\ttotal: 28s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.9575027\ttotal: 28.2s\tremaining: 1m 38s\n",
      "111:\tlearn: 0.9580739\ttotal: 28.5s\tremaining: 1m 38s\n",
      "112:\tlearn: 0.9597584\ttotal: 28.8s\tremaining: 1m 38s\n",
      "113:\tlearn: 0.9610656\ttotal: 29s\tremaining: 1m 38s\n",
      "114:\tlearn: 0.9617225\ttotal: 29.3s\tremaining: 1m 37s\n",
      "115:\tlearn: 0.9625867\ttotal: 29.5s\tremaining: 1m 37s\n",
      "116:\tlearn: 0.9637199\ttotal: 29.8s\tremaining: 1m 37s\n",
      "117:\tlearn: 0.9647681\ttotal: 30s\tremaining: 1m 37s\n",
      "118:\tlearn: 0.9653179\ttotal: 30.3s\tremaining: 1m 36s\n",
      "119:\tlearn: 0.9656186\ttotal: 30.5s\tremaining: 1m 36s\n",
      "120:\tlearn: 0.9665686\ttotal: 30.8s\tremaining: 1m 36s\n",
      "121:\tlearn: 0.9683725\ttotal: 31s\tremaining: 1m 36s\n",
      "122:\tlearn: 0.9690448\ttotal: 31.3s\tremaining: 1m 35s\n",
      "123:\tlearn: 0.9693185\ttotal: 31.5s\tremaining: 1m 35s\n",
      "124:\tlearn: 0.9698043\ttotal: 31.8s\tremaining: 1m 35s\n",
      "125:\tlearn: 0.9702844\ttotal: 32s\tremaining: 1m 35s\n",
      "126:\tlearn: 0.9705738\ttotal: 32.3s\tremaining: 1m 34s\n",
      "127:\tlearn: 0.9716256\ttotal: 32.5s\tremaining: 1m 34s\n",
      "128:\tlearn: 0.9720114\ttotal: 32.8s\tremaining: 1m 34s\n",
      "129:\tlearn: 0.9724906\ttotal: 33s\tremaining: 1m 34s\n",
      "130:\tlearn: 0.9730636\ttotal: 33.3s\tremaining: 1m 33s\n",
      "131:\tlearn: 0.9745084\ttotal: 33.6s\tremaining: 1m 33s\n",
      "132:\tlearn: 0.9750840\ttotal: 33.8s\tremaining: 1m 33s\n",
      "133:\tlearn: 0.9759525\ttotal: 34.1s\tremaining: 1m 33s\n",
      "134:\tlearn: 0.9760515\ttotal: 34.3s\tremaining: 1m 32s\n",
      "135:\tlearn: 0.9772074\ttotal: 34.6s\tremaining: 1m 32s\n",
      "136:\tlearn: 0.9777954\ttotal: 34.8s\tremaining: 1m 32s\n",
      "137:\tlearn: 0.9792535\ttotal: 35.1s\tremaining: 1m 32s\n",
      "138:\tlearn: 0.9798351\ttotal: 35.3s\tremaining: 1m 31s\n",
      "139:\tlearn: 0.9807157\ttotal: 35.6s\tremaining: 1m 31s\n",
      "140:\tlearn: 0.9810083\ttotal: 35.8s\tremaining: 1m 31s\n",
      "141:\tlearn: 0.9816915\ttotal: 36.1s\tremaining: 1m 30s\n",
      "142:\tlearn: 0.9827655\ttotal: 36.3s\tremaining: 1m 30s\n",
      "143:\tlearn: 0.9830593\ttotal: 36.6s\tremaining: 1m 30s\n",
      "144:\tlearn: 0.9840431\ttotal: 36.9s\tremaining: 1m 30s\n",
      "145:\tlearn: 0.9844374\ttotal: 37.1s\tremaining: 1m 30s\n",
      "146:\tlearn: 0.9848319\ttotal: 37.4s\tremaining: 1m 29s\n",
      "147:\tlearn: 0.9849301\ttotal: 37.7s\tremaining: 1m 29s\n",
      "148:\tlearn: 0.9848319\ttotal: 37.9s\tremaining: 1m 29s\n",
      "149:\tlearn: 0.9859155\ttotal: 38.2s\tremaining: 1m 29s\n",
      "150:\tlearn: 0.9859155\ttotal: 38.4s\tremaining: 1m 28s\n",
      "151:\tlearn: 0.9865067\ttotal: 38.7s\tremaining: 1m 28s\n",
      "152:\tlearn: 0.9865081\ttotal: 39s\tremaining: 1m 28s\n",
      "153:\tlearn: 0.9868053\ttotal: 39.2s\tremaining: 1m 28s\n",
      "154:\tlearn: 0.9869039\ttotal: 39.5s\tremaining: 1m 27s\n",
      "155:\tlearn: 0.9871013\ttotal: 39.7s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.9872000\ttotal: 40s\tremaining: 1m 27s\n",
      "157:\tlearn: 0.9870026\ttotal: 40.2s\tremaining: 1m 27s\n",
      "158:\tlearn: 0.9874962\ttotal: 40.5s\tremaining: 1m 26s\n",
      "159:\tlearn: 0.9875950\ttotal: 40.8s\tremaining: 1m 26s\n",
      "160:\tlearn: 0.9889802\ttotal: 41s\tremaining: 1m 26s\n",
      "161:\tlearn: 0.9901705\ttotal: 41.3s\tremaining: 1m 26s\n",
      "162:\tlearn: 0.9903692\ttotal: 41.5s\tremaining: 1m 25s\n",
      "163:\tlearn: 0.9908662\ttotal: 41.8s\tremaining: 1m 25s\n",
      "164:\tlearn: 0.9912642\ttotal: 42s\tremaining: 1m 25s\n",
      "165:\tlearn: 0.9912642\ttotal: 42.3s\tremaining: 1m 25s\n",
      "166:\tlearn: 0.9915629\ttotal: 42.5s\tremaining: 1m 24s\n",
      "167:\tlearn: 0.9918618\ttotal: 42.8s\tremaining: 1m 24s\n",
      "168:\tlearn: 0.9920611\ttotal: 43s\tremaining: 1m 24s\n",
      "169:\tlearn: 0.9926596\ttotal: 43.3s\tremaining: 1m 24s\n",
      "170:\tlearn: 0.9926596\ttotal: 43.5s\tremaining: 1m 23s\n",
      "171:\tlearn: 0.9929592\ttotal: 43.8s\tremaining: 1m 23s\n",
      "172:\tlearn: 0.9931590\ttotal: 44s\tremaining: 1m 23s\n",
      "173:\tlearn: 0.9928600\ttotal: 44.3s\tremaining: 1m 22s\n",
      "174:\tlearn: 0.9930597\ttotal: 44.5s\tremaining: 1m 22s\n",
      "175:\tlearn: 0.9937601\ttotal: 44.8s\tremaining: 1m 22s\n",
      "176:\tlearn: 0.9941603\ttotal: 45s\tremaining: 1m 22s\n",
      "177:\tlearn: 0.9942604\ttotal: 45.3s\tremaining: 1m 21s\n",
      "178:\tlearn: 0.9943605\ttotal: 45.5s\tremaining: 1m 21s\n",
      "179:\tlearn: 0.9946605\ttotal: 45.8s\tremaining: 1m 21s\n",
      "180:\tlearn: 0.9946605\ttotal: 46s\tremaining: 1m 21s\n",
      "181:\tlearn: 0.9948609\ttotal: 46.3s\tremaining: 1m 20s\n",
      "182:\tlearn: 0.9947612\ttotal: 46.5s\tremaining: 1m 20s\n",
      "183:\tlearn: 0.9954633\ttotal: 46.8s\tremaining: 1m 20s\n",
      "184:\tlearn: 0.9956640\ttotal: 47s\tremaining: 1m 20s\n",
      "185:\tlearn: 0.9959657\ttotal: 47.3s\tremaining: 1m 19s\n",
      "186:\tlearn: 0.9959657\ttotal: 47.6s\tremaining: 1m 19s\n",
      "187:\tlearn: 0.9960662\ttotal: 47.8s\tremaining: 1m 19s\n",
      "188:\tlearn: 0.9958657\ttotal: 48.1s\tremaining: 1m 19s\n",
      "189:\tlearn: 0.9959661\ttotal: 48.3s\tremaining: 1m 18s\n",
      "190:\tlearn: 0.9962675\ttotal: 48.6s\tremaining: 1m 18s\n",
      "191:\tlearn: 0.9964686\ttotal: 48.8s\tremaining: 1m 18s\n",
      "192:\tlearn: 0.9964686\ttotal: 49.1s\tremaining: 1m 18s\n",
      "193:\tlearn: 0.9964686\ttotal: 49.3s\tremaining: 1m 17s\n",
      "194:\tlearn: 0.9964686\ttotal: 49.6s\tremaining: 1m 17s\n",
      "195:\tlearn: 0.9966697\ttotal: 49.8s\tremaining: 1m 17s\n",
      "196:\tlearn: 0.9966697\ttotal: 50.1s\tremaining: 1m 17s\n",
      "197:\tlearn: 0.9967703\ttotal: 50.3s\tremaining: 1m 16s\n",
      "198:\tlearn: 0.9966700\ttotal: 50.6s\tremaining: 1m 16s\n",
      "199:\tlearn: 0.9968712\ttotal: 50.8s\tremaining: 1m 16s\n",
      "200:\tlearn: 0.9968712\ttotal: 51.1s\tremaining: 1m 16s\n",
      "201:\tlearn: 0.9967709\ttotal: 51.4s\tremaining: 1m 15s\n",
      "202:\tlearn: 0.9968715\ttotal: 51.6s\tremaining: 1m 15s\n",
      "203:\tlearn: 0.9967709\ttotal: 51.9s\tremaining: 1m 15s\n",
      "204:\tlearn: 0.9967709\ttotal: 52.1s\tremaining: 1m 15s\n",
      "205:\tlearn: 0.9970728\ttotal: 52.4s\tremaining: 1m 14s\n",
      "206:\tlearn: 0.9974753\ttotal: 52.6s\tremaining: 1m 14s\n",
      "207:\tlearn: 0.9976768\ttotal: 52.9s\tremaining: 1m 14s\n",
      "208:\tlearn: 0.9976770\ttotal: 53.1s\tremaining: 1m 13s\n",
      "209:\tlearn: 0.9975762\ttotal: 53.4s\tremaining: 1m 13s\n",
      "210:\tlearn: 0.9976768\ttotal: 53.7s\tremaining: 1m 13s\n",
      "211:\tlearn: 0.9976768\ttotal: 53.9s\tremaining: 1m 13s\n",
      "212:\tlearn: 0.9977778\ttotal: 54.2s\tremaining: 1m 12s\n",
      "213:\tlearn: 0.9977778\ttotal: 54.4s\tremaining: 1m 12s\n",
      "214:\tlearn: 0.9977778\ttotal: 54.7s\tremaining: 1m 12s\n",
      "215:\tlearn: 0.9978786\ttotal: 54.9s\tremaining: 1m 12s\n",
      "216:\tlearn: 0.9977778\ttotal: 55.2s\tremaining: 1m 11s\n",
      "217:\tlearn: 0.9977778\ttotal: 55.4s\tremaining: 1m 11s\n",
      "218:\tlearn: 0.9977778\ttotal: 55.7s\tremaining: 1m 11s\n",
      "219:\tlearn: 0.9979794\ttotal: 55.9s\tremaining: 1m 11s\n",
      "220:\tlearn: 0.9981811\ttotal: 56.2s\tremaining: 1m 10s\n",
      "221:\tlearn: 0.9981811\ttotal: 56.4s\tremaining: 1m 10s\n",
      "222:\tlearn: 0.9981811\ttotal: 56.7s\tremaining: 1m 10s\n",
      "223:\tlearn: 0.9982820\ttotal: 56.9s\tremaining: 1m 10s\n",
      "224:\tlearn: 0.9983829\ttotal: 57.2s\tremaining: 1m 9s\n",
      "225:\tlearn: 0.9983829\ttotal: 57.5s\tremaining: 1m 9s\n",
      "226:\tlearn: 0.9983829\ttotal: 57.7s\tremaining: 1m 9s\n",
      "227:\tlearn: 0.9983829\ttotal: 58s\tremaining: 1m 9s\n",
      "228:\tlearn: 0.9983829\ttotal: 58.2s\tremaining: 1m 8s\n",
      "229:\tlearn: 0.9984838\ttotal: 58.5s\tremaining: 1m 8s\n",
      "230:\tlearn: 0.9983829\ttotal: 58.7s\tremaining: 1m 8s\n",
      "231:\tlearn: 0.9984838\ttotal: 59s\tremaining: 1m 8s\n",
      "232:\tlearn: 0.9985847\ttotal: 59.3s\tremaining: 1m 7s\n",
      "233:\tlearn: 0.9985847\ttotal: 59.5s\tremaining: 1m 7s\n",
      "234:\tlearn: 0.9986857\ttotal: 59.8s\tremaining: 1m 7s\n",
      "235:\tlearn: 0.9985847\ttotal: 1m\tremaining: 1m 7s\n",
      "236:\tlearn: 0.9986857\ttotal: 1m\tremaining: 1m 6s\n",
      "237:\tlearn: 0.9986857\ttotal: 1m\tremaining: 1m 6s\n",
      "238:\tlearn: 0.9987867\ttotal: 1m\tremaining: 1m 6s\n",
      "239:\tlearn: 0.9986857\ttotal: 1m 1s\tremaining: 1m 6s\n",
      "240:\tlearn: 0.9986857\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "241:\tlearn: 0.9987867\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "242:\tlearn: 0.9988877\ttotal: 1m 1s\tremaining: 1m 5s\n",
      "243:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 5s\n",
      "244:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "245:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "246:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 4s\n",
      "247:\tlearn: 0.9989887\ttotal: 1m 3s\tremaining: 1m 4s\n",
      "248:\tlearn: 0.9990897\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "249:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "250:\tlearn: 0.9991908\ttotal: 1m 3s\tremaining: 1m 3s\n",
      "251:\tlearn: 0.9990897\ttotal: 1m 4s\tremaining: 1m 3s\n",
      "252:\tlearn: 0.9990897\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "253:\tlearn: 0.9991908\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "254:\tlearn: 0.9990897\ttotal: 1m 4s\tremaining: 1m 2s\n",
      "255:\tlearn: 0.9990897\ttotal: 1m 5s\tremaining: 1m 2s\n",
      "256:\tlearn: 0.9989887\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "257:\tlearn: 0.9989887\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "258:\tlearn: 0.9990897\ttotal: 1m 5s\tremaining: 1m 1s\n",
      "259:\tlearn: 0.9991908\ttotal: 1m 6s\tremaining: 1m\n",
      "260:\tlearn: 0.9990897\ttotal: 1m 6s\tremaining: 1m\n",
      "261:\tlearn: 0.9990897\ttotal: 1m 6s\tremaining: 1m\n",
      "262:\tlearn: 0.9991908\ttotal: 1m 6s\tremaining: 1m\n",
      "263:\tlearn: 0.9991908\ttotal: 1m 7s\tremaining: 60s\n",
      "264:\tlearn: 0.9991908\ttotal: 1m 7s\tremaining: 59.7s\n",
      "265:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 59.5s\n",
      "266:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 59.2s\n",
      "267:\tlearn: 0.9991908\ttotal: 1m 8s\tremaining: 59s\n",
      "268:\tlearn: 0.9991908\ttotal: 1m 8s\tremaining: 58.7s\n",
      "269:\tlearn: 0.9992919\ttotal: 1m 8s\tremaining: 58.4s\n",
      "270:\tlearn: 0.9993930\ttotal: 1m 8s\tremaining: 58.2s\n",
      "271:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 57.9s\n",
      "272:\tlearn: 0.9994941\ttotal: 1m 9s\tremaining: 57.7s\n",
      "273:\tlearn: 0.9994941\ttotal: 1m 9s\tremaining: 57.4s\n",
      "274:\tlearn: 0.9994941\ttotal: 1m 9s\tremaining: 57.2s\n",
      "275:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.9s\n",
      "276:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.6s\n",
      "277:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.4s\n",
      "278:\tlearn: 0.9994941\ttotal: 1m 10s\tremaining: 56.1s\n",
      "279:\tlearn: 0.9995952\ttotal: 1m 11s\tremaining: 55.9s\n",
      "280:\tlearn: 0.9995952\ttotal: 1m 11s\tremaining: 55.6s\n",
      "281:\tlearn: 0.9995952\ttotal: 1m 11s\tremaining: 55.4s\n",
      "282:\tlearn: 0.9994941\ttotal: 1m 11s\tremaining: 55.1s\n",
      "283:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 54.9s\n",
      "284:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 54.6s\n",
      "285:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 54.3s\n",
      "286:\tlearn: 0.9996964\ttotal: 1m 12s\tremaining: 54.1s\n",
      "287:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.8s\n",
      "288:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.6s\n",
      "289:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.3s\n",
      "290:\tlearn: 0.9996964\ttotal: 1m 13s\tremaining: 53.1s\n",
      "291:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 52.8s\n",
      "292:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 52.6s\n",
      "293:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 52.3s\n",
      "294:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 52.1s\n",
      "295:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51.8s\n",
      "296:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51.5s\n",
      "297:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51.3s\n",
      "298:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 51s\n",
      "299:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50.8s\n",
      "300:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50.5s\n",
      "301:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50.3s\n",
      "302:\tlearn: 0.9996964\ttotal: 1m 16s\tremaining: 50s\n",
      "303:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49.8s\n",
      "304:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49.5s\n",
      "305:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49.3s\n",
      "306:\tlearn: 0.9996964\ttotal: 1m 17s\tremaining: 49s\n",
      "307:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 48.7s\n",
      "308:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 48.5s\n",
      "309:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 48.2s\n",
      "310:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 48s\n",
      "311:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 47.7s\n",
      "312:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 47.5s\n",
      "313:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 47.2s\n",
      "314:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 47s\n",
      "315:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 46.7s\n",
      "316:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 46.4s\n",
      "317:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 46.2s\n",
      "318:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 45.9s\n",
      "319:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 45.7s\n",
      "320:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 45.4s\n",
      "321:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 45.2s\n",
      "322:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 44.9s\n",
      "323:\tlearn: 0.9996964\ttotal: 1m 22s\tremaining: 44.7s\n",
      "324:\tlearn: 0.9996964\ttotal: 1m 22s\tremaining: 44.4s\n",
      "325:\tlearn: 0.9996964\ttotal: 1m 22s\tremaining: 44.2s\n",
      "326:\tlearn: 0.9996964\ttotal: 1m 22s\tremaining: 43.9s\n",
      "327:\tlearn: 0.9996964\ttotal: 1m 23s\tremaining: 43.6s\n",
      "328:\tlearn: 0.9996964\ttotal: 1m 23s\tremaining: 43.4s\n",
      "329:\tlearn: 0.9996964\ttotal: 1m 23s\tremaining: 43.1s\n",
      "330:\tlearn: 0.9996964\ttotal: 1m 23s\tremaining: 42.9s\n",
      "331:\tlearn: 0.9996964\ttotal: 1m 24s\tremaining: 42.6s\n",
      "332:\tlearn: 0.9996964\ttotal: 1m 24s\tremaining: 42.4s\n",
      "333:\tlearn: 0.9996964\ttotal: 1m 24s\tremaining: 42.1s\n",
      "334:\tlearn: 0.9996964\ttotal: 1m 25s\tremaining: 41.9s\n",
      "335:\tlearn: 0.9996964\ttotal: 1m 25s\tremaining: 41.6s\n",
      "336:\tlearn: 0.9996964\ttotal: 1m 25s\tremaining: 41.4s\n",
      "337:\tlearn: 0.9996964\ttotal: 1m 25s\tremaining: 41.1s\n",
      "338:\tlearn: 0.9996964\ttotal: 1m 26s\tremaining: 40.9s\n",
      "339:\tlearn: 0.9996964\ttotal: 1m 26s\tremaining: 40.6s\n",
      "340:\tlearn: 0.9996964\ttotal: 1m 26s\tremaining: 40.3s\n",
      "341:\tlearn: 0.9996964\ttotal: 1m 26s\tremaining: 40.1s\n",
      "342:\tlearn: 0.9996964\ttotal: 1m 27s\tremaining: 39.8s\n",
      "343:\tlearn: 0.9996964\ttotal: 1m 27s\tremaining: 39.6s\n",
      "344:\tlearn: 0.9996964\ttotal: 1m 27s\tremaining: 39.3s\n",
      "345:\tlearn: 0.9996964\ttotal: 1m 27s\tremaining: 39.1s\n",
      "346:\tlearn: 0.9996964\ttotal: 1m 28s\tremaining: 38.8s\n",
      "347:\tlearn: 0.9996964\ttotal: 1m 28s\tremaining: 38.6s\n",
      "348:\tlearn: 0.9996964\ttotal: 1m 28s\tremaining: 38.3s\n",
      "349:\tlearn: 0.9996964\ttotal: 1m 28s\tremaining: 38.1s\n",
      "350:\tlearn: 0.9996964\ttotal: 1m 29s\tremaining: 37.8s\n",
      "351:\tlearn: 0.9996964\ttotal: 1m 29s\tremaining: 37.6s\n",
      "352:\tlearn: 0.9996964\ttotal: 1m 29s\tremaining: 37.3s\n",
      "353:\tlearn: 0.9996964\ttotal: 1m 29s\tremaining: 37s\n",
      "354:\tlearn: 0.9996964\ttotal: 1m 30s\tremaining: 36.8s\n",
      "355:\tlearn: 0.9996964\ttotal: 1m 30s\tremaining: 36.5s\n",
      "356:\tlearn: 0.9996964\ttotal: 1m 30s\tremaining: 36.3s\n",
      "357:\tlearn: 0.9996964\ttotal: 1m 30s\tremaining: 36s\n",
      "358:\tlearn: 0.9996964\ttotal: 1m 31s\tremaining: 35.8s\n",
      "359:\tlearn: 0.9996964\ttotal: 1m 31s\tremaining: 35.5s\n",
      "360:\tlearn: 0.9996964\ttotal: 1m 31s\tremaining: 35.3s\n",
      "361:\tlearn: 0.9996964\ttotal: 1m 31s\tremaining: 35s\n",
      "362:\tlearn: 0.9996964\ttotal: 1m 32s\tremaining: 34.8s\n",
      "363:\tlearn: 0.9996964\ttotal: 1m 32s\tremaining: 34.5s\n",
      "364:\tlearn: 0.9996964\ttotal: 1m 32s\tremaining: 34.3s\n",
      "365:\tlearn: 0.9996964\ttotal: 1m 32s\tremaining: 34s\n",
      "366:\tlearn: 0.9996964\ttotal: 1m 33s\tremaining: 33.8s\n",
      "367:\tlearn: 0.9996964\ttotal: 1m 33s\tremaining: 33.5s\n",
      "368:\tlearn: 0.9996964\ttotal: 1m 33s\tremaining: 33.3s\n",
      "369:\tlearn: 0.9996964\ttotal: 1m 33s\tremaining: 33s\n",
      "370:\tlearn: 0.9996964\ttotal: 1m 34s\tremaining: 32.8s\n",
      "371:\tlearn: 0.9996964\ttotal: 1m 34s\tremaining: 32.5s\n",
      "372:\tlearn: 0.9996964\ttotal: 1m 34s\tremaining: 32.3s\n",
      "373:\tlearn: 0.9997976\ttotal: 1m 34s\tremaining: 32s\n",
      "374:\tlearn: 0.9997976\ttotal: 1m 35s\tremaining: 31.7s\n",
      "375:\tlearn: 0.9997976\ttotal: 1m 35s\tremaining: 31.5s\n",
      "376:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 31.2s\n",
      "377:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 31s\n",
      "378:\tlearn: 0.9997976\ttotal: 1m 36s\tremaining: 30.7s\n",
      "379:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 30.5s\n",
      "380:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 30.2s\n",
      "381:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 30s\n",
      "382:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 29.7s\n",
      "383:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 29.5s\n",
      "384:\tlearn: 1.0000000\ttotal: 1m 37s\tremaining: 29.2s\n",
      "385:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 29s\n",
      "386:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.7s\n",
      "387:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.4s\n",
      "388:\tlearn: 1.0000000\ttotal: 1m 38s\tremaining: 28.2s\n",
      "389:\tlearn: 1.0000000\ttotal: 1m 39s\tremaining: 27.9s\n",
      "390:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 27.7s\n",
      "391:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 27.4s\n",
      "392:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 27.2s\n",
      "393:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 26.9s\n",
      "394:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 26.7s\n",
      "395:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 26.4s\n",
      "396:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 26.2s\n",
      "397:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.9s\n",
      "398:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.6s\n",
      "399:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.4s\n",
      "400:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 25.1s\n",
      "401:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 24.9s\n",
      "402:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 24.6s\n",
      "403:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.4s\n",
      "404:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 24.1s\n",
      "405:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.9s\n",
      "406:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.6s\n",
      "407:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.4s\n",
      "408:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 23.1s\n",
      "409:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.9s\n",
      "410:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.6s\n",
      "411:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.4s\n",
      "412:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 22.1s\n",
      "413:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.9s\n",
      "414:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.6s\n",
      "415:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.3s\n",
      "416:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 21.1s\n",
      "417:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.8s\n",
      "418:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.6s\n",
      "419:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.3s\n",
      "420:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 20.1s\n",
      "421:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.8s\n",
      "422:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.6s\n",
      "423:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 19.3s\n",
      "424:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 19.1s\n",
      "425:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.8s\n",
      "426:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.6s\n",
      "427:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 18.3s\n",
      "428:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 18s\n",
      "429:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.8s\n",
      "430:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.5s\n",
      "431:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 17.3s\n",
      "432:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 17s\n",
      "433:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.8s\n",
      "434:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.5s\n",
      "435:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 16.3s\n",
      "436:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 16s\n",
      "437:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.8s\n",
      "438:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.5s\n",
      "439:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 15.2s\n",
      "440:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 15s\n",
      "441:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.7s\n",
      "442:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.5s\n",
      "443:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 14.2s\n",
      "444:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 14s\n",
      "445:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.7s\n",
      "446:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.5s\n",
      "447:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 13.2s\n",
      "448:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 13s\n",
      "449:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.7s\n",
      "450:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.5s\n",
      "451:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 12.2s\n",
      "452:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.9s\n",
      "453:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.7s\n",
      "454:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.4s\n",
      "455:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 11.2s\n",
      "456:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.9s\n",
      "457:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.7s\n",
      "458:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.4s\n",
      "459:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 10.2s\n",
      "460:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.91s\n",
      "461:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.66s\n",
      "462:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.41s\n",
      "463:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 9.15s\n",
      "464:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.9s\n",
      "465:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.64s\n",
      "466:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 8.39s\n",
      "467:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 8.14s\n",
      "468:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.88s\n",
      "469:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.63s\n",
      "470:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 7.38s\n",
      "471:\tlearn: 1.0000000\ttotal: 2m\tremaining: 7.12s\n",
      "472:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.87s\n",
      "473:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.61s\n",
      "474:\tlearn: 1.0000000\ttotal: 2m\tremaining: 6.36s\n",
      "475:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 6.11s\n",
      "476:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.85s\n",
      "477:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.6s\n",
      "478:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 5.34s\n",
      "479:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 5.09s\n",
      "480:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.83s\n",
      "481:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.58s\n",
      "482:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 4.33s\n",
      "483:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 4.07s\n",
      "484:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.82s\n",
      "485:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.56s\n",
      "486:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 3.31s\n",
      "487:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 3.05s\n",
      "488:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.8s\n",
      "489:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.54s\n",
      "490:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 2.29s\n",
      "491:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 2.04s\n",
      "492:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.78s\n",
      "493:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.53s\n",
      "494:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 1.27s\n",
      "495:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 1.02s\n",
      "496:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 763ms\n",
      "497:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 509ms\n",
      "498:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 254ms\n",
      "499:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=96, depth=9, eval_metric=Precision, iterations=500, l2_leaf_reg=1, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=1; total time= 2.1min\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=1, border_count=32, depth=7, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=2; total time=   0.0s\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=1, border_count=32, depth=7, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=2; total time=   0.0s\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=1, border_count=32, depth=7, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=2; total time=   0.0s\n",
      "0:\tlearn: 0.5547682\ttotal: 47.6ms\tremaining: 28.5s\n",
      "1:\tlearn: 0.6044746\ttotal: 94ms\tremaining: 28.1s\n",
      "2:\tlearn: 0.5868597\ttotal: 140ms\tremaining: 27.9s\n",
      "3:\tlearn: 0.6139907\ttotal: 186ms\tremaining: 27.8s\n",
      "4:\tlearn: 0.6481069\ttotal: 233ms\tremaining: 27.8s\n",
      "5:\tlearn: 0.6589391\ttotal: 276ms\tremaining: 27.3s\n",
      "6:\tlearn: 0.6590403\ttotal: 317ms\tremaining: 26.9s\n",
      "7:\tlearn: 0.6506378\ttotal: 360ms\tremaining: 26.7s\n",
      "8:\tlearn: 0.6575218\ttotal: 404ms\tremaining: 26.6s\n",
      "9:\tlearn: 0.6580279\ttotal: 449ms\tremaining: 26.5s\n",
      "10:\tlearn: 0.6587366\ttotal: 496ms\tremaining: 26.5s\n",
      "11:\tlearn: 0.6603563\ttotal: 542ms\tremaining: 26.6s\n",
      "12:\tlearn: 0.6654181\ttotal: 588ms\tremaining: 26.5s\n",
      "13:\tlearn: 0.6677465\ttotal: 632ms\tremaining: 26.4s\n",
      "14:\tlearn: 0.6647095\ttotal: 678ms\tremaining: 26.4s\n",
      "15:\tlearn: 0.6604576\ttotal: 722ms\tremaining: 26.3s\n",
      "16:\tlearn: 0.6660255\ttotal: 769ms\tremaining: 26.4s\n",
      "17:\tlearn: 0.6678477\ttotal: 810ms\tremaining: 26.2s\n",
      "18:\tlearn: 0.6707836\ttotal: 857ms\tremaining: 26.2s\n",
      "19:\tlearn: 0.6666329\ttotal: 906ms\tremaining: 26.3s\n",
      "20:\tlearn: 0.6690626\ttotal: 952ms\tremaining: 26.2s\n",
      "21:\tlearn: 0.6693663\ttotal: 998ms\tremaining: 26.2s\n",
      "22:\tlearn: 0.6699737\ttotal: 1.04s\tremaining: 26.2s\n",
      "23:\tlearn: 0.6665317\ttotal: 1.09s\tremaining: 26.1s\n",
      "24:\tlearn: 0.6706823\ttotal: 1.13s\tremaining: 26s\n",
      "25:\tlearn: 0.6888034\ttotal: 1.18s\tremaining: 26s\n",
      "26:\tlearn: 0.6895120\ttotal: 1.22s\tremaining: 25.9s\n",
      "27:\tlearn: 0.6918405\ttotal: 1.26s\tremaining: 25.8s\n",
      "28:\tlearn: 0.6931565\ttotal: 1.31s\tremaining: 25.8s\n",
      "29:\tlearn: 0.6891071\ttotal: 1.35s\tremaining: 25.6s\n",
      "30:\tlearn: 0.6902207\ttotal: 1.39s\tremaining: 25.6s\n",
      "31:\tlearn: 0.6914355\ttotal: 1.44s\tremaining: 25.5s\n",
      "32:\tlearn: 0.6928528\ttotal: 1.49s\tremaining: 25.5s\n",
      "33:\tlearn: 0.6951812\ttotal: 1.53s\tremaining: 25.5s\n",
      "34:\tlearn: 0.6981170\ttotal: 1.58s\tremaining: 25.5s\n",
      "35:\tlearn: 0.6972059\ttotal: 1.62s\tremaining: 25.4s\n",
      "36:\tlearn: 0.7034825\ttotal: 1.66s\tremaining: 25.3s\n",
      "37:\tlearn: 0.7031788\ttotal: 1.71s\tremaining: 25.3s\n",
      "38:\tlearn: 0.7025714\ttotal: 1.75s\tremaining: 25.2s\n",
      "39:\tlearn: 0.7045961\ttotal: 1.8s\tremaining: 25.2s\n",
      "40:\tlearn: 0.7056084\ttotal: 1.84s\tremaining: 25.1s\n",
      "41:\tlearn: 0.7068232\ttotal: 1.89s\tremaining: 25.1s\n",
      "42:\tlearn: 0.7095566\ttotal: 1.93s\tremaining: 25s\n",
      "43:\tlearn: 0.7164406\ttotal: 1.98s\tremaining: 25s\n",
      "44:\tlearn: 0.7150233\ttotal: 2.02s\tremaining: 24.9s\n",
      "45:\tlearn: 0.7163393\ttotal: 2.06s\tremaining: 24.9s\n",
      "46:\tlearn: 0.7191739\ttotal: 2.11s\tremaining: 24.8s\n",
      "47:\tlearn: 0.7211986\ttotal: 2.15s\tremaining: 24.8s\n",
      "48:\tlearn: 0.7206924\ttotal: 2.19s\tremaining: 24.7s\n",
      "49:\tlearn: 0.7205912\ttotal: 2.24s\tremaining: 24.6s\n",
      "50:\tlearn: 0.7190727\ttotal: 2.29s\tremaining: 24.6s\n",
      "51:\tlearn: 0.7212999\ttotal: 2.33s\tremaining: 24.5s\n",
      "52:\tlearn: 0.7214011\ttotal: 2.38s\tremaining: 24.5s\n",
      "53:\tlearn: 0.7235270\ttotal: 2.42s\tremaining: 24.5s\n",
      "54:\tlearn: 0.7209962\ttotal: 2.46s\tremaining: 24.4s\n",
      "55:\tlearn: 0.7220085\ttotal: 2.51s\tremaining: 24.4s\n",
      "56:\tlearn: 0.7234258\ttotal: 2.56s\tremaining: 24.4s\n",
      "57:\tlearn: 0.7214011\ttotal: 2.6s\tremaining: 24.3s\n",
      "58:\tlearn: 0.7221097\ttotal: 2.65s\tremaining: 24.3s\n",
      "59:\tlearn: 0.7243369\ttotal: 2.69s\tremaining: 24.2s\n",
      "60:\tlearn: 0.7266653\ttotal: 2.73s\tremaining: 24.2s\n",
      "61:\tlearn: 0.7283863\ttotal: 2.78s\tremaining: 24.1s\n",
      "62:\tlearn: 0.7284875\ttotal: 2.82s\tremaining: 24.1s\n",
      "63:\tlearn: 0.7328407\ttotal: 2.87s\tremaining: 24.1s\n",
      "64:\tlearn: 0.7327394\ttotal: 2.92s\tremaining: 24s\n",
      "65:\tlearn: 0.7332456\ttotal: 2.96s\tremaining: 24s\n",
      "66:\tlearn: 0.7368901\ttotal: 3.01s\tremaining: 23.9s\n",
      "67:\tlearn: 0.7373962\ttotal: 3.05s\tremaining: 23.9s\n",
      "68:\tlearn: 0.7378012\ttotal: 3.09s\tremaining: 23.8s\n",
      "69:\tlearn: 0.7376999\ttotal: 3.14s\tremaining: 23.8s\n",
      "70:\tlearn: 0.7372950\ttotal: 3.18s\tremaining: 23.7s\n",
      "71:\tlearn: 0.7359789\ttotal: 3.23s\tremaining: 23.7s\n",
      "72:\tlearn: 0.7394209\ttotal: 3.27s\tremaining: 23.6s\n",
      "73:\tlearn: 0.7380036\ttotal: 3.32s\tremaining: 23.6s\n",
      "74:\tlearn: 0.7385098\ttotal: 3.36s\tremaining: 23.5s\n",
      "75:\tlearn: 0.7408382\ttotal: 3.41s\tremaining: 23.5s\n",
      "76:\tlearn: 0.7411419\ttotal: 3.45s\tremaining: 23.4s\n",
      "77:\tlearn: 0.7382061\ttotal: 3.5s\tremaining: 23.4s\n",
      "78:\tlearn: 0.7419518\ttotal: 3.54s\tremaining: 23.3s\n",
      "79:\tlearn: 0.7425592\ttotal: 3.58s\tremaining: 23.3s\n",
      "80:\tlearn: 0.7422555\ttotal: 3.63s\tremaining: 23.2s\n",
      "81:\tlearn: 0.7432679\ttotal: 3.67s\tremaining: 23.2s\n",
      "82:\tlearn: 0.7464062\ttotal: 3.72s\tremaining: 23.2s\n",
      "83:\tlearn: 0.7451913\ttotal: 3.76s\tremaining: 23.1s\n",
      "84:\tlearn: 0.7443815\ttotal: 3.8s\tremaining: 23s\n",
      "85:\tlearn: 0.7450901\ttotal: 3.85s\tremaining: 23s\n",
      "86:\tlearn: 0.7464062\ttotal: 3.89s\tremaining: 23s\n",
      "87:\tlearn: 0.7452926\ttotal: 3.94s\tremaining: 22.9s\n",
      "88:\tlearn: 0.7472160\ttotal: 3.98s\tremaining: 22.8s\n",
      "89:\tlearn: 0.7480259\ttotal: 4.03s\tremaining: 22.8s\n",
      "90:\tlearn: 0.7487346\ttotal: 4.07s\tremaining: 22.8s\n",
      "91:\tlearn: 0.7520753\ttotal: 4.12s\tremaining: 22.7s\n",
      "92:\tlearn: 0.7533914\ttotal: 4.16s\tremaining: 22.7s\n",
      "93:\tlearn: 0.7518728\ttotal: 4.21s\tremaining: 22.7s\n",
      "94:\tlearn: 0.7537963\ttotal: 4.25s\tremaining: 22.6s\n",
      "95:\tlearn: 0.7536951\ttotal: 4.3s\tremaining: 22.6s\n",
      "96:\tlearn: 0.7536951\ttotal: 4.34s\tremaining: 22.5s\n",
      "97:\tlearn: 0.7550111\ttotal: 4.38s\tremaining: 22.5s\n",
      "98:\tlearn: 0.7555173\ttotal: 4.43s\tremaining: 22.4s\n",
      "99:\tlearn: 0.7567321\ttotal: 4.47s\tremaining: 22.4s\n",
      "100:\tlearn: 0.7551124\ttotal: 4.53s\tremaining: 22.4s\n",
      "101:\tlearn: 0.7566309\ttotal: 4.57s\tremaining: 22.3s\n",
      "102:\tlearn: 0.7574408\ttotal: 4.62s\tremaining: 22.3s\n",
      "103:\tlearn: 0.7569346\ttotal: 4.66s\tremaining: 22.2s\n",
      "104:\tlearn: 0.7575420\ttotal: 4.71s\tremaining: 22.2s\n",
      "105:\tlearn: 0.7590605\ttotal: 4.75s\tremaining: 22.1s\n",
      "106:\tlearn: 0.7610852\ttotal: 4.79s\tremaining: 22.1s\n",
      "107:\tlearn: 0.7609840\ttotal: 4.84s\tremaining: 22s\n",
      "108:\tlearn: 0.7611865\ttotal: 4.88s\tremaining: 22s\n",
      "109:\tlearn: 0.7632112\ttotal: 4.93s\tremaining: 22s\n",
      "110:\tlearn: 0.7640211\ttotal: 4.97s\tremaining: 21.9s\n",
      "111:\tlearn: 0.7647297\ttotal: 5.01s\tremaining: 21.8s\n",
      "112:\tlearn: 0.7659445\ttotal: 5.05s\tremaining: 21.8s\n",
      "113:\tlearn: 0.7656408\ttotal: 5.1s\tremaining: 21.7s\n",
      "114:\tlearn: 0.7670581\ttotal: 5.14s\tremaining: 21.7s\n",
      "115:\tlearn: 0.7675643\ttotal: 5.19s\tremaining: 21.6s\n",
      "116:\tlearn: 0.7670581\ttotal: 5.23s\tremaining: 21.6s\n",
      "117:\tlearn: 0.7672606\ttotal: 5.28s\tremaining: 21.6s\n",
      "118:\tlearn: 0.7664507\ttotal: 5.32s\tremaining: 21.5s\n",
      "119:\tlearn: 0.7658433\ttotal: 5.37s\tremaining: 21.5s\n",
      "120:\tlearn: 0.7685766\ttotal: 5.42s\tremaining: 21.4s\n",
      "121:\tlearn: 0.7688803\ttotal: 5.46s\tremaining: 21.4s\n",
      "122:\tlearn: 0.7691840\ttotal: 5.51s\tremaining: 21.4s\n",
      "123:\tlearn: 0.7695890\ttotal: 5.55s\tremaining: 21.3s\n",
      "124:\tlearn: 0.7689816\ttotal: 5.59s\tremaining: 21.2s\n",
      "125:\tlearn: 0.7688803\ttotal: 5.63s\tremaining: 21.2s\n",
      "126:\tlearn: 0.7701964\ttotal: 5.68s\tremaining: 21.2s\n",
      "127:\tlearn: 0.7708038\ttotal: 5.72s\tremaining: 21.1s\n",
      "128:\tlearn: 0.7706013\ttotal: 5.76s\tremaining: 21s\n",
      "129:\tlearn: 0.7712087\ttotal: 5.8s\tremaining: 21s\n",
      "130:\tlearn: 0.7714112\ttotal: 5.86s\tremaining: 21s\n",
      "131:\tlearn: 0.7714112\ttotal: 5.9s\tremaining: 20.9s\n",
      "132:\tlearn: 0.7720186\ttotal: 5.95s\tremaining: 20.9s\n",
      "133:\tlearn: 0.7723223\ttotal: 5.99s\tremaining: 20.8s\n",
      "134:\tlearn: 0.7736384\ttotal: 6.03s\tremaining: 20.8s\n",
      "135:\tlearn: 0.7734359\ttotal: 6.08s\tremaining: 20.7s\n",
      "136:\tlearn: 0.7736384\ttotal: 6.12s\tremaining: 20.7s\n",
      "137:\tlearn: 0.7739421\ttotal: 6.17s\tremaining: 20.7s\n",
      "138:\tlearn: 0.7743470\ttotal: 6.22s\tremaining: 20.6s\n",
      "139:\tlearn: 0.7744483\ttotal: 6.26s\tremaining: 20.6s\n",
      "140:\tlearn: 0.7745495\ttotal: 6.31s\tremaining: 20.5s\n",
      "141:\tlearn: 0.7756631\ttotal: 6.35s\tremaining: 20.5s\n",
      "142:\tlearn: 0.7772829\ttotal: 6.4s\tremaining: 20.5s\n",
      "143:\tlearn: 0.7780927\ttotal: 6.44s\tremaining: 20.4s\n",
      "144:\tlearn: 0.7787001\ttotal: 6.49s\tremaining: 20.4s\n",
      "145:\tlearn: 0.7790038\ttotal: 6.53s\tremaining: 20.3s\n",
      "146:\tlearn: 0.7796113\ttotal: 6.58s\tremaining: 20.3s\n",
      "147:\tlearn: 0.7791051\ttotal: 6.62s\tremaining: 20.2s\n",
      "148:\tlearn: 0.7799150\ttotal: 6.66s\tremaining: 20.1s\n",
      "149:\tlearn: 0.7806236\ttotal: 6.71s\tremaining: 20.1s\n",
      "150:\tlearn: 0.7807248\ttotal: 6.75s\tremaining: 20.1s\n",
      "151:\tlearn: 0.7822434\ttotal: 6.8s\tremaining: 20s\n",
      "152:\tlearn: 0.7825471\ttotal: 6.84s\tremaining: 20s\n",
      "153:\tlearn: 0.7821421\ttotal: 6.88s\tremaining: 19.9s\n",
      "154:\tlearn: 0.7820409\ttotal: 6.93s\tremaining: 19.9s\n",
      "155:\tlearn: 0.7832557\ttotal: 6.97s\tremaining: 19.8s\n",
      "156:\tlearn: 0.7833570\ttotal: 7.02s\tremaining: 19.8s\n",
      "157:\tlearn: 0.7850780\ttotal: 7.07s\tremaining: 19.8s\n",
      "158:\tlearn: 0.7855841\ttotal: 7.12s\tremaining: 19.7s\n",
      "159:\tlearn: 0.7859891\ttotal: 7.17s\tremaining: 19.7s\n",
      "160:\tlearn: 0.7869002\ttotal: 7.21s\tremaining: 19.7s\n",
      "161:\tlearn: 0.7876088\ttotal: 7.26s\tremaining: 19.6s\n",
      "162:\tlearn: 0.7876088\ttotal: 7.3s\tremaining: 19.6s\n",
      "163:\tlearn: 0.7894311\ttotal: 7.35s\tremaining: 19.5s\n",
      "164:\tlearn: 0.7891274\ttotal: 7.39s\tremaining: 19.5s\n",
      "165:\tlearn: 0.7887224\ttotal: 7.44s\tremaining: 19.4s\n",
      "166:\tlearn: 0.7880138\ttotal: 7.48s\tremaining: 19.4s\n",
      "167:\tlearn: 0.7904434\ttotal: 7.52s\tremaining: 19.3s\n",
      "168:\tlearn: 0.7916582\ttotal: 7.57s\tremaining: 19.3s\n",
      "169:\tlearn: 0.7923669\ttotal: 7.61s\tremaining: 19.3s\n",
      "170:\tlearn: 0.7916582\ttotal: 7.65s\tremaining: 19.2s\n",
      "171:\tlearn: 0.7921644\ttotal: 7.7s\tremaining: 19.2s\n",
      "172:\tlearn: 0.7923669\ttotal: 7.75s\tremaining: 19.1s\n",
      "173:\tlearn: 0.7926706\ttotal: 7.79s\tremaining: 19.1s\n",
      "174:\tlearn: 0.7932780\ttotal: 7.83s\tremaining: 19s\n",
      "175:\tlearn: 0.7927718\ttotal: 7.88s\tremaining: 19s\n",
      "176:\tlearn: 0.7937842\ttotal: 7.92s\tremaining: 18.9s\n",
      "177:\tlearn: 0.7957076\ttotal: 7.97s\tremaining: 18.9s\n",
      "178:\tlearn: 0.7965175\ttotal: 8.01s\tremaining: 18.8s\n",
      "179:\tlearn: 0.7966187\ttotal: 8.06s\tremaining: 18.8s\n",
      "180:\tlearn: 0.7969225\ttotal: 8.1s\tremaining: 18.8s\n",
      "181:\tlearn: 0.7958089\ttotal: 8.14s\tremaining: 18.7s\n",
      "182:\tlearn: 0.7974286\ttotal: 8.19s\tremaining: 18.7s\n",
      "183:\tlearn: 0.7993521\ttotal: 8.23s\tremaining: 18.6s\n",
      "184:\tlearn: 0.8000607\ttotal: 8.28s\tremaining: 18.6s\n",
      "185:\tlearn: 0.8019842\ttotal: 8.32s\tremaining: 18.5s\n",
      "186:\tlearn: 0.8023891\ttotal: 8.37s\tremaining: 18.5s\n",
      "187:\tlearn: 0.8015793\ttotal: 8.41s\tremaining: 18.4s\n",
      "188:\tlearn: 0.8037052\ttotal: 8.46s\tremaining: 18.4s\n",
      "189:\tlearn: 0.8030978\ttotal: 8.5s\tremaining: 18.3s\n",
      "190:\tlearn: 0.8026929\ttotal: 8.54s\tremaining: 18.3s\n",
      "191:\tlearn: 0.8029966\ttotal: 8.59s\tremaining: 18.3s\n",
      "192:\tlearn: 0.8037052\ttotal: 8.63s\tremaining: 18.2s\n",
      "193:\tlearn: 0.8050213\ttotal: 8.68s\tremaining: 18.2s\n",
      "194:\tlearn: 0.8069447\ttotal: 8.72s\tremaining: 18.1s\n",
      "195:\tlearn: 0.8083620\ttotal: 8.77s\tremaining: 18.1s\n",
      "196:\tlearn: 0.8052237\ttotal: 8.81s\tremaining: 18s\n",
      "197:\tlearn: 0.8075521\ttotal: 8.85s\tremaining: 18s\n",
      "198:\tlearn: 0.8074509\ttotal: 8.89s\tremaining: 17.9s\n",
      "199:\tlearn: 0.8073497\ttotal: 8.94s\tremaining: 17.9s\n",
      "200:\tlearn: 0.8101842\ttotal: 8.99s\tremaining: 17.8s\n",
      "201:\tlearn: 0.8118040\ttotal: 9.04s\tremaining: 17.8s\n",
      "202:\tlearn: 0.8121077\ttotal: 9.09s\tremaining: 17.8s\n",
      "203:\tlearn: 0.8108929\ttotal: 9.14s\tremaining: 17.7s\n",
      "204:\tlearn: 0.8106904\ttotal: 9.19s\tremaining: 17.7s\n",
      "205:\tlearn: 0.8120065\ttotal: 9.23s\tremaining: 17.7s\n",
      "206:\tlearn: 0.8138287\ttotal: 9.27s\tremaining: 17.6s\n",
      "207:\tlearn: 0.8129176\ttotal: 9.32s\tremaining: 17.6s\n",
      "208:\tlearn: 0.8127151\ttotal: 9.36s\tremaining: 17.5s\n",
      "209:\tlearn: 0.8125127\ttotal: 9.41s\tremaining: 17.5s\n",
      "210:\tlearn: 0.8133225\ttotal: 9.45s\tremaining: 17.4s\n",
      "211:\tlearn: 0.8143349\ttotal: 9.49s\tremaining: 17.4s\n",
      "212:\tlearn: 0.8169670\ttotal: 9.54s\tremaining: 17.3s\n",
      "213:\tlearn: 0.8183843\ttotal: 9.59s\tremaining: 17.3s\n",
      "214:\tlearn: 0.8191942\ttotal: 9.63s\tremaining: 17.2s\n",
      "215:\tlearn: 0.8202065\ttotal: 9.67s\tremaining: 17.2s\n",
      "216:\tlearn: 0.8199028\ttotal: 9.72s\tremaining: 17.2s\n",
      "217:\tlearn: 0.8231423\ttotal: 9.76s\tremaining: 17.1s\n",
      "218:\tlearn: 0.8245596\ttotal: 9.81s\tremaining: 17.1s\n",
      "219:\tlearn: 0.8251670\ttotal: 9.85s\tremaining: 17s\n",
      "220:\tlearn: 0.8259769\ttotal: 9.89s\tremaining: 17s\n",
      "221:\tlearn: 0.8265843\ttotal: 9.94s\tremaining: 16.9s\n",
      "222:\tlearn: 0.8275967\ttotal: 9.98s\tremaining: 16.9s\n",
      "223:\tlearn: 0.8267868\ttotal: 10s\tremaining: 16.8s\n",
      "224:\tlearn: 0.8268880\ttotal: 10.1s\tremaining: 16.8s\n",
      "225:\tlearn: 0.8296214\ttotal: 10.1s\tremaining: 16.7s\n",
      "226:\tlearn: 0.8302288\ttotal: 10.2s\tremaining: 16.7s\n",
      "227:\tlearn: 0.8317473\ttotal: 10.2s\tremaining: 16.6s\n",
      "228:\tlearn: 0.8329621\ttotal: 10.2s\tremaining: 16.6s\n",
      "229:\tlearn: 0.8332658\ttotal: 10.3s\tremaining: 16.6s\n",
      "230:\tlearn: 0.8331646\ttotal: 10.3s\tremaining: 16.5s\n",
      "231:\tlearn: 0.8354930\ttotal: 10.4s\tremaining: 16.5s\n",
      "232:\tlearn: 0.8359992\ttotal: 10.4s\tremaining: 16.4s\n",
      "233:\tlearn: 0.8366066\ttotal: 10.5s\tremaining: 16.4s\n",
      "234:\tlearn: 0.8372140\ttotal: 10.5s\tremaining: 16.3s\n",
      "235:\tlearn: 0.8384288\ttotal: 10.6s\tremaining: 16.3s\n",
      "236:\tlearn: 0.8402511\ttotal: 10.6s\tremaining: 16.2s\n",
      "237:\tlearn: 0.8386313\ttotal: 10.7s\tremaining: 16.2s\n",
      "238:\tlearn: 0.8388338\ttotal: 10.7s\tremaining: 16.2s\n",
      "239:\tlearn: 0.8390362\ttotal: 10.7s\tremaining: 16.1s\n",
      "240:\tlearn: 0.8409597\ttotal: 10.8s\tremaining: 16.1s\n",
      "241:\tlearn: 0.8407572\ttotal: 10.8s\tremaining: 16s\n",
      "242:\tlearn: 0.8428832\ttotal: 10.9s\tremaining: 16s\n",
      "243:\tlearn: 0.8435918\ttotal: 10.9s\tremaining: 15.9s\n",
      "244:\tlearn: 0.8444017\ttotal: 11s\tremaining: 15.9s\n",
      "245:\tlearn: 0.8461227\ttotal: 11s\tremaining: 15.8s\n",
      "246:\tlearn: 0.8471350\ttotal: 11.1s\tremaining: 15.8s\n",
      "247:\tlearn: 0.8479449\ttotal: 11.1s\tremaining: 15.7s\n",
      "248:\tlearn: 0.8487548\ttotal: 11.1s\tremaining: 15.7s\n",
      "249:\tlearn: 0.8523993\ttotal: 11.2s\tremaining: 15.7s\n",
      "250:\tlearn: 0.8528042\ttotal: 11.2s\tremaining: 15.6s\n",
      "251:\tlearn: 0.8546264\ttotal: 11.3s\tremaining: 15.6s\n",
      "252:\tlearn: 0.8540190\ttotal: 11.3s\tremaining: 15.5s\n",
      "253:\tlearn: 0.8545252\ttotal: 11.3s\tremaining: 15.5s\n",
      "254:\tlearn: 0.8547277\ttotal: 11.4s\tremaining: 15.4s\n",
      "255:\tlearn: 0.8558413\ttotal: 11.4s\tremaining: 15.4s\n",
      "256:\tlearn: 0.8557400\ttotal: 11.5s\tremaining: 15.3s\n",
      "257:\tlearn: 0.8561450\ttotal: 11.5s\tremaining: 15.3s\n",
      "258:\tlearn: 0.8564487\ttotal: 11.6s\tremaining: 15.2s\n",
      "259:\tlearn: 0.8567524\ttotal: 11.6s\tremaining: 15.2s\n",
      "260:\tlearn: 0.8564487\ttotal: 11.7s\tremaining: 15.2s\n",
      "261:\tlearn: 0.8590808\ttotal: 11.7s\tremaining: 15.1s\n",
      "262:\tlearn: 0.8596882\ttotal: 11.8s\tremaining: 15.1s\n",
      "263:\tlearn: 0.8597894\ttotal: 11.8s\tremaining: 15s\n",
      "264:\tlearn: 0.8609030\ttotal: 11.9s\tremaining: 15s\n",
      "265:\tlearn: 0.8617129\ttotal: 11.9s\tremaining: 14.9s\n",
      "266:\tlearn: 0.8636364\ttotal: 11.9s\tremaining: 14.9s\n",
      "267:\tlearn: 0.8635351\ttotal: 12s\tremaining: 14.9s\n",
      "268:\tlearn: 0.8637376\ttotal: 12s\tremaining: 14.8s\n",
      "269:\tlearn: 0.8654586\ttotal: 12.1s\tremaining: 14.8s\n",
      "270:\tlearn: 0.8659648\ttotal: 12.1s\tremaining: 14.7s\n",
      "271:\tlearn: 0.8674833\ttotal: 12.2s\tremaining: 14.7s\n",
      "272:\tlearn: 0.8685969\ttotal: 12.2s\tremaining: 14.6s\n",
      "273:\tlearn: 0.8700142\ttotal: 12.3s\tremaining: 14.6s\n",
      "274:\tlearn: 0.8701154\ttotal: 12.3s\tremaining: 14.5s\n",
      "275:\tlearn: 0.8713302\ttotal: 12.3s\tremaining: 14.5s\n",
      "276:\tlearn: 0.8721401\ttotal: 12.4s\tremaining: 14.4s\n",
      "277:\tlearn: 0.8730512\ttotal: 12.4s\tremaining: 14.4s\n",
      "278:\tlearn: 0.8734562\ttotal: 12.5s\tremaining: 14.4s\n",
      "279:\tlearn: 0.8754809\ttotal: 12.5s\tremaining: 14.3s\n",
      "280:\tlearn: 0.8759870\ttotal: 12.6s\tremaining: 14.3s\n",
      "281:\tlearn: 0.8764932\ttotal: 12.6s\tremaining: 14.2s\n",
      "282:\tlearn: 0.8754809\ttotal: 12.6s\tremaining: 14.2s\n",
      "283:\tlearn: 0.8760883\ttotal: 12.7s\tremaining: 14.1s\n",
      "284:\tlearn: 0.8762907\ttotal: 12.7s\tremaining: 14.1s\n",
      "285:\tlearn: 0.8774043\ttotal: 12.8s\tremaining: 14s\n",
      "286:\tlearn: 0.8782142\ttotal: 12.8s\tremaining: 14s\n",
      "287:\tlearn: 0.8775056\ttotal: 12.9s\tremaining: 13.9s\n",
      "288:\tlearn: 0.8782142\ttotal: 12.9s\tremaining: 13.9s\n",
      "289:\tlearn: 0.8795303\ttotal: 13s\tremaining: 13.8s\n",
      "290:\tlearn: 0.8792266\ttotal: 13s\tremaining: 13.8s\n",
      "291:\tlearn: 0.8796315\ttotal: 13s\tremaining: 13.8s\n",
      "292:\tlearn: 0.8806439\ttotal: 13.1s\tremaining: 13.7s\n",
      "293:\tlearn: 0.8815550\ttotal: 13.1s\tremaining: 13.7s\n",
      "294:\tlearn: 0.8822636\ttotal: 13.2s\tremaining: 13.6s\n",
      "295:\tlearn: 0.8818587\ttotal: 13.2s\tremaining: 13.6s\n",
      "296:\tlearn: 0.8838834\ttotal: 13.3s\tremaining: 13.5s\n",
      "297:\tlearn: 0.8840858\ttotal: 13.3s\tremaining: 13.5s\n",
      "298:\tlearn: 0.8842883\ttotal: 13.4s\tremaining: 13.4s\n",
      "299:\tlearn: 0.8849970\ttotal: 13.4s\tremaining: 13.4s\n",
      "300:\tlearn: 0.8860093\ttotal: 13.4s\tremaining: 13.3s\n",
      "301:\tlearn: 0.8867180\ttotal: 13.5s\tremaining: 13.3s\n",
      "302:\tlearn: 0.8861105\ttotal: 13.5s\tremaining: 13.3s\n",
      "303:\tlearn: 0.8868192\ttotal: 13.6s\tremaining: 13.2s\n",
      "304:\tlearn: 0.8872241\ttotal: 13.6s\tremaining: 13.2s\n",
      "305:\tlearn: 0.8883377\ttotal: 13.7s\tremaining: 13.1s\n",
      "306:\tlearn: 0.8885402\ttotal: 13.7s\tremaining: 13.1s\n",
      "307:\tlearn: 0.8901600\ttotal: 13.7s\tremaining: 13s\n",
      "308:\tlearn: 0.8900587\ttotal: 13.8s\tremaining: 13s\n",
      "309:\tlearn: 0.8908686\ttotal: 13.8s\tremaining: 13s\n",
      "310:\tlearn: 0.8903624\ttotal: 13.9s\tremaining: 12.9s\n",
      "311:\tlearn: 0.8910711\ttotal: 13.9s\tremaining: 12.9s\n",
      "312:\tlearn: 0.8917797\ttotal: 14s\tremaining: 12.8s\n",
      "313:\tlearn: 0.8933995\ttotal: 14s\tremaining: 12.8s\n",
      "314:\tlearn: 0.8930958\ttotal: 14.1s\tremaining: 12.7s\n",
      "315:\tlearn: 0.8937032\ttotal: 14.1s\tremaining: 12.7s\n",
      "316:\tlearn: 0.8935007\ttotal: 14.2s\tremaining: 12.6s\n",
      "317:\tlearn: 0.8943106\ttotal: 14.2s\tremaining: 12.6s\n",
      "318:\tlearn: 0.8944118\ttotal: 14.2s\tremaining: 12.5s\n",
      "319:\tlearn: 0.8951205\ttotal: 14.3s\tremaining: 12.5s\n",
      "320:\tlearn: 0.8953229\ttotal: 14.3s\tremaining: 12.5s\n",
      "321:\tlearn: 0.8953229\ttotal: 14.4s\tremaining: 12.4s\n",
      "322:\tlearn: 0.8955254\ttotal: 14.4s\tremaining: 12.4s\n",
      "323:\tlearn: 0.8961328\ttotal: 14.5s\tremaining: 12.3s\n",
      "324:\tlearn: 0.8961328\ttotal: 14.5s\tremaining: 12.3s\n",
      "325:\tlearn: 0.8955254\ttotal: 14.6s\tremaining: 12.2s\n",
      "326:\tlearn: 0.8960316\ttotal: 14.6s\tremaining: 12.2s\n",
      "327:\tlearn: 0.8964365\ttotal: 14.6s\tremaining: 12.1s\n",
      "328:\tlearn: 0.8969427\ttotal: 14.7s\tremaining: 12.1s\n",
      "329:\tlearn: 0.8963353\ttotal: 14.7s\tremaining: 12.1s\n",
      "330:\tlearn: 0.8966390\ttotal: 14.8s\tremaining: 12s\n",
      "331:\tlearn: 0.8977526\ttotal: 14.8s\tremaining: 12s\n",
      "332:\tlearn: 0.8986637\ttotal: 14.9s\tremaining: 11.9s\n",
      "333:\tlearn: 0.8987649\ttotal: 14.9s\tremaining: 11.9s\n",
      "334:\tlearn: 0.8985625\ttotal: 15s\tremaining: 11.8s\n",
      "335:\tlearn: 0.8995748\ttotal: 15s\tremaining: 11.8s\n",
      "336:\tlearn: 0.8997773\ttotal: 15s\tremaining: 11.7s\n",
      "337:\tlearn: 0.9000810\ttotal: 15.1s\tremaining: 11.7s\n",
      "338:\tlearn: 0.9007896\ttotal: 15.1s\tremaining: 11.7s\n",
      "339:\tlearn: 0.9003847\ttotal: 15.2s\tremaining: 11.6s\n",
      "340:\tlearn: 0.9001822\ttotal: 15.2s\tremaining: 11.6s\n",
      "341:\tlearn: 0.9008909\ttotal: 15.3s\tremaining: 11.5s\n",
      "342:\tlearn: 0.9017007\ttotal: 15.3s\tremaining: 11.5s\n",
      "343:\tlearn: 0.9014983\ttotal: 15.3s\tremaining: 11.4s\n",
      "344:\tlearn: 0.9025106\ttotal: 15.4s\tremaining: 11.4s\n",
      "345:\tlearn: 0.9033205\ttotal: 15.4s\tremaining: 11.3s\n",
      "346:\tlearn: 0.9022069\ttotal: 15.5s\tremaining: 11.3s\n",
      "347:\tlearn: 0.9030168\ttotal: 15.5s\tremaining: 11.2s\n",
      "348:\tlearn: 0.9038267\ttotal: 15.6s\tremaining: 11.2s\n",
      "349:\tlearn: 0.9037255\ttotal: 15.6s\tremaining: 11.2s\n",
      "350:\tlearn: 0.9038267\ttotal: 15.7s\tremaining: 11.1s\n",
      "351:\tlearn: 0.9043329\ttotal: 15.7s\tremaining: 11.1s\n",
      "352:\tlearn: 0.9056489\ttotal: 15.7s\tremaining: 11s\n",
      "353:\tlearn: 0.9060539\ttotal: 15.8s\tremaining: 11s\n",
      "354:\tlearn: 0.9057502\ttotal: 15.8s\tremaining: 10.9s\n",
      "355:\tlearn: 0.9060539\ttotal: 15.9s\tremaining: 10.9s\n",
      "356:\tlearn: 0.9069650\ttotal: 15.9s\tremaining: 10.8s\n",
      "357:\tlearn: 0.9068637\ttotal: 16s\tremaining: 10.8s\n",
      "358:\tlearn: 0.9074711\ttotal: 16s\tremaining: 10.8s\n",
      "359:\tlearn: 0.9078761\ttotal: 16.1s\tremaining: 10.7s\n",
      "360:\tlearn: 0.9077749\ttotal: 16.1s\tremaining: 10.7s\n",
      "361:\tlearn: 0.9074711\ttotal: 16.2s\tremaining: 10.6s\n",
      "362:\tlearn: 0.9073699\ttotal: 16.2s\tremaining: 10.6s\n",
      "363:\tlearn: 0.9074711\ttotal: 16.2s\tremaining: 10.5s\n",
      "364:\tlearn: 0.9073699\ttotal: 16.3s\tremaining: 10.5s\n",
      "365:\tlearn: 0.9078761\ttotal: 16.3s\tremaining: 10.4s\n",
      "366:\tlearn: 0.9081798\ttotal: 16.4s\tremaining: 10.4s\n",
      "367:\tlearn: 0.9077749\ttotal: 16.4s\tremaining: 10.4s\n",
      "368:\tlearn: 0.9082810\ttotal: 16.5s\tremaining: 10.3s\n",
      "369:\tlearn: 0.9076736\ttotal: 16.5s\tremaining: 10.3s\n",
      "370:\tlearn: 0.9082810\ttotal: 16.6s\tremaining: 10.2s\n",
      "371:\tlearn: 0.9083823\ttotal: 16.6s\tremaining: 10.2s\n",
      "372:\tlearn: 0.9090909\ttotal: 16.6s\tremaining: 10.1s\n",
      "373:\tlearn: 0.9099008\ttotal: 16.7s\tremaining: 10.1s\n",
      "374:\tlearn: 0.9094958\ttotal: 16.7s\tremaining: 10s\n",
      "375:\tlearn: 0.9106094\ttotal: 16.8s\tremaining: 9.99s\n",
      "376:\tlearn: 0.9108119\ttotal: 16.8s\tremaining: 9.95s\n",
      "377:\tlearn: 0.9108119\ttotal: 16.9s\tremaining: 9.91s\n",
      "378:\tlearn: 0.9105082\ttotal: 16.9s\tremaining: 9.86s\n",
      "379:\tlearn: 0.9105082\ttotal: 17s\tremaining: 9.81s\n",
      "380:\tlearn: 0.9111156\ttotal: 17s\tremaining: 9.77s\n",
      "381:\tlearn: 0.9118243\ttotal: 17.1s\tremaining: 9.73s\n",
      "382:\tlearn: 0.9119255\ttotal: 17.1s\tremaining: 9.69s\n",
      "383:\tlearn: 0.9118243\ttotal: 17.1s\tremaining: 9.64s\n",
      "384:\tlearn: 0.9123304\ttotal: 17.2s\tremaining: 9.6s\n",
      "385:\tlearn: 0.9123304\ttotal: 17.2s\tremaining: 9.55s\n",
      "386:\tlearn: 0.9120267\ttotal: 17.3s\tremaining: 9.51s\n",
      "387:\tlearn: 0.9127354\ttotal: 17.3s\tremaining: 9.46s\n",
      "388:\tlearn: 0.9121280\ttotal: 17.4s\tremaining: 9.42s\n",
      "389:\tlearn: 0.9123304\ttotal: 17.4s\tremaining: 9.38s\n",
      "390:\tlearn: 0.9131403\ttotal: 17.5s\tremaining: 9.33s\n",
      "391:\tlearn: 0.9130391\ttotal: 17.5s\tremaining: 9.29s\n",
      "392:\tlearn: 0.9135453\ttotal: 17.5s\tremaining: 9.24s\n",
      "393:\tlearn: 0.9141527\ttotal: 17.6s\tremaining: 9.2s\n",
      "394:\tlearn: 0.9146588\ttotal: 17.6s\tremaining: 9.15s\n",
      "395:\tlearn: 0.9141527\ttotal: 17.7s\tremaining: 9.11s\n",
      "396:\tlearn: 0.9146588\ttotal: 17.7s\tremaining: 9.06s\n",
      "397:\tlearn: 0.9154687\ttotal: 17.8s\tremaining: 9.02s\n",
      "398:\tlearn: 0.9155700\ttotal: 17.8s\tremaining: 8.97s\n",
      "399:\tlearn: 0.9155700\ttotal: 17.9s\tremaining: 8.93s\n",
      "400:\tlearn: 0.9158737\ttotal: 17.9s\tremaining: 8.88s\n",
      "401:\tlearn: 0.9164811\ttotal: 17.9s\tremaining: 8.84s\n",
      "402:\tlearn: 0.9166835\ttotal: 18s\tremaining: 8.79s\n",
      "403:\tlearn: 0.9171897\ttotal: 18s\tremaining: 8.75s\n",
      "404:\tlearn: 0.9174934\ttotal: 18.1s\tremaining: 8.7s\n",
      "405:\tlearn: 0.9178984\ttotal: 18.1s\tremaining: 8.65s\n",
      "406:\tlearn: 0.9181008\ttotal: 18.2s\tremaining: 8.61s\n",
      "407:\tlearn: 0.9187082\ttotal: 18.2s\tremaining: 8.56s\n",
      "408:\tlearn: 0.9188095\ttotal: 18.2s\tremaining: 8.52s\n",
      "409:\tlearn: 0.9183033\ttotal: 18.3s\tremaining: 8.48s\n",
      "410:\tlearn: 0.9191132\ttotal: 18.3s\tremaining: 8.43s\n",
      "411:\tlearn: 0.9193157\ttotal: 18.4s\tremaining: 8.39s\n",
      "412:\tlearn: 0.9206317\ttotal: 18.4s\tremaining: 8.34s\n",
      "413:\tlearn: 0.9211379\ttotal: 18.5s\tremaining: 8.3s\n",
      "414:\tlearn: 0.9210366\ttotal: 18.5s\tremaining: 8.26s\n",
      "415:\tlearn: 0.9214416\ttotal: 18.6s\tremaining: 8.21s\n",
      "416:\tlearn: 0.9213404\ttotal: 18.6s\tremaining: 8.17s\n",
      "417:\tlearn: 0.9223527\ttotal: 18.7s\tremaining: 8.12s\n",
      "418:\tlearn: 0.9220490\ttotal: 18.7s\tremaining: 8.08s\n",
      "419:\tlearn: 0.9223527\ttotal: 18.7s\tremaining: 8.03s\n",
      "420:\tlearn: 0.9229601\ttotal: 18.8s\tremaining: 7.99s\n",
      "421:\tlearn: 0.9230613\ttotal: 18.8s\tremaining: 7.95s\n",
      "422:\tlearn: 0.9241749\ttotal: 18.9s\tremaining: 7.9s\n",
      "423:\tlearn: 0.9245799\ttotal: 18.9s\tremaining: 7.86s\n",
      "424:\tlearn: 0.9250860\ttotal: 19s\tremaining: 7.81s\n",
      "425:\tlearn: 0.9251873\ttotal: 19s\tremaining: 7.77s\n",
      "426:\tlearn: 0.9252885\ttotal: 19.1s\tremaining: 7.72s\n",
      "427:\tlearn: 0.9246811\ttotal: 19.1s\tremaining: 7.67s\n",
      "428:\tlearn: 0.9250860\ttotal: 19.1s\tremaining: 7.63s\n",
      "429:\tlearn: 0.9254910\ttotal: 19.2s\tremaining: 7.58s\n",
      "430:\tlearn: 0.9257947\ttotal: 19.2s\tremaining: 7.54s\n",
      "431:\tlearn: 0.9259972\ttotal: 19.3s\tremaining: 7.5s\n",
      "432:\tlearn: 0.9258959\ttotal: 19.3s\tremaining: 7.45s\n",
      "433:\tlearn: 0.9261996\ttotal: 19.4s\tremaining: 7.41s\n",
      "434:\tlearn: 0.9268070\ttotal: 19.4s\tremaining: 7.36s\n",
      "435:\tlearn: 0.9261996\ttotal: 19.5s\tremaining: 7.32s\n",
      "436:\tlearn: 0.9259972\ttotal: 19.5s\tremaining: 7.28s\n",
      "437:\tlearn: 0.9264021\ttotal: 19.5s\tremaining: 7.23s\n",
      "438:\tlearn: 0.9266046\ttotal: 19.6s\tremaining: 7.18s\n",
      "439:\tlearn: 0.9277182\ttotal: 19.6s\tremaining: 7.14s\n",
      "440:\tlearn: 0.9270095\ttotal: 19.7s\tremaining: 7.09s\n",
      "441:\tlearn: 0.9278194\ttotal: 19.7s\tremaining: 7.05s\n",
      "442:\tlearn: 0.9285280\ttotal: 19.8s\tremaining: 7.01s\n",
      "443:\tlearn: 0.9283256\ttotal: 19.8s\tremaining: 6.96s\n",
      "444:\tlearn: 0.9285280\ttotal: 19.9s\tremaining: 6.92s\n",
      "445:\tlearn: 0.9288317\ttotal: 19.9s\tremaining: 6.87s\n",
      "446:\tlearn: 0.9291355\ttotal: 19.9s\tremaining: 6.83s\n",
      "447:\tlearn: 0.9292367\ttotal: 20s\tremaining: 6.78s\n",
      "448:\tlearn: 0.9293379\ttotal: 20s\tremaining: 6.74s\n",
      "449:\tlearn: 0.9298441\ttotal: 20.1s\tremaining: 6.69s\n",
      "450:\tlearn: 0.9307552\ttotal: 20.1s\tremaining: 6.65s\n",
      "451:\tlearn: 0.9306540\ttotal: 20.2s\tremaining: 6.6s\n",
      "452:\tlearn: 0.9311602\ttotal: 20.2s\tremaining: 6.56s\n",
      "453:\tlearn: 0.9313626\ttotal: 20.3s\tremaining: 6.51s\n",
      "454:\tlearn: 0.9314639\ttotal: 20.3s\tremaining: 6.47s\n",
      "455:\tlearn: 0.9318688\ttotal: 20.3s\tremaining: 6.42s\n",
      "456:\tlearn: 0.9319700\ttotal: 20.4s\tremaining: 6.38s\n",
      "457:\tlearn: 0.9322737\ttotal: 20.4s\tremaining: 6.33s\n",
      "458:\tlearn: 0.9326787\ttotal: 20.5s\tremaining: 6.29s\n",
      "459:\tlearn: 0.9332861\ttotal: 20.5s\tremaining: 6.24s\n",
      "460:\tlearn: 0.9329824\ttotal: 20.5s\tremaining: 6.2s\n",
      "461:\tlearn: 0.9332861\ttotal: 20.6s\tremaining: 6.15s\n",
      "462:\tlearn: 0.9337923\ttotal: 20.6s\tremaining: 6.11s\n",
      "463:\tlearn: 0.9337923\ttotal: 20.7s\tremaining: 6.06s\n",
      "464:\tlearn: 0.9339947\ttotal: 20.7s\tremaining: 6.02s\n",
      "465:\tlearn: 0.9341972\ttotal: 20.8s\tremaining: 5.97s\n",
      "466:\tlearn: 0.9345009\ttotal: 20.8s\tremaining: 5.93s\n",
      "467:\tlearn: 0.9350071\ttotal: 20.9s\tremaining: 5.88s\n",
      "468:\tlearn: 0.9353108\ttotal: 20.9s\tremaining: 5.84s\n",
      "469:\tlearn: 0.9359182\ttotal: 20.9s\tremaining: 5.79s\n",
      "470:\tlearn: 0.9358170\ttotal: 21s\tremaining: 5.75s\n",
      "471:\tlearn: 0.9364244\ttotal: 21s\tremaining: 5.7s\n",
      "472:\tlearn: 0.9361207\ttotal: 21.1s\tremaining: 5.66s\n",
      "473:\tlearn: 0.9367281\ttotal: 21.1s\tremaining: 5.61s\n",
      "474:\tlearn: 0.9372343\ttotal: 21.2s\tremaining: 5.57s\n",
      "475:\tlearn: 0.9375380\ttotal: 21.2s\tremaining: 5.52s\n",
      "476:\tlearn: 0.9384491\ttotal: 21.3s\tremaining: 5.48s\n",
      "477:\tlearn: 0.9380441\ttotal: 21.3s\tremaining: 5.44s\n",
      "478:\tlearn: 0.9371330\ttotal: 21.3s\tremaining: 5.39s\n",
      "479:\tlearn: 0.9379429\ttotal: 21.4s\tremaining: 5.35s\n",
      "480:\tlearn: 0.9383478\ttotal: 21.4s\tremaining: 5.3s\n",
      "481:\tlearn: 0.9384491\ttotal: 21.5s\tremaining: 5.26s\n",
      "482:\tlearn: 0.9382466\ttotal: 21.5s\tremaining: 5.21s\n",
      "483:\tlearn: 0.9389553\ttotal: 21.6s\tremaining: 5.17s\n",
      "484:\tlearn: 0.9389553\ttotal: 21.6s\tremaining: 5.12s\n",
      "485:\tlearn: 0.9393602\ttotal: 21.7s\tremaining: 5.08s\n",
      "486:\tlearn: 0.9403725\ttotal: 21.7s\tremaining: 5.04s\n",
      "487:\tlearn: 0.9402713\ttotal: 21.7s\tremaining: 4.99s\n",
      "488:\tlearn: 0.9405750\ttotal: 21.8s\tremaining: 4.95s\n",
      "489:\tlearn: 0.9406763\ttotal: 21.8s\tremaining: 4.9s\n",
      "490:\tlearn: 0.9407775\ttotal: 21.9s\tremaining: 4.86s\n",
      "491:\tlearn: 0.9406763\ttotal: 21.9s\tremaining: 4.81s\n",
      "492:\tlearn: 0.9409800\ttotal: 22s\tremaining: 4.77s\n",
      "493:\tlearn: 0.9412837\ttotal: 22s\tremaining: 4.72s\n",
      "494:\tlearn: 0.9419923\ttotal: 22.1s\tremaining: 4.68s\n",
      "495:\tlearn: 0.9422960\ttotal: 22.1s\tremaining: 4.63s\n",
      "496:\tlearn: 0.9423972\ttotal: 22.1s\tremaining: 4.59s\n",
      "497:\tlearn: 0.9421948\ttotal: 22.2s\tremaining: 4.54s\n",
      "498:\tlearn: 0.9418911\ttotal: 22.2s\tremaining: 4.5s\n",
      "499:\tlearn: 0.9425997\ttotal: 22.3s\tremaining: 4.45s\n",
      "500:\tlearn: 0.9425997\ttotal: 22.3s\tremaining: 4.41s\n",
      "501:\tlearn: 0.9432071\ttotal: 22.4s\tremaining: 4.37s\n",
      "502:\tlearn: 0.9427010\ttotal: 22.4s\tremaining: 4.32s\n",
      "503:\tlearn: 0.9429034\ttotal: 22.5s\tremaining: 4.28s\n",
      "504:\tlearn: 0.9435108\ttotal: 22.5s\tremaining: 4.23s\n",
      "505:\tlearn: 0.9440170\ttotal: 22.5s\tremaining: 4.19s\n",
      "506:\tlearn: 0.9442195\ttotal: 22.6s\tremaining: 4.14s\n",
      "507:\tlearn: 0.9440170\ttotal: 22.6s\tremaining: 4.1s\n",
      "508:\tlearn: 0.9438145\ttotal: 22.7s\tremaining: 4.05s\n",
      "509:\tlearn: 0.9440170\ttotal: 22.7s\tremaining: 4.01s\n",
      "510:\tlearn: 0.9443207\ttotal: 22.8s\tremaining: 3.96s\n",
      "511:\tlearn: 0.9445232\ttotal: 22.8s\tremaining: 3.92s\n",
      "512:\tlearn: 0.9445232\ttotal: 22.8s\tremaining: 3.87s\n",
      "513:\tlearn: 0.9445232\ttotal: 22.9s\tremaining: 3.83s\n",
      "514:\tlearn: 0.9448269\ttotal: 22.9s\tremaining: 3.78s\n",
      "515:\tlearn: 0.9449281\ttotal: 23s\tremaining: 3.74s\n",
      "516:\tlearn: 0.9449281\ttotal: 23s\tremaining: 3.69s\n",
      "517:\tlearn: 0.9450294\ttotal: 23.1s\tremaining: 3.65s\n",
      "518:\tlearn: 0.9457380\ttotal: 23.1s\tremaining: 3.6s\n",
      "519:\tlearn: 0.9457380\ttotal: 23.1s\tremaining: 3.56s\n",
      "520:\tlearn: 0.9465479\ttotal: 23.2s\tremaining: 3.51s\n",
      "521:\tlearn: 0.9461429\ttotal: 23.2s\tremaining: 3.47s\n",
      "522:\tlearn: 0.9461429\ttotal: 23.3s\tremaining: 3.42s\n",
      "523:\tlearn: 0.9469528\ttotal: 23.3s\tremaining: 3.38s\n",
      "524:\tlearn: 0.9468516\ttotal: 23.4s\tremaining: 3.33s\n",
      "525:\tlearn: 0.9468516\ttotal: 23.4s\tremaining: 3.29s\n",
      "526:\tlearn: 0.9475602\ttotal: 23.4s\tremaining: 3.25s\n",
      "527:\tlearn: 0.9475602\ttotal: 23.5s\tremaining: 3.2s\n",
      "528:\tlearn: 0.9473578\ttotal: 23.5s\tremaining: 3.16s\n",
      "529:\tlearn: 0.9482689\ttotal: 23.6s\tremaining: 3.11s\n",
      "530:\tlearn: 0.9486738\ttotal: 23.6s\tremaining: 3.07s\n",
      "531:\tlearn: 0.9485726\ttotal: 23.7s\tremaining: 3.02s\n",
      "532:\tlearn: 0.9483701\ttotal: 23.7s\tremaining: 2.98s\n",
      "533:\tlearn: 0.9485726\ttotal: 23.7s\tremaining: 2.93s\n",
      "534:\tlearn: 0.9484714\ttotal: 23.8s\tremaining: 2.89s\n",
      "535:\tlearn: 0.9486738\ttotal: 23.8s\tremaining: 2.85s\n",
      "536:\tlearn: 0.9485726\ttotal: 23.9s\tremaining: 2.8s\n",
      "537:\tlearn: 0.9489775\ttotal: 23.9s\tremaining: 2.76s\n",
      "538:\tlearn: 0.9490788\ttotal: 24s\tremaining: 2.71s\n",
      "539:\tlearn: 0.9491800\ttotal: 24s\tremaining: 2.67s\n",
      "540:\tlearn: 0.9491800\ttotal: 24s\tremaining: 2.62s\n",
      "541:\tlearn: 0.9493825\ttotal: 24.1s\tremaining: 2.58s\n",
      "542:\tlearn: 0.9495849\ttotal: 24.1s\tremaining: 2.53s\n",
      "543:\tlearn: 0.9494837\ttotal: 24.2s\tremaining: 2.49s\n",
      "544:\tlearn: 0.9497874\ttotal: 24.2s\tremaining: 2.44s\n",
      "545:\tlearn: 0.9500911\ttotal: 24.3s\tremaining: 2.4s\n",
      "546:\tlearn: 0.9501923\ttotal: 24.3s\tremaining: 2.35s\n",
      "547:\tlearn: 0.9500911\ttotal: 24.3s\tremaining: 2.31s\n",
      "548:\tlearn: 0.9509010\ttotal: 24.4s\tremaining: 2.27s\n",
      "549:\tlearn: 0.9512047\ttotal: 24.4s\tremaining: 2.22s\n",
      "550:\tlearn: 0.9515084\ttotal: 24.5s\tremaining: 2.18s\n",
      "551:\tlearn: 0.9510022\ttotal: 24.5s\tremaining: 2.13s\n",
      "552:\tlearn: 0.9514072\ttotal: 24.6s\tremaining: 2.09s\n",
      "553:\tlearn: 0.9518121\ttotal: 24.6s\tremaining: 2.04s\n",
      "554:\tlearn: 0.9523183\ttotal: 24.7s\tremaining: 2s\n",
      "555:\tlearn: 0.9524195\ttotal: 24.7s\tremaining: 1.96s\n",
      "556:\tlearn: 0.9526220\ttotal: 24.8s\tremaining: 1.91s\n",
      "557:\tlearn: 0.9533306\ttotal: 24.8s\tremaining: 1.87s\n",
      "558:\tlearn: 0.9541405\ttotal: 24.9s\tremaining: 1.82s\n",
      "559:\tlearn: 0.9541405\ttotal: 24.9s\tremaining: 1.78s\n",
      "560:\tlearn: 0.9541405\ttotal: 24.9s\tremaining: 1.73s\n",
      "561:\tlearn: 0.9537356\ttotal: 25s\tremaining: 1.69s\n",
      "562:\tlearn: 0.9537356\ttotal: 25s\tremaining: 1.64s\n",
      "563:\tlearn: 0.9539380\ttotal: 25.1s\tremaining: 1.6s\n",
      "564:\tlearn: 0.9538368\ttotal: 25.1s\tremaining: 1.55s\n",
      "565:\tlearn: 0.9539380\ttotal: 25.2s\tremaining: 1.51s\n",
      "566:\tlearn: 0.9545455\ttotal: 25.2s\tremaining: 1.47s\n",
      "567:\tlearn: 0.9549504\ttotal: 25.3s\tremaining: 1.42s\n",
      "568:\tlearn: 0.9552541\ttotal: 25.3s\tremaining: 1.38s\n",
      "569:\tlearn: 0.9556590\ttotal: 25.4s\tremaining: 1.33s\n",
      "570:\tlearn: 0.9556590\ttotal: 25.4s\tremaining: 1.29s\n",
      "571:\tlearn: 0.9557603\ttotal: 25.4s\tremaining: 1.25s\n",
      "572:\tlearn: 0.9564689\ttotal: 25.5s\tremaining: 1.2s\n",
      "573:\tlearn: 0.9565702\ttotal: 25.5s\tremaining: 1.16s\n",
      "574:\tlearn: 0.9567726\ttotal: 25.6s\tremaining: 1.11s\n",
      "575:\tlearn: 0.9569751\ttotal: 25.6s\tremaining: 1.07s\n",
      "576:\tlearn: 0.9570763\ttotal: 25.7s\tremaining: 1.02s\n",
      "577:\tlearn: 0.9569751\ttotal: 25.7s\tremaining: 978ms\n",
      "578:\tlearn: 0.9568739\ttotal: 25.8s\tremaining: 934ms\n",
      "579:\tlearn: 0.9574813\ttotal: 25.8s\tremaining: 890ms\n",
      "580:\tlearn: 0.9578862\ttotal: 25.8s\tremaining: 845ms\n",
      "581:\tlearn: 0.9576837\ttotal: 25.9s\tremaining: 801ms\n",
      "582:\tlearn: 0.9576837\ttotal: 25.9s\tremaining: 756ms\n",
      "583:\tlearn: 0.9575825\ttotal: 26s\tremaining: 711ms\n",
      "584:\tlearn: 0.9573800\ttotal: 26s\tremaining: 667ms\n",
      "585:\tlearn: 0.9582912\ttotal: 26.1s\tremaining: 623ms\n",
      "586:\tlearn: 0.9584936\ttotal: 26.1s\tremaining: 578ms\n",
      "587:\tlearn: 0.9581899\ttotal: 26.1s\tremaining: 534ms\n",
      "588:\tlearn: 0.9580887\ttotal: 26.2s\tremaining: 489ms\n",
      "589:\tlearn: 0.9583924\ttotal: 26.2s\tremaining: 445ms\n",
      "590:\tlearn: 0.9585949\ttotal: 26.3s\tremaining: 400ms\n",
      "591:\tlearn: 0.9592023\ttotal: 26.3s\tremaining: 356ms\n",
      "592:\tlearn: 0.9589998\ttotal: 26.4s\tremaining: 311ms\n",
      "593:\tlearn: 0.9589998\ttotal: 26.4s\tremaining: 267ms\n",
      "594:\tlearn: 0.9588986\ttotal: 26.4s\tremaining: 222ms\n",
      "595:\tlearn: 0.9594047\ttotal: 26.5s\tremaining: 178ms\n",
      "596:\tlearn: 0.9593035\ttotal: 26.5s\tremaining: 133ms\n",
      "597:\tlearn: 0.9599109\ttotal: 26.6s\tremaining: 88.9ms\n",
      "598:\tlearn: 0.9597084\ttotal: 26.6s\tremaining: 44.4ms\n",
      "599:\tlearn: 0.9597084\ttotal: 26.7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=5, eval_metric=Recall, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.05, random_strength=5; total time=  27.2s\n",
      "0:\tlearn: 0.7101640\ttotal: 45.3ms\tremaining: 27.1s\n",
      "1:\tlearn: 0.5832152\ttotal: 92.9ms\tremaining: 27.8s\n",
      "2:\tlearn: 0.6056894\ttotal: 137ms\tremaining: 27.3s\n",
      "3:\tlearn: 0.6462847\ttotal: 182ms\tremaining: 27.2s\n",
      "4:\tlearn: 0.6354525\ttotal: 227ms\tremaining: 27.1s\n",
      "5:\tlearn: 0.6471958\ttotal: 273ms\tremaining: 27s\n",
      "6:\tlearn: 0.6525612\ttotal: 315ms\tremaining: 26.7s\n",
      "7:\tlearn: 0.6440575\ttotal: 361ms\tremaining: 26.7s\n",
      "8:\tlearn: 0.6320105\ttotal: 406ms\tremaining: 26.6s\n",
      "9:\tlearn: 0.6331241\ttotal: 449ms\tremaining: 26.5s\n",
      "10:\tlearn: 0.6519538\ttotal: 490ms\tremaining: 26.3s\n",
      "11:\tlearn: 0.6458797\ttotal: 534ms\tremaining: 26.1s\n",
      "12:\tlearn: 0.6510427\ttotal: 579ms\tremaining: 26.1s\n",
      "13:\tlearn: 0.6529662\ttotal: 624ms\tremaining: 26.1s\n",
      "14:\tlearn: 0.6604576\ttotal: 665ms\tremaining: 25.9s\n",
      "15:\tlearn: 0.6555983\ttotal: 708ms\tremaining: 25.8s\n",
      "16:\tlearn: 0.6568131\ttotal: 753ms\tremaining: 25.8s\n",
      "17:\tlearn: 0.6620773\ttotal: 796ms\tremaining: 25.7s\n",
      "18:\tlearn: 0.6636971\ttotal: 844ms\tremaining: 25.8s\n",
      "19:\tlearn: 0.6640008\ttotal: 888ms\tremaining: 25.8s\n",
      "20:\tlearn: 0.6663292\ttotal: 935ms\tremaining: 25.8s\n",
      "21:\tlearn: 0.6644058\ttotal: 985ms\tremaining: 25.9s\n",
      "22:\tlearn: 0.6647095\ttotal: 1.03s\tremaining: 25.9s\n",
      "23:\tlearn: 0.6697712\ttotal: 1.08s\tremaining: 25.8s\n",
      "24:\tlearn: 0.6701761\ttotal: 1.12s\tremaining: 25.8s\n",
      "25:\tlearn: 0.6687589\ttotal: 1.17s\tremaining: 25.8s\n",
      "26:\tlearn: 0.6738206\ttotal: 1.21s\tremaining: 25.8s\n",
      "27:\tlearn: 0.6669366\ttotal: 1.26s\tremaining: 25.7s\n",
      "28:\tlearn: 0.6682527\ttotal: 1.3s\tremaining: 25.6s\n",
      "29:\tlearn: 0.6690626\ttotal: 1.34s\tremaining: 25.6s\n",
      "30:\tlearn: 0.6707836\ttotal: 1.39s\tremaining: 25.5s\n",
      "31:\tlearn: 0.6735169\ttotal: 1.43s\tremaining: 25.5s\n",
      "32:\tlearn: 0.6750354\ttotal: 1.48s\tremaining: 25.4s\n",
      "33:\tlearn: 0.6756428\ttotal: 1.52s\tremaining: 25.3s\n",
      "34:\tlearn: 0.6766552\ttotal: 1.56s\tremaining: 25.2s\n",
      "35:\tlearn: 0.6760478\ttotal: 1.61s\tremaining: 25.2s\n",
      "36:\tlearn: 0.6808058\ttotal: 1.65s\tremaining: 25.2s\n",
      "37:\tlearn: 0.6814132\ttotal: 1.7s\tremaining: 25.1s\n",
      "38:\tlearn: 0.6815145\ttotal: 1.74s\tremaining: 25.1s\n",
      "39:\tlearn: 0.6809071\ttotal: 1.78s\tremaining: 25s\n",
      "40:\tlearn: 0.6800972\ttotal: 1.83s\tremaining: 24.9s\n",
      "41:\tlearn: 0.6795910\ttotal: 1.87s\tremaining: 24.8s\n",
      "42:\tlearn: 0.6853614\ttotal: 1.91s\tremaining: 24.8s\n",
      "43:\tlearn: 0.6860701\ttotal: 1.96s\tremaining: 24.7s\n",
      "44:\tlearn: 0.6856651\ttotal: 2s\tremaining: 24.7s\n",
      "45:\tlearn: 0.6866775\ttotal: 2.04s\tremaining: 24.6s\n",
      "46:\tlearn: 0.6910306\ttotal: 2.09s\tremaining: 24.6s\n",
      "47:\tlearn: 0.6970034\ttotal: 2.14s\tremaining: 24.6s\n",
      "48:\tlearn: 0.6991294\ttotal: 2.19s\tremaining: 24.6s\n",
      "49:\tlearn: 0.6999393\ttotal: 2.23s\tremaining: 24.5s\n",
      "50:\tlearn: 0.7007491\ttotal: 2.27s\tremaining: 24.4s\n",
      "51:\tlearn: 0.7038874\ttotal: 2.31s\tremaining: 24.4s\n",
      "52:\tlearn: 0.7031788\ttotal: 2.35s\tremaining: 24.3s\n",
      "53:\tlearn: 0.7046973\ttotal: 2.4s\tremaining: 24.3s\n",
      "54:\tlearn: 0.7042924\ttotal: 2.44s\tremaining: 24.2s\n",
      "55:\tlearn: 0.7064183\ttotal: 2.49s\tremaining: 24.2s\n",
      "56:\tlearn: 0.7087467\ttotal: 2.53s\tremaining: 24.1s\n",
      "57:\tlearn: 0.7095566\ttotal: 2.58s\tremaining: 24.1s\n",
      "58:\tlearn: 0.7104677\ttotal: 2.62s\tremaining: 24s\n",
      "59:\tlearn: 0.7113788\ttotal: 2.67s\tremaining: 24s\n",
      "60:\tlearn: 0.7125936\ttotal: 2.71s\tremaining: 23.9s\n",
      "61:\tlearn: 0.7122899\ttotal: 2.75s\tremaining: 23.9s\n",
      "62:\tlearn: 0.7135048\ttotal: 2.79s\tremaining: 23.8s\n",
      "63:\tlearn: 0.7151245\ttotal: 2.84s\tremaining: 23.8s\n",
      "64:\tlearn: 0.7150233\ttotal: 2.88s\tremaining: 23.7s\n",
      "65:\tlearn: 0.7138085\ttotal: 2.93s\tremaining: 23.7s\n",
      "66:\tlearn: 0.7133023\ttotal: 2.98s\tremaining: 23.7s\n",
      "67:\tlearn: 0.7157319\ttotal: 3.03s\tremaining: 23.7s\n",
      "68:\tlearn: 0.7162381\ttotal: 3.08s\tremaining: 23.7s\n",
      "69:\tlearn: 0.7177566\ttotal: 3.13s\tremaining: 23.7s\n",
      "70:\tlearn: 0.7178579\ttotal: 3.17s\tremaining: 23.6s\n",
      "71:\tlearn: 0.7176554\ttotal: 3.22s\tremaining: 23.6s\n",
      "72:\tlearn: 0.7182628\ttotal: 3.26s\tremaining: 23.5s\n",
      "73:\tlearn: 0.7188702\ttotal: 3.31s\tremaining: 23.5s\n",
      "74:\tlearn: 0.7182628\ttotal: 3.35s\tremaining: 23.5s\n",
      "75:\tlearn: 0.7222110\ttotal: 3.4s\tremaining: 23.4s\n",
      "76:\tlearn: 0.7240332\ttotal: 3.44s\tremaining: 23.4s\n",
      "77:\tlearn: 0.7278801\ttotal: 3.49s\tremaining: 23.3s\n",
      "78:\tlearn: 0.7297024\ttotal: 3.54s\tremaining: 23.3s\n",
      "79:\tlearn: 0.7306135\ttotal: 3.58s\tremaining: 23.3s\n",
      "80:\tlearn: 0.7323345\ttotal: 3.62s\tremaining: 23.2s\n",
      "81:\tlearn: 0.7335493\ttotal: 3.67s\tremaining: 23.2s\n",
      "82:\tlearn: 0.7354728\ttotal: 3.71s\tremaining: 23.1s\n",
      "83:\tlearn: 0.7381049\ttotal: 3.75s\tremaining: 23.1s\n",
      "84:\tlearn: 0.7393197\ttotal: 3.8s\tremaining: 23s\n",
      "85:\tlearn: 0.7402308\ttotal: 3.85s\tremaining: 23s\n",
      "86:\tlearn: 0.7406358\ttotal: 3.89s\tremaining: 22.9s\n",
      "87:\tlearn: 0.7412432\ttotal: 3.93s\tremaining: 22.9s\n",
      "88:\tlearn: 0.7421543\ttotal: 3.98s\tremaining: 22.9s\n",
      "89:\tlearn: 0.7447864\ttotal: 4.02s\tremaining: 22.8s\n",
      "90:\tlearn: 0.7443815\ttotal: 4.07s\tremaining: 22.8s\n",
      "91:\tlearn: 0.7461024\ttotal: 4.11s\tremaining: 22.7s\n",
      "92:\tlearn: 0.7457987\ttotal: 4.16s\tremaining: 22.7s\n",
      "93:\tlearn: 0.7468111\ttotal: 4.2s\tremaining: 22.6s\n",
      "94:\tlearn: 0.7480259\ttotal: 4.25s\tremaining: 22.6s\n",
      "95:\tlearn: 0.7475197\ttotal: 4.29s\tremaining: 22.5s\n",
      "96:\tlearn: 0.7491395\ttotal: 4.33s\tremaining: 22.5s\n",
      "97:\tlearn: 0.7482284\ttotal: 4.38s\tremaining: 22.4s\n",
      "98:\tlearn: 0.7481272\ttotal: 4.43s\tremaining: 22.4s\n",
      "99:\tlearn: 0.7473173\ttotal: 4.47s\tremaining: 22.4s\n",
      "100:\tlearn: 0.7500506\ttotal: 4.51s\tremaining: 22.3s\n",
      "101:\tlearn: 0.7483296\ttotal: 4.56s\tremaining: 22.3s\n",
      "102:\tlearn: 0.7512654\ttotal: 4.61s\tremaining: 22.2s\n",
      "103:\tlearn: 0.7503543\ttotal: 4.65s\tremaining: 22.2s\n",
      "104:\tlearn: 0.7519741\ttotal: 4.69s\tremaining: 22.1s\n",
      "105:\tlearn: 0.7527840\ttotal: 4.73s\tremaining: 22.1s\n",
      "106:\tlearn: 0.7530877\ttotal: 4.77s\tremaining: 22s\n",
      "107:\tlearn: 0.7536951\ttotal: 4.82s\tremaining: 22s\n",
      "108:\tlearn: 0.7560235\ttotal: 4.86s\tremaining: 21.9s\n",
      "109:\tlearn: 0.7566309\ttotal: 4.91s\tremaining: 21.9s\n",
      "110:\tlearn: 0.7566309\ttotal: 4.96s\tremaining: 21.8s\n",
      "111:\tlearn: 0.7580482\ttotal: 5s\tremaining: 21.8s\n",
      "112:\tlearn: 0.7602754\ttotal: 5.05s\tremaining: 21.7s\n",
      "113:\tlearn: 0.7596679\ttotal: 5.09s\tremaining: 21.7s\n",
      "114:\tlearn: 0.7596679\ttotal: 5.14s\tremaining: 21.7s\n",
      "115:\tlearn: 0.7590605\ttotal: 5.18s\tremaining: 21.6s\n",
      "116:\tlearn: 0.7617939\ttotal: 5.23s\tremaining: 21.6s\n",
      "117:\tlearn: 0.7645272\ttotal: 5.27s\tremaining: 21.5s\n",
      "118:\tlearn: 0.7650334\ttotal: 5.31s\tremaining: 21.5s\n",
      "119:\tlearn: 0.7664507\ttotal: 5.36s\tremaining: 21.4s\n",
      "120:\tlearn: 0.7671593\ttotal: 5.41s\tremaining: 21.4s\n",
      "121:\tlearn: 0.7688803\ttotal: 5.45s\tremaining: 21.4s\n",
      "122:\tlearn: 0.7697915\ttotal: 5.5s\tremaining: 21.3s\n",
      "123:\tlearn: 0.7701964\ttotal: 5.54s\tremaining: 21.3s\n",
      "124:\tlearn: 0.7699939\ttotal: 5.59s\tremaining: 21.2s\n",
      "125:\tlearn: 0.7698927\ttotal: 5.63s\tremaining: 21.2s\n",
      "126:\tlearn: 0.7700952\ttotal: 5.68s\tremaining: 21.1s\n",
      "127:\tlearn: 0.7721199\ttotal: 5.72s\tremaining: 21.1s\n",
      "128:\tlearn: 0.7727273\ttotal: 5.76s\tremaining: 21s\n",
      "129:\tlearn: 0.7721199\ttotal: 5.8s\tremaining: 21s\n",
      "130:\tlearn: 0.7728285\ttotal: 5.85s\tremaining: 20.9s\n",
      "131:\tlearn: 0.7737396\ttotal: 5.89s\tremaining: 20.9s\n",
      "132:\tlearn: 0.7747520\ttotal: 5.94s\tremaining: 20.9s\n",
      "133:\tlearn: 0.7743470\ttotal: 5.99s\tremaining: 20.8s\n",
      "134:\tlearn: 0.7739421\ttotal: 6.03s\tremaining: 20.8s\n",
      "135:\tlearn: 0.7738409\ttotal: 6.07s\tremaining: 20.7s\n",
      "136:\tlearn: 0.7747520\ttotal: 6.12s\tremaining: 20.7s\n",
      "137:\tlearn: 0.7735372\ttotal: 6.17s\tremaining: 20.6s\n",
      "138:\tlearn: 0.7751569\ttotal: 6.21s\tremaining: 20.6s\n",
      "139:\tlearn: 0.7760680\ttotal: 6.25s\tremaining: 20.6s\n",
      "140:\tlearn: 0.7766754\ttotal: 6.3s\tremaining: 20.5s\n",
      "141:\tlearn: 0.7781940\ttotal: 6.34s\tremaining: 20.4s\n",
      "142:\tlearn: 0.7784977\ttotal: 6.38s\tremaining: 20.4s\n",
      "143:\tlearn: 0.7799150\ttotal: 6.43s\tremaining: 20.4s\n",
      "144:\tlearn: 0.7793076\ttotal: 6.47s\tremaining: 20.3s\n",
      "145:\tlearn: 0.7809273\ttotal: 6.51s\tremaining: 20.3s\n",
      "146:\tlearn: 0.7823446\ttotal: 6.56s\tremaining: 20.2s\n",
      "147:\tlearn: 0.7822434\ttotal: 6.61s\tremaining: 20.2s\n",
      "148:\tlearn: 0.7809273\ttotal: 6.66s\tremaining: 20.2s\n",
      "149:\tlearn: 0.7811298\ttotal: 6.71s\tremaining: 20.1s\n",
      "150:\tlearn: 0.7841668\ttotal: 6.75s\tremaining: 20.1s\n",
      "151:\tlearn: 0.7833570\ttotal: 6.8s\tremaining: 20s\n",
      "152:\tlearn: 0.7849767\ttotal: 6.84s\tremaining: 20s\n",
      "153:\tlearn: 0.7860903\ttotal: 6.89s\tremaining: 19.9s\n",
      "154:\tlearn: 0.7866977\ttotal: 6.93s\tremaining: 19.9s\n",
      "155:\tlearn: 0.7878113\ttotal: 6.98s\tremaining: 19.9s\n",
      "156:\tlearn: 0.7872039\ttotal: 7.03s\tremaining: 19.8s\n",
      "157:\tlearn: 0.7892286\ttotal: 7.07s\tremaining: 19.8s\n",
      "158:\tlearn: 0.7903422\ttotal: 7.11s\tremaining: 19.7s\n",
      "159:\tlearn: 0.7927718\ttotal: 7.15s\tremaining: 19.7s\n",
      "160:\tlearn: 0.7927718\ttotal: 7.2s\tremaining: 19.6s\n",
      "161:\tlearn: 0.7954039\ttotal: 7.25s\tremaining: 19.6s\n",
      "162:\tlearn: 0.7963150\ttotal: 7.29s\tremaining: 19.5s\n",
      "163:\tlearn: 0.7971249\ttotal: 7.34s\tremaining: 19.5s\n",
      "164:\tlearn: 0.7981373\ttotal: 7.38s\tremaining: 19.4s\n",
      "165:\tlearn: 0.7997570\ttotal: 7.42s\tremaining: 19.4s\n",
      "166:\tlearn: 0.8000607\ttotal: 7.47s\tremaining: 19.4s\n",
      "167:\tlearn: 0.8016805\ttotal: 7.51s\tremaining: 19.3s\n",
      "168:\tlearn: 0.8007694\ttotal: 7.55s\tremaining: 19.3s\n",
      "169:\tlearn: 0.8014780\ttotal: 7.59s\tremaining: 19.2s\n",
      "170:\tlearn: 0.8016805\ttotal: 7.63s\tremaining: 19.2s\n",
      "171:\tlearn: 0.8010731\ttotal: 7.68s\tremaining: 19.1s\n",
      "172:\tlearn: 0.8021867\ttotal: 7.72s\tremaining: 19.1s\n",
      "173:\tlearn: 0.8031990\ttotal: 7.76s\tremaining: 19s\n",
      "174:\tlearn: 0.8025916\ttotal: 7.81s\tremaining: 19s\n",
      "175:\tlearn: 0.8022879\ttotal: 7.86s\tremaining: 18.9s\n",
      "176:\tlearn: 0.8038064\ttotal: 7.9s\tremaining: 18.9s\n",
      "177:\tlearn: 0.8036040\ttotal: 7.94s\tremaining: 18.8s\n",
      "178:\tlearn: 0.8040089\ttotal: 7.98s\tremaining: 18.8s\n",
      "179:\tlearn: 0.8048188\ttotal: 8.03s\tremaining: 18.7s\n",
      "180:\tlearn: 0.8064386\ttotal: 8.07s\tremaining: 18.7s\n",
      "181:\tlearn: 0.8059324\ttotal: 8.11s\tremaining: 18.6s\n",
      "182:\tlearn: 0.8064386\ttotal: 8.16s\tremaining: 18.6s\n",
      "183:\tlearn: 0.8066410\ttotal: 8.2s\tremaining: 18.5s\n",
      "184:\tlearn: 0.8061348\ttotal: 8.24s\tremaining: 18.5s\n",
      "185:\tlearn: 0.8062361\ttotal: 8.29s\tremaining: 18.5s\n",
      "186:\tlearn: 0.8054262\ttotal: 8.34s\tremaining: 18.4s\n",
      "187:\tlearn: 0.8082608\ttotal: 8.39s\tremaining: 18.4s\n",
      "188:\tlearn: 0.8078558\ttotal: 8.44s\tremaining: 18.4s\n",
      "189:\tlearn: 0.8084633\ttotal: 8.48s\tremaining: 18.3s\n",
      "190:\tlearn: 0.8091719\ttotal: 8.53s\tremaining: 18.3s\n",
      "191:\tlearn: 0.8094756\ttotal: 8.57s\tremaining: 18.2s\n",
      "192:\tlearn: 0.8107917\ttotal: 8.61s\tremaining: 18.2s\n",
      "193:\tlearn: 0.8108929\ttotal: 8.65s\tremaining: 18.1s\n",
      "194:\tlearn: 0.8121077\ttotal: 8.7s\tremaining: 18.1s\n",
      "195:\tlearn: 0.8126139\ttotal: 8.74s\tremaining: 18s\n",
      "196:\tlearn: 0.8122089\ttotal: 8.79s\tremaining: 18s\n",
      "197:\tlearn: 0.8122089\ttotal: 8.83s\tremaining: 17.9s\n",
      "198:\tlearn: 0.8120065\ttotal: 8.88s\tremaining: 17.9s\n",
      "199:\tlearn: 0.8117028\ttotal: 8.92s\tremaining: 17.8s\n",
      "200:\tlearn: 0.8130188\ttotal: 8.96s\tremaining: 17.8s\n",
      "201:\tlearn: 0.8128164\ttotal: 9.01s\tremaining: 17.7s\n",
      "202:\tlearn: 0.8146386\ttotal: 9.05s\tremaining: 17.7s\n",
      "203:\tlearn: 0.8141324\ttotal: 9.1s\tremaining: 17.7s\n",
      "204:\tlearn: 0.8146386\ttotal: 9.15s\tremaining: 17.6s\n",
      "205:\tlearn: 0.8143349\ttotal: 9.19s\tremaining: 17.6s\n",
      "206:\tlearn: 0.8140312\ttotal: 9.24s\tremaining: 17.5s\n",
      "207:\tlearn: 0.8147398\ttotal: 9.29s\tremaining: 17.5s\n",
      "208:\tlearn: 0.8160559\ttotal: 9.34s\tremaining: 17.5s\n",
      "209:\tlearn: 0.8179793\ttotal: 9.38s\tremaining: 17.4s\n",
      "210:\tlearn: 0.8185868\ttotal: 9.43s\tremaining: 17.4s\n",
      "211:\tlearn: 0.8201053\ttotal: 9.47s\tremaining: 17.3s\n",
      "212:\tlearn: 0.8216238\ttotal: 9.52s\tremaining: 17.3s\n",
      "213:\tlearn: 0.8219275\ttotal: 9.56s\tremaining: 17.2s\n",
      "214:\tlearn: 0.8217250\ttotal: 9.61s\tremaining: 17.2s\n",
      "215:\tlearn: 0.8244584\ttotal: 9.65s\tremaining: 17.2s\n",
      "216:\tlearn: 0.8247621\ttotal: 9.7s\tremaining: 17.1s\n",
      "217:\tlearn: 0.8240535\ttotal: 9.74s\tremaining: 17.1s\n",
      "218:\tlearn: 0.8240535\ttotal: 9.79s\tremaining: 17s\n",
      "219:\tlearn: 0.8238510\ttotal: 9.83s\tremaining: 17s\n",
      "220:\tlearn: 0.8246609\ttotal: 9.88s\tremaining: 16.9s\n",
      "221:\tlearn: 0.8275967\ttotal: 9.92s\tremaining: 16.9s\n",
      "222:\tlearn: 0.8290140\ttotal: 9.97s\tremaining: 16.9s\n",
      "223:\tlearn: 0.8290140\ttotal: 10s\tremaining: 16.8s\n",
      "224:\tlearn: 0.8302288\ttotal: 10.1s\tremaining: 16.8s\n",
      "225:\tlearn: 0.8302288\ttotal: 10.1s\tremaining: 16.7s\n",
      "226:\tlearn: 0.8325572\ttotal: 10.1s\tremaining: 16.7s\n",
      "227:\tlearn: 0.8325572\ttotal: 10.2s\tremaining: 16.6s\n",
      "228:\tlearn: 0.8359992\ttotal: 10.2s\tremaining: 16.6s\n",
      "229:\tlearn: 0.8361004\ttotal: 10.3s\tremaining: 16.5s\n",
      "230:\tlearn: 0.8375177\ttotal: 10.3s\tremaining: 16.5s\n",
      "231:\tlearn: 0.8377202\ttotal: 10.4s\tremaining: 16.4s\n",
      "232:\tlearn: 0.8398461\ttotal: 10.4s\tremaining: 16.4s\n",
      "233:\tlearn: 0.8397449\ttotal: 10.5s\tremaining: 16.4s\n",
      "234:\tlearn: 0.8402511\ttotal: 10.5s\tremaining: 16.3s\n",
      "235:\tlearn: 0.8394412\ttotal: 10.6s\tremaining: 16.3s\n",
      "236:\tlearn: 0.8402511\ttotal: 10.6s\tremaining: 16.2s\n",
      "237:\tlearn: 0.8401498\ttotal: 10.6s\tremaining: 16.2s\n",
      "238:\tlearn: 0.8402511\ttotal: 10.7s\tremaining: 16.1s\n",
      "239:\tlearn: 0.8417696\ttotal: 10.7s\tremaining: 16.1s\n",
      "240:\tlearn: 0.8432881\ttotal: 10.8s\tremaining: 16s\n",
      "241:\tlearn: 0.8446042\ttotal: 10.8s\tremaining: 16s\n",
      "242:\tlearn: 0.8441992\ttotal: 10.9s\tremaining: 16s\n",
      "243:\tlearn: 0.8451103\ttotal: 10.9s\tremaining: 15.9s\n",
      "244:\tlearn: 0.8462239\ttotal: 10.9s\tremaining: 15.9s\n",
      "245:\tlearn: 0.8461227\ttotal: 11s\tremaining: 15.8s\n",
      "246:\tlearn: 0.8491597\ttotal: 11s\tremaining: 15.8s\n",
      "247:\tlearn: 0.8494635\ttotal: 11.1s\tremaining: 15.7s\n",
      "248:\tlearn: 0.8502733\ttotal: 11.1s\tremaining: 15.7s\n",
      "249:\tlearn: 0.8511845\ttotal: 11.2s\tremaining: 15.6s\n",
      "250:\tlearn: 0.8508807\ttotal: 11.2s\tremaining: 15.6s\n",
      "251:\tlearn: 0.8521968\ttotal: 11.3s\tremaining: 15.6s\n",
      "252:\tlearn: 0.8535129\ttotal: 11.3s\tremaining: 15.5s\n",
      "253:\tlearn: 0.8534116\ttotal: 11.3s\tremaining: 15.5s\n",
      "254:\tlearn: 0.8533104\ttotal: 11.4s\tremaining: 15.4s\n",
      "255:\tlearn: 0.8538166\ttotal: 11.4s\tremaining: 15.4s\n",
      "256:\tlearn: 0.8547277\ttotal: 11.5s\tremaining: 15.3s\n",
      "257:\tlearn: 0.8560437\ttotal: 11.5s\tremaining: 15.3s\n",
      "258:\tlearn: 0.8577647\ttotal: 11.6s\tremaining: 15.2s\n",
      "259:\tlearn: 0.8584734\ttotal: 11.6s\tremaining: 15.2s\n",
      "260:\tlearn: 0.8591820\ttotal: 11.6s\tremaining: 15.1s\n",
      "261:\tlearn: 0.8594857\ttotal: 11.7s\tremaining: 15.1s\n",
      "262:\tlearn: 0.8596882\ttotal: 11.7s\tremaining: 15s\n",
      "263:\tlearn: 0.8626240\ttotal: 11.8s\tremaining: 15s\n",
      "264:\tlearn: 0.8622191\ttotal: 11.8s\tremaining: 15s\n",
      "265:\tlearn: 0.8647499\ttotal: 11.9s\tremaining: 14.9s\n",
      "266:\tlearn: 0.8664709\ttotal: 11.9s\tremaining: 14.9s\n",
      "267:\tlearn: 0.8659648\ttotal: 12s\tremaining: 14.8s\n",
      "268:\tlearn: 0.8678882\ttotal: 12s\tremaining: 14.8s\n",
      "269:\tlearn: 0.8681919\ttotal: 12s\tremaining: 14.7s\n",
      "270:\tlearn: 0.8690018\ttotal: 12.1s\tremaining: 14.7s\n",
      "271:\tlearn: 0.8704191\ttotal: 12.1s\tremaining: 14.6s\n",
      "272:\tlearn: 0.8717352\ttotal: 12.2s\tremaining: 14.6s\n",
      "273:\tlearn: 0.8715327\ttotal: 12.2s\tremaining: 14.5s\n",
      "274:\tlearn: 0.8729500\ttotal: 12.3s\tremaining: 14.5s\n",
      "275:\tlearn: 0.8741648\ttotal: 12.3s\tremaining: 14.5s\n",
      "276:\tlearn: 0.8744685\ttotal: 12.4s\tremaining: 14.4s\n",
      "277:\tlearn: 0.8750759\ttotal: 12.4s\tremaining: 14.4s\n",
      "278:\tlearn: 0.8747722\ttotal: 12.4s\tremaining: 14.3s\n",
      "279:\tlearn: 0.8747722\ttotal: 12.5s\tremaining: 14.3s\n",
      "280:\tlearn: 0.8753796\ttotal: 12.5s\tremaining: 14.2s\n",
      "281:\tlearn: 0.8769994\ttotal: 12.6s\tremaining: 14.2s\n",
      "282:\tlearn: 0.8774043\ttotal: 12.6s\tremaining: 14.1s\n",
      "283:\tlearn: 0.8782142\ttotal: 12.7s\tremaining: 14.1s\n",
      "284:\tlearn: 0.8787204\ttotal: 12.7s\tremaining: 14s\n",
      "285:\tlearn: 0.8803401\ttotal: 12.8s\tremaining: 14s\n",
      "286:\tlearn: 0.8805426\ttotal: 12.8s\tremaining: 14s\n",
      "287:\tlearn: 0.8814537\ttotal: 12.9s\tremaining: 13.9s\n",
      "288:\tlearn: 0.8818587\ttotal: 12.9s\tremaining: 13.9s\n",
      "289:\tlearn: 0.8824661\ttotal: 12.9s\tremaining: 13.8s\n",
      "290:\tlearn: 0.8834784\ttotal: 13s\tremaining: 13.8s\n",
      "291:\tlearn: 0.8843896\ttotal: 13s\tremaining: 13.7s\n",
      "292:\tlearn: 0.8843896\ttotal: 13.1s\tremaining: 13.7s\n",
      "293:\tlearn: 0.8845920\ttotal: 13.1s\tremaining: 13.6s\n",
      "294:\tlearn: 0.8861105\ttotal: 13.2s\tremaining: 13.6s\n",
      "295:\tlearn: 0.8863130\ttotal: 13.2s\tremaining: 13.6s\n",
      "296:\tlearn: 0.8861105\ttotal: 13.3s\tremaining: 13.5s\n",
      "297:\tlearn: 0.8872241\ttotal: 13.3s\tremaining: 13.5s\n",
      "298:\tlearn: 0.8880340\ttotal: 13.4s\tremaining: 13.4s\n",
      "299:\tlearn: 0.8873254\ttotal: 13.4s\tremaining: 13.4s\n",
      "300:\tlearn: 0.8872241\ttotal: 13.4s\tremaining: 13.3s\n",
      "301:\tlearn: 0.8882365\ttotal: 13.5s\tremaining: 13.3s\n",
      "302:\tlearn: 0.8884390\ttotal: 13.5s\tremaining: 13.3s\n",
      "303:\tlearn: 0.8886414\ttotal: 13.6s\tremaining: 13.2s\n",
      "304:\tlearn: 0.8892488\ttotal: 13.6s\tremaining: 13.2s\n",
      "305:\tlearn: 0.8899575\ttotal: 13.7s\tremaining: 13.1s\n",
      "306:\tlearn: 0.8904637\ttotal: 13.7s\tremaining: 13.1s\n",
      "307:\tlearn: 0.8919822\ttotal: 13.8s\tremaining: 13.1s\n",
      "308:\tlearn: 0.8930958\ttotal: 13.8s\tremaining: 13s\n",
      "309:\tlearn: 0.8930958\ttotal: 13.9s\tremaining: 13s\n",
      "310:\tlearn: 0.8928933\ttotal: 13.9s\tremaining: 12.9s\n",
      "311:\tlearn: 0.8918809\ttotal: 13.9s\tremaining: 12.9s\n",
      "312:\tlearn: 0.8917797\ttotal: 14s\tremaining: 12.8s\n",
      "313:\tlearn: 0.8928933\ttotal: 14s\tremaining: 12.8s\n",
      "314:\tlearn: 0.8928933\ttotal: 14.1s\tremaining: 12.7s\n",
      "315:\tlearn: 0.8939056\ttotal: 14.1s\tremaining: 12.7s\n",
      "316:\tlearn: 0.8951205\ttotal: 14.2s\tremaining: 12.7s\n",
      "317:\tlearn: 0.8957279\ttotal: 14.2s\tremaining: 12.6s\n",
      "318:\tlearn: 0.8963353\ttotal: 14.3s\tremaining: 12.6s\n",
      "319:\tlearn: 0.8966390\ttotal: 14.3s\tremaining: 12.5s\n",
      "320:\tlearn: 0.8964365\ttotal: 14.4s\tremaining: 12.5s\n",
      "321:\tlearn: 0.8963353\ttotal: 14.4s\tremaining: 12.4s\n",
      "322:\tlearn: 0.8969427\ttotal: 14.5s\tremaining: 12.4s\n",
      "323:\tlearn: 0.8982588\ttotal: 14.5s\tremaining: 12.4s\n",
      "324:\tlearn: 0.8986637\ttotal: 14.6s\tremaining: 12.3s\n",
      "325:\tlearn: 0.8990686\ttotal: 14.6s\tremaining: 12.3s\n",
      "326:\tlearn: 0.8992711\ttotal: 14.6s\tremaining: 12.2s\n",
      "327:\tlearn: 0.8996760\ttotal: 14.7s\tremaining: 12.2s\n",
      "328:\tlearn: 0.8996760\ttotal: 14.7s\tremaining: 12.1s\n",
      "329:\tlearn: 0.9004859\ttotal: 14.8s\tremaining: 12.1s\n",
      "330:\tlearn: 0.9012958\ttotal: 14.8s\tremaining: 12s\n",
      "331:\tlearn: 0.9020045\ttotal: 14.9s\tremaining: 12s\n",
      "332:\tlearn: 0.9019032\ttotal: 14.9s\tremaining: 12s\n",
      "333:\tlearn: 0.9029156\ttotal: 15s\tremaining: 11.9s\n",
      "334:\tlearn: 0.9032193\ttotal: 15s\tremaining: 11.9s\n",
      "335:\tlearn: 0.9033205\ttotal: 15.1s\tremaining: 11.8s\n",
      "336:\tlearn: 0.9037255\ttotal: 15.1s\tremaining: 11.8s\n",
      "337:\tlearn: 0.9039279\ttotal: 15.1s\tremaining: 11.7s\n",
      "338:\tlearn: 0.9042316\ttotal: 15.2s\tremaining: 11.7s\n",
      "339:\tlearn: 0.9042316\ttotal: 15.2s\tremaining: 11.6s\n",
      "340:\tlearn: 0.9048390\ttotal: 15.3s\tremaining: 11.6s\n",
      "341:\tlearn: 0.9050415\ttotal: 15.3s\tremaining: 11.6s\n",
      "342:\tlearn: 0.9048390\ttotal: 15.4s\tremaining: 11.5s\n",
      "343:\tlearn: 0.9057502\ttotal: 15.4s\tremaining: 11.5s\n",
      "344:\tlearn: 0.9060539\ttotal: 15.4s\tremaining: 11.4s\n",
      "345:\tlearn: 0.9068637\ttotal: 15.5s\tremaining: 11.4s\n",
      "346:\tlearn: 0.9074711\ttotal: 15.6s\tremaining: 11.3s\n",
      "347:\tlearn: 0.9089897\ttotal: 15.6s\tremaining: 11.3s\n",
      "348:\tlearn: 0.9090909\ttotal: 15.6s\tremaining: 11.2s\n",
      "349:\tlearn: 0.9093946\ttotal: 15.7s\tremaining: 11.2s\n",
      "350:\tlearn: 0.9101033\ttotal: 15.7s\tremaining: 11.2s\n",
      "351:\tlearn: 0.9111156\ttotal: 15.8s\tremaining: 11.1s\n",
      "352:\tlearn: 0.9118243\ttotal: 15.8s\tremaining: 11.1s\n",
      "353:\tlearn: 0.9122292\ttotal: 15.9s\tremaining: 11s\n",
      "354:\tlearn: 0.9117230\ttotal: 15.9s\tremaining: 11s\n",
      "355:\tlearn: 0.9119255\ttotal: 16s\tremaining: 10.9s\n",
      "356:\tlearn: 0.9126341\ttotal: 16s\tremaining: 10.9s\n",
      "357:\tlearn: 0.9126341\ttotal: 16s\tremaining: 10.8s\n",
      "358:\tlearn: 0.9128366\ttotal: 16.1s\tremaining: 10.8s\n",
      "359:\tlearn: 0.9131403\ttotal: 16.1s\tremaining: 10.8s\n",
      "360:\tlearn: 0.9132415\ttotal: 16.2s\tremaining: 10.7s\n",
      "361:\tlearn: 0.9134440\ttotal: 16.2s\tremaining: 10.7s\n",
      "362:\tlearn: 0.9130391\ttotal: 16.3s\tremaining: 10.6s\n",
      "363:\tlearn: 0.9122292\ttotal: 16.3s\tremaining: 10.6s\n",
      "364:\tlearn: 0.9126341\ttotal: 16.4s\tremaining: 10.5s\n",
      "365:\tlearn: 0.9119255\ttotal: 16.4s\tremaining: 10.5s\n",
      "366:\tlearn: 0.9137477\ttotal: 16.5s\tremaining: 10.4s\n",
      "367:\tlearn: 0.9137477\ttotal: 16.5s\tremaining: 10.4s\n",
      "368:\tlearn: 0.9140514\ttotal: 16.5s\tremaining: 10.4s\n",
      "369:\tlearn: 0.9142539\ttotal: 16.6s\tremaining: 10.3s\n",
      "370:\tlearn: 0.9154687\ttotal: 16.6s\tremaining: 10.3s\n",
      "371:\tlearn: 0.9156712\ttotal: 16.7s\tremaining: 10.2s\n",
      "372:\tlearn: 0.9158737\ttotal: 16.7s\tremaining: 10.2s\n",
      "373:\tlearn: 0.9154687\ttotal: 16.8s\tremaining: 10.1s\n",
      "374:\tlearn: 0.9164811\ttotal: 16.8s\tremaining: 10.1s\n",
      "375:\tlearn: 0.9161774\ttotal: 16.9s\tremaining: 10s\n",
      "376:\tlearn: 0.9164811\ttotal: 16.9s\tremaining: 10s\n",
      "377:\tlearn: 0.9166835\ttotal: 17s\tremaining: 9.96s\n",
      "378:\tlearn: 0.9170885\ttotal: 17s\tremaining: 9.91s\n",
      "379:\tlearn: 0.9175947\ttotal: 17s\tremaining: 9.87s\n",
      "380:\tlearn: 0.9176959\ttotal: 17.1s\tremaining: 9.82s\n",
      "381:\tlearn: 0.9173922\ttotal: 17.1s\tremaining: 9.77s\n",
      "382:\tlearn: 0.9172909\ttotal: 17.2s\tremaining: 9.73s\n",
      "383:\tlearn: 0.9178984\ttotal: 17.2s\tremaining: 9.69s\n",
      "384:\tlearn: 0.9185058\ttotal: 17.3s\tremaining: 9.64s\n",
      "385:\tlearn: 0.9178984\ttotal: 17.3s\tremaining: 9.6s\n",
      "386:\tlearn: 0.9188095\ttotal: 17.4s\tremaining: 9.55s\n",
      "387:\tlearn: 0.9185058\ttotal: 17.4s\tremaining: 9.51s\n",
      "388:\tlearn: 0.9192144\ttotal: 17.4s\tremaining: 9.46s\n",
      "389:\tlearn: 0.9199231\ttotal: 17.5s\tremaining: 9.42s\n",
      "390:\tlearn: 0.9203280\ttotal: 17.5s\tremaining: 9.37s\n",
      "391:\tlearn: 0.9199231\ttotal: 17.6s\tremaining: 9.33s\n",
      "392:\tlearn: 0.9202268\ttotal: 17.6s\tremaining: 9.29s\n",
      "393:\tlearn: 0.9201255\ttotal: 17.7s\tremaining: 9.24s\n",
      "394:\tlearn: 0.9210366\ttotal: 17.7s\tremaining: 9.2s\n",
      "395:\tlearn: 0.9204292\ttotal: 17.8s\tremaining: 9.15s\n",
      "396:\tlearn: 0.9210366\ttotal: 17.8s\tremaining: 9.11s\n",
      "397:\tlearn: 0.9218465\ttotal: 17.9s\tremaining: 9.06s\n",
      "398:\tlearn: 0.9222515\ttotal: 17.9s\tremaining: 9.02s\n",
      "399:\tlearn: 0.9222515\ttotal: 17.9s\tremaining: 8.97s\n",
      "400:\tlearn: 0.9225552\ttotal: 18s\tremaining: 8.92s\n",
      "401:\tlearn: 0.9226564\ttotal: 18s\tremaining: 8.88s\n",
      "402:\tlearn: 0.9226564\ttotal: 18.1s\tremaining: 8.83s\n",
      "403:\tlearn: 0.9230613\ttotal: 18.1s\tremaining: 8.79s\n",
      "404:\tlearn: 0.9245799\ttotal: 18.2s\tremaining: 8.74s\n",
      "405:\tlearn: 0.9248836\ttotal: 18.2s\tremaining: 8.69s\n",
      "406:\tlearn: 0.9251873\ttotal: 18.2s\tremaining: 8.65s\n",
      "407:\tlearn: 0.9253898\ttotal: 18.3s\tremaining: 8.61s\n",
      "408:\tlearn: 0.9250860\ttotal: 18.3s\tremaining: 8.56s\n",
      "409:\tlearn: 0.9257947\ttotal: 18.4s\tremaining: 8.51s\n",
      "410:\tlearn: 0.9249848\ttotal: 18.4s\tremaining: 8.47s\n",
      "411:\tlearn: 0.9256935\ttotal: 18.5s\tremaining: 8.43s\n",
      "412:\tlearn: 0.9273132\ttotal: 18.5s\tremaining: 8.38s\n",
      "413:\tlearn: 0.9272120\ttotal: 18.6s\tremaining: 8.34s\n",
      "414:\tlearn: 0.9279206\ttotal: 18.6s\tremaining: 8.29s\n",
      "415:\tlearn: 0.9273132\ttotal: 18.6s\tremaining: 8.25s\n",
      "416:\tlearn: 0.9273132\ttotal: 18.7s\tremaining: 8.21s\n",
      "417:\tlearn: 0.9272120\ttotal: 18.7s\tremaining: 8.16s\n",
      "418:\tlearn: 0.9282243\ttotal: 18.8s\tremaining: 8.12s\n",
      "419:\tlearn: 0.9286293\ttotal: 18.8s\tremaining: 8.07s\n",
      "420:\tlearn: 0.9288317\ttotal: 18.9s\tremaining: 8.02s\n",
      "421:\tlearn: 0.9298441\ttotal: 18.9s\tremaining: 7.98s\n",
      "422:\tlearn: 0.9298441\ttotal: 19s\tremaining: 7.93s\n",
      "423:\tlearn: 0.9300466\ttotal: 19s\tremaining: 7.89s\n",
      "424:\tlearn: 0.9309577\ttotal: 19s\tremaining: 7.84s\n",
      "425:\tlearn: 0.9308564\ttotal: 19.1s\tremaining: 7.8s\n",
      "426:\tlearn: 0.9313626\ttotal: 19.1s\tremaining: 7.75s\n",
      "427:\tlearn: 0.9309577\ttotal: 19.2s\tremaining: 7.71s\n",
      "428:\tlearn: 0.9313626\ttotal: 19.2s\tremaining: 7.66s\n",
      "429:\tlearn: 0.9321725\ttotal: 19.3s\tremaining: 7.62s\n",
      "430:\tlearn: 0.9328812\ttotal: 19.3s\tremaining: 7.57s\n",
      "431:\tlearn: 0.9331849\ttotal: 19.4s\tremaining: 7.53s\n",
      "432:\tlearn: 0.9333873\ttotal: 19.4s\tremaining: 7.48s\n",
      "433:\tlearn: 0.9325774\ttotal: 19.4s\tremaining: 7.44s\n",
      "434:\tlearn: 0.9327799\ttotal: 19.5s\tremaining: 7.39s\n",
      "435:\tlearn: 0.9334886\ttotal: 19.5s\tremaining: 7.35s\n",
      "436:\tlearn: 0.9336910\ttotal: 19.6s\tremaining: 7.3s\n",
      "437:\tlearn: 0.9339947\ttotal: 19.6s\tremaining: 7.26s\n",
      "438:\tlearn: 0.9337923\ttotal: 19.7s\tremaining: 7.21s\n",
      "439:\tlearn: 0.9347034\ttotal: 19.7s\tremaining: 7.17s\n",
      "440:\tlearn: 0.9347034\ttotal: 19.8s\tremaining: 7.12s\n",
      "441:\tlearn: 0.9350071\ttotal: 19.8s\tremaining: 7.08s\n",
      "442:\tlearn: 0.9350071\ttotal: 19.8s\tremaining: 7.03s\n",
      "443:\tlearn: 0.9352096\ttotal: 19.9s\tremaining: 6.99s\n",
      "444:\tlearn: 0.9350071\ttotal: 19.9s\tremaining: 6.94s\n",
      "445:\tlearn: 0.9356145\ttotal: 20s\tremaining: 6.9s\n",
      "446:\tlearn: 0.9360194\ttotal: 20s\tremaining: 6.85s\n",
      "447:\tlearn: 0.9370318\ttotal: 20.1s\tremaining: 6.81s\n",
      "448:\tlearn: 0.9366268\ttotal: 20.1s\tremaining: 6.76s\n",
      "449:\tlearn: 0.9369306\ttotal: 20.2s\tremaining: 6.72s\n",
      "450:\tlearn: 0.9371330\ttotal: 20.2s\tremaining: 6.67s\n",
      "451:\tlearn: 0.9381454\ttotal: 20.2s\tremaining: 6.63s\n",
      "452:\tlearn: 0.9388540\ttotal: 20.3s\tremaining: 6.58s\n",
      "453:\tlearn: 0.9382466\ttotal: 20.3s\tremaining: 6.54s\n",
      "454:\tlearn: 0.9387528\ttotal: 20.4s\tremaining: 6.49s\n",
      "455:\tlearn: 0.9391577\ttotal: 20.4s\tremaining: 6.45s\n",
      "456:\tlearn: 0.9396639\ttotal: 20.5s\tremaining: 6.4s\n",
      "457:\tlearn: 0.9399676\ttotal: 20.5s\tremaining: 6.36s\n",
      "458:\tlearn: 0.9398664\ttotal: 20.6s\tremaining: 6.31s\n",
      "459:\tlearn: 0.9399676\ttotal: 20.6s\tremaining: 6.27s\n",
      "460:\tlearn: 0.9404738\ttotal: 20.6s\tremaining: 6.22s\n",
      "461:\tlearn: 0.9404738\ttotal: 20.7s\tremaining: 6.18s\n",
      "462:\tlearn: 0.9402713\ttotal: 20.7s\tremaining: 6.13s\n",
      "463:\tlearn: 0.9410812\ttotal: 20.8s\tremaining: 6.09s\n",
      "464:\tlearn: 0.9407775\ttotal: 20.8s\tremaining: 6.04s\n",
      "465:\tlearn: 0.9410812\ttotal: 20.9s\tremaining: 6s\n",
      "466:\tlearn: 0.9412837\ttotal: 20.9s\tremaining: 5.95s\n",
      "467:\tlearn: 0.9414861\ttotal: 21s\tremaining: 5.91s\n",
      "468:\tlearn: 0.9415874\ttotal: 21s\tremaining: 5.86s\n",
      "469:\tlearn: 0.9420935\ttotal: 21s\tremaining: 5.82s\n",
      "470:\tlearn: 0.9430047\ttotal: 21.1s\tremaining: 5.77s\n",
      "471:\tlearn: 0.9427010\ttotal: 21.1s\tremaining: 5.73s\n",
      "472:\tlearn: 0.9430047\ttotal: 21.2s\tremaining: 5.68s\n",
      "473:\tlearn: 0.9430047\ttotal: 21.2s\tremaining: 5.64s\n",
      "474:\tlearn: 0.9436121\ttotal: 21.3s\tremaining: 5.59s\n",
      "475:\tlearn: 0.9438145\ttotal: 21.3s\tremaining: 5.55s\n",
      "476:\tlearn: 0.9441182\ttotal: 21.3s\tremaining: 5.5s\n",
      "477:\tlearn: 0.9445232\ttotal: 21.4s\tremaining: 5.46s\n",
      "478:\tlearn: 0.9448269\ttotal: 21.4s\tremaining: 5.41s\n",
      "479:\tlearn: 0.9446244\ttotal: 21.5s\tremaining: 5.37s\n",
      "480:\tlearn: 0.9445232\ttotal: 21.5s\tremaining: 5.32s\n",
      "481:\tlearn: 0.9442195\ttotal: 21.6s\tremaining: 5.28s\n",
      "482:\tlearn: 0.9449281\ttotal: 21.6s\tremaining: 5.23s\n",
      "483:\tlearn: 0.9453331\ttotal: 21.7s\tremaining: 5.19s\n",
      "484:\tlearn: 0.9462442\ttotal: 21.7s\tremaining: 5.14s\n",
      "485:\tlearn: 0.9456368\ttotal: 21.7s\tremaining: 5.1s\n",
      "486:\tlearn: 0.9459405\ttotal: 21.8s\tremaining: 5.05s\n",
      "487:\tlearn: 0.9465479\ttotal: 21.8s\tremaining: 5.01s\n",
      "488:\tlearn: 0.9460417\ttotal: 21.9s\tremaining: 4.96s\n",
      "489:\tlearn: 0.9461429\ttotal: 21.9s\tremaining: 4.92s\n",
      "490:\tlearn: 0.9464466\ttotal: 21.9s\tremaining: 4.87s\n",
      "491:\tlearn: 0.9467504\ttotal: 22s\tremaining: 4.83s\n",
      "492:\tlearn: 0.9466491\ttotal: 22s\tremaining: 4.78s\n",
      "493:\tlearn: 0.9470541\ttotal: 22.1s\tremaining: 4.74s\n",
      "494:\tlearn: 0.9472565\ttotal: 22.1s\tremaining: 4.69s\n",
      "495:\tlearn: 0.9479652\ttotal: 22.2s\tremaining: 4.65s\n",
      "496:\tlearn: 0.9483701\ttotal: 22.2s\tremaining: 4.6s\n",
      "497:\tlearn: 0.9483701\ttotal: 22.3s\tremaining: 4.56s\n",
      "498:\tlearn: 0.9482689\ttotal: 22.3s\tremaining: 4.51s\n",
      "499:\tlearn: 0.9487751\ttotal: 22.3s\tremaining: 4.47s\n",
      "500:\tlearn: 0.9492812\ttotal: 22.4s\tremaining: 4.42s\n",
      "501:\tlearn: 0.9494837\ttotal: 22.4s\tremaining: 4.38s\n",
      "502:\tlearn: 0.9491800\ttotal: 22.5s\tremaining: 4.33s\n",
      "503:\tlearn: 0.9498886\ttotal: 22.5s\tremaining: 4.29s\n",
      "504:\tlearn: 0.9503948\ttotal: 22.6s\tremaining: 4.24s\n",
      "505:\tlearn: 0.9499899\ttotal: 22.6s\tremaining: 4.2s\n",
      "506:\tlearn: 0.9501923\ttotal: 22.6s\tremaining: 4.15s\n",
      "507:\tlearn: 0.9513059\ttotal: 22.7s\tremaining: 4.11s\n",
      "508:\tlearn: 0.9516096\ttotal: 22.7s\tremaining: 4.06s\n",
      "509:\tlearn: 0.9514072\ttotal: 22.8s\tremaining: 4.02s\n",
      "510:\tlearn: 0.9514072\ttotal: 22.8s\tremaining: 3.97s\n",
      "511:\tlearn: 0.9517109\ttotal: 22.9s\tremaining: 3.93s\n",
      "512:\tlearn: 0.9524195\ttotal: 22.9s\tremaining: 3.88s\n",
      "513:\tlearn: 0.9523183\ttotal: 23s\tremaining: 3.84s\n",
      "514:\tlearn: 0.9520146\ttotal: 23s\tremaining: 3.79s\n",
      "515:\tlearn: 0.9522170\ttotal: 23s\tremaining: 3.75s\n",
      "516:\tlearn: 0.9526220\ttotal: 23.1s\tremaining: 3.71s\n",
      "517:\tlearn: 0.9530269\ttotal: 23.1s\tremaining: 3.66s\n",
      "518:\tlearn: 0.9527232\ttotal: 23.2s\tremaining: 3.62s\n",
      "519:\tlearn: 0.9531282\ttotal: 23.2s\tremaining: 3.57s\n",
      "520:\tlearn: 0.9534319\ttotal: 23.3s\tremaining: 3.53s\n",
      "521:\tlearn: 0.9538368\ttotal: 23.3s\tremaining: 3.48s\n",
      "522:\tlearn: 0.9538368\ttotal: 23.3s\tremaining: 3.44s\n",
      "523:\tlearn: 0.9540393\ttotal: 23.4s\tremaining: 3.39s\n",
      "524:\tlearn: 0.9540393\ttotal: 23.4s\tremaining: 3.35s\n",
      "525:\tlearn: 0.9539380\ttotal: 23.5s\tremaining: 3.3s\n",
      "526:\tlearn: 0.9544442\ttotal: 23.5s\tremaining: 3.26s\n",
      "527:\tlearn: 0.9549504\ttotal: 23.6s\tremaining: 3.21s\n",
      "528:\tlearn: 0.9549504\ttotal: 23.6s\tremaining: 3.17s\n",
      "529:\tlearn: 0.9551529\ttotal: 23.6s\tremaining: 3.12s\n",
      "530:\tlearn: 0.9553553\ttotal: 23.7s\tremaining: 3.08s\n",
      "531:\tlearn: 0.9555578\ttotal: 23.7s\tremaining: 3.03s\n",
      "532:\tlearn: 0.9556590\ttotal: 23.8s\tremaining: 2.99s\n",
      "533:\tlearn: 0.9560640\ttotal: 23.8s\tremaining: 2.94s\n",
      "534:\tlearn: 0.9562665\ttotal: 23.9s\tremaining: 2.9s\n",
      "535:\tlearn: 0.9564689\ttotal: 23.9s\tremaining: 2.85s\n",
      "536:\tlearn: 0.9561652\ttotal: 24s\tremaining: 2.81s\n",
      "537:\tlearn: 0.9562665\ttotal: 24s\tremaining: 2.77s\n",
      "538:\tlearn: 0.9571776\ttotal: 24s\tremaining: 2.72s\n",
      "539:\tlearn: 0.9567726\ttotal: 24.1s\tremaining: 2.68s\n",
      "540:\tlearn: 0.9573800\ttotal: 24.1s\tremaining: 2.63s\n",
      "541:\tlearn: 0.9574813\ttotal: 24.2s\tremaining: 2.59s\n",
      "542:\tlearn: 0.9579874\ttotal: 24.2s\tremaining: 2.54s\n",
      "543:\tlearn: 0.9579874\ttotal: 24.3s\tremaining: 2.5s\n",
      "544:\tlearn: 0.9582912\ttotal: 24.3s\tremaining: 2.45s\n",
      "545:\tlearn: 0.9581899\ttotal: 24.4s\tremaining: 2.41s\n",
      "546:\tlearn: 0.9579874\ttotal: 24.4s\tremaining: 2.36s\n",
      "547:\tlearn: 0.9580887\ttotal: 24.5s\tremaining: 2.32s\n",
      "548:\tlearn: 0.9576837\ttotal: 24.5s\tremaining: 2.27s\n",
      "549:\tlearn: 0.9575825\ttotal: 24.5s\tremaining: 2.23s\n",
      "550:\tlearn: 0.9580887\ttotal: 24.6s\tremaining: 2.19s\n",
      "551:\tlearn: 0.9580887\ttotal: 24.6s\tremaining: 2.14s\n",
      "552:\tlearn: 0.9580887\ttotal: 24.7s\tremaining: 2.1s\n",
      "553:\tlearn: 0.9580887\ttotal: 24.7s\tremaining: 2.05s\n",
      "554:\tlearn: 0.9584936\ttotal: 24.8s\tremaining: 2.01s\n",
      "555:\tlearn: 0.9584936\ttotal: 24.8s\tremaining: 1.96s\n",
      "556:\tlearn: 0.9583924\ttotal: 24.8s\tremaining: 1.92s\n",
      "557:\tlearn: 0.9594047\ttotal: 24.9s\tremaining: 1.87s\n",
      "558:\tlearn: 0.9591010\ttotal: 24.9s\tremaining: 1.83s\n",
      "559:\tlearn: 0.9593035\ttotal: 25s\tremaining: 1.78s\n",
      "560:\tlearn: 0.9595060\ttotal: 25s\tremaining: 1.74s\n",
      "561:\tlearn: 0.9599109\ttotal: 25.1s\tremaining: 1.69s\n",
      "562:\tlearn: 0.9598097\ttotal: 25.1s\tremaining: 1.65s\n",
      "563:\tlearn: 0.9603159\ttotal: 25.1s\tremaining: 1.6s\n",
      "564:\tlearn: 0.9603159\ttotal: 25.2s\tremaining: 1.56s\n",
      "565:\tlearn: 0.9603159\ttotal: 25.2s\tremaining: 1.51s\n",
      "566:\tlearn: 0.9603159\ttotal: 25.3s\tremaining: 1.47s\n",
      "567:\tlearn: 0.9603159\ttotal: 25.3s\tremaining: 1.43s\n",
      "568:\tlearn: 0.9602146\ttotal: 25.4s\tremaining: 1.38s\n",
      "569:\tlearn: 0.9603159\ttotal: 25.4s\tremaining: 1.34s\n",
      "570:\tlearn: 0.9601134\ttotal: 25.4s\tremaining: 1.29s\n",
      "571:\tlearn: 0.9601134\ttotal: 25.5s\tremaining: 1.25s\n",
      "572:\tlearn: 0.9607208\ttotal: 25.5s\tremaining: 1.2s\n",
      "573:\tlearn: 0.9605183\ttotal: 25.6s\tremaining: 1.16s\n",
      "574:\tlearn: 0.9605183\ttotal: 25.6s\tremaining: 1.11s\n",
      "575:\tlearn: 0.9606196\ttotal: 25.7s\tremaining: 1.07s\n",
      "576:\tlearn: 0.9605183\ttotal: 25.7s\tremaining: 1.02s\n",
      "577:\tlearn: 0.9610245\ttotal: 25.7s\tremaining: 980ms\n",
      "578:\tlearn: 0.9616319\ttotal: 25.8s\tremaining: 935ms\n",
      "579:\tlearn: 0.9616319\ttotal: 25.8s\tremaining: 891ms\n",
      "580:\tlearn: 0.9616319\ttotal: 25.9s\tremaining: 846ms\n",
      "581:\tlearn: 0.9614294\ttotal: 25.9s\tremaining: 802ms\n",
      "582:\tlearn: 0.9613282\ttotal: 26s\tremaining: 757ms\n",
      "583:\tlearn: 0.9617331\ttotal: 26s\tremaining: 713ms\n",
      "584:\tlearn: 0.9623406\ttotal: 26.1s\tremaining: 668ms\n",
      "585:\tlearn: 0.9617331\ttotal: 26.1s\tremaining: 623ms\n",
      "586:\tlearn: 0.9620368\ttotal: 26.1s\tremaining: 579ms\n",
      "587:\tlearn: 0.9619356\ttotal: 26.2s\tremaining: 534ms\n",
      "588:\tlearn: 0.9620368\ttotal: 26.2s\tremaining: 490ms\n",
      "589:\tlearn: 0.9630492\ttotal: 26.3s\tremaining: 445ms\n",
      "590:\tlearn: 0.9632517\ttotal: 26.3s\tremaining: 401ms\n",
      "591:\tlearn: 0.9633529\ttotal: 26.3s\tremaining: 356ms\n",
      "592:\tlearn: 0.9637578\ttotal: 26.4s\tremaining: 312ms\n",
      "593:\tlearn: 0.9641628\ttotal: 26.4s\tremaining: 267ms\n",
      "594:\tlearn: 0.9636566\ttotal: 26.5s\tremaining: 223ms\n",
      "595:\tlearn: 0.9637578\ttotal: 26.5s\tremaining: 178ms\n",
      "596:\tlearn: 0.9639603\ttotal: 26.6s\tremaining: 134ms\n",
      "597:\tlearn: 0.9641628\ttotal: 26.6s\tremaining: 89ms\n",
      "598:\tlearn: 0.9642640\ttotal: 26.7s\tremaining: 44.5ms\n",
      "599:\tlearn: 0.9642640\ttotal: 26.7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=5, eval_metric=Recall, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.05, random_strength=5; total time=  27.4s\n",
      "0:\tlearn: 0.7236283\ttotal: 46.6ms\tremaining: 27.9s\n",
      "1:\tlearn: 0.6317068\ttotal: 98.3ms\tremaining: 29.4s\n",
      "2:\tlearn: 0.6256327\ttotal: 140ms\tremaining: 27.9s\n",
      "3:\tlearn: 0.6184450\ttotal: 185ms\tremaining: 27.6s\n",
      "4:\tlearn: 0.6013363\ttotal: 230ms\tremaining: 27.4s\n",
      "5:\tlearn: 0.6222920\ttotal: 276ms\tremaining: 27.4s\n",
      "6:\tlearn: 0.6209759\ttotal: 320ms\tremaining: 27.1s\n",
      "7:\tlearn: 0.6314031\ttotal: 362ms\tremaining: 26.8s\n",
      "8:\tlearn: 0.6320105\ttotal: 403ms\tremaining: 26.4s\n",
      "9:\tlearn: 0.6324155\ttotal: 447ms\tremaining: 26.4s\n",
      "10:\tlearn: 0.6323142\ttotal: 492ms\tremaining: 26.4s\n",
      "11:\tlearn: 0.6385908\ttotal: 537ms\tremaining: 26.3s\n",
      "12:\tlearn: 0.6339340\ttotal: 584ms\tremaining: 26.4s\n",
      "13:\tlearn: 0.6331241\ttotal: 630ms\tremaining: 26.4s\n",
      "14:\tlearn: 0.6392995\ttotal: 676ms\tremaining: 26.3s\n",
      "15:\tlearn: 0.6362624\ttotal: 728ms\tremaining: 26.6s\n",
      "16:\tlearn: 0.6367686\ttotal: 774ms\tremaining: 26.5s\n",
      "17:\tlearn: 0.6371735\ttotal: 818ms\tremaining: 26.5s\n",
      "18:\tlearn: 0.6342377\ttotal: 868ms\tremaining: 26.5s\n",
      "19:\tlearn: 0.6428427\ttotal: 911ms\tremaining: 26.4s\n",
      "20:\tlearn: 0.6425390\ttotal: 959ms\tremaining: 26.4s\n",
      "21:\tlearn: 0.6501316\ttotal: 1s\tremaining: 26.3s\n",
      "22:\tlearn: 0.6546872\ttotal: 1.05s\tremaining: 26.4s\n",
      "23:\tlearn: 0.6512452\ttotal: 1.1s\tremaining: 26.4s\n",
      "24:\tlearn: 0.6532699\ttotal: 1.15s\tremaining: 26.4s\n",
      "25:\tlearn: 0.6537761\ttotal: 1.19s\tremaining: 26.4s\n",
      "26:\tlearn: 0.6540798\ttotal: 1.24s\tremaining: 26.3s\n",
      "27:\tlearn: 0.6545859\ttotal: 1.28s\tremaining: 26.2s\n",
      "28:\tlearn: 0.6560032\ttotal: 1.33s\tremaining: 26.1s\n",
      "29:\tlearn: 0.6601539\ttotal: 1.37s\tremaining: 26.1s\n",
      "30:\tlearn: 0.6647095\ttotal: 1.42s\tremaining: 26s\n",
      "31:\tlearn: 0.6650132\ttotal: 1.46s\tremaining: 25.9s\n",
      "32:\tlearn: 0.6684552\ttotal: 1.51s\tremaining: 26s\n",
      "33:\tlearn: 0.6690626\ttotal: 1.55s\tremaining: 25.9s\n",
      "34:\tlearn: 0.6697712\ttotal: 1.6s\tremaining: 25.8s\n",
      "35:\tlearn: 0.6708848\ttotal: 1.64s\tremaining: 25.8s\n",
      "36:\tlearn: 0.6716947\ttotal: 1.69s\tremaining: 25.7s\n",
      "37:\tlearn: 0.6714922\ttotal: 1.74s\tremaining: 25.7s\n",
      "38:\tlearn: 0.6741243\ttotal: 1.78s\tremaining: 25.6s\n",
      "39:\tlearn: 0.6755416\ttotal: 1.82s\tremaining: 25.6s\n",
      "40:\tlearn: 0.6757441\ttotal: 1.86s\tremaining: 25.4s\n",
      "41:\tlearn: 0.6801984\ttotal: 1.91s\tremaining: 25.4s\n",
      "42:\tlearn: 0.6836404\ttotal: 1.96s\tremaining: 25.3s\n",
      "43:\tlearn: 0.6839441\ttotal: 2s\tremaining: 25.3s\n",
      "44:\tlearn: 0.6847540\ttotal: 2.04s\tremaining: 25.2s\n",
      "45:\tlearn: 0.6853614\ttotal: 2.09s\tremaining: 25.2s\n",
      "46:\tlearn: 0.6884997\ttotal: 2.13s\tremaining: 25.1s\n",
      "47:\tlearn: 0.6940676\ttotal: 2.18s\tremaining: 25.1s\n",
      "48:\tlearn: 0.6926503\ttotal: 2.23s\tremaining: 25.1s\n",
      "49:\tlearn: 0.6957886\ttotal: 2.28s\tremaining: 25.1s\n",
      "50:\tlearn: 0.6956874\ttotal: 2.33s\tremaining: 25.1s\n",
      "51:\tlearn: 0.6986232\ttotal: 2.37s\tremaining: 25s\n",
      "52:\tlearn: 0.6991294\ttotal: 2.41s\tremaining: 24.8s\n",
      "53:\tlearn: 0.6985220\ttotal: 2.45s\tremaining: 24.8s\n",
      "54:\tlearn: 0.7011541\ttotal: 2.49s\tremaining: 24.7s\n",
      "55:\tlearn: 0.7012553\ttotal: 2.53s\tremaining: 24.6s\n",
      "56:\tlearn: 0.7022677\ttotal: 2.58s\tremaining: 24.5s\n",
      "57:\tlearn: 0.7024701\ttotal: 2.62s\tremaining: 24.5s\n",
      "58:\tlearn: 0.7037862\ttotal: 2.67s\tremaining: 24.5s\n",
      "59:\tlearn: 0.7081393\ttotal: 2.71s\tremaining: 24.4s\n",
      "60:\tlearn: 0.7076331\ttotal: 2.76s\tremaining: 24.4s\n",
      "61:\tlearn: 0.7072282\ttotal: 2.8s\tremaining: 24.3s\n",
      "62:\tlearn: 0.7095566\ttotal: 2.85s\tremaining: 24.3s\n",
      "63:\tlearn: 0.7085442\ttotal: 2.9s\tremaining: 24.3s\n",
      "64:\tlearn: 0.7099615\ttotal: 2.95s\tremaining: 24.3s\n",
      "65:\tlearn: 0.7100628\ttotal: 2.99s\tremaining: 24.2s\n",
      "66:\tlearn: 0.7104677\ttotal: 3.04s\tremaining: 24.2s\n",
      "67:\tlearn: 0.7113788\ttotal: 3.08s\tremaining: 24.1s\n",
      "68:\tlearn: 0.7111764\ttotal: 3.12s\tremaining: 24s\n",
      "69:\tlearn: 0.7128973\ttotal: 3.16s\tremaining: 24s\n",
      "70:\tlearn: 0.7159344\ttotal: 3.21s\tremaining: 23.9s\n",
      "71:\tlearn: 0.7164406\ttotal: 3.25s\tremaining: 23.9s\n",
      "72:\tlearn: 0.7196801\ttotal: 3.3s\tremaining: 23.8s\n",
      "73:\tlearn: 0.7210974\ttotal: 3.34s\tremaining: 23.8s\n",
      "74:\tlearn: 0.7210974\ttotal: 3.38s\tremaining: 23.7s\n",
      "75:\tlearn: 0.7234258\ttotal: 3.43s\tremaining: 23.7s\n",
      "76:\tlearn: 0.7259567\ttotal: 3.48s\tremaining: 23.6s\n",
      "77:\tlearn: 0.7269690\ttotal: 3.52s\tremaining: 23.6s\n",
      "78:\tlearn: 0.7270703\ttotal: 3.57s\tremaining: 23.5s\n",
      "79:\tlearn: 0.7298036\ttotal: 3.61s\tremaining: 23.5s\n",
      "80:\tlearn: 0.7318283\ttotal: 3.66s\tremaining: 23.4s\n",
      "81:\tlearn: 0.7314234\ttotal: 3.7s\tremaining: 23.4s\n",
      "82:\tlearn: 0.7339542\ttotal: 3.75s\tremaining: 23.4s\n",
      "83:\tlearn: 0.7330431\ttotal: 3.79s\tremaining: 23.3s\n",
      "84:\tlearn: 0.7342579\ttotal: 3.84s\tremaining: 23.3s\n",
      "85:\tlearn: 0.7347641\ttotal: 3.89s\tremaining: 23.2s\n",
      "86:\tlearn: 0.7352703\ttotal: 3.93s\tremaining: 23.2s\n",
      "87:\tlearn: 0.7354728\ttotal: 3.98s\tremaining: 23.1s\n",
      "88:\tlearn: 0.7375987\ttotal: 4.02s\tremaining: 23.1s\n",
      "89:\tlearn: 0.7369913\ttotal: 4.06s\tremaining: 23s\n",
      "90:\tlearn: 0.7368901\ttotal: 4.11s\tremaining: 23s\n",
      "91:\tlearn: 0.7357765\ttotal: 4.15s\tremaining: 22.9s\n",
      "92:\tlearn: 0.7376999\ttotal: 4.2s\tremaining: 22.9s\n",
      "93:\tlearn: 0.7380036\ttotal: 4.24s\tremaining: 22.8s\n",
      "94:\tlearn: 0.7398259\ttotal: 4.29s\tremaining: 22.8s\n",
      "95:\tlearn: 0.7403321\ttotal: 4.33s\tremaining: 22.7s\n",
      "96:\tlearn: 0.7421543\ttotal: 4.37s\tremaining: 22.7s\n",
      "97:\tlearn: 0.7424580\ttotal: 4.42s\tremaining: 22.6s\n",
      "98:\tlearn: 0.7391172\ttotal: 4.46s\tremaining: 22.6s\n",
      "99:\tlearn: 0.7411419\ttotal: 4.5s\tremaining: 22.5s\n",
      "100:\tlearn: 0.7429642\ttotal: 4.55s\tremaining: 22.5s\n",
      "101:\tlearn: 0.7441790\ttotal: 4.59s\tremaining: 22.4s\n",
      "102:\tlearn: 0.7436728\ttotal: 4.64s\tremaining: 22.4s\n",
      "103:\tlearn: 0.7461024\ttotal: 4.69s\tremaining: 22.4s\n",
      "104:\tlearn: 0.7460012\ttotal: 4.73s\tremaining: 22.3s\n",
      "105:\tlearn: 0.7454950\ttotal: 4.78s\tremaining: 22.3s\n",
      "106:\tlearn: 0.7462037\ttotal: 4.82s\tremaining: 22.2s\n",
      "107:\tlearn: 0.7499494\ttotal: 4.87s\tremaining: 22.2s\n",
      "108:\tlearn: 0.7486333\ttotal: 4.91s\tremaining: 22.1s\n",
      "109:\tlearn: 0.7505568\ttotal: 4.96s\tremaining: 22.1s\n",
      "110:\tlearn: 0.7506580\ttotal: 5s\tremaining: 22s\n",
      "111:\tlearn: 0.7517716\ttotal: 5.04s\tremaining: 22s\n",
      "112:\tlearn: 0.7525815\ttotal: 5.08s\tremaining: 21.9s\n",
      "113:\tlearn: 0.7526827\ttotal: 5.13s\tremaining: 21.9s\n",
      "114:\tlearn: 0.7539988\ttotal: 5.17s\tremaining: 21.8s\n",
      "115:\tlearn: 0.7553148\ttotal: 5.22s\tremaining: 21.8s\n",
      "116:\tlearn: 0.7573395\ttotal: 5.26s\tremaining: 21.7s\n",
      "117:\tlearn: 0.7583519\ttotal: 5.31s\tremaining: 21.7s\n",
      "118:\tlearn: 0.7581494\ttotal: 5.35s\tremaining: 21.6s\n",
      "119:\tlearn: 0.7603766\ttotal: 5.39s\tremaining: 21.6s\n",
      "120:\tlearn: 0.7599717\ttotal: 5.44s\tremaining: 21.5s\n",
      "121:\tlearn: 0.7589593\ttotal: 5.48s\tremaining: 21.5s\n",
      "122:\tlearn: 0.7599717\ttotal: 5.53s\tremaining: 21.4s\n",
      "123:\tlearn: 0.7607815\ttotal: 5.57s\tremaining: 21.4s\n",
      "124:\tlearn: 0.7597692\ttotal: 5.62s\tremaining: 21.3s\n",
      "125:\tlearn: 0.7609840\ttotal: 5.66s\tremaining: 21.3s\n",
      "126:\tlearn: 0.7618951\ttotal: 5.71s\tremaining: 21.3s\n",
      "127:\tlearn: 0.7609840\ttotal: 5.76s\tremaining: 21.2s\n",
      "128:\tlearn: 0.7618951\ttotal: 5.8s\tremaining: 21.2s\n",
      "129:\tlearn: 0.7618951\ttotal: 5.84s\tremaining: 21.1s\n",
      "130:\tlearn: 0.7630087\ttotal: 5.89s\tremaining: 21.1s\n",
      "131:\tlearn: 0.7645272\ttotal: 5.93s\tremaining: 21s\n",
      "132:\tlearn: 0.7638186\ttotal: 5.97s\tremaining: 21s\n",
      "133:\tlearn: 0.7643248\ttotal: 6.02s\tremaining: 20.9s\n",
      "134:\tlearn: 0.7650334\ttotal: 6.06s\tremaining: 20.9s\n",
      "135:\tlearn: 0.7671593\ttotal: 6.11s\tremaining: 20.8s\n",
      "136:\tlearn: 0.7684754\ttotal: 6.15s\tremaining: 20.8s\n",
      "137:\tlearn: 0.7697915\ttotal: 6.19s\tremaining: 20.7s\n",
      "138:\tlearn: 0.7699939\ttotal: 6.24s\tremaining: 20.7s\n",
      "139:\tlearn: 0.7701964\ttotal: 6.28s\tremaining: 20.6s\n",
      "140:\tlearn: 0.7713100\ttotal: 6.32s\tremaining: 20.6s\n",
      "141:\tlearn: 0.7701964\ttotal: 6.36s\tremaining: 20.5s\n",
      "142:\tlearn: 0.7707026\ttotal: 6.41s\tremaining: 20.5s\n",
      "143:\tlearn: 0.7725248\ttotal: 6.45s\tremaining: 20.4s\n",
      "144:\tlearn: 0.7718162\ttotal: 6.49s\tremaining: 20.4s\n",
      "145:\tlearn: 0.7744483\ttotal: 6.54s\tremaining: 20.3s\n",
      "146:\tlearn: 0.7753594\ttotal: 6.58s\tremaining: 20.3s\n",
      "147:\tlearn: 0.7745495\ttotal: 6.63s\tremaining: 20.2s\n",
      "148:\tlearn: 0.7758656\ttotal: 6.67s\tremaining: 20.2s\n",
      "149:\tlearn: 0.7765742\ttotal: 6.71s\tremaining: 20.1s\n",
      "150:\tlearn: 0.7760680\ttotal: 6.75s\tremaining: 20.1s\n",
      "151:\tlearn: 0.7750557\ttotal: 6.79s\tremaining: 20s\n",
      "152:\tlearn: 0.7757643\ttotal: 6.84s\tremaining: 20s\n",
      "153:\tlearn: 0.7760680\ttotal: 6.89s\tremaining: 19.9s\n",
      "154:\tlearn: 0.7778903\ttotal: 6.94s\tremaining: 19.9s\n",
      "155:\tlearn: 0.7790038\ttotal: 6.99s\tremaining: 19.9s\n",
      "156:\tlearn: 0.7796113\ttotal: 7.04s\tremaining: 19.9s\n",
      "157:\tlearn: 0.7802187\ttotal: 7.08s\tremaining: 19.8s\n",
      "158:\tlearn: 0.7802187\ttotal: 7.12s\tremaining: 19.8s\n",
      "159:\tlearn: 0.7792063\ttotal: 7.17s\tremaining: 19.7s\n",
      "160:\tlearn: 0.7795100\ttotal: 7.21s\tremaining: 19.7s\n",
      "161:\tlearn: 0.7819397\ttotal: 7.26s\tremaining: 19.6s\n",
      "162:\tlearn: 0.7829520\ttotal: 7.3s\tremaining: 19.6s\n",
      "163:\tlearn: 0.7832557\ttotal: 7.35s\tremaining: 19.5s\n",
      "164:\tlearn: 0.7838631\ttotal: 7.39s\tremaining: 19.5s\n",
      "165:\tlearn: 0.7858878\ttotal: 7.44s\tremaining: 19.4s\n",
      "166:\tlearn: 0.7872039\ttotal: 7.49s\tremaining: 19.4s\n",
      "167:\tlearn: 0.7855841\ttotal: 7.53s\tremaining: 19.4s\n",
      "168:\tlearn: 0.7863940\ttotal: 7.58s\tremaining: 19.3s\n",
      "169:\tlearn: 0.7875076\ttotal: 7.62s\tremaining: 19.3s\n",
      "170:\tlearn: 0.7894311\ttotal: 7.67s\tremaining: 19.2s\n",
      "171:\tlearn: 0.7905446\ttotal: 7.71s\tremaining: 19.2s\n",
      "172:\tlearn: 0.7914558\ttotal: 7.76s\tremaining: 19.1s\n",
      "173:\tlearn: 0.7923669\ttotal: 7.8s\tremaining: 19.1s\n",
      "174:\tlearn: 0.7937842\ttotal: 7.84s\tremaining: 19s\n",
      "175:\tlearn: 0.7941891\ttotal: 7.89s\tremaining: 19s\n",
      "176:\tlearn: 0.7957076\ttotal: 7.93s\tremaining: 19s\n",
      "177:\tlearn: 0.7963150\ttotal: 7.98s\tremaining: 18.9s\n",
      "178:\tlearn: 0.7949990\ttotal: 8.02s\tremaining: 18.9s\n",
      "179:\tlearn: 0.7973274\ttotal: 8.06s\tremaining: 18.8s\n",
      "180:\tlearn: 0.7966187\ttotal: 8.11s\tremaining: 18.8s\n",
      "181:\tlearn: 0.7969225\ttotal: 8.15s\tremaining: 18.7s\n",
      "182:\tlearn: 0.7981373\ttotal: 8.2s\tremaining: 18.7s\n",
      "183:\tlearn: 0.7987447\ttotal: 8.24s\tremaining: 18.6s\n",
      "184:\tlearn: 0.8001620\ttotal: 8.28s\tremaining: 18.6s\n",
      "185:\tlearn: 0.8006682\ttotal: 8.33s\tremaining: 18.5s\n",
      "186:\tlearn: 0.7991496\ttotal: 8.38s\tremaining: 18.5s\n",
      "187:\tlearn: 0.8009719\ttotal: 8.43s\tremaining: 18.5s\n",
      "188:\tlearn: 0.8020854\ttotal: 8.47s\tremaining: 18.4s\n",
      "189:\tlearn: 0.8023891\ttotal: 8.52s\tremaining: 18.4s\n",
      "190:\tlearn: 0.8033003\ttotal: 8.56s\tremaining: 18.3s\n",
      "191:\tlearn: 0.8034015\ttotal: 8.61s\tremaining: 18.3s\n",
      "192:\tlearn: 0.8037052\ttotal: 8.66s\tremaining: 18.3s\n",
      "193:\tlearn: 0.8041101\ttotal: 8.7s\tremaining: 18.2s\n",
      "194:\tlearn: 0.8039077\ttotal: 8.75s\tremaining: 18.2s\n",
      "195:\tlearn: 0.8062361\ttotal: 8.79s\tremaining: 18.1s\n",
      "196:\tlearn: 0.8058311\ttotal: 8.83s\tremaining: 18.1s\n",
      "197:\tlearn: 0.8053250\ttotal: 8.87s\tremaining: 18s\n",
      "198:\tlearn: 0.8054262\ttotal: 8.91s\tremaining: 18s\n",
      "199:\tlearn: 0.8057299\ttotal: 8.97s\tremaining: 17.9s\n",
      "200:\tlearn: 0.8052237\ttotal: 9.01s\tremaining: 17.9s\n",
      "201:\tlearn: 0.8055274\ttotal: 9.05s\tremaining: 17.8s\n",
      "202:\tlearn: 0.8072484\ttotal: 9.1s\tremaining: 17.8s\n",
      "203:\tlearn: 0.8054262\ttotal: 9.15s\tremaining: 17.8s\n",
      "204:\tlearn: 0.8057299\ttotal: 9.19s\tremaining: 17.7s\n",
      "205:\tlearn: 0.8071472\ttotal: 9.24s\tremaining: 17.7s\n",
      "206:\tlearn: 0.8076534\ttotal: 9.28s\tremaining: 17.6s\n",
      "207:\tlearn: 0.8078558\ttotal: 9.32s\tremaining: 17.6s\n",
      "208:\tlearn: 0.8085645\ttotal: 9.37s\tremaining: 17.5s\n",
      "209:\tlearn: 0.8094756\ttotal: 9.42s\tremaining: 17.5s\n",
      "210:\tlearn: 0.8095768\ttotal: 9.46s\tremaining: 17.4s\n",
      "211:\tlearn: 0.8108929\ttotal: 9.51s\tremaining: 17.4s\n",
      "212:\tlearn: 0.8136262\ttotal: 9.55s\tremaining: 17.3s\n",
      "213:\tlearn: 0.8153472\ttotal: 9.59s\tremaining: 17.3s\n",
      "214:\tlearn: 0.8168658\ttotal: 9.64s\tremaining: 17.3s\n",
      "215:\tlearn: 0.8159546\ttotal: 9.69s\tremaining: 17.2s\n",
      "216:\tlearn: 0.8185868\ttotal: 9.73s\tremaining: 17.2s\n",
      "217:\tlearn: 0.8171695\ttotal: 9.78s\tremaining: 17.1s\n",
      "218:\tlearn: 0.8191942\ttotal: 9.83s\tremaining: 17.1s\n",
      "219:\tlearn: 0.8200040\ttotal: 9.87s\tremaining: 17.1s\n",
      "220:\tlearn: 0.8200040\ttotal: 9.92s\tremaining: 17s\n",
      "221:\tlearn: 0.8224337\ttotal: 9.96s\tremaining: 17s\n",
      "222:\tlearn: 0.8220288\ttotal: 10s\tremaining: 16.9s\n",
      "223:\tlearn: 0.8214213\ttotal: 10.1s\tremaining: 16.9s\n",
      "224:\tlearn: 0.8243572\ttotal: 10.1s\tremaining: 16.8s\n",
      "225:\tlearn: 0.8252683\ttotal: 10.1s\tremaining: 16.8s\n",
      "226:\tlearn: 0.8253695\ttotal: 10.2s\tremaining: 16.7s\n",
      "227:\tlearn: 0.8264831\ttotal: 10.2s\tremaining: 16.7s\n",
      "228:\tlearn: 0.8264831\ttotal: 10.3s\tremaining: 16.7s\n",
      "229:\tlearn: 0.8270905\ttotal: 10.3s\tremaining: 16.6s\n",
      "230:\tlearn: 0.8274954\ttotal: 10.4s\tremaining: 16.6s\n",
      "231:\tlearn: 0.8291152\ttotal: 10.4s\tremaining: 16.5s\n",
      "232:\tlearn: 0.8301276\ttotal: 10.4s\tremaining: 16.5s\n",
      "233:\tlearn: 0.8318486\ttotal: 10.5s\tremaining: 16.4s\n",
      "234:\tlearn: 0.8324560\ttotal: 10.5s\tremaining: 16.4s\n",
      "235:\tlearn: 0.8347844\ttotal: 10.6s\tremaining: 16.3s\n",
      "236:\tlearn: 0.8392387\ttotal: 10.6s\tremaining: 16.3s\n",
      "237:\tlearn: 0.8412634\ttotal: 10.7s\tremaining: 16.2s\n",
      "238:\tlearn: 0.8432881\ttotal: 10.7s\tremaining: 16.2s\n",
      "239:\tlearn: 0.8456165\ttotal: 10.8s\tremaining: 16.1s\n",
      "240:\tlearn: 0.8465276\ttotal: 10.8s\tremaining: 16.1s\n",
      "241:\tlearn: 0.8481474\ttotal: 10.8s\tremaining: 16s\n",
      "242:\tlearn: 0.8469326\ttotal: 10.9s\tremaining: 16s\n",
      "243:\tlearn: 0.8481474\ttotal: 10.9s\tremaining: 15.9s\n",
      "244:\tlearn: 0.8499696\ttotal: 11s\tremaining: 15.9s\n",
      "245:\tlearn: 0.8511845\ttotal: 11s\tremaining: 15.9s\n",
      "246:\tlearn: 0.8519943\ttotal: 11.1s\tremaining: 15.8s\n",
      "247:\tlearn: 0.8517919\ttotal: 11.1s\tremaining: 15.8s\n",
      "248:\tlearn: 0.8532092\ttotal: 11.1s\tremaining: 15.7s\n",
      "249:\tlearn: 0.8535129\ttotal: 11.2s\tremaining: 15.7s\n",
      "250:\tlearn: 0.8552339\ttotal: 11.2s\tremaining: 15.6s\n",
      "251:\tlearn: 0.8555376\ttotal: 11.3s\tremaining: 15.6s\n",
      "252:\tlearn: 0.8551326\ttotal: 11.3s\tremaining: 15.5s\n",
      "253:\tlearn: 0.8546264\ttotal: 11.4s\tremaining: 15.5s\n",
      "254:\tlearn: 0.8558413\ttotal: 11.4s\tremaining: 15.4s\n",
      "255:\tlearn: 0.8565499\ttotal: 11.4s\tremaining: 15.4s\n",
      "256:\tlearn: 0.8583721\ttotal: 11.5s\tremaining: 15.3s\n",
      "257:\tlearn: 0.8595870\ttotal: 11.5s\tremaining: 15.3s\n",
      "258:\tlearn: 0.8596882\ttotal: 11.6s\tremaining: 15.2s\n",
      "259:\tlearn: 0.8584734\ttotal: 11.6s\tremaining: 15.2s\n",
      "260:\tlearn: 0.8585746\ttotal: 11.7s\tremaining: 15.2s\n",
      "261:\tlearn: 0.8595870\ttotal: 11.7s\tremaining: 15.1s\n",
      "262:\tlearn: 0.8595870\ttotal: 11.8s\tremaining: 15.1s\n",
      "263:\tlearn: 0.8605993\ttotal: 11.8s\tremaining: 15s\n",
      "264:\tlearn: 0.8618141\ttotal: 11.8s\tremaining: 15s\n",
      "265:\tlearn: 0.8621178\ttotal: 11.9s\tremaining: 14.9s\n",
      "266:\tlearn: 0.8625228\ttotal: 11.9s\tremaining: 14.9s\n",
      "267:\tlearn: 0.8630290\ttotal: 12s\tremaining: 14.8s\n",
      "268:\tlearn: 0.8641425\ttotal: 12s\tremaining: 14.8s\n",
      "269:\tlearn: 0.8651549\ttotal: 12.1s\tremaining: 14.7s\n",
      "270:\tlearn: 0.8654586\ttotal: 12.1s\tremaining: 14.7s\n",
      "271:\tlearn: 0.8664709\ttotal: 12.2s\tremaining: 14.7s\n",
      "272:\tlearn: 0.8675845\ttotal: 12.2s\tremaining: 14.6s\n",
      "273:\tlearn: 0.8672808\ttotal: 12.3s\tremaining: 14.6s\n",
      "274:\tlearn: 0.8667747\ttotal: 12.3s\tremaining: 14.5s\n",
      "275:\tlearn: 0.8673821\ttotal: 12.3s\tremaining: 14.5s\n",
      "276:\tlearn: 0.8676858\ttotal: 12.4s\tremaining: 14.4s\n",
      "277:\tlearn: 0.8690018\ttotal: 12.4s\tremaining: 14.4s\n",
      "278:\tlearn: 0.8700142\ttotal: 12.5s\tremaining: 14.3s\n",
      "279:\tlearn: 0.8711278\ttotal: 12.5s\tremaining: 14.3s\n",
      "280:\tlearn: 0.8710265\ttotal: 12.6s\tremaining: 14.3s\n",
      "281:\tlearn: 0.8729500\ttotal: 12.6s\tremaining: 14.2s\n",
      "282:\tlearn: 0.8715327\ttotal: 12.6s\tremaining: 14.2s\n",
      "283:\tlearn: 0.8715327\ttotal: 12.7s\tremaining: 14.1s\n",
      "284:\tlearn: 0.8721401\ttotal: 12.7s\tremaining: 14.1s\n",
      "285:\tlearn: 0.8716339\ttotal: 12.8s\tremaining: 14s\n",
      "286:\tlearn: 0.8732537\ttotal: 12.8s\tremaining: 14s\n",
      "287:\tlearn: 0.8715327\ttotal: 12.9s\tremaining: 13.9s\n",
      "288:\tlearn: 0.8731525\ttotal: 12.9s\tremaining: 13.9s\n",
      "289:\tlearn: 0.8743673\ttotal: 13s\tremaining: 13.9s\n",
      "290:\tlearn: 0.8757846\ttotal: 13s\tremaining: 13.8s\n",
      "291:\tlearn: 0.8748735\ttotal: 13.1s\tremaining: 13.8s\n",
      "292:\tlearn: 0.8750759\ttotal: 13.1s\tremaining: 13.7s\n",
      "293:\tlearn: 0.8771006\ttotal: 13.1s\tremaining: 13.7s\n",
      "294:\tlearn: 0.8776068\ttotal: 13.2s\tremaining: 13.6s\n",
      "295:\tlearn: 0.8782142\ttotal: 13.2s\tremaining: 13.6s\n",
      "296:\tlearn: 0.8787204\ttotal: 13.3s\tremaining: 13.5s\n",
      "297:\tlearn: 0.8782142\ttotal: 13.3s\tremaining: 13.5s\n",
      "298:\tlearn: 0.8785179\ttotal: 13.4s\tremaining: 13.5s\n",
      "299:\tlearn: 0.8791253\ttotal: 13.4s\tremaining: 13.4s\n",
      "300:\tlearn: 0.8791253\ttotal: 13.4s\tremaining: 13.4s\n",
      "301:\tlearn: 0.8794290\ttotal: 13.5s\tremaining: 13.3s\n",
      "302:\tlearn: 0.8806439\ttotal: 13.5s\tremaining: 13.3s\n",
      "303:\tlearn: 0.8815550\ttotal: 13.6s\tremaining: 13.2s\n",
      "304:\tlearn: 0.8821624\ttotal: 13.6s\tremaining: 13.2s\n",
      "305:\tlearn: 0.8824661\ttotal: 13.7s\tremaining: 13.1s\n",
      "306:\tlearn: 0.8825673\ttotal: 13.7s\tremaining: 13.1s\n",
      "307:\tlearn: 0.8848957\ttotal: 13.8s\tremaining: 13s\n",
      "308:\tlearn: 0.8836809\ttotal: 13.8s\tremaining: 13s\n",
      "309:\tlearn: 0.8853007\ttotal: 13.9s\tremaining: 13s\n",
      "310:\tlearn: 0.8844908\ttotal: 13.9s\tremaining: 12.9s\n",
      "311:\tlearn: 0.8850982\ttotal: 13.9s\tremaining: 12.9s\n",
      "312:\tlearn: 0.8844908\ttotal: 14s\tremaining: 12.8s\n",
      "313:\tlearn: 0.8864143\ttotal: 14s\tremaining: 12.8s\n",
      "314:\tlearn: 0.8866167\ttotal: 14.1s\tremaining: 12.7s\n",
      "315:\tlearn: 0.8872241\ttotal: 14.1s\tremaining: 12.7s\n",
      "316:\tlearn: 0.8875278\ttotal: 14.2s\tremaining: 12.7s\n",
      "317:\tlearn: 0.8887427\ttotal: 14.2s\tremaining: 12.6s\n",
      "318:\tlearn: 0.8889451\ttotal: 14.3s\tremaining: 12.6s\n",
      "319:\tlearn: 0.8893501\ttotal: 14.3s\tremaining: 12.5s\n",
      "320:\tlearn: 0.8890464\ttotal: 14.4s\tremaining: 12.5s\n",
      "321:\tlearn: 0.8880340\ttotal: 14.4s\tremaining: 12.4s\n",
      "322:\tlearn: 0.8884390\ttotal: 14.4s\tremaining: 12.4s\n",
      "323:\tlearn: 0.8892488\ttotal: 14.5s\tremaining: 12.3s\n",
      "324:\tlearn: 0.8902612\ttotal: 14.5s\tremaining: 12.3s\n",
      "325:\tlearn: 0.8901600\ttotal: 14.6s\tremaining: 12.3s\n",
      "326:\tlearn: 0.8909698\ttotal: 14.6s\tremaining: 12.2s\n",
      "327:\tlearn: 0.8918809\ttotal: 14.7s\tremaining: 12.2s\n",
      "328:\tlearn: 0.8918809\ttotal: 14.7s\tremaining: 12.1s\n",
      "329:\tlearn: 0.8914760\ttotal: 14.8s\tremaining: 12.1s\n",
      "330:\tlearn: 0.8930958\ttotal: 14.8s\tremaining: 12s\n",
      "331:\tlearn: 0.8938044\ttotal: 14.8s\tremaining: 12s\n",
      "332:\tlearn: 0.8929945\ttotal: 14.9s\tremaining: 11.9s\n",
      "333:\tlearn: 0.8936019\ttotal: 14.9s\tremaining: 11.9s\n",
      "334:\tlearn: 0.8937032\ttotal: 15s\tremaining: 11.8s\n",
      "335:\tlearn: 0.8947155\ttotal: 15s\tremaining: 11.8s\n",
      "336:\tlearn: 0.8948168\ttotal: 15.1s\tremaining: 11.8s\n",
      "337:\tlearn: 0.8945131\ttotal: 15.1s\tremaining: 11.7s\n",
      "338:\tlearn: 0.8950192\ttotal: 15.1s\tremaining: 11.7s\n",
      "339:\tlearn: 0.8955254\ttotal: 15.2s\tremaining: 11.6s\n",
      "340:\tlearn: 0.8956266\ttotal: 15.2s\tremaining: 11.6s\n",
      "341:\tlearn: 0.8957279\ttotal: 15.3s\tremaining: 11.5s\n",
      "342:\tlearn: 0.8961328\ttotal: 15.3s\tremaining: 11.5s\n",
      "343:\tlearn: 0.8958291\ttotal: 15.4s\tremaining: 11.4s\n",
      "344:\tlearn: 0.8964365\ttotal: 15.4s\tremaining: 11.4s\n",
      "345:\tlearn: 0.8967402\ttotal: 15.5s\tremaining: 11.3s\n",
      "346:\tlearn: 0.8978538\ttotal: 15.5s\tremaining: 11.3s\n",
      "347:\tlearn: 0.8981575\ttotal: 15.5s\tremaining: 11.3s\n",
      "348:\tlearn: 0.8990686\ttotal: 15.6s\tremaining: 11.2s\n",
      "349:\tlearn: 0.8981575\ttotal: 15.6s\tremaining: 11.2s\n",
      "350:\tlearn: 0.8995748\ttotal: 15.7s\tremaining: 11.1s\n",
      "351:\tlearn: 0.8993723\ttotal: 15.7s\tremaining: 11.1s\n",
      "352:\tlearn: 0.8998785\ttotal: 15.8s\tremaining: 11s\n",
      "353:\tlearn: 0.8994736\ttotal: 15.8s\tremaining: 11s\n",
      "354:\tlearn: 0.8998785\ttotal: 15.9s\tremaining: 10.9s\n",
      "355:\tlearn: 0.9006884\ttotal: 15.9s\tremaining: 10.9s\n",
      "356:\tlearn: 0.9010933\ttotal: 15.9s\tremaining: 10.9s\n",
      "357:\tlearn: 0.9025106\ttotal: 16s\tremaining: 10.8s\n",
      "358:\tlearn: 0.9023082\ttotal: 16s\tremaining: 10.8s\n",
      "359:\tlearn: 0.9026119\ttotal: 16.1s\tremaining: 10.7s\n",
      "360:\tlearn: 0.9036242\ttotal: 16.1s\tremaining: 10.7s\n",
      "361:\tlearn: 0.9029156\ttotal: 16.2s\tremaining: 10.6s\n",
      "362:\tlearn: 0.9037255\ttotal: 16.2s\tremaining: 10.6s\n",
      "363:\tlearn: 0.9041304\ttotal: 16.3s\tremaining: 10.5s\n",
      "364:\tlearn: 0.9043329\ttotal: 16.3s\tremaining: 10.5s\n",
      "365:\tlearn: 0.9049403\ttotal: 16.3s\tremaining: 10.4s\n",
      "366:\tlearn: 0.9054464\ttotal: 16.4s\tremaining: 10.4s\n",
      "367:\tlearn: 0.9059526\ttotal: 16.4s\tremaining: 10.4s\n",
      "368:\tlearn: 0.9052440\ttotal: 16.5s\tremaining: 10.3s\n",
      "369:\tlearn: 0.9057502\ttotal: 16.5s\tremaining: 10.3s\n",
      "370:\tlearn: 0.9064588\ttotal: 16.6s\tremaining: 10.2s\n",
      "371:\tlearn: 0.9069650\ttotal: 16.6s\tremaining: 10.2s\n",
      "372:\tlearn: 0.9074711\ttotal: 16.7s\tremaining: 10.1s\n",
      "373:\tlearn: 0.9076736\ttotal: 16.7s\tremaining: 10.1s\n",
      "374:\tlearn: 0.9071674\ttotal: 16.7s\tremaining: 10s\n",
      "375:\tlearn: 0.9078761\ttotal: 16.8s\tremaining: 10s\n",
      "376:\tlearn: 0.9078761\ttotal: 16.8s\tremaining: 9.95s\n",
      "377:\tlearn: 0.9081798\ttotal: 16.9s\tremaining: 9.91s\n",
      "378:\tlearn: 0.9080786\ttotal: 16.9s\tremaining: 9.86s\n",
      "379:\tlearn: 0.9077749\ttotal: 17s\tremaining: 9.82s\n",
      "380:\tlearn: 0.9083823\ttotal: 17s\tremaining: 9.77s\n",
      "381:\tlearn: 0.9080786\ttotal: 17s\tremaining: 9.73s\n",
      "382:\tlearn: 0.9085847\ttotal: 17.1s\tremaining: 9.68s\n",
      "383:\tlearn: 0.9088884\ttotal: 17.1s\tremaining: 9.64s\n",
      "384:\tlearn: 0.9103057\ttotal: 17.2s\tremaining: 9.59s\n",
      "385:\tlearn: 0.9101033\ttotal: 17.2s\tremaining: 9.54s\n",
      "386:\tlearn: 0.9112168\ttotal: 17.3s\tremaining: 9.5s\n",
      "387:\tlearn: 0.9129378\ttotal: 17.3s\tremaining: 9.45s\n",
      "388:\tlearn: 0.9127354\ttotal: 17.3s\tremaining: 9.41s\n",
      "389:\tlearn: 0.9131403\ttotal: 17.4s\tremaining: 9.36s\n",
      "390:\tlearn: 0.9141527\ttotal: 17.4s\tremaining: 9.31s\n",
      "391:\tlearn: 0.9140514\ttotal: 17.5s\tremaining: 9.27s\n",
      "392:\tlearn: 0.9140514\ttotal: 17.5s\tremaining: 9.22s\n",
      "393:\tlearn: 0.9142539\ttotal: 17.6s\tremaining: 9.18s\n",
      "394:\tlearn: 0.9142539\ttotal: 17.6s\tremaining: 9.13s\n",
      "395:\tlearn: 0.9142539\ttotal: 17.6s\tremaining: 9.09s\n",
      "396:\tlearn: 0.9151650\ttotal: 17.7s\tremaining: 9.04s\n",
      "397:\tlearn: 0.9150638\ttotal: 17.7s\tremaining: 9s\n",
      "398:\tlearn: 0.9152662\ttotal: 17.8s\tremaining: 8.95s\n",
      "399:\tlearn: 0.9153675\ttotal: 17.8s\tremaining: 8.91s\n",
      "400:\tlearn: 0.9159749\ttotal: 17.9s\tremaining: 8.86s\n",
      "401:\tlearn: 0.9160761\ttotal: 17.9s\tremaining: 8.82s\n",
      "402:\tlearn: 0.9166835\ttotal: 17.9s\tremaining: 8.77s\n",
      "403:\tlearn: 0.9173922\ttotal: 18s\tremaining: 8.73s\n",
      "404:\tlearn: 0.9182021\ttotal: 18s\tremaining: 8.68s\n",
      "405:\tlearn: 0.9189107\ttotal: 18.1s\tremaining: 8.64s\n",
      "406:\tlearn: 0.9191132\ttotal: 18.1s\tremaining: 8.59s\n",
      "407:\tlearn: 0.9195181\ttotal: 18.2s\tremaining: 8.55s\n",
      "408:\tlearn: 0.9196194\ttotal: 18.2s\tremaining: 8.51s\n",
      "409:\tlearn: 0.9198218\ttotal: 18.3s\tremaining: 8.46s\n",
      "410:\tlearn: 0.9207329\ttotal: 18.3s\tremaining: 8.42s\n",
      "411:\tlearn: 0.9220490\ttotal: 18.4s\tremaining: 8.37s\n",
      "412:\tlearn: 0.9216441\ttotal: 18.4s\tremaining: 8.33s\n",
      "413:\tlearn: 0.9211379\ttotal: 18.4s\tremaining: 8.29s\n",
      "414:\tlearn: 0.9217453\ttotal: 18.5s\tremaining: 8.24s\n",
      "415:\tlearn: 0.9216441\ttotal: 18.5s\tremaining: 8.2s\n",
      "416:\tlearn: 0.9219478\ttotal: 18.6s\tremaining: 8.15s\n",
      "417:\tlearn: 0.9219478\ttotal: 18.6s\tremaining: 8.11s\n",
      "418:\tlearn: 0.9221502\ttotal: 18.7s\tremaining: 8.06s\n",
      "419:\tlearn: 0.9225552\ttotal: 18.7s\tremaining: 8.02s\n",
      "420:\tlearn: 0.9225552\ttotal: 18.8s\tremaining: 7.97s\n",
      "421:\tlearn: 0.9225552\ttotal: 18.8s\tremaining: 7.93s\n",
      "422:\tlearn: 0.9228589\ttotal: 18.9s\tremaining: 7.89s\n",
      "423:\tlearn: 0.9227576\ttotal: 18.9s\tremaining: 7.84s\n",
      "424:\tlearn: 0.9234663\ttotal: 18.9s\tremaining: 7.8s\n",
      "425:\tlearn: 0.9233651\ttotal: 19s\tremaining: 7.76s\n",
      "426:\tlearn: 0.9239725\ttotal: 19s\tremaining: 7.71s\n",
      "427:\tlearn: 0.9239725\ttotal: 19.1s\tremaining: 7.67s\n",
      "428:\tlearn: 0.9244786\ttotal: 19.1s\tremaining: 7.62s\n",
      "429:\tlearn: 0.9252885\ttotal: 19.2s\tremaining: 7.58s\n",
      "430:\tlearn: 0.9257947\ttotal: 19.2s\tremaining: 7.53s\n",
      "431:\tlearn: 0.9258959\ttotal: 19.2s\tremaining: 7.49s\n",
      "432:\tlearn: 0.9247823\ttotal: 19.3s\tremaining: 7.44s\n",
      "433:\tlearn: 0.9255922\ttotal: 19.3s\tremaining: 7.4s\n",
      "434:\tlearn: 0.9258959\ttotal: 19.4s\tremaining: 7.35s\n",
      "435:\tlearn: 0.9269083\ttotal: 19.4s\tremaining: 7.31s\n",
      "436:\tlearn: 0.9265033\ttotal: 19.5s\tremaining: 7.26s\n",
      "437:\tlearn: 0.9275157\ttotal: 19.5s\tremaining: 7.22s\n",
      "438:\tlearn: 0.9274145\ttotal: 19.6s\tremaining: 7.17s\n",
      "439:\tlearn: 0.9279206\ttotal: 19.6s\tremaining: 7.13s\n",
      "440:\tlearn: 0.9283256\ttotal: 19.6s\tremaining: 7.08s\n",
      "441:\tlearn: 0.9288317\ttotal: 19.7s\tremaining: 7.04s\n",
      "442:\tlearn: 0.9292367\ttotal: 19.7s\tremaining: 6.99s\n",
      "443:\tlearn: 0.9292367\ttotal: 19.8s\tremaining: 6.95s\n",
      "444:\tlearn: 0.9297429\ttotal: 19.8s\tremaining: 6.91s\n",
      "445:\tlearn: 0.9289330\ttotal: 19.9s\tremaining: 6.86s\n",
      "446:\tlearn: 0.9298441\ttotal: 19.9s\tremaining: 6.81s\n",
      "447:\tlearn: 0.9295404\ttotal: 20s\tremaining: 6.77s\n",
      "448:\tlearn: 0.9294392\ttotal: 20s\tremaining: 6.73s\n",
      "449:\tlearn: 0.9289330\ttotal: 20s\tremaining: 6.68s\n",
      "450:\tlearn: 0.9296416\ttotal: 20.1s\tremaining: 6.63s\n",
      "451:\tlearn: 0.9298441\ttotal: 20.1s\tremaining: 6.59s\n",
      "452:\tlearn: 0.9305527\ttotal: 20.2s\tremaining: 6.54s\n",
      "453:\tlearn: 0.9306540\ttotal: 20.2s\tremaining: 6.5s\n",
      "454:\tlearn: 0.9314639\ttotal: 20.3s\tremaining: 6.46s\n",
      "455:\tlearn: 0.9313626\ttotal: 20.3s\tremaining: 6.41s\n",
      "456:\tlearn: 0.9315651\ttotal: 20.3s\tremaining: 6.37s\n",
      "457:\tlearn: 0.9311602\ttotal: 20.4s\tremaining: 6.32s\n",
      "458:\tlearn: 0.9318688\ttotal: 20.4s\tremaining: 6.28s\n",
      "459:\tlearn: 0.9313626\ttotal: 20.5s\tremaining: 6.23s\n",
      "460:\tlearn: 0.9320713\ttotal: 20.5s\tremaining: 6.19s\n",
      "461:\tlearn: 0.9326787\ttotal: 20.6s\tremaining: 6.14s\n",
      "462:\tlearn: 0.9331849\ttotal: 20.6s\tremaining: 6.1s\n",
      "463:\tlearn: 0.9335898\ttotal: 20.7s\tremaining: 6.05s\n",
      "464:\tlearn: 0.9340960\ttotal: 20.7s\tremaining: 6.01s\n",
      "465:\tlearn: 0.9341972\ttotal: 20.7s\tremaining: 5.96s\n",
      "466:\tlearn: 0.9342984\ttotal: 20.8s\tremaining: 5.92s\n",
      "467:\tlearn: 0.9341972\ttotal: 20.9s\tremaining: 5.88s\n",
      "468:\tlearn: 0.9341972\ttotal: 20.9s\tremaining: 5.84s\n",
      "469:\tlearn: 0.9343997\ttotal: 20.9s\tremaining: 5.79s\n",
      "470:\tlearn: 0.9340960\ttotal: 21s\tremaining: 5.75s\n",
      "471:\tlearn: 0.9340960\ttotal: 21s\tremaining: 5.7s\n",
      "472:\tlearn: 0.9349059\ttotal: 21.1s\tremaining: 5.66s\n",
      "473:\tlearn: 0.9350071\ttotal: 21.1s\tremaining: 5.62s\n",
      "474:\tlearn: 0.9354120\ttotal: 21.2s\tremaining: 5.57s\n",
      "475:\tlearn: 0.9356145\ttotal: 21.2s\tremaining: 5.53s\n",
      "476:\tlearn: 0.9360194\ttotal: 21.3s\tremaining: 5.48s\n",
      "477:\tlearn: 0.9362219\ttotal: 21.3s\tremaining: 5.44s\n",
      "478:\tlearn: 0.9361207\ttotal: 21.3s\tremaining: 5.39s\n",
      "479:\tlearn: 0.9365256\ttotal: 21.4s\tremaining: 5.35s\n",
      "480:\tlearn: 0.9362219\ttotal: 21.4s\tremaining: 5.3s\n",
      "481:\tlearn: 0.9361207\ttotal: 21.5s\tremaining: 5.26s\n",
      "482:\tlearn: 0.9368293\ttotal: 21.5s\tremaining: 5.21s\n",
      "483:\tlearn: 0.9371330\ttotal: 21.6s\tremaining: 5.17s\n",
      "484:\tlearn: 0.9375380\ttotal: 21.6s\tremaining: 5.13s\n",
      "485:\tlearn: 0.9377404\ttotal: 21.7s\tremaining: 5.08s\n",
      "486:\tlearn: 0.9381454\ttotal: 21.7s\tremaining: 5.04s\n",
      "487:\tlearn: 0.9384491\ttotal: 21.8s\tremaining: 5s\n",
      "488:\tlearn: 0.9392590\ttotal: 21.8s\tremaining: 4.95s\n",
      "489:\tlearn: 0.9387528\ttotal: 21.9s\tremaining: 4.91s\n",
      "490:\tlearn: 0.9388540\ttotal: 21.9s\tremaining: 4.86s\n",
      "491:\tlearn: 0.9389553\ttotal: 22s\tremaining: 4.82s\n",
      "492:\tlearn: 0.9393602\ttotal: 22s\tremaining: 4.78s\n",
      "493:\tlearn: 0.9395627\ttotal: 22s\tremaining: 4.73s\n",
      "494:\tlearn: 0.9398664\ttotal: 22.1s\tremaining: 4.69s\n",
      "495:\tlearn: 0.9397651\ttotal: 22.1s\tremaining: 4.64s\n",
      "496:\tlearn: 0.9405750\ttotal: 22.2s\tremaining: 4.6s\n",
      "497:\tlearn: 0.9409800\ttotal: 22.2s\tremaining: 4.55s\n",
      "498:\tlearn: 0.9408787\ttotal: 22.3s\tremaining: 4.51s\n",
      "499:\tlearn: 0.9409800\ttotal: 22.3s\tremaining: 4.46s\n",
      "500:\tlearn: 0.9411824\ttotal: 22.4s\tremaining: 4.42s\n",
      "501:\tlearn: 0.9411824\ttotal: 22.4s\tremaining: 4.37s\n",
      "502:\tlearn: 0.9415874\ttotal: 22.4s\tremaining: 4.33s\n",
      "503:\tlearn: 0.9422960\ttotal: 22.5s\tremaining: 4.28s\n",
      "504:\tlearn: 0.9423972\ttotal: 22.5s\tremaining: 4.24s\n",
      "505:\tlearn: 0.9420935\ttotal: 22.6s\tremaining: 4.19s\n",
      "506:\tlearn: 0.9424985\ttotal: 22.6s\tremaining: 4.15s\n",
      "507:\tlearn: 0.9425997\ttotal: 22.7s\tremaining: 4.1s\n",
      "508:\tlearn: 0.9432071\ttotal: 22.7s\tremaining: 4.06s\n",
      "509:\tlearn: 0.9429034\ttotal: 22.7s\tremaining: 4.01s\n",
      "510:\tlearn: 0.9433084\ttotal: 22.8s\tremaining: 3.97s\n",
      "511:\tlearn: 0.9431059\ttotal: 22.8s\tremaining: 3.92s\n",
      "512:\tlearn: 0.9435108\ttotal: 22.9s\tremaining: 3.88s\n",
      "513:\tlearn: 0.9430047\ttotal: 22.9s\tremaining: 3.84s\n",
      "514:\tlearn: 0.9433084\ttotal: 23s\tremaining: 3.79s\n",
      "515:\tlearn: 0.9445232\ttotal: 23s\tremaining: 3.75s\n",
      "516:\tlearn: 0.9446244\ttotal: 23.1s\tremaining: 3.7s\n",
      "517:\tlearn: 0.9446244\ttotal: 23.1s\tremaining: 3.66s\n",
      "518:\tlearn: 0.9449281\ttotal: 23.2s\tremaining: 3.61s\n",
      "519:\tlearn: 0.9445232\ttotal: 23.2s\tremaining: 3.57s\n",
      "520:\tlearn: 0.9450294\ttotal: 23.2s\tremaining: 3.52s\n",
      "521:\tlearn: 0.9452318\ttotal: 23.3s\tremaining: 3.48s\n",
      "522:\tlearn: 0.9454343\ttotal: 23.3s\tremaining: 3.43s\n",
      "523:\tlearn: 0.9455355\ttotal: 23.4s\tremaining: 3.39s\n",
      "524:\tlearn: 0.9456368\ttotal: 23.4s\tremaining: 3.34s\n",
      "525:\tlearn: 0.9454343\ttotal: 23.4s\tremaining: 3.3s\n",
      "526:\tlearn: 0.9458392\ttotal: 23.5s\tremaining: 3.25s\n",
      "527:\tlearn: 0.9466491\ttotal: 23.5s\tremaining: 3.21s\n",
      "528:\tlearn: 0.9464466\ttotal: 23.6s\tremaining: 3.16s\n",
      "529:\tlearn: 0.9463454\ttotal: 23.6s\tremaining: 3.12s\n",
      "530:\tlearn: 0.9465479\ttotal: 23.7s\tremaining: 3.07s\n",
      "531:\tlearn: 0.9470541\ttotal: 23.7s\tremaining: 3.03s\n",
      "532:\tlearn: 0.9475602\ttotal: 23.8s\tremaining: 2.98s\n",
      "533:\tlearn: 0.9480664\ttotal: 23.8s\tremaining: 2.94s\n",
      "534:\tlearn: 0.9475602\ttotal: 23.8s\tremaining: 2.9s\n",
      "535:\tlearn: 0.9471553\ttotal: 23.9s\tremaining: 2.85s\n",
      "536:\tlearn: 0.9477627\ttotal: 23.9s\tremaining: 2.81s\n",
      "537:\tlearn: 0.9480664\ttotal: 24s\tremaining: 2.76s\n",
      "538:\tlearn: 0.9479652\ttotal: 24s\tremaining: 2.72s\n",
      "539:\tlearn: 0.9477627\ttotal: 24.1s\tremaining: 2.67s\n",
      "540:\tlearn: 0.9478639\ttotal: 24.1s\tremaining: 2.63s\n",
      "541:\tlearn: 0.9488763\ttotal: 24.2s\tremaining: 2.58s\n",
      "542:\tlearn: 0.9486738\ttotal: 24.2s\tremaining: 2.54s\n",
      "543:\tlearn: 0.9496862\ttotal: 24.2s\tremaining: 2.5s\n",
      "544:\tlearn: 0.9497874\ttotal: 24.3s\tremaining: 2.45s\n",
      "545:\tlearn: 0.9511035\ttotal: 24.3s\tremaining: 2.41s\n",
      "546:\tlearn: 0.9509010\ttotal: 24.4s\tremaining: 2.36s\n",
      "547:\tlearn: 0.9513059\ttotal: 24.4s\tremaining: 2.32s\n",
      "548:\tlearn: 0.9513059\ttotal: 24.5s\tremaining: 2.27s\n",
      "549:\tlearn: 0.9517109\ttotal: 24.5s\tremaining: 2.23s\n",
      "550:\tlearn: 0.9516096\ttotal: 24.5s\tremaining: 2.18s\n",
      "551:\tlearn: 0.9518121\ttotal: 24.6s\tremaining: 2.14s\n",
      "552:\tlearn: 0.9519133\ttotal: 24.6s\tremaining: 2.09s\n",
      "553:\tlearn: 0.9522170\ttotal: 24.7s\tremaining: 2.05s\n",
      "554:\tlearn: 0.9523183\ttotal: 24.7s\tremaining: 2s\n",
      "555:\tlearn: 0.9522170\ttotal: 24.8s\tremaining: 1.96s\n",
      "556:\tlearn: 0.9522170\ttotal: 24.8s\tremaining: 1.92s\n",
      "557:\tlearn: 0.9520146\ttotal: 24.9s\tremaining: 1.87s\n",
      "558:\tlearn: 0.9517109\ttotal: 24.9s\tremaining: 1.83s\n",
      "559:\tlearn: 0.9522170\ttotal: 24.9s\tremaining: 1.78s\n",
      "560:\tlearn: 0.9522170\ttotal: 25s\tremaining: 1.74s\n",
      "561:\tlearn: 0.9533306\ttotal: 25s\tremaining: 1.69s\n",
      "562:\tlearn: 0.9524195\ttotal: 25.1s\tremaining: 1.65s\n",
      "563:\tlearn: 0.9535331\ttotal: 25.1s\tremaining: 1.6s\n",
      "564:\tlearn: 0.9536343\ttotal: 25.2s\tremaining: 1.56s\n",
      "565:\tlearn: 0.9542417\ttotal: 25.2s\tremaining: 1.51s\n",
      "566:\tlearn: 0.9543430\ttotal: 25.2s\tremaining: 1.47s\n",
      "567:\tlearn: 0.9542417\ttotal: 25.3s\tremaining: 1.43s\n",
      "568:\tlearn: 0.9544442\ttotal: 25.3s\tremaining: 1.38s\n",
      "569:\tlearn: 0.9553553\ttotal: 25.4s\tremaining: 1.34s\n",
      "570:\tlearn: 0.9558615\ttotal: 25.4s\tremaining: 1.29s\n",
      "571:\tlearn: 0.9556590\ttotal: 25.5s\tremaining: 1.25s\n",
      "572:\tlearn: 0.9556590\ttotal: 25.5s\tremaining: 1.2s\n",
      "573:\tlearn: 0.9558615\ttotal: 25.6s\tremaining: 1.16s\n",
      "574:\tlearn: 0.9554566\ttotal: 25.6s\tremaining: 1.11s\n",
      "575:\tlearn: 0.9553553\ttotal: 25.6s\tremaining: 1.07s\n",
      "576:\tlearn: 0.9556590\ttotal: 25.7s\tremaining: 1.02s\n",
      "577:\tlearn: 0.9556590\ttotal: 25.7s\tremaining: 980ms\n",
      "578:\tlearn: 0.9553553\ttotal: 25.8s\tremaining: 935ms\n",
      "579:\tlearn: 0.9560640\ttotal: 25.8s\tremaining: 891ms\n",
      "580:\tlearn: 0.9562665\ttotal: 25.9s\tremaining: 846ms\n",
      "581:\tlearn: 0.9566714\ttotal: 25.9s\tremaining: 802ms\n",
      "582:\tlearn: 0.9573800\ttotal: 26s\tremaining: 757ms\n",
      "583:\tlearn: 0.9567726\ttotal: 26s\tremaining: 712ms\n",
      "584:\tlearn: 0.9573800\ttotal: 26.1s\tremaining: 668ms\n",
      "585:\tlearn: 0.9573800\ttotal: 26.1s\tremaining: 623ms\n",
      "586:\tlearn: 0.9574813\ttotal: 26.1s\tremaining: 579ms\n",
      "587:\tlearn: 0.9572788\ttotal: 26.2s\tremaining: 534ms\n",
      "588:\tlearn: 0.9573800\ttotal: 26.2s\tremaining: 490ms\n",
      "589:\tlearn: 0.9575825\ttotal: 26.3s\tremaining: 445ms\n",
      "590:\tlearn: 0.9578862\ttotal: 26.3s\tremaining: 401ms\n",
      "591:\tlearn: 0.9583924\ttotal: 26.4s\tremaining: 356ms\n",
      "592:\tlearn: 0.9583924\ttotal: 26.4s\tremaining: 312ms\n",
      "593:\tlearn: 0.9587973\ttotal: 26.5s\tremaining: 267ms\n",
      "594:\tlearn: 0.9585949\ttotal: 26.5s\tremaining: 223ms\n",
      "595:\tlearn: 0.9588986\ttotal: 26.5s\tremaining: 178ms\n",
      "596:\tlearn: 0.9588986\ttotal: 26.6s\tremaining: 134ms\n",
      "597:\tlearn: 0.9591010\ttotal: 26.6s\tremaining: 89.1ms\n",
      "598:\tlearn: 0.9594047\ttotal: 26.7s\tremaining: 44.5ms\n",
      "599:\tlearn: 0.9596072\ttotal: 26.7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=5, eval_metric=Recall, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.05, random_strength=5; total time=  27.3s\n",
      "0:\tlearn: 0.6225815\ttotal: 188ms\tremaining: 18.6s\n",
      "1:\tlearn: 0.6586001\ttotal: 373ms\tremaining: 18.3s\n",
      "2:\tlearn: 0.6853364\ttotal: 565ms\tremaining: 18.3s\n",
      "3:\tlearn: 0.6991766\ttotal: 759ms\tremaining: 18.2s\n",
      "4:\tlearn: 0.7110236\ttotal: 942ms\tremaining: 17.9s\n",
      "5:\tlearn: 0.7252671\ttotal: 1.12s\tremaining: 17.6s\n",
      "6:\tlearn: 0.7340426\ttotal: 1.3s\tremaining: 17.3s\n",
      "7:\tlearn: 0.7429483\ttotal: 1.48s\tremaining: 17.1s\n",
      "8:\tlearn: 0.7509165\ttotal: 1.68s\tremaining: 17s\n",
      "9:\tlearn: 0.7595175\ttotal: 1.86s\tremaining: 16.7s\n",
      "10:\tlearn: 0.7693373\ttotal: 2.04s\tremaining: 16.5s\n",
      "11:\tlearn: 0.7765485\ttotal: 2.22s\tremaining: 16.3s\n",
      "12:\tlearn: 0.7836286\ttotal: 2.4s\tremaining: 16s\n",
      "13:\tlearn: 0.7879295\ttotal: 2.59s\tremaining: 15.9s\n",
      "14:\tlearn: 0.7982871\ttotal: 2.79s\tremaining: 15.8s\n",
      "15:\tlearn: 0.8054006\ttotal: 2.97s\tremaining: 15.6s\n",
      "16:\tlearn: 0.8127626\ttotal: 3.14s\tremaining: 15.3s\n",
      "17:\tlearn: 0.8244036\ttotal: 3.32s\tremaining: 15.1s\n",
      "18:\tlearn: 0.8368850\ttotal: 3.51s\tremaining: 15s\n",
      "19:\tlearn: 0.8447144\ttotal: 3.69s\tremaining: 14.8s\n",
      "20:\tlearn: 0.8521926\ttotal: 3.88s\tremaining: 14.6s\n",
      "21:\tlearn: 0.8609747\ttotal: 4.06s\tremaining: 14.4s\n",
      "22:\tlearn: 0.8663908\ttotal: 4.24s\tremaining: 14.2s\n",
      "23:\tlearn: 0.8718805\ttotal: 4.41s\tremaining: 13.9s\n",
      "24:\tlearn: 0.8766598\ttotal: 4.58s\tremaining: 13.7s\n",
      "25:\tlearn: 0.8826651\ttotal: 4.76s\tremaining: 13.5s\n",
      "26:\tlearn: 0.8876194\ttotal: 4.93s\tremaining: 13.3s\n",
      "27:\tlearn: 0.8926997\ttotal: 5.11s\tremaining: 13.1s\n",
      "28:\tlearn: 0.8982852\ttotal: 5.29s\tremaining: 12.9s\n",
      "29:\tlearn: 0.9011258\ttotal: 5.46s\tremaining: 12.7s\n",
      "30:\tlearn: 0.9054054\ttotal: 5.65s\tremaining: 12.6s\n",
      "31:\tlearn: 0.9101961\ttotal: 5.84s\tremaining: 12.4s\n",
      "32:\tlearn: 0.9140027\ttotal: 6.02s\tremaining: 12.2s\n",
      "33:\tlearn: 0.9196815\ttotal: 6.19s\tremaining: 12s\n",
      "34:\tlearn: 0.9217724\ttotal: 6.37s\tremaining: 11.8s\n",
      "35:\tlearn: 0.9237030\ttotal: 6.54s\tremaining: 11.6s\n",
      "36:\tlearn: 0.9287049\ttotal: 6.72s\tremaining: 11.4s\n",
      "37:\tlearn: 0.9308652\ttotal: 6.9s\tremaining: 11.3s\n",
      "38:\tlearn: 0.9351980\ttotal: 7.08s\tremaining: 11.1s\n",
      "39:\tlearn: 0.9386788\ttotal: 7.26s\tremaining: 10.9s\n",
      "40:\tlearn: 0.9417045\ttotal: 7.44s\tremaining: 10.7s\n",
      "41:\tlearn: 0.9441374\ttotal: 7.62s\tremaining: 10.5s\n",
      "42:\tlearn: 0.9459193\ttotal: 7.79s\tremaining: 10.3s\n",
      "43:\tlearn: 0.9482622\ttotal: 7.96s\tremaining: 10.1s\n",
      "44:\tlearn: 0.9506624\ttotal: 8.14s\tremaining: 9.95s\n",
      "45:\tlearn: 0.9539786\ttotal: 8.32s\tremaining: 9.77s\n",
      "46:\tlearn: 0.9566551\ttotal: 8.5s\tremaining: 9.59s\n",
      "47:\tlearn: 0.9583622\ttotal: 8.68s\tremaining: 9.4s\n",
      "48:\tlearn: 0.9587292\ttotal: 8.86s\tremaining: 9.22s\n",
      "49:\tlearn: 0.9613402\ttotal: 9.03s\tremaining: 9.03s\n",
      "50:\tlearn: 0.9631725\ttotal: 9.21s\tremaining: 8.85s\n",
      "51:\tlearn: 0.9649349\ttotal: 9.38s\tremaining: 8.66s\n",
      "52:\tlearn: 0.9673827\ttotal: 9.57s\tremaining: 8.48s\n",
      "53:\tlearn: 0.9692323\ttotal: 9.74s\tremaining: 8.29s\n",
      "54:\tlearn: 0.9719645\ttotal: 9.93s\tremaining: 8.13s\n",
      "55:\tlearn: 0.9743103\ttotal: 10.1s\tremaining: 7.95s\n",
      "56:\tlearn: 0.9757267\ttotal: 10.3s\tremaining: 7.77s\n",
      "57:\tlearn: 0.9781088\ttotal: 10.5s\tremaining: 7.59s\n",
      "58:\tlearn: 0.9785043\ttotal: 10.7s\tremaining: 7.41s\n",
      "59:\tlearn: 0.9796939\ttotal: 10.8s\tremaining: 7.22s\n",
      "60:\tlearn: 0.9808866\ttotal: 11s\tremaining: 7.04s\n",
      "61:\tlearn: 0.9817727\ttotal: 11.2s\tremaining: 6.85s\n",
      "62:\tlearn: 0.9820785\ttotal: 11.3s\tremaining: 6.67s\n",
      "63:\tlearn: 0.9822752\ttotal: 11.5s\tremaining: 6.48s\n",
      "64:\tlearn: 0.9831798\ttotal: 11.7s\tremaining: 6.31s\n",
      "65:\tlearn: 0.9836821\ttotal: 11.9s\tremaining: 6.12s\n",
      "66:\tlearn: 0.9854637\ttotal: 12.1s\tremaining: 5.94s\n",
      "67:\tlearn: 0.9866546\ttotal: 12.2s\tremaining: 5.76s\n",
      "68:\tlearn: 0.9875439\ttotal: 12.4s\tremaining: 5.58s\n",
      "69:\tlearn: 0.9882471\ttotal: 12.6s\tremaining: 5.39s\n",
      "70:\tlearn: 0.9897395\ttotal: 12.8s\tremaining: 5.22s\n",
      "71:\tlearn: 0.9897436\ttotal: 12.9s\tremaining: 5.03s\n",
      "72:\tlearn: 0.9911433\ttotal: 13.1s\tremaining: 4.85s\n",
      "73:\tlearn: 0.9919452\ttotal: 13.3s\tremaining: 4.67s\n",
      "74:\tlearn: 0.9929464\ttotal: 13.5s\tremaining: 4.49s\n",
      "75:\tlearn: 0.9933468\ttotal: 13.7s\tremaining: 4.31s\n",
      "76:\tlearn: 0.9936498\ttotal: 13.8s\tremaining: 4.13s\n",
      "77:\tlearn: 0.9940518\ttotal: 14s\tremaining: 3.95s\n",
      "78:\tlearn: 0.9946540\ttotal: 14.2s\tremaining: 3.77s\n",
      "79:\tlearn: 0.9944562\ttotal: 14.4s\tremaining: 3.59s\n",
      "80:\tlearn: 0.9947586\ttotal: 14.5s\tremaining: 3.41s\n",
      "81:\tlearn: 0.9960630\ttotal: 14.7s\tremaining: 3.23s\n",
      "82:\tlearn: 0.9966673\ttotal: 14.9s\tremaining: 3.05s\n",
      "83:\tlearn: 0.9972705\ttotal: 15.1s\tremaining: 2.87s\n",
      "84:\tlearn: 0.9971706\ttotal: 15.3s\tremaining: 2.69s\n",
      "85:\tlearn: 0.9975740\ttotal: 15.4s\tremaining: 2.51s\n",
      "86:\tlearn: 0.9977760\ttotal: 15.6s\tremaining: 2.33s\n",
      "87:\tlearn: 0.9975748\ttotal: 15.8s\tremaining: 2.15s\n",
      "88:\tlearn: 0.9977767\ttotal: 16s\tremaining: 1.97s\n",
      "89:\tlearn: 0.9982811\ttotal: 16.1s\tremaining: 1.79s\n",
      "90:\tlearn: 0.9983820\ttotal: 16.3s\tremaining: 1.61s\n",
      "91:\tlearn: 0.9986851\ttotal: 16.5s\tremaining: 1.43s\n",
      "92:\tlearn: 0.9989883\ttotal: 16.7s\tremaining: 1.25s\n",
      "93:\tlearn: 0.9988873\ttotal: 16.8s\tremaining: 1.07s\n",
      "94:\tlearn: 0.9987863\ttotal: 17s\tremaining: 896ms\n",
      "95:\tlearn: 0.9989886\ttotal: 17.2s\tremaining: 717ms\n",
      "96:\tlearn: 0.9990895\ttotal: 17.4s\tremaining: 537ms\n",
      "97:\tlearn: 0.9990895\ttotal: 17.6s\tremaining: 358ms\n",
      "98:\tlearn: 0.9990896\ttotal: 17.7s\tremaining: 179ms\n",
      "99:\tlearn: 0.9994940\ttotal: 17.9s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=128, depth=8, eval_metric=Precision, iterations=100, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=2; total time=  18.4s\n",
      "0:\tlearn: 0.6199507\ttotal: 197ms\tremaining: 19.5s\n",
      "1:\tlearn: 0.6509670\ttotal: 375ms\tremaining: 18.4s\n",
      "2:\tlearn: 0.6831471\ttotal: 556ms\tremaining: 18s\n",
      "3:\tlearn: 0.7029842\ttotal: 734ms\tremaining: 17.6s\n",
      "4:\tlearn: 0.7190467\ttotal: 909ms\tremaining: 17.3s\n",
      "5:\tlearn: 0.7275598\ttotal: 1.1s\tremaining: 17.2s\n",
      "6:\tlearn: 0.7376133\ttotal: 1.28s\tremaining: 17s\n",
      "7:\tlearn: 0.7479315\ttotal: 1.46s\tremaining: 16.8s\n",
      "8:\tlearn: 0.7595575\ttotal: 1.65s\tremaining: 16.7s\n",
      "9:\tlearn: 0.7754430\ttotal: 1.84s\tremaining: 16.6s\n",
      "10:\tlearn: 0.7821763\ttotal: 2.03s\tremaining: 16.4s\n",
      "11:\tlearn: 0.7902680\ttotal: 2.21s\tremaining: 16.2s\n",
      "12:\tlearn: 0.8008376\ttotal: 2.39s\tremaining: 16s\n",
      "13:\tlearn: 0.8077036\ttotal: 2.57s\tremaining: 15.8s\n",
      "14:\tlearn: 0.8127730\ttotal: 2.75s\tremaining: 15.6s\n",
      "15:\tlearn: 0.8223266\ttotal: 2.93s\tremaining: 15.4s\n",
      "16:\tlearn: 0.8306987\ttotal: 3.11s\tremaining: 15.2s\n",
      "17:\tlearn: 0.8413302\ttotal: 3.3s\tremaining: 15s\n",
      "18:\tlearn: 0.8519206\ttotal: 3.48s\tremaining: 14.8s\n",
      "19:\tlearn: 0.8546341\ttotal: 3.65s\tremaining: 14.6s\n",
      "20:\tlearn: 0.8610080\ttotal: 3.83s\tremaining: 14.4s\n",
      "21:\tlearn: 0.8687616\ttotal: 4.01s\tremaining: 14.2s\n",
      "22:\tlearn: 0.8750244\ttotal: 4.19s\tremaining: 14s\n",
      "23:\tlearn: 0.8807753\ttotal: 4.37s\tremaining: 13.8s\n",
      "24:\tlearn: 0.8853422\ttotal: 4.55s\tremaining: 13.7s\n",
      "25:\tlearn: 0.8892151\ttotal: 4.73s\tremaining: 13.5s\n",
      "26:\tlearn: 0.8952213\ttotal: 4.91s\tremaining: 13.3s\n",
      "27:\tlearn: 0.8980549\ttotal: 5.08s\tremaining: 13.1s\n",
      "28:\tlearn: 0.9021484\ttotal: 5.26s\tremaining: 12.9s\n",
      "29:\tlearn: 0.9066106\ttotal: 5.44s\tremaining: 12.7s\n",
      "30:\tlearn: 0.9118252\ttotal: 5.62s\tremaining: 12.5s\n",
      "31:\tlearn: 0.9147560\ttotal: 5.8s\tremaining: 12.3s\n",
      "32:\tlearn: 0.9186012\ttotal: 5.98s\tremaining: 12.1s\n",
      "33:\tlearn: 0.9226319\ttotal: 6.17s\tremaining: 12s\n",
      "34:\tlearn: 0.9247870\ttotal: 6.35s\tremaining: 11.8s\n",
      "35:\tlearn: 0.9307700\ttotal: 6.54s\tremaining: 11.6s\n",
      "36:\tlearn: 0.9318940\ttotal: 6.72s\tremaining: 11.4s\n",
      "37:\tlearn: 0.9353317\ttotal: 6.89s\tremaining: 11.2s\n",
      "38:\tlearn: 0.9396356\ttotal: 7.07s\tremaining: 11.1s\n",
      "39:\tlearn: 0.9441153\ttotal: 7.25s\tremaining: 10.9s\n",
      "40:\tlearn: 0.9453325\ttotal: 7.43s\tremaining: 10.7s\n",
      "41:\tlearn: 0.9487889\ttotal: 7.62s\tremaining: 10.5s\n",
      "42:\tlearn: 0.9502620\ttotal: 7.8s\tremaining: 10.3s\n",
      "43:\tlearn: 0.9512051\ttotal: 7.98s\tremaining: 10.2s\n",
      "44:\tlearn: 0.9526907\ttotal: 8.17s\tremaining: 9.98s\n",
      "45:\tlearn: 0.9560787\ttotal: 8.35s\tremaining: 9.8s\n",
      "46:\tlearn: 0.9571626\ttotal: 8.52s\tremaining: 9.61s\n",
      "47:\tlearn: 0.9581028\ttotal: 8.71s\tremaining: 9.44s\n",
      "48:\tlearn: 0.9597309\ttotal: 8.89s\tremaining: 9.25s\n",
      "49:\tlearn: 0.9631318\ttotal: 9.06s\tremaining: 9.06s\n",
      "50:\tlearn: 0.9664350\ttotal: 9.23s\tremaining: 8.87s\n",
      "51:\tlearn: 0.9679022\ttotal: 9.41s\tremaining: 8.69s\n",
      "52:\tlearn: 0.9683312\ttotal: 9.6s\tremaining: 8.51s\n",
      "53:\tlearn: 0.9695855\ttotal: 9.77s\tremaining: 8.32s\n",
      "54:\tlearn: 0.9699256\ttotal: 9.95s\tremaining: 8.14s\n",
      "55:\tlearn: 0.9731370\ttotal: 10.1s\tremaining: 7.96s\n",
      "56:\tlearn: 0.9749950\ttotal: 10.3s\tremaining: 7.78s\n",
      "57:\tlearn: 0.9780286\ttotal: 10.5s\tremaining: 7.61s\n",
      "58:\tlearn: 0.9793083\ttotal: 10.7s\tremaining: 7.42s\n",
      "59:\tlearn: 0.9801139\ttotal: 10.9s\tremaining: 7.24s\n",
      "60:\tlearn: 0.9807135\ttotal: 11s\tremaining: 7.05s\n",
      "61:\tlearn: 0.9815074\ttotal: 11.2s\tremaining: 6.87s\n",
      "62:\tlearn: 0.9830865\ttotal: 11.4s\tremaining: 6.68s\n",
      "63:\tlearn: 0.9837773\ttotal: 11.6s\tremaining: 6.5s\n",
      "64:\tlearn: 0.9849609\ttotal: 11.7s\tremaining: 6.31s\n",
      "65:\tlearn: 0.9855610\ttotal: 11.9s\tremaining: 6.13s\n",
      "66:\tlearn: 0.9862629\ttotal: 12.1s\tremaining: 5.95s\n",
      "67:\tlearn: 0.9871602\ttotal: 12.2s\tremaining: 5.76s\n",
      "68:\tlearn: 0.9881538\ttotal: 12.4s\tremaining: 5.58s\n",
      "69:\tlearn: 0.9883546\ttotal: 12.6s\tremaining: 5.39s\n",
      "70:\tlearn: 0.9893553\ttotal: 12.8s\tremaining: 5.21s\n",
      "71:\tlearn: 0.9906523\ttotal: 12.9s\tremaining: 5.03s\n",
      "72:\tlearn: 0.9908524\ttotal: 13.1s\tremaining: 4.85s\n",
      "73:\tlearn: 0.9909520\ttotal: 13.3s\tremaining: 4.67s\n",
      "74:\tlearn: 0.9912528\ttotal: 13.5s\tremaining: 4.49s\n",
      "75:\tlearn: 0.9917530\ttotal: 13.6s\tremaining: 4.31s\n",
      "76:\tlearn: 0.9923518\ttotal: 13.8s\tremaining: 4.13s\n",
      "77:\tlearn: 0.9930535\ttotal: 14s\tremaining: 3.94s\n",
      "78:\tlearn: 0.9935562\ttotal: 14.2s\tremaining: 3.76s\n",
      "79:\tlearn: 0.9933562\ttotal: 14.3s\tremaining: 3.58s\n",
      "80:\tlearn: 0.9939571\ttotal: 14.5s\tremaining: 3.4s\n",
      "81:\tlearn: 0.9946594\ttotal: 14.7s\tremaining: 3.22s\n",
      "82:\tlearn: 0.9959649\ttotal: 14.9s\tremaining: 3.04s\n",
      "83:\tlearn: 0.9963677\ttotal: 15s\tremaining: 2.87s\n",
      "84:\tlearn: 0.9965681\ttotal: 15.2s\tremaining: 2.68s\n",
      "85:\tlearn: 0.9966690\ttotal: 15.4s\tremaining: 2.5s\n",
      "86:\tlearn: 0.9969709\ttotal: 15.6s\tremaining: 2.32s\n",
      "87:\tlearn: 0.9972730\ttotal: 15.7s\tremaining: 2.15s\n",
      "88:\tlearn: 0.9976761\ttotal: 15.9s\tremaining: 1.97s\n",
      "89:\tlearn: 0.9977771\ttotal: 16.1s\tremaining: 1.79s\n",
      "90:\tlearn: 0.9981807\ttotal: 16.3s\tremaining: 1.61s\n",
      "91:\tlearn: 0.9979790\ttotal: 16.4s\tremaining: 1.43s\n",
      "92:\tlearn: 0.9986854\ttotal: 16.6s\tremaining: 1.25s\n",
      "93:\tlearn: 0.9989885\ttotal: 16.8s\tremaining: 1.07s\n",
      "94:\tlearn: 0.9989885\ttotal: 17s\tremaining: 893ms\n",
      "95:\tlearn: 0.9989886\ttotal: 17.1s\tremaining: 714ms\n",
      "96:\tlearn: 0.9993928\ttotal: 17.3s\tremaining: 535ms\n",
      "97:\tlearn: 0.9994940\ttotal: 17.5s\tremaining: 357ms\n",
      "98:\tlearn: 0.9994940\ttotal: 17.7s\tremaining: 178ms\n",
      "99:\tlearn: 0.9995951\ttotal: 17.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=128, depth=8, eval_metric=Precision, iterations=100, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=2; total time=  18.3s\n",
      "0:\tlearn: 0.6163103\ttotal: 195ms\tremaining: 19.3s\n",
      "1:\tlearn: 0.6541652\ttotal: 376ms\tremaining: 18.4s\n",
      "2:\tlearn: 0.6709025\ttotal: 554ms\tremaining: 17.9s\n",
      "3:\tlearn: 0.6982938\ttotal: 734ms\tremaining: 17.6s\n",
      "4:\tlearn: 0.7204713\ttotal: 919ms\tremaining: 17.5s\n",
      "5:\tlearn: 0.7255430\ttotal: 1.09s\tremaining: 17.2s\n",
      "6:\tlearn: 0.7361649\ttotal: 1.27s\tremaining: 16.8s\n",
      "7:\tlearn: 0.7439683\ttotal: 1.45s\tremaining: 16.7s\n",
      "8:\tlearn: 0.7476834\ttotal: 1.63s\tremaining: 16.5s\n",
      "9:\tlearn: 0.7563916\ttotal: 1.8s\tremaining: 16.2s\n",
      "10:\tlearn: 0.7678103\ttotal: 1.98s\tremaining: 16s\n",
      "11:\tlearn: 0.7744003\ttotal: 2.16s\tremaining: 15.8s\n",
      "12:\tlearn: 0.7823512\ttotal: 2.35s\tremaining: 15.7s\n",
      "13:\tlearn: 0.7861744\ttotal: 2.53s\tremaining: 15.5s\n",
      "14:\tlearn: 0.7996914\ttotal: 2.71s\tremaining: 15.4s\n",
      "15:\tlearn: 0.8126879\ttotal: 2.9s\tremaining: 15.2s\n",
      "16:\tlearn: 0.8217303\ttotal: 3.08s\tremaining: 15.1s\n",
      "17:\tlearn: 0.8319744\ttotal: 3.26s\tremaining: 14.9s\n",
      "18:\tlearn: 0.8400467\ttotal: 3.44s\tremaining: 14.7s\n",
      "19:\tlearn: 0.8515054\ttotal: 3.62s\tremaining: 14.5s\n",
      "20:\tlearn: 0.8600526\ttotal: 3.81s\tremaining: 14.3s\n",
      "21:\tlearn: 0.8648386\ttotal: 4s\tremaining: 14.2s\n",
      "22:\tlearn: 0.8716124\ttotal: 4.18s\tremaining: 14s\n",
      "23:\tlearn: 0.8769651\ttotal: 4.35s\tremaining: 13.8s\n",
      "24:\tlearn: 0.8835522\ttotal: 4.53s\tremaining: 13.6s\n",
      "25:\tlearn: 0.8882692\ttotal: 4.71s\tremaining: 13.4s\n",
      "26:\tlearn: 0.8933985\ttotal: 4.89s\tremaining: 13.2s\n",
      "27:\tlearn: 0.8964439\ttotal: 5.06s\tremaining: 13s\n",
      "28:\tlearn: 0.9033963\ttotal: 5.24s\tremaining: 12.8s\n",
      "29:\tlearn: 0.9089391\ttotal: 5.42s\tremaining: 12.7s\n",
      "30:\tlearn: 0.9134710\ttotal: 5.6s\tremaining: 12.5s\n",
      "31:\tlearn: 0.9183975\ttotal: 5.78s\tremaining: 12.3s\n",
      "32:\tlearn: 0.9214953\ttotal: 5.96s\tremaining: 12.1s\n",
      "33:\tlearn: 0.9259917\ttotal: 6.15s\tremaining: 11.9s\n",
      "34:\tlearn: 0.9280150\ttotal: 6.33s\tremaining: 11.7s\n",
      "35:\tlearn: 0.9294903\ttotal: 6.51s\tremaining: 11.6s\n",
      "36:\tlearn: 0.9350777\ttotal: 6.69s\tremaining: 11.4s\n",
      "37:\tlearn: 0.9377524\ttotal: 6.87s\tremaining: 11.2s\n",
      "38:\tlearn: 0.9397970\ttotal: 7.06s\tremaining: 11s\n",
      "39:\tlearn: 0.9426036\ttotal: 7.24s\tremaining: 10.9s\n",
      "40:\tlearn: 0.9460794\ttotal: 7.42s\tremaining: 10.7s\n",
      "41:\tlearn: 0.9510212\ttotal: 7.6s\tremaining: 10.5s\n",
      "42:\tlearn: 0.9534584\ttotal: 7.77s\tremaining: 10.3s\n",
      "43:\tlearn: 0.9554652\ttotal: 7.95s\tremaining: 10.1s\n",
      "44:\tlearn: 0.9571032\ttotal: 8.13s\tremaining: 9.93s\n",
      "45:\tlearn: 0.9607824\ttotal: 8.3s\tremaining: 9.74s\n",
      "46:\tlearn: 0.9620731\ttotal: 8.47s\tremaining: 9.55s\n",
      "47:\tlearn: 0.9637717\ttotal: 8.65s\tremaining: 9.37s\n",
      "48:\tlearn: 0.9653392\ttotal: 8.82s\tremaining: 9.18s\n",
      "49:\tlearn: 0.9672326\ttotal: 9s\tremaining: 9s\n",
      "50:\tlearn: 0.9684985\ttotal: 9.18s\tremaining: 8.82s\n",
      "51:\tlearn: 0.9695674\ttotal: 9.35s\tremaining: 8.63s\n",
      "52:\tlearn: 0.9706584\ttotal: 9.52s\tremaining: 8.45s\n",
      "53:\tlearn: 0.9731290\ttotal: 9.7s\tremaining: 8.26s\n",
      "54:\tlearn: 0.9750872\ttotal: 9.88s\tremaining: 8.08s\n",
      "55:\tlearn: 0.9767511\ttotal: 10.1s\tremaining: 7.9s\n",
      "56:\tlearn: 0.9779265\ttotal: 10.2s\tremaining: 7.72s\n",
      "57:\tlearn: 0.9800841\ttotal: 10.4s\tremaining: 7.53s\n",
      "58:\tlearn: 0.9825634\ttotal: 10.6s\tremaining: 7.35s\n",
      "59:\tlearn: 0.9834702\ttotal: 10.8s\tremaining: 7.17s\n",
      "60:\tlearn: 0.9846693\ttotal: 10.9s\tremaining: 6.99s\n",
      "61:\tlearn: 0.9855552\ttotal: 11.1s\tremaining: 6.81s\n",
      "62:\tlearn: 0.9874523\ttotal: 11.3s\tremaining: 6.63s\n",
      "63:\tlearn: 0.9880522\ttotal: 11.5s\tremaining: 6.45s\n",
      "64:\tlearn: 0.9884492\ttotal: 11.6s\tremaining: 6.27s\n",
      "65:\tlearn: 0.9890463\ttotal: 11.8s\tremaining: 6.09s\n",
      "66:\tlearn: 0.9889591\ttotal: 12s\tremaining: 5.9s\n",
      "67:\tlearn: 0.9893564\ttotal: 12.2s\tremaining: 5.72s\n",
      "68:\tlearn: 0.9905528\ttotal: 12.3s\tremaining: 5.54s\n",
      "69:\tlearn: 0.9913524\ttotal: 12.5s\tremaining: 5.36s\n",
      "70:\tlearn: 0.9919517\ttotal: 12.7s\tremaining: 5.18s\n",
      "71:\tlearn: 0.9922535\ttotal: 12.9s\tremaining: 5.01s\n",
      "72:\tlearn: 0.9927551\ttotal: 13s\tremaining: 4.83s\n",
      "73:\tlearn: 0.9934575\ttotal: 13.2s\tremaining: 4.65s\n",
      "74:\tlearn: 0.9939577\ttotal: 13.4s\tremaining: 4.46s\n",
      "75:\tlearn: 0.9943577\ttotal: 13.6s\tremaining: 4.28s\n",
      "76:\tlearn: 0.9960646\ttotal: 13.7s\tremaining: 4.11s\n",
      "77:\tlearn: 0.9963662\ttotal: 13.9s\tremaining: 3.93s\n",
      "78:\tlearn: 0.9963669\ttotal: 14.1s\tremaining: 3.75s\n",
      "79:\tlearn: 0.9965681\ttotal: 14.3s\tremaining: 3.57s\n",
      "80:\tlearn: 0.9966694\ttotal: 14.4s\tremaining: 3.39s\n",
      "81:\tlearn: 0.9970716\ttotal: 14.6s\tremaining: 3.21s\n",
      "82:\tlearn: 0.9974750\ttotal: 14.8s\tremaining: 3.03s\n",
      "83:\tlearn: 0.9976765\ttotal: 15s\tremaining: 2.85s\n",
      "84:\tlearn: 0.9981805\ttotal: 15.2s\tremaining: 2.67s\n",
      "85:\tlearn: 0.9984833\ttotal: 15.3s\tremaining: 2.5s\n",
      "86:\tlearn: 0.9986855\ttotal: 15.5s\tremaining: 2.32s\n",
      "87:\tlearn: 0.9989886\ttotal: 15.7s\tremaining: 2.14s\n",
      "88:\tlearn: 0.9986855\ttotal: 15.9s\tremaining: 1.96s\n",
      "89:\tlearn: 0.9987865\ttotal: 16s\tremaining: 1.78s\n",
      "90:\tlearn: 0.9987865\ttotal: 16.2s\tremaining: 1.6s\n",
      "91:\tlearn: 0.9989887\ttotal: 16.4s\tremaining: 1.42s\n",
      "92:\tlearn: 0.9990896\ttotal: 16.6s\tremaining: 1.25s\n",
      "93:\tlearn: 0.9992918\ttotal: 16.7s\tremaining: 1.07s\n",
      "94:\tlearn: 0.9990897\ttotal: 16.9s\tremaining: 889ms\n",
      "95:\tlearn: 0.9991907\ttotal: 17.1s\tremaining: 711ms\n",
      "96:\tlearn: 0.9993929\ttotal: 17.3s\tremaining: 534ms\n",
      "97:\tlearn: 0.9993929\ttotal: 17.4s\tremaining: 356ms\n",
      "98:\tlearn: 0.9995952\ttotal: 17.6s\tremaining: 178ms\n",
      "99:\tlearn: 0.9994940\ttotal: 17.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=128, depth=8, eval_metric=Precision, iterations=100, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.7, random_strength=2; total time=  18.5s\n",
      "0:\tlearn: 0.6668556\ttotal: 231ms\tremaining: 2m 41s\n",
      "1:\tlearn: 0.6862504\ttotal: 453ms\tremaining: 2m 37s\n",
      "2:\tlearn: 0.7157674\ttotal: 672ms\tremaining: 2m 36s\n",
      "3:\tlearn: 0.7331021\ttotal: 891ms\tremaining: 2m 34s\n",
      "4:\tlearn: 0.7369509\ttotal: 1.11s\tremaining: 2m 34s\n",
      "5:\tlearn: 0.7471713\ttotal: 1.32s\tremaining: 2m 33s\n",
      "6:\tlearn: 0.7588832\ttotal: 1.55s\tremaining: 2m 33s\n",
      "7:\tlearn: 0.7686847\ttotal: 1.76s\tremaining: 2m 32s\n",
      "8:\tlearn: 0.7718668\ttotal: 1.98s\tremaining: 2m 31s\n",
      "9:\tlearn: 0.7780960\ttotal: 2.2s\tremaining: 2m 31s\n",
      "10:\tlearn: 0.7846139\ttotal: 2.42s\tremaining: 2m 31s\n",
      "11:\tlearn: 0.7934592\ttotal: 2.63s\tremaining: 2m 30s\n",
      "12:\tlearn: 0.7932207\ttotal: 2.85s\tremaining: 2m 30s\n",
      "13:\tlearn: 0.7966966\ttotal: 3.06s\tremaining: 2m 30s\n",
      "14:\tlearn: 0.7943490\ttotal: 3.28s\tremaining: 2m 29s\n",
      "15:\tlearn: 0.7982102\ttotal: 3.49s\tremaining: 2m 29s\n",
      "16:\tlearn: 0.8001167\ttotal: 3.71s\tremaining: 2m 29s\n",
      "17:\tlearn: 0.8032285\ttotal: 3.93s\tremaining: 2m 28s\n",
      "18:\tlearn: 0.8040167\ttotal: 4.13s\tremaining: 2m 28s\n",
      "19:\tlearn: 0.8059281\ttotal: 4.35s\tremaining: 2m 28s\n",
      "20:\tlearn: 0.8065676\ttotal: 4.57s\tremaining: 2m 27s\n",
      "21:\tlearn: 0.8027045\ttotal: 4.79s\tremaining: 2m 27s\n",
      "22:\tlearn: 0.8052491\ttotal: 5.01s\tremaining: 2m 27s\n",
      "23:\tlearn: 0.8065332\ttotal: 5.22s\tremaining: 2m 27s\n",
      "24:\tlearn: 0.8091625\ttotal: 5.46s\tremaining: 2m 27s\n",
      "25:\tlearn: 0.8098643\ttotal: 5.68s\tremaining: 2m 27s\n",
      "26:\tlearn: 0.8129734\ttotal: 5.89s\tremaining: 2m 26s\n",
      "27:\tlearn: 0.8116251\ttotal: 6.11s\tremaining: 2m 26s\n",
      "28:\tlearn: 0.8121847\ttotal: 6.32s\tremaining: 2m 26s\n",
      "29:\tlearn: 0.8139976\ttotal: 6.55s\tremaining: 2m 26s\n",
      "30:\tlearn: 0.8145479\ttotal: 6.77s\tremaining: 2m 26s\n",
      "31:\tlearn: 0.8146669\ttotal: 6.98s\tremaining: 2m 25s\n",
      "32:\tlearn: 0.8160506\ttotal: 7.2s\tremaining: 2m 25s\n",
      "33:\tlearn: 0.8183942\ttotal: 7.42s\tremaining: 2m 25s\n",
      "34:\tlearn: 0.8181200\ttotal: 7.63s\tremaining: 2m 24s\n",
      "35:\tlearn: 0.8189191\ttotal: 7.85s\tremaining: 2m 24s\n",
      "36:\tlearn: 0.8185748\ttotal: 8.06s\tremaining: 2m 24s\n",
      "37:\tlearn: 0.8209318\ttotal: 8.28s\tremaining: 2m 24s\n",
      "38:\tlearn: 0.8226073\ttotal: 8.5s\tremaining: 2m 24s\n",
      "39:\tlearn: 0.8220925\ttotal: 8.72s\tremaining: 2m 23s\n",
      "40:\tlearn: 0.8241421\ttotal: 8.94s\tremaining: 2m 23s\n",
      "41:\tlearn: 0.8263601\ttotal: 9.16s\tremaining: 2m 23s\n",
      "42:\tlearn: 0.8272807\ttotal: 9.37s\tremaining: 2m 23s\n",
      "43:\tlearn: 0.8279784\ttotal: 9.58s\tremaining: 2m 22s\n",
      "44:\tlearn: 0.8290412\ttotal: 9.78s\tremaining: 2m 22s\n",
      "45:\tlearn: 0.8279648\ttotal: 10s\tremaining: 2m 22s\n",
      "46:\tlearn: 0.8304071\ttotal: 10.2s\tremaining: 2m 22s\n",
      "47:\tlearn: 0.8295074\ttotal: 10.4s\tremaining: 2m 21s\n",
      "48:\tlearn: 0.8288568\ttotal: 10.7s\tremaining: 2m 21s\n",
      "49:\tlearn: 0.8305183\ttotal: 10.9s\tremaining: 2m 21s\n",
      "50:\tlearn: 0.8306334\ttotal: 11.1s\tremaining: 2m 21s\n",
      "51:\tlearn: 0.8321373\ttotal: 11.3s\tremaining: 2m 21s\n",
      "52:\tlearn: 0.8328244\ttotal: 11.5s\tremaining: 2m 20s\n",
      "53:\tlearn: 0.8332768\ttotal: 11.8s\tremaining: 2m 20s\n",
      "54:\tlearn: 0.8328722\ttotal: 12s\tremaining: 2m 20s\n",
      "55:\tlearn: 0.8341919\ttotal: 12.2s\tremaining: 2m 20s\n",
      "56:\tlearn: 0.8353027\ttotal: 12.4s\tremaining: 2m 19s\n",
      "57:\tlearn: 0.8377550\ttotal: 12.6s\tremaining: 2m 19s\n",
      "58:\tlearn: 0.8380878\ttotal: 12.8s\tremaining: 2m 19s\n",
      "59:\tlearn: 0.8376152\ttotal: 13.1s\tremaining: 2m 19s\n",
      "60:\tlearn: 0.8379839\ttotal: 13.3s\tremaining: 2m 19s\n",
      "61:\tlearn: 0.8381435\ttotal: 13.5s\tremaining: 2m 18s\n",
      "62:\tlearn: 0.8386687\ttotal: 13.7s\tremaining: 2m 18s\n",
      "63:\tlearn: 0.8379932\ttotal: 13.9s\tremaining: 2m 18s\n",
      "64:\tlearn: 0.8392317\ttotal: 14.1s\tremaining: 2m 18s\n",
      "65:\tlearn: 0.8409435\ttotal: 14.4s\tremaining: 2m 17s\n",
      "66:\tlearn: 0.8411343\ttotal: 14.6s\tremaining: 2m 17s\n",
      "67:\tlearn: 0.8405034\ttotal: 14.8s\tremaining: 2m 17s\n",
      "68:\tlearn: 0.8415039\ttotal: 15s\tremaining: 2m 17s\n",
      "69:\tlearn: 0.8420437\ttotal: 15.2s\tremaining: 2m 16s\n",
      "70:\tlearn: 0.8434910\ttotal: 15.4s\tremaining: 2m 16s\n",
      "71:\tlearn: 0.8426802\ttotal: 15.7s\tremaining: 2m 16s\n",
      "72:\tlearn: 0.8433382\ttotal: 15.9s\tremaining: 2m 16s\n",
      "73:\tlearn: 0.8438917\ttotal: 16.1s\tremaining: 2m 16s\n",
      "74:\tlearn: 0.8444206\ttotal: 16.3s\tremaining: 2m 16s\n",
      "75:\tlearn: 0.8455316\ttotal: 16.5s\tremaining: 2m 15s\n",
      "76:\tlearn: 0.8457716\ttotal: 16.8s\tremaining: 2m 15s\n",
      "77:\tlearn: 0.8467345\ttotal: 17s\tremaining: 2m 15s\n",
      "78:\tlearn: 0.8471884\ttotal: 17.2s\tremaining: 2m 15s\n",
      "79:\tlearn: 0.8469179\ttotal: 17.4s\tremaining: 2m 14s\n",
      "80:\tlearn: 0.8472263\ttotal: 17.6s\tremaining: 2m 14s\n",
      "81:\tlearn: 0.8462325\ttotal: 17.9s\tremaining: 2m 14s\n",
      "82:\tlearn: 0.8475533\ttotal: 18.1s\tremaining: 2m 14s\n",
      "83:\tlearn: 0.8479837\ttotal: 18.3s\tremaining: 2m 14s\n",
      "84:\tlearn: 0.8503186\ttotal: 18.5s\tremaining: 2m 14s\n",
      "85:\tlearn: 0.8502895\ttotal: 18.8s\tremaining: 2m 13s\n",
      "86:\tlearn: 0.8508900\ttotal: 19s\tremaining: 2m 13s\n",
      "87:\tlearn: 0.8519293\ttotal: 19.2s\tremaining: 2m 13s\n",
      "88:\tlearn: 0.8526249\ttotal: 19.4s\tremaining: 2m 13s\n",
      "89:\tlearn: 0.8525532\ttotal: 19.6s\tremaining: 2m 13s\n",
      "90:\tlearn: 0.8530142\ttotal: 19.8s\tremaining: 2m 12s\n",
      "91:\tlearn: 0.8531557\ttotal: 20s\tremaining: 2m 12s\n",
      "92:\tlearn: 0.8535211\ttotal: 20.3s\tremaining: 2m 12s\n",
      "93:\tlearn: 0.8535910\ttotal: 20.5s\tremaining: 2m 12s\n",
      "94:\tlearn: 0.8544095\ttotal: 20.7s\tremaining: 2m 11s\n",
      "95:\tlearn: 0.8542699\ttotal: 20.9s\tremaining: 2m 11s\n",
      "96:\tlearn: 0.8546735\ttotal: 21.1s\tremaining: 2m 11s\n",
      "97:\tlearn: 0.8548810\ttotal: 21.4s\tremaining: 2m 11s\n",
      "98:\tlearn: 0.8563933\ttotal: 21.6s\tremaining: 2m 10s\n",
      "99:\tlearn: 0.8570179\ttotal: 21.8s\tremaining: 2m 10s\n",
      "100:\tlearn: 0.8578648\ttotal: 22s\tremaining: 2m 10s\n",
      "101:\tlearn: 0.8581843\ttotal: 22.2s\tremaining: 2m 10s\n",
      "102:\tlearn: 0.8575598\ttotal: 22.4s\tremaining: 2m 9s\n",
      "103:\tlearn: 0.8587279\ttotal: 22.6s\tremaining: 2m 9s\n",
      "104:\tlearn: 0.8585043\ttotal: 22.9s\tremaining: 2m 9s\n",
      "105:\tlearn: 0.8595919\ttotal: 23.1s\tremaining: 2m 9s\n",
      "106:\tlearn: 0.8598841\ttotal: 23.3s\tremaining: 2m 9s\n",
      "107:\tlearn: 0.8597594\ttotal: 23.5s\tremaining: 2m 8s\n",
      "108:\tlearn: 0.8603450\ttotal: 23.7s\tremaining: 2m 8s\n",
      "109:\tlearn: 0.8607632\ttotal: 24s\tremaining: 2m 8s\n",
      "110:\tlearn: 0.8617815\ttotal: 24.2s\tremaining: 2m 8s\n",
      "111:\tlearn: 0.8625846\ttotal: 24.4s\tremaining: 2m 8s\n",
      "112:\tlearn: 0.8632911\ttotal: 24.6s\tremaining: 2m 7s\n",
      "113:\tlearn: 0.8630410\ttotal: 24.8s\tremaining: 2m 7s\n",
      "114:\tlearn: 0.8639307\ttotal: 25.1s\tremaining: 2m 7s\n",
      "115:\tlearn: 0.8640280\ttotal: 25.3s\tremaining: 2m 7s\n",
      "116:\tlearn: 0.8634726\ttotal: 25.5s\tremaining: 2m 7s\n",
      "117:\tlearn: 0.8638777\ttotal: 25.7s\tremaining: 2m 6s\n",
      "118:\tlearn: 0.8640569\ttotal: 25.9s\tremaining: 2m 6s\n",
      "119:\tlearn: 0.8650701\ttotal: 26.1s\tremaining: 2m 6s\n",
      "120:\tlearn: 0.8646807\ttotal: 26.4s\tremaining: 2m 6s\n",
      "121:\tlearn: 0.8651778\ttotal: 26.6s\tremaining: 2m 5s\n",
      "122:\tlearn: 0.8648018\ttotal: 26.8s\tremaining: 2m 5s\n",
      "123:\tlearn: 0.8654174\ttotal: 27s\tremaining: 2m 5s\n",
      "124:\tlearn: 0.8656280\ttotal: 27.2s\tremaining: 2m 5s\n",
      "125:\tlearn: 0.8656048\ttotal: 27.5s\tremaining: 2m 5s\n",
      "126:\tlearn: 0.8660466\ttotal: 27.7s\tremaining: 2m 4s\n",
      "127:\tlearn: 0.8665270\ttotal: 27.9s\tremaining: 2m 4s\n",
      "128:\tlearn: 0.8667705\ttotal: 28.1s\tremaining: 2m 4s\n",
      "129:\tlearn: 0.8668875\ttotal: 28.3s\tremaining: 2m 4s\n",
      "130:\tlearn: 0.8680992\ttotal: 28.5s\tremaining: 2m 3s\n",
      "131:\tlearn: 0.8687902\ttotal: 28.7s\tremaining: 2m 3s\n",
      "132:\tlearn: 0.8700141\ttotal: 29s\tremaining: 2m 3s\n",
      "133:\tlearn: 0.8712929\ttotal: 29.2s\tremaining: 2m 3s\n",
      "134:\tlearn: 0.8713903\ttotal: 29.4s\tremaining: 2m 2s\n",
      "135:\tlearn: 0.8717299\ttotal: 29.6s\tremaining: 2m 2s\n",
      "136:\tlearn: 0.8723415\ttotal: 29.8s\tremaining: 2m 2s\n",
      "137:\tlearn: 0.8725733\ttotal: 30s\tremaining: 2m 2s\n",
      "138:\tlearn: 0.8727910\ttotal: 30.3s\tremaining: 2m 2s\n",
      "139:\tlearn: 0.8728158\ttotal: 30.5s\tremaining: 2m 1s\n",
      "140:\tlearn: 0.8726282\ttotal: 30.7s\tremaining: 2m 1s\n",
      "141:\tlearn: 0.8730955\ttotal: 30.9s\tremaining: 2m 1s\n",
      "142:\tlearn: 0.8730599\ttotal: 31.1s\tremaining: 2m 1s\n",
      "143:\tlearn: 0.8730777\ttotal: 31.3s\tremaining: 2m 1s\n",
      "144:\tlearn: 0.8731202\ttotal: 31.6s\tremaining: 2m\n",
      "145:\tlearn: 0.8730475\ttotal: 31.8s\tremaining: 2m\n",
      "146:\tlearn: 0.8740272\ttotal: 32s\tremaining: 2m\n",
      "147:\tlearn: 0.8739357\ttotal: 32.2s\tremaining: 2m\n",
      "148:\tlearn: 0.8738204\ttotal: 32.4s\tremaining: 1m 59s\n",
      "149:\tlearn: 0.8748602\ttotal: 32.6s\tremaining: 1m 59s\n",
      "150:\tlearn: 0.8754015\ttotal: 32.8s\tremaining: 1m 59s\n",
      "151:\tlearn: 0.8755720\ttotal: 33s\tremaining: 1m 59s\n",
      "152:\tlearn: 0.8760894\ttotal: 33.3s\tremaining: 1m 58s\n",
      "153:\tlearn: 0.8760282\ttotal: 33.5s\tremaining: 1m 58s\n",
      "154:\tlearn: 0.8767950\ttotal: 33.7s\tremaining: 1m 58s\n",
      "155:\tlearn: 0.8770512\ttotal: 33.9s\tremaining: 1m 58s\n",
      "156:\tlearn: 0.8770512\ttotal: 34.1s\tremaining: 1m 58s\n",
      "157:\tlearn: 0.8771178\ttotal: 34.4s\tremaining: 1m 57s\n",
      "158:\tlearn: 0.8774765\ttotal: 34.6s\tremaining: 1m 57s\n",
      "159:\tlearn: 0.8771537\ttotal: 34.8s\tremaining: 1m 57s\n",
      "160:\tlearn: 0.8776047\ttotal: 35s\tremaining: 1m 57s\n",
      "161:\tlearn: 0.8780488\ttotal: 35.2s\tremaining: 1m 57s\n",
      "162:\tlearn: 0.8782008\ttotal: 35.5s\tremaining: 1m 56s\n",
      "163:\tlearn: 0.8779228\ttotal: 35.7s\tremaining: 1m 56s\n",
      "164:\tlearn: 0.8781723\ttotal: 35.9s\tremaining: 1m 56s\n",
      "165:\tlearn: 0.8781914\ttotal: 36.1s\tremaining: 1m 56s\n",
      "166:\tlearn: 0.8784264\ttotal: 36.4s\tremaining: 1m 56s\n",
      "167:\tlearn: 0.8787805\ttotal: 36.6s\tremaining: 1m 55s\n",
      "168:\tlearn: 0.8783172\ttotal: 36.8s\tremaining: 1m 55s\n",
      "169:\tlearn: 0.8781580\ttotal: 37s\tremaining: 1m 55s\n",
      "170:\tlearn: 0.8778659\ttotal: 37.2s\tremaining: 1m 55s\n",
      "171:\tlearn: 0.8785238\ttotal: 37.5s\tremaining: 1m 54s\n",
      "172:\tlearn: 0.8784619\ttotal: 37.7s\tremaining: 1m 54s\n",
      "173:\tlearn: 0.8785047\ttotal: 37.9s\tremaining: 1m 54s\n",
      "174:\tlearn: 0.8792524\ttotal: 38.1s\tremaining: 1m 54s\n",
      "175:\tlearn: 0.8794899\ttotal: 38.3s\tremaining: 1m 54s\n",
      "176:\tlearn: 0.8797157\ttotal: 38.5s\tremaining: 1m 53s\n",
      "177:\tlearn: 0.8806616\ttotal: 38.8s\tremaining: 1m 53s\n",
      "178:\tlearn: 0.8811087\ttotal: 39s\tremaining: 1m 53s\n",
      "179:\tlearn: 0.8817487\ttotal: 39.2s\tremaining: 1m 53s\n",
      "180:\tlearn: 0.8813906\ttotal: 39.4s\tremaining: 1m 53s\n",
      "181:\tlearn: 0.8814021\ttotal: 39.6s\tremaining: 1m 52s\n",
      "182:\tlearn: 0.8815886\ttotal: 39.9s\tremaining: 1m 52s\n",
      "183:\tlearn: 0.8820178\ttotal: 40.1s\tremaining: 1m 52s\n",
      "184:\tlearn: 0.8821496\ttotal: 40.3s\tremaining: 1m 52s\n",
      "185:\tlearn: 0.8823988\ttotal: 40.5s\tremaining: 1m 51s\n",
      "186:\tlearn: 0.8832952\ttotal: 40.7s\tremaining: 1m 51s\n",
      "187:\tlearn: 0.8832067\ttotal: 40.9s\tremaining: 1m 51s\n",
      "188:\tlearn: 0.8840199\ttotal: 41.1s\tremaining: 1m 51s\n",
      "189:\tlearn: 0.8842577\ttotal: 41.4s\tremaining: 1m 51s\n",
      "190:\tlearn: 0.8843233\ttotal: 41.6s\tremaining: 1m 50s\n",
      "191:\tlearn: 0.8845910\ttotal: 41.8s\tremaining: 1m 50s\n",
      "192:\tlearn: 0.8844843\ttotal: 42s\tremaining: 1m 50s\n",
      "193:\tlearn: 0.8845817\ttotal: 42.2s\tremaining: 1m 50s\n",
      "194:\tlearn: 0.8846454\ttotal: 42.4s\tremaining: 1m 49s\n",
      "195:\tlearn: 0.8847109\ttotal: 42.6s\tremaining: 1m 49s\n",
      "196:\tlearn: 0.8852092\ttotal: 42.9s\tremaining: 1m 49s\n",
      "197:\tlearn: 0.8854583\ttotal: 43.1s\tremaining: 1m 49s\n",
      "198:\tlearn: 0.8855125\ttotal: 43.3s\tremaining: 1m 48s\n",
      "199:\tlearn: 0.8860747\ttotal: 43.5s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.8862264\ttotal: 43.7s\tremaining: 1m 48s\n",
      "201:\tlearn: 0.8856948\ttotal: 43.9s\tremaining: 1m 48s\n",
      "202:\tlearn: 0.8860858\ttotal: 44.2s\tremaining: 1m 48s\n",
      "203:\tlearn: 0.8863227\ttotal: 44.4s\tremaining: 1m 47s\n",
      "204:\tlearn: 0.8858786\ttotal: 44.6s\tremaining: 1m 47s\n",
      "205:\tlearn: 0.8861499\ttotal: 44.8s\tremaining: 1m 47s\n",
      "206:\tlearn: 0.8865286\ttotal: 45s\tremaining: 1m 47s\n",
      "207:\tlearn: 0.8869184\ttotal: 45.3s\tremaining: 1m 47s\n",
      "208:\tlearn: 0.8870158\ttotal: 45.5s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.8874488\ttotal: 45.7s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.8879474\ttotal: 45.9s\tremaining: 1m 46s\n",
      "211:\tlearn: 0.8881201\ttotal: 46.1s\tremaining: 1m 46s\n",
      "212:\tlearn: 0.8877954\ttotal: 46.3s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.8878928\ttotal: 46.5s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.8883580\ttotal: 46.8s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.8886723\ttotal: 47s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.8887914\ttotal: 47.2s\tremaining: 1m 45s\n",
      "217:\tlearn: 0.8894303\ttotal: 47.4s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.8896034\ttotal: 47.6s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.8895709\ttotal: 47.8s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.8900467\ttotal: 48s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.8905337\ttotal: 48.3s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.8902308\ttotal: 48.5s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.8903282\ttotal: 48.7s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.8902089\ttotal: 48.9s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.8898627\ttotal: 49.1s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.8896898\ttotal: 49.3s\tremaining: 1m 42s\n",
      "227:\tlearn: 0.8899932\ttotal: 49.6s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.8903069\ttotal: 49.8s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.8905344\ttotal: 50s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.8906859\ttotal: 50.2s\tremaining: 1m 41s\n",
      "231:\tlearn: 0.8912376\ttotal: 50.4s\tremaining: 1m 41s\n",
      "232:\tlearn: 0.8913351\ttotal: 50.6s\tremaining: 1m 41s\n",
      "233:\tlearn: 0.8914007\ttotal: 50.9s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.8917365\ttotal: 51.1s\tremaining: 1m 41s\n",
      "235:\tlearn: 0.8924935\ttotal: 51.3s\tremaining: 1m 40s\n",
      "236:\tlearn: 0.8922013\ttotal: 51.5s\tremaining: 1m 40s\n",
      "237:\tlearn: 0.8930677\ttotal: 51.7s\tremaining: 1m 40s\n",
      "238:\tlearn: 0.8928728\ttotal: 52s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.8937600\ttotal: 52.2s\tremaining: 1m 40s\n",
      "240:\tlearn: 0.8934139\ttotal: 52.4s\tremaining: 1m 39s\n",
      "241:\tlearn: 0.8934326\ttotal: 52.6s\tremaining: 1m 39s\n",
      "242:\tlearn: 0.8931736\ttotal: 52.8s\tremaining: 1m 39s\n",
      "243:\tlearn: 0.8932171\ttotal: 53.1s\tremaining: 1m 39s\n",
      "244:\tlearn: 0.8929702\ttotal: 53.3s\tremaining: 1m 38s\n",
      "245:\tlearn: 0.8933353\ttotal: 53.5s\tremaining: 1m 38s\n",
      "246:\tlearn: 0.8936502\ttotal: 53.7s\tremaining: 1m 38s\n",
      "247:\tlearn: 0.8937476\ttotal: 53.9s\tremaining: 1m 38s\n",
      "248:\tlearn: 0.8937372\ttotal: 54.1s\tremaining: 1m 38s\n",
      "249:\tlearn: 0.8940397\ttotal: 54.4s\tremaining: 1m 37s\n",
      "250:\tlearn: 0.8943089\ttotal: 54.6s\tremaining: 1m 37s\n",
      "251:\tlearn: 0.8941577\ttotal: 54.8s\tremaining: 1m 37s\n",
      "252:\tlearn: 0.8942448\ttotal: 55s\tremaining: 1m 37s\n",
      "253:\tlearn: 0.8942551\ttotal: 55.2s\tremaining: 1m 37s\n",
      "254:\tlearn: 0.8944166\ttotal: 55.5s\tremaining: 1m 36s\n",
      "255:\tlearn: 0.8944807\ttotal: 55.7s\tremaining: 1m 36s\n",
      "256:\tlearn: 0.8945805\ttotal: 55.9s\tremaining: 1m 36s\n",
      "257:\tlearn: 0.8948624\ttotal: 56.1s\tremaining: 1m 36s\n",
      "258:\tlearn: 0.8954672\ttotal: 56.3s\tremaining: 1m 35s\n",
      "259:\tlearn: 0.8956081\ttotal: 56.5s\tremaining: 1m 35s\n",
      "260:\tlearn: 0.8953188\ttotal: 56.7s\tremaining: 1m 35s\n",
      "261:\tlearn: 0.8961520\ttotal: 57s\tremaining: 1m 35s\n",
      "262:\tlearn: 0.8966793\ttotal: 57.2s\tremaining: 1m 35s\n",
      "263:\tlearn: 0.8965517\ttotal: 57.4s\tremaining: 1m 34s\n",
      "264:\tlearn: 0.8966457\ttotal: 57.6s\tremaining: 1m 34s\n",
      "265:\tlearn: 0.8968204\ttotal: 57.8s\tremaining: 1m 34s\n",
      "266:\tlearn: 0.8970116\ttotal: 58s\tremaining: 1m 34s\n",
      "267:\tlearn: 0.8968806\ttotal: 58.2s\tremaining: 1m 33s\n",
      "268:\tlearn: 0.8970016\ttotal: 58.5s\tremaining: 1m 33s\n",
      "269:\tlearn: 0.8971025\ttotal: 58.7s\tremaining: 1m 33s\n",
      "270:\tlearn: 0.8976731\ttotal: 58.9s\tremaining: 1m 33s\n",
      "271:\tlearn: 0.8975757\ttotal: 59.1s\tremaining: 1m 32s\n",
      "272:\tlearn: 0.8979850\ttotal: 59.3s\tremaining: 1m 32s\n",
      "273:\tlearn: 0.8979751\ttotal: 59.5s\tremaining: 1m 32s\n",
      "274:\tlearn: 0.8981202\ttotal: 59.7s\tremaining: 1m 32s\n",
      "275:\tlearn: 0.8982712\ttotal: 60s\tremaining: 1m 32s\n",
      "276:\tlearn: 0.8979791\ttotal: 1m\tremaining: 1m 31s\n",
      "277:\tlearn: 0.8981400\ttotal: 1m\tremaining: 1m 31s\n",
      "278:\tlearn: 0.8984124\ttotal: 1m\tremaining: 1m 31s\n",
      "279:\tlearn: 0.8987582\ttotal: 1m\tremaining: 1m 31s\n",
      "280:\tlearn: 0.8992890\ttotal: 1m 1s\tremaining: 1m 31s\n",
      "281:\tlearn: 0.8992354\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "282:\tlearn: 0.8995518\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "283:\tlearn: 0.8994936\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "284:\tlearn: 0.9000341\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "285:\tlearn: 0.9000730\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "286:\tlearn: 0.9000584\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "287:\tlearn: 0.8999220\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "288:\tlearn: 0.9006384\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "289:\tlearn: 0.9005797\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "290:\tlearn: 0.9005700\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "291:\tlearn: 0.9009009\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "292:\tlearn: 0.9009737\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "293:\tlearn: 0.9013536\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "294:\tlearn: 0.9011781\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "295:\tlearn: 0.9016210\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "296:\tlearn: 0.9020543\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "297:\tlearn: 0.9022681\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "298:\tlearn: 0.9024188\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "299:\tlearn: 0.9025257\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "300:\tlearn: 0.9028710\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "301:\tlearn: 0.9031881\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "302:\tlearn: 0.9031191\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "303:\tlearn: 0.9031913\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "304:\tlearn: 0.9033859\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "305:\tlearn: 0.9033325\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "306:\tlearn: 0.9033953\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "307:\tlearn: 0.9036684\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "308:\tlearn: 0.9037657\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "309:\tlearn: 0.9039070\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "310:\tlearn: 0.9039416\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "311:\tlearn: 0.9041269\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "312:\tlearn: 0.9048268\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "313:\tlearn: 0.9048360\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "314:\tlearn: 0.9050584\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "315:\tlearn: 0.9051556\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "316:\tlearn: 0.9049703\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "317:\tlearn: 0.9049703\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "318:\tlearn: 0.9048986\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "319:\tlearn: 0.9050584\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "320:\tlearn: 0.9055099\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "321:\tlearn: 0.9057136\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "322:\tlearn: 0.9062622\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "323:\tlearn: 0.9063944\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "324:\tlearn: 0.9067574\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "325:\tlearn: 0.9069168\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "326:\tlearn: 0.9067483\ttotal: 1m 10s\tremaining: 1m 20s\n",
      "327:\tlearn: 0.9068015\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "328:\tlearn: 0.9071463\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "329:\tlearn: 0.9069700\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "330:\tlearn: 0.9074470\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "331:\tlearn: 0.9074200\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "332:\tlearn: 0.9070661\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "333:\tlearn: 0.9069779\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "334:\tlearn: 0.9074110\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "335:\tlearn: 0.9074641\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "336:\tlearn: 0.9075786\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "337:\tlearn: 0.9075344\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "338:\tlearn: 0.9076145\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "339:\tlearn: 0.9075254\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "340:\tlearn: 0.9074371\ttotal: 1m 13s\tremaining: 1m 17s\n",
      "341:\tlearn: 0.9076317\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "342:\tlearn: 0.9075696\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "343:\tlearn: 0.9075696\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "344:\tlearn: 0.9075696\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "345:\tlearn: 0.9078615\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "346:\tlearn: 0.9076227\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "347:\tlearn: 0.9078083\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "348:\tlearn: 0.9079940\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "349:\tlearn: 0.9080208\ttotal: 1m 15s\tremaining: 1m 15s\n",
      "350:\tlearn: 0.9080035\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "351:\tlearn: 0.9081891\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "352:\tlearn: 0.9083216\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "353:\tlearn: 0.9086134\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "354:\tlearn: 0.9084630\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "355:\tlearn: 0.9084630\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "356:\tlearn: 0.9083483\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "357:\tlearn: 0.9086312\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "358:\tlearn: 0.9085870\ttotal: 1m 17s\tremaining: 1m 13s\n",
      "359:\tlearn: 0.9088699\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "360:\tlearn: 0.9090202\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "361:\tlearn: 0.9092589\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "362:\tlearn: 0.9094800\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "363:\tlearn: 0.9093916\ttotal: 1m 18s\tremaining: 1m 12s\n",
      "364:\tlearn: 0.9093031\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "365:\tlearn: 0.9092235\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "366:\tlearn: 0.9092765\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "367:\tlearn: 0.9092059\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "368:\tlearn: 0.9095861\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "369:\tlearn: 0.9094446\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "370:\tlearn: 0.9097364\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "371:\tlearn: 0.9094180\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "372:\tlearn: 0.9095064\ttotal: 1m 20s\tremaining: 1m 10s\n",
      "373:\tlearn: 0.9096037\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "374:\tlearn: 0.9098245\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "375:\tlearn: 0.9100457\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "376:\tlearn: 0.9098600\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "377:\tlearn: 0.9100102\ttotal: 1m 21s\tremaining: 1m 9s\n",
      "378:\tlearn: 0.9104173\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "379:\tlearn: 0.9104703\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "380:\tlearn: 0.9104703\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "381:\tlearn: 0.9104173\ttotal: 1m 22s\tremaining: 1m 8s\n",
      "382:\tlearn: 0.9106205\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "383:\tlearn: 0.9103375\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "384:\tlearn: 0.9105849\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "385:\tlearn: 0.9107620\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "386:\tlearn: 0.9109296\ttotal: 1m 23s\tremaining: 1m 7s\n",
      "387:\tlearn: 0.9110182\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "388:\tlearn: 0.9113456\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "389:\tlearn: 0.9113456\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "390:\tlearn: 0.9115931\ttotal: 1m 24s\tremaining: 1m 6s\n",
      "391:\tlearn: 0.9117876\ttotal: 1m 24s\tremaining: 1m 6s\n",
      "392:\tlearn: 0.9117075\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "393:\tlearn: 0.9116989\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "394:\tlearn: 0.9120607\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "395:\tlearn: 0.9120692\ttotal: 1m 25s\tremaining: 1m 5s\n",
      "396:\tlearn: 0.9124155\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "397:\tlearn: 0.9124240\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "398:\tlearn: 0.9123268\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "399:\tlearn: 0.9126185\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "400:\tlearn: 0.9129272\ttotal: 1m 26s\tremaining: 1m 4s\n",
      "401:\tlearn: 0.9127243\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "402:\tlearn: 0.9127517\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "403:\tlearn: 0.9131576\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "404:\tlearn: 0.9132549\ttotal: 1m 27s\tremaining: 1m 3s\n",
      "405:\tlearn: 0.9133162\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "406:\tlearn: 0.9133690\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "407:\tlearn: 0.9131470\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "408:\tlearn: 0.9132633\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "409:\tlearn: 0.9134578\ttotal: 1m 28s\tremaining: 1m 2s\n",
      "410:\tlearn: 0.9132802\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "411:\tlearn: 0.9133330\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "412:\tlearn: 0.9133690\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "413:\tlearn: 0.9137663\ttotal: 1m 29s\tremaining: 1m 1s\n",
      "414:\tlearn: 0.9136439\ttotal: 1m 29s\tremaining: 1m 1s\n",
      "415:\tlearn: 0.9138384\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "416:\tlearn: 0.9139079\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "417:\tlearn: 0.9139884\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "418:\tlearn: 0.9142440\ttotal: 1m 30s\tremaining: 1m\n",
      "419:\tlearn: 0.9144663\ttotal: 1m 31s\tremaining: 1m\n",
      "420:\tlearn: 0.9144580\ttotal: 1m 31s\tremaining: 1m\n",
      "421:\tlearn: 0.9144219\ttotal: 1m 31s\tremaining: 1m\n",
      "422:\tlearn: 0.9146081\ttotal: 1m 31s\tremaining: 1m\n",
      "423:\tlearn: 0.9145470\ttotal: 1m 31s\tremaining: 59.8s\n",
      "424:\tlearn: 0.9147581\ttotal: 1m 32s\tremaining: 59.6s\n",
      "425:\tlearn: 0.9149609\ttotal: 1m 32s\tremaining: 59.4s\n",
      "426:\tlearn: 0.9151586\ttotal: 1m 32s\tremaining: 59.1s\n",
      "427:\tlearn: 0.9154916\ttotal: 1m 32s\tremaining: 58.9s\n",
      "428:\tlearn: 0.9154059\ttotal: 1m 32s\tremaining: 58.7s\n",
      "429:\tlearn: 0.9153943\ttotal: 1m 33s\tremaining: 58.5s\n",
      "430:\tlearn: 0.9153943\ttotal: 1m 33s\tremaining: 58.3s\n",
      "431:\tlearn: 0.9154834\ttotal: 1m 33s\tremaining: 58s\n",
      "432:\tlearn: 0.9155888\ttotal: 1m 33s\tremaining: 57.8s\n",
      "433:\tlearn: 0.9158888\ttotal: 1m 34s\tremaining: 57.6s\n",
      "434:\tlearn: 0.9156334\ttotal: 1m 34s\tremaining: 57.4s\n",
      "435:\tlearn: 0.9159333\ttotal: 1m 34s\tremaining: 57.2s\n",
      "436:\tlearn: 0.9157306\ttotal: 1m 34s\tremaining: 57s\n",
      "437:\tlearn: 0.9158724\ttotal: 1m 34s\tremaining: 56.8s\n",
      "438:\tlearn: 0.9160587\ttotal: 1m 35s\tremaining: 56.5s\n",
      "439:\tlearn: 0.9159333\ttotal: 1m 35s\tremaining: 56.3s\n",
      "440:\tlearn: 0.9161968\ttotal: 1m 35s\tremaining: 56.1s\n",
      "441:\tlearn: 0.9162696\ttotal: 1m 35s\tremaining: 55.9s\n",
      "442:\tlearn: 0.9160587\ttotal: 1m 35s\tremaining: 55.7s\n",
      "443:\tlearn: 0.9163060\ttotal: 1m 36s\tremaining: 55.5s\n",
      "444:\tlearn: 0.9164032\ttotal: 1m 36s\tremaining: 55.2s\n",
      "445:\tlearn: 0.9165005\ttotal: 1m 36s\tremaining: 55s\n",
      "446:\tlearn: 0.9165249\ttotal: 1m 36s\tremaining: 54.8s\n",
      "447:\tlearn: 0.9168247\ttotal: 1m 37s\tremaining: 54.6s\n",
      "448:\tlearn: 0.9169057\ttotal: 1m 37s\tremaining: 54.4s\n",
      "449:\tlearn: 0.9172055\ttotal: 1m 37s\tremaining: 54.1s\n",
      "450:\tlearn: 0.9172501\ttotal: 1m 37s\tremaining: 53.9s\n",
      "451:\tlearn: 0.9174972\ttotal: 1m 37s\tremaining: 53.7s\n",
      "452:\tlearn: 0.9178335\ttotal: 1m 38s\tremaining: 53.5s\n",
      "453:\tlearn: 0.9175784\ttotal: 1m 38s\tremaining: 53.3s\n",
      "454:\tlearn: 0.9176230\ttotal: 1m 38s\tremaining: 53.1s\n",
      "455:\tlearn: 0.9176310\ttotal: 1m 38s\tremaining: 52.9s\n",
      "456:\tlearn: 0.9180726\ttotal: 1m 38s\tremaining: 52.6s\n",
      "457:\tlearn: 0.9182225\ttotal: 1m 39s\tremaining: 52.4s\n",
      "458:\tlearn: 0.9184537\ttotal: 1m 39s\tremaining: 52.2s\n",
      "459:\tlearn: 0.9186640\ttotal: 1m 39s\tremaining: 52s\n",
      "460:\tlearn: 0.9183802\ttotal: 1m 39s\tremaining: 51.8s\n",
      "461:\tlearn: 0.9184328\ttotal: 1m 40s\tremaining: 51.6s\n",
      "462:\tlearn: 0.9183723\ttotal: 1m 40s\tremaining: 51.3s\n",
      "463:\tlearn: 0.9185589\ttotal: 1m 40s\tremaining: 51.1s\n",
      "464:\tlearn: 0.9187980\ttotal: 1m 40s\tremaining: 50.9s\n",
      "465:\tlearn: 0.9187166\ttotal: 1m 40s\tremaining: 50.7s\n",
      "466:\tlearn: 0.9189478\ttotal: 1m 41s\tremaining: 50.5s\n",
      "467:\tlearn: 0.9190529\ttotal: 1m 41s\tremaining: 50.3s\n",
      "468:\tlearn: 0.9189268\ttotal: 1m 41s\tremaining: 50.1s\n",
      "469:\tlearn: 0.9191659\ttotal: 1m 41s\tremaining: 49.8s\n",
      "470:\tlearn: 0.9192184\ttotal: 1m 42s\tremaining: 49.6s\n",
      "471:\tlearn: 0.9192631\ttotal: 1m 42s\tremaining: 49.4s\n",
      "472:\tlearn: 0.9190687\ttotal: 1m 42s\tremaining: 49.2s\n",
      "473:\tlearn: 0.9193446\ttotal: 1m 42s\tremaining: 49s\n",
      "474:\tlearn: 0.9193737\ttotal: 1m 42s\tremaining: 48.8s\n",
      "475:\tlearn: 0.9198152\ttotal: 1m 43s\tremaining: 48.5s\n",
      "476:\tlearn: 0.9197861\ttotal: 1m 43s\tremaining: 48.3s\n",
      "477:\tlearn: 0.9200408\ttotal: 1m 43s\tremaining: 48.1s\n",
      "478:\tlearn: 0.9199203\ttotal: 1m 43s\tremaining: 47.9s\n",
      "479:\tlearn: 0.9198755\ttotal: 1m 44s\tremaining: 47.7s\n",
      "480:\tlearn: 0.9198074\ttotal: 1m 44s\tremaining: 47.5s\n",
      "481:\tlearn: 0.9197627\ttotal: 1m 44s\tremaining: 47.3s\n",
      "482:\tlearn: 0.9199572\ttotal: 1m 44s\tremaining: 47s\n",
      "483:\tlearn: 0.9198599\ttotal: 1m 44s\tremaining: 46.8s\n",
      "484:\tlearn: 0.9199047\ttotal: 1m 45s\tremaining: 46.6s\n",
      "485:\tlearn: 0.9200331\ttotal: 1m 45s\tremaining: 46.4s\n",
      "486:\tlearn: 0.9200331\ttotal: 1m 45s\tremaining: 46.2s\n",
      "487:\tlearn: 0.9199572\ttotal: 1m 45s\tremaining: 46s\n",
      "488:\tlearn: 0.9198833\ttotal: 1m 46s\tremaining: 45.7s\n",
      "489:\tlearn: 0.9199203\ttotal: 1m 46s\tremaining: 45.5s\n",
      "490:\tlearn: 0.9200778\ttotal: 1m 46s\tremaining: 45.3s\n",
      "491:\tlearn: 0.9202645\ttotal: 1m 46s\tremaining: 45.1s\n",
      "492:\tlearn: 0.9202120\ttotal: 1m 46s\tremaining: 44.9s\n",
      "493:\tlearn: 0.9202722\ttotal: 1m 47s\tremaining: 44.7s\n",
      "494:\tlearn: 0.9200933\ttotal: 1m 47s\tremaining: 44.5s\n",
      "495:\tlearn: 0.9204822\ttotal: 1m 47s\tremaining: 44.2s\n",
      "496:\tlearn: 0.9205269\ttotal: 1m 47s\tremaining: 44s\n",
      "497:\tlearn: 0.9205717\ttotal: 1m 47s\tremaining: 43.8s\n",
      "498:\tlearn: 0.9208479\ttotal: 1m 48s\tremaining: 43.6s\n",
      "499:\tlearn: 0.9210424\ttotal: 1m 48s\tremaining: 43.4s\n",
      "500:\tlearn: 0.9212369\ttotal: 1m 48s\tremaining: 43.2s\n",
      "501:\tlearn: 0.9211997\ttotal: 1m 48s\tremaining: 42.9s\n",
      "502:\tlearn: 0.9212074\ttotal: 1m 49s\tremaining: 42.7s\n",
      "503:\tlearn: 0.9214018\ttotal: 1m 49s\tremaining: 42.5s\n",
      "504:\tlearn: 0.9214466\ttotal: 1m 49s\tremaining: 42.3s\n",
      "505:\tlearn: 0.9214914\ttotal: 1m 49s\tremaining: 42.1s\n",
      "506:\tlearn: 0.9215438\ttotal: 1m 49s\tremaining: 41.8s\n",
      "507:\tlearn: 0.9218355\ttotal: 1m 50s\tremaining: 41.6s\n",
      "508:\tlearn: 0.9216411\ttotal: 1m 50s\tremaining: 41.4s\n",
      "509:\tlearn: 0.9216258\ttotal: 1m 50s\tremaining: 41.2s\n",
      "510:\tlearn: 0.9217679\ttotal: 1m 50s\tremaining: 41s\n",
      "511:\tlearn: 0.9217383\ttotal: 1m 51s\tremaining: 40.8s\n",
      "512:\tlearn: 0.9218279\ttotal: 1m 51s\tremaining: 40.5s\n",
      "513:\tlearn: 0.9222319\ttotal: 1m 51s\tremaining: 40.3s\n",
      "514:\tlearn: 0.9221871\ttotal: 1m 51s\tremaining: 40.1s\n",
      "515:\tlearn: 0.9221272\ttotal: 1m 51s\tremaining: 39.9s\n",
      "516:\tlearn: 0.9222768\ttotal: 1m 52s\tremaining: 39.7s\n",
      "517:\tlearn: 0.9226133\ttotal: 1m 52s\tremaining: 39.5s\n",
      "518:\tlearn: 0.9229049\ttotal: 1m 52s\tremaining: 39.2s\n",
      "519:\tlearn: 0.9228974\ttotal: 1m 52s\tremaining: 39s\n",
      "520:\tlearn: 0.9231816\ttotal: 1m 52s\tremaining: 38.8s\n",
      "521:\tlearn: 0.9230545\ttotal: 1m 53s\tremaining: 38.6s\n",
      "522:\tlearn: 0.9233610\ttotal: 1m 53s\tremaining: 38.4s\n",
      "523:\tlearn: 0.9233387\ttotal: 1m 53s\tremaining: 38.2s\n",
      "524:\tlearn: 0.9232938\ttotal: 1m 53s\tremaining: 37.9s\n",
      "525:\tlearn: 0.9231891\ttotal: 1m 54s\tremaining: 37.7s\n",
      "526:\tlearn: 0.9232789\ttotal: 1m 54s\tremaining: 37.5s\n",
      "527:\tlearn: 0.9231293\ttotal: 1m 54s\tremaining: 37.3s\n",
      "528:\tlearn: 0.9232340\ttotal: 1m 54s\tremaining: 37.1s\n",
      "529:\tlearn: 0.9233836\ttotal: 1m 54s\tremaining: 36.9s\n",
      "530:\tlearn: 0.9232789\ttotal: 1m 55s\tremaining: 36.6s\n",
      "531:\tlearn: 0.9233761\ttotal: 1m 55s\tremaining: 36.4s\n",
      "532:\tlearn: 0.9234210\ttotal: 1m 55s\tremaining: 36.2s\n",
      "533:\tlearn: 0.9232789\ttotal: 1m 55s\tremaining: 36s\n",
      "534:\tlearn: 0.9230919\ttotal: 1m 55s\tremaining: 35.8s\n",
      "535:\tlearn: 0.9231891\ttotal: 1m 56s\tremaining: 35.6s\n",
      "536:\tlearn: 0.9232938\ttotal: 1m 56s\tremaining: 35.3s\n",
      "537:\tlearn: 0.9236155\ttotal: 1m 56s\tremaining: 35.1s\n",
      "538:\tlearn: 0.9235257\ttotal: 1m 56s\tremaining: 34.9s\n",
      "539:\tlearn: 0.9236604\ttotal: 1m 57s\tremaining: 34.7s\n",
      "540:\tlearn: 0.9235257\ttotal: 1m 57s\tremaining: 34.5s\n",
      "541:\tlearn: 0.9238697\ttotal: 1m 57s\tremaining: 34.3s\n",
      "542:\tlearn: 0.9239294\ttotal: 1m 57s\tremaining: 34s\n",
      "543:\tlearn: 0.9237276\ttotal: 1m 57s\tremaining: 33.8s\n",
      "544:\tlearn: 0.9239669\ttotal: 1m 58s\tremaining: 33.6s\n",
      "545:\tlearn: 0.9239743\ttotal: 1m 58s\tremaining: 33.4s\n",
      "546:\tlearn: 0.9239220\ttotal: 1m 58s\tremaining: 33.2s\n",
      "547:\tlearn: 0.9244302\ttotal: 1m 58s\tremaining: 33s\n",
      "548:\tlearn: 0.9245879\ttotal: 1m 59s\tremaining: 32.7s\n",
      "549:\tlearn: 0.9244310\ttotal: 1m 59s\tremaining: 32.5s\n",
      "550:\tlearn: 0.9247448\ttotal: 1m 59s\tremaining: 32.3s\n",
      "551:\tlearn: 0.9248420\ttotal: 1m 59s\tremaining: 32.1s\n",
      "552:\tlearn: 0.9248493\ttotal: 1m 59s\tremaining: 31.9s\n",
      "553:\tlearn: 0.9249538\ttotal: 2m\tremaining: 31.7s\n",
      "554:\tlearn: 0.9251033\ttotal: 2m\tremaining: 31.4s\n",
      "555:\tlearn: 0.9252382\ttotal: 2m\tremaining: 31.2s\n",
      "556:\tlearn: 0.9252686\ttotal: 2m\tremaining: 31s\n",
      "557:\tlearn: 0.9255604\ttotal: 2m\tremaining: 30.8s\n",
      "558:\tlearn: 0.9257098\ttotal: 2m 1s\tremaining: 30.6s\n",
      "559:\tlearn: 0.9259043\ttotal: 2m 1s\tremaining: 30.4s\n",
      "560:\tlearn: 0.9261132\ttotal: 2m 1s\tremaining: 30.1s\n",
      "561:\tlearn: 0.9261582\ttotal: 2m 1s\tremaining: 29.9s\n",
      "562:\tlearn: 0.9264499\ttotal: 2m 2s\tremaining: 29.7s\n",
      "563:\tlearn: 0.9265092\ttotal: 2m 2s\tremaining: 29.5s\n",
      "564:\tlearn: 0.9265399\ttotal: 2m 2s\tremaining: 29.3s\n",
      "565:\tlearn: 0.9265471\ttotal: 2m 2s\tremaining: 29.1s\n",
      "566:\tlearn: 0.9265542\ttotal: 2m 2s\tremaining: 28.8s\n",
      "567:\tlearn: 0.9266514\ttotal: 2m 3s\tremaining: 28.6s\n",
      "568:\tlearn: 0.9268150\ttotal: 2m 3s\tremaining: 28.4s\n",
      "569:\tlearn: 0.9267558\ttotal: 2m 3s\tremaining: 28.2s\n",
      "570:\tlearn: 0.9271066\ttotal: 2m 3s\tremaining: 28s\n",
      "571:\tlearn: 0.9272418\ttotal: 2m 4s\tremaining: 27.8s\n",
      "572:\tlearn: 0.9273841\ttotal: 2m 4s\tremaining: 27.5s\n",
      "573:\tlearn: 0.9273770\ttotal: 2m 4s\tremaining: 27.3s\n",
      "574:\tlearn: 0.9272869\ttotal: 2m 4s\tremaining: 27.1s\n",
      "575:\tlearn: 0.9272869\ttotal: 2m 4s\tremaining: 26.9s\n",
      "576:\tlearn: 0.9277138\ttotal: 2m 5s\tremaining: 26.7s\n",
      "577:\tlearn: 0.9276898\ttotal: 2m 5s\tremaining: 26.5s\n",
      "578:\tlearn: 0.9276447\ttotal: 2m 5s\tremaining: 26.3s\n",
      "579:\tlearn: 0.9276898\ttotal: 2m 5s\tremaining: 26s\n",
      "580:\tlearn: 0.9280054\ttotal: 2m 6s\tremaining: 25.8s\n",
      "581:\tlearn: 0.9279463\ttotal: 2m 6s\tremaining: 25.6s\n",
      "582:\tlearn: 0.9279012\ttotal: 2m 6s\tremaining: 25.4s\n",
      "583:\tlearn: 0.9278561\ttotal: 2m 6s\tremaining: 25.2s\n",
      "584:\tlearn: 0.9278561\ttotal: 2m 6s\tremaining: 25s\n",
      "585:\tlearn: 0.9279533\ttotal: 2m 7s\tremaining: 24.7s\n",
      "586:\tlearn: 0.9280506\ttotal: 2m 7s\tremaining: 24.5s\n",
      "587:\tlearn: 0.9280645\ttotal: 2m 7s\tremaining: 24.3s\n",
      "588:\tlearn: 0.9281548\ttotal: 2m 7s\tremaining: 24.1s\n",
      "589:\tlearn: 0.9282901\ttotal: 2m 8s\tremaining: 23.9s\n",
      "590:\tlearn: 0.9282901\ttotal: 2m 8s\tremaining: 23.7s\n",
      "591:\tlearn: 0.9284603\ttotal: 2m 8s\tremaining: 23.4s\n",
      "592:\tlearn: 0.9287519\ttotal: 2m 8s\tremaining: 23.2s\n",
      "593:\tlearn: 0.9284603\ttotal: 2m 8s\tremaining: 23s\n",
      "594:\tlearn: 0.9287068\ttotal: 2m 9s\tremaining: 22.8s\n",
      "595:\tlearn: 0.9288040\ttotal: 2m 9s\tremaining: 22.6s\n",
      "596:\tlearn: 0.9288630\ttotal: 2m 9s\tremaining: 22.4s\n",
      "597:\tlearn: 0.9289219\ttotal: 2m 9s\tremaining: 22.1s\n",
      "598:\tlearn: 0.9292134\ttotal: 2m 10s\tremaining: 21.9s\n",
      "599:\tlearn: 0.9291614\ttotal: 2m 10s\tremaining: 21.7s\n",
      "600:\tlearn: 0.9292723\ttotal: 2m 10s\tremaining: 21.5s\n",
      "601:\tlearn: 0.9295364\ttotal: 2m 10s\tremaining: 21.3s\n",
      "602:\tlearn: 0.9296651\ttotal: 2m 10s\tremaining: 21.1s\n",
      "603:\tlearn: 0.9295227\ttotal: 2m 11s\tremaining: 20.9s\n",
      "604:\tlearn: 0.9297760\ttotal: 2m 11s\tremaining: 20.6s\n",
      "605:\tlearn: 0.9297308\ttotal: 2m 11s\tremaining: 20.4s\n",
      "606:\tlearn: 0.9297444\ttotal: 2m 11s\tremaining: 20.2s\n",
      "607:\tlearn: 0.9295775\ttotal: 2m 12s\tremaining: 20s\n",
      "608:\tlearn: 0.9295323\ttotal: 2m 12s\tremaining: 19.8s\n",
      "609:\tlearn: 0.9299072\ttotal: 2m 12s\tremaining: 19.6s\n",
      "610:\tlearn: 0.9297061\ttotal: 2m 12s\tremaining: 19.3s\n",
      "611:\tlearn: 0.9298484\ttotal: 2m 12s\tremaining: 19.1s\n",
      "612:\tlearn: 0.9298936\ttotal: 2m 13s\tremaining: 18.9s\n",
      "613:\tlearn: 0.9303659\ttotal: 2m 13s\tremaining: 18.7s\n",
      "614:\tlearn: 0.9304382\ttotal: 2m 13s\tremaining: 18.5s\n",
      "615:\tlearn: 0.9304834\ttotal: 2m 13s\tremaining: 18.3s\n",
      "616:\tlearn: 0.9305873\ttotal: 2m 14s\tremaining: 18s\n",
      "617:\tlearn: 0.9308066\ttotal: 2m 14s\tremaining: 17.8s\n",
      "618:\tlearn: 0.9308854\ttotal: 2m 14s\tremaining: 17.6s\n",
      "619:\tlearn: 0.9308335\ttotal: 2m 14s\tremaining: 17.4s\n",
      "620:\tlearn: 0.9310144\ttotal: 2m 14s\tremaining: 17.2s\n",
      "621:\tlearn: 0.9310982\ttotal: 2m 15s\tremaining: 17s\n",
      "622:\tlearn: 0.9312087\ttotal: 2m 15s\tremaining: 16.7s\n",
      "623:\tlearn: 0.9310864\ttotal: 2m 15s\tremaining: 16.5s\n",
      "624:\tlearn: 0.9311635\ttotal: 2m 15s\tremaining: 16.3s\n",
      "625:\tlearn: 0.9311568\ttotal: 2m 16s\tremaining: 16.1s\n",
      "626:\tlearn: 0.9312606\ttotal: 2m 16s\tremaining: 15.9s\n",
      "627:\tlearn: 0.9312288\ttotal: 2m 16s\tremaining: 15.7s\n",
      "628:\tlearn: 0.9312221\ttotal: 2m 16s\tremaining: 15.4s\n",
      "629:\tlearn: 0.9312740\ttotal: 2m 16s\tremaining: 15.2s\n",
      "630:\tlearn: 0.9313778\ttotal: 2m 17s\tremaining: 15s\n",
      "631:\tlearn: 0.9315135\ttotal: 2m 17s\tremaining: 14.8s\n",
      "632:\tlearn: 0.9316945\ttotal: 2m 17s\tremaining: 14.6s\n",
      "633:\tlearn: 0.9318370\ttotal: 2m 17s\tremaining: 14.3s\n",
      "634:\tlearn: 0.9319794\ttotal: 2m 18s\tremaining: 14.1s\n",
      "635:\tlearn: 0.9317851\ttotal: 2m 18s\tremaining: 13.9s\n",
      "636:\tlearn: 0.9316493\ttotal: 2m 18s\tremaining: 13.7s\n",
      "637:\tlearn: 0.9318568\ttotal: 2m 18s\tremaining: 13.5s\n",
      "638:\tlearn: 0.9319087\ttotal: 2m 18s\tremaining: 13.3s\n",
      "639:\tlearn: 0.9320058\ttotal: 2m 19s\tremaining: 13s\n",
      "640:\tlearn: 0.9320898\ttotal: 2m 19s\tremaining: 12.8s\n",
      "641:\tlearn: 0.9321416\ttotal: 2m 19s\tremaining: 12.6s\n",
      "642:\tlearn: 0.9322322\ttotal: 2m 19s\tremaining: 12.4s\n",
      "643:\tlearn: 0.9323878\ttotal: 2m 19s\tremaining: 12.2s\n",
      "644:\tlearn: 0.9322322\ttotal: 2m 20s\tremaining: 12s\n",
      "645:\tlearn: 0.9323425\ttotal: 2m 20s\tremaining: 11.7s\n",
      "646:\tlearn: 0.9324915\ttotal: 2m 20s\tremaining: 11.5s\n",
      "647:\tlearn: 0.9326208\ttotal: 2m 20s\tremaining: 11.3s\n",
      "648:\tlearn: 0.9326661\ttotal: 2m 21s\tremaining: 11.1s\n",
      "649:\tlearn: 0.9328605\ttotal: 2m 21s\tremaining: 10.9s\n",
      "650:\tlearn: 0.9328152\ttotal: 2m 21s\tremaining: 10.6s\n",
      "651:\tlearn: 0.9328993\ttotal: 2m 21s\tremaining: 10.4s\n",
      "652:\tlearn: 0.9330095\ttotal: 2m 21s\tremaining: 10.2s\n",
      "653:\tlearn: 0.9329899\ttotal: 2m 22s\tremaining: 10s\n",
      "654:\tlearn: 0.9330806\ttotal: 2m 22s\tremaining: 9.78s\n",
      "655:\tlearn: 0.9330418\ttotal: 2m 22s\tremaining: 9.56s\n",
      "656:\tlearn: 0.9331325\ttotal: 2m 22s\tremaining: 9.34s\n",
      "657:\tlearn: 0.9332880\ttotal: 2m 22s\tremaining: 9.13s\n",
      "658:\tlearn: 0.9335148\ttotal: 2m 23s\tremaining: 8.91s\n",
      "659:\tlearn: 0.9334565\ttotal: 2m 23s\tremaining: 8.69s\n",
      "660:\tlearn: 0.9332620\ttotal: 2m 23s\tremaining: 8.47s\n",
      "661:\tlearn: 0.9332556\ttotal: 2m 23s\tremaining: 8.26s\n",
      "662:\tlearn: 0.9334111\ttotal: 2m 24s\tremaining: 8.04s\n",
      "663:\tlearn: 0.9335018\ttotal: 2m 24s\tremaining: 7.82s\n",
      "664:\tlearn: 0.9336509\ttotal: 2m 24s\tremaining: 7.61s\n",
      "665:\tlearn: 0.9336055\ttotal: 2m 24s\tremaining: 7.39s\n",
      "666:\tlearn: 0.9335537\ttotal: 2m 24s\tremaining: 7.17s\n",
      "667:\tlearn: 0.9335472\ttotal: 2m 25s\tremaining: 6.95s\n",
      "668:\tlearn: 0.9338196\ttotal: 2m 25s\tremaining: 6.74s\n",
      "669:\tlearn: 0.9339168\ttotal: 2m 25s\tremaining: 6.52s\n",
      "670:\tlearn: 0.9339233\ttotal: 2m 25s\tremaining: 6.3s\n",
      "671:\tlearn: 0.9340205\ttotal: 2m 26s\tremaining: 6.08s\n",
      "672:\tlearn: 0.9339687\ttotal: 2m 26s\tremaining: 5.87s\n",
      "673:\tlearn: 0.9339751\ttotal: 2m 26s\tremaining: 5.65s\n",
      "674:\tlearn: 0.9340269\ttotal: 2m 26s\tremaining: 5.43s\n",
      "675:\tlearn: 0.9340141\ttotal: 2m 26s\tremaining: 5.21s\n",
      "676:\tlearn: 0.9341178\ttotal: 2m 27s\tremaining: 5s\n",
      "677:\tlearn: 0.9342150\ttotal: 2m 27s\tremaining: 4.78s\n",
      "678:\tlearn: 0.9341568\ttotal: 2m 27s\tremaining: 4.56s\n",
      "679:\tlearn: 0.9343122\ttotal: 2m 27s\tremaining: 4.34s\n",
      "680:\tlearn: 0.9342796\ttotal: 2m 27s\tremaining: 4.13s\n",
      "681:\tlearn: 0.9342406\ttotal: 2m 28s\tremaining: 3.91s\n",
      "682:\tlearn: 0.9344159\ttotal: 2m 28s\tremaining: 3.69s\n",
      "683:\tlearn: 0.9342342\ttotal: 2m 28s\tremaining: 3.48s\n",
      "684:\tlearn: 0.9341370\ttotal: 2m 28s\tremaining: 3.26s\n",
      "685:\tlearn: 0.9342278\ttotal: 2m 29s\tremaining: 3.04s\n",
      "686:\tlearn: 0.9344222\ttotal: 2m 29s\tremaining: 2.82s\n",
      "687:\tlearn: 0.9342732\ttotal: 2m 29s\tremaining: 2.61s\n",
      "688:\tlearn: 0.9345067\ttotal: 2m 29s\tremaining: 2.39s\n",
      "689:\tlearn: 0.9345522\ttotal: 2m 29s\tremaining: 2.17s\n",
      "690:\tlearn: 0.9345522\ttotal: 2m 30s\tremaining: 1.96s\n",
      "691:\tlearn: 0.9346494\ttotal: 2m 30s\tremaining: 1.74s\n",
      "692:\tlearn: 0.9347012\ttotal: 2m 30s\tremaining: 1.52s\n",
      "693:\tlearn: 0.9350384\ttotal: 2m 30s\tremaining: 1.3s\n",
      "694:\tlearn: 0.9351294\ttotal: 2m 31s\tremaining: 1.09s\n",
      "695:\tlearn: 0.9351167\ttotal: 2m 31s\tremaining: 869ms\n",
      "696:\tlearn: 0.9350713\ttotal: 2m 31s\tremaining: 652ms\n",
      "697:\tlearn: 0.9350258\ttotal: 2m 31s\tremaining: 435ms\n",
      "698:\tlearn: 0.9349803\ttotal: 2m 31s\tremaining: 217ms\n",
      "699:\tlearn: 0.9353239\ttotal: 2m 32s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=8, eval_metric=F1, iterations=700, l2_leaf_reg=3, leaf_estimation_method=Newton, learning_rate=0.01, random_strength=1; total time= 2.5min\n",
      "0:\tlearn: 0.6754248\ttotal: 231ms\tremaining: 2m 41s\n",
      "1:\tlearn: 0.7141613\ttotal: 448ms\tremaining: 2m 36s\n",
      "2:\tlearn: 0.7308313\ttotal: 667ms\tremaining: 2m 34s\n",
      "3:\tlearn: 0.7407516\ttotal: 885ms\tremaining: 2m 33s\n",
      "4:\tlearn: 0.7582610\ttotal: 1.1s\tremaining: 2m 32s\n",
      "5:\tlearn: 0.7661550\ttotal: 1.32s\tremaining: 2m 32s\n",
      "6:\tlearn: 0.7710125\ttotal: 1.54s\tremaining: 2m 32s\n",
      "7:\tlearn: 0.7758201\ttotal: 1.76s\tremaining: 2m 32s\n",
      "8:\tlearn: 0.7767507\ttotal: 1.98s\tremaining: 2m 31s\n",
      "9:\tlearn: 0.7771802\ttotal: 2.2s\tremaining: 2m 32s\n",
      "10:\tlearn: 0.7861311\ttotal: 2.43s\tremaining: 2m 31s\n",
      "11:\tlearn: 0.7887650\ttotal: 2.64s\tremaining: 2m 31s\n",
      "12:\tlearn: 0.7929737\ttotal: 2.86s\tremaining: 2m 31s\n",
      "13:\tlearn: 0.7943509\ttotal: 3.07s\tremaining: 2m 30s\n",
      "14:\tlearn: 0.7911898\ttotal: 3.29s\tremaining: 2m 30s\n",
      "15:\tlearn: 0.7910255\ttotal: 3.5s\tremaining: 2m 29s\n",
      "16:\tlearn: 0.7932494\ttotal: 3.72s\tremaining: 2m 29s\n",
      "17:\tlearn: 0.7930605\ttotal: 3.94s\tremaining: 2m 29s\n",
      "18:\tlearn: 0.7931957\ttotal: 4.15s\tremaining: 2m 28s\n",
      "19:\tlearn: 0.7914541\ttotal: 4.37s\tremaining: 2m 28s\n",
      "20:\tlearn: 0.7926794\ttotal: 4.59s\tremaining: 2m 28s\n",
      "21:\tlearn: 0.7928323\ttotal: 4.81s\tremaining: 2m 28s\n",
      "22:\tlearn: 0.7992137\ttotal: 5.04s\tremaining: 2m 28s\n",
      "23:\tlearn: 0.8038328\ttotal: 5.26s\tremaining: 2m 28s\n",
      "24:\tlearn: 0.8050120\ttotal: 5.48s\tremaining: 2m 27s\n",
      "25:\tlearn: 0.8051610\ttotal: 5.7s\tremaining: 2m 27s\n",
      "26:\tlearn: 0.8087823\ttotal: 5.92s\tremaining: 2m 27s\n",
      "27:\tlearn: 0.8075530\ttotal: 6.13s\tremaining: 2m 27s\n",
      "28:\tlearn: 0.8109491\ttotal: 6.35s\tremaining: 2m 26s\n",
      "29:\tlearn: 0.8127690\ttotal: 6.57s\tremaining: 2m 26s\n",
      "30:\tlearn: 0.8165721\ttotal: 6.79s\tremaining: 2m 26s\n",
      "31:\tlearn: 0.8181333\ttotal: 7.01s\tremaining: 2m 26s\n",
      "32:\tlearn: 0.8171157\ttotal: 7.22s\tremaining: 2m 26s\n",
      "33:\tlearn: 0.8173770\ttotal: 7.44s\tremaining: 2m 25s\n",
      "34:\tlearn: 0.8205749\ttotal: 7.65s\tremaining: 2m 25s\n",
      "35:\tlearn: 0.8217836\ttotal: 7.87s\tremaining: 2m 25s\n",
      "36:\tlearn: 0.8231645\ttotal: 8.09s\tremaining: 2m 24s\n",
      "37:\tlearn: 0.8232955\ttotal: 8.31s\tremaining: 2m 24s\n",
      "38:\tlearn: 0.8249333\ttotal: 8.53s\tremaining: 2m 24s\n",
      "39:\tlearn: 0.8276700\ttotal: 8.75s\tremaining: 2m 24s\n",
      "40:\tlearn: 0.8287105\ttotal: 8.96s\tremaining: 2m 24s\n",
      "41:\tlearn: 0.8291782\ttotal: 9.18s\tremaining: 2m 23s\n",
      "42:\tlearn: 0.8303741\ttotal: 9.4s\tremaining: 2m 23s\n",
      "43:\tlearn: 0.8316225\ttotal: 9.62s\tremaining: 2m 23s\n",
      "44:\tlearn: 0.8331389\ttotal: 9.84s\tremaining: 2m 23s\n",
      "45:\tlearn: 0.8333171\ttotal: 10.1s\tremaining: 2m 23s\n",
      "46:\tlearn: 0.8346411\ttotal: 10.3s\tremaining: 2m 22s\n",
      "47:\tlearn: 0.8360464\ttotal: 10.5s\tremaining: 2m 22s\n",
      "48:\tlearn: 0.8375110\ttotal: 10.7s\tremaining: 2m 22s\n",
      "49:\tlearn: 0.8371730\ttotal: 10.9s\tremaining: 2m 22s\n",
      "50:\tlearn: 0.8374707\ttotal: 11.1s\tremaining: 2m 21s\n",
      "51:\tlearn: 0.8395991\ttotal: 11.4s\tremaining: 2m 21s\n",
      "52:\tlearn: 0.8399473\ttotal: 11.6s\tremaining: 2m 21s\n",
      "53:\tlearn: 0.8405543\ttotal: 11.8s\tremaining: 2m 21s\n",
      "54:\tlearn: 0.8420950\ttotal: 12s\tremaining: 2m 21s\n",
      "55:\tlearn: 0.8433735\ttotal: 12.2s\tremaining: 2m 20s\n",
      "56:\tlearn: 0.8434545\ttotal: 12.5s\tremaining: 2m 20s\n",
      "57:\tlearn: 0.8425619\ttotal: 12.7s\tremaining: 2m 20s\n",
      "58:\tlearn: 0.8442866\ttotal: 12.9s\tremaining: 2m 19s\n",
      "59:\tlearn: 0.8445072\ttotal: 13.1s\tremaining: 2m 19s\n",
      "60:\tlearn: 0.8446909\ttotal: 13.3s\tremaining: 2m 19s\n",
      "61:\tlearn: 0.8451924\ttotal: 13.5s\tremaining: 2m 19s\n",
      "62:\tlearn: 0.8463858\ttotal: 13.8s\tremaining: 2m 19s\n",
      "63:\tlearn: 0.8479213\ttotal: 14s\tremaining: 2m 18s\n",
      "64:\tlearn: 0.8475384\ttotal: 14.2s\tremaining: 2m 18s\n",
      "65:\tlearn: 0.8489097\ttotal: 14.4s\tremaining: 2m 18s\n",
      "66:\tlearn: 0.8486352\ttotal: 14.6s\tremaining: 2m 18s\n",
      "67:\tlearn: 0.8488157\ttotal: 14.9s\tremaining: 2m 18s\n",
      "68:\tlearn: 0.8491320\ttotal: 15.1s\tremaining: 2m 18s\n",
      "69:\tlearn: 0.8492884\ttotal: 15.3s\tremaining: 2m 17s\n",
      "70:\tlearn: 0.8496394\ttotal: 15.5s\tremaining: 2m 17s\n",
      "71:\tlearn: 0.8493671\ttotal: 15.8s\tremaining: 2m 17s\n",
      "72:\tlearn: 0.8528023\ttotal: 16s\tremaining: 2m 17s\n",
      "73:\tlearn: 0.8523712\ttotal: 16.2s\tremaining: 2m 16s\n",
      "74:\tlearn: 0.8525931\ttotal: 16.4s\tremaining: 2m 16s\n",
      "75:\tlearn: 0.8523330\ttotal: 16.6s\tremaining: 2m 16s\n",
      "76:\tlearn: 0.8532257\ttotal: 16.9s\tremaining: 2m 16s\n",
      "77:\tlearn: 0.8536301\ttotal: 17.1s\tremaining: 2m 16s\n",
      "78:\tlearn: 0.8529355\ttotal: 17.3s\tremaining: 2m 15s\n",
      "79:\tlearn: 0.8529755\ttotal: 17.5s\tremaining: 2m 15s\n",
      "80:\tlearn: 0.8527682\ttotal: 17.7s\tremaining: 2m 15s\n",
      "81:\tlearn: 0.8536159\ttotal: 18s\tremaining: 2m 15s\n",
      "82:\tlearn: 0.8533942\ttotal: 18.2s\tremaining: 2m 15s\n",
      "83:\tlearn: 0.8539249\ttotal: 18.4s\tremaining: 2m 15s\n",
      "84:\tlearn: 0.8541444\ttotal: 18.6s\tremaining: 2m 14s\n",
      "85:\tlearn: 0.8541565\ttotal: 18.9s\tremaining: 2m 14s\n",
      "86:\tlearn: 0.8551704\ttotal: 19.1s\tremaining: 2m 14s\n",
      "87:\tlearn: 0.8554205\ttotal: 19.3s\tremaining: 2m 14s\n",
      "88:\tlearn: 0.8563651\ttotal: 19.5s\tremaining: 2m 13s\n",
      "89:\tlearn: 0.8558519\ttotal: 19.7s\tremaining: 2m 13s\n",
      "90:\tlearn: 0.8569487\ttotal: 19.9s\tremaining: 2m 13s\n",
      "91:\tlearn: 0.8572538\ttotal: 20.1s\tremaining: 2m 13s\n",
      "92:\tlearn: 0.8576561\ttotal: 20.4s\tremaining: 2m 12s\n",
      "93:\tlearn: 0.8581966\ttotal: 20.6s\tremaining: 2m 12s\n",
      "94:\tlearn: 0.8588481\ttotal: 20.8s\tremaining: 2m 12s\n",
      "95:\tlearn: 0.8584466\ttotal: 21s\tremaining: 2m 12s\n",
      "96:\tlearn: 0.8597351\ttotal: 21.3s\tremaining: 2m 12s\n",
      "97:\tlearn: 0.8607091\ttotal: 21.5s\tremaining: 2m 11s\n",
      "98:\tlearn: 0.8611394\ttotal: 21.7s\tremaining: 2m 11s\n",
      "99:\tlearn: 0.8606414\ttotal: 21.9s\tremaining: 2m 11s\n",
      "100:\tlearn: 0.8609317\ttotal: 22.1s\tremaining: 2m 11s\n",
      "101:\tlearn: 0.8616655\ttotal: 22.3s\tremaining: 2m 10s\n",
      "102:\tlearn: 0.8621242\ttotal: 22.6s\tremaining: 2m 10s\n",
      "103:\tlearn: 0.8625735\ttotal: 22.8s\tremaining: 2m 10s\n",
      "104:\tlearn: 0.8627375\ttotal: 23s\tremaining: 2m 10s\n",
      "105:\tlearn: 0.8631507\ttotal: 23.2s\tremaining: 2m 10s\n",
      "106:\tlearn: 0.8641508\ttotal: 23.4s\tremaining: 2m 9s\n",
      "107:\tlearn: 0.8638283\ttotal: 23.6s\tremaining: 2m 9s\n",
      "108:\tlearn: 0.8646416\ttotal: 23.9s\tremaining: 2m 9s\n",
      "109:\tlearn: 0.8653014\ttotal: 24.1s\tremaining: 2m 9s\n",
      "110:\tlearn: 0.8659894\ttotal: 24.3s\tremaining: 2m 8s\n",
      "111:\tlearn: 0.8669098\ttotal: 24.5s\tremaining: 2m 8s\n",
      "112:\tlearn: 0.8670948\ttotal: 24.7s\tremaining: 2m 8s\n",
      "113:\tlearn: 0.8671723\ttotal: 24.9s\tremaining: 2m 8s\n",
      "114:\tlearn: 0.8675484\ttotal: 25.2s\tremaining: 2m 7s\n",
      "115:\tlearn: 0.8674898\ttotal: 25.4s\tremaining: 2m 7s\n",
      "116:\tlearn: 0.8679594\ttotal: 25.6s\tremaining: 2m 7s\n",
      "117:\tlearn: 0.8688214\ttotal: 25.8s\tremaining: 2m 7s\n",
      "118:\tlearn: 0.8689146\ttotal: 26s\tremaining: 2m 7s\n",
      "119:\tlearn: 0.8692401\ttotal: 26.2s\tremaining: 2m 6s\n",
      "120:\tlearn: 0.8689615\ttotal: 26.4s\tremaining: 2m 6s\n",
      "121:\tlearn: 0.8693541\ttotal: 26.7s\tremaining: 2m 6s\n",
      "122:\tlearn: 0.8691938\ttotal: 26.9s\tremaining: 2m 6s\n",
      "123:\tlearn: 0.8701645\ttotal: 27.1s\tremaining: 2m 5s\n",
      "124:\tlearn: 0.8704432\ttotal: 27.3s\tremaining: 2m 5s\n",
      "125:\tlearn: 0.8703290\ttotal: 27.5s\tremaining: 2m 5s\n",
      "126:\tlearn: 0.8713717\ttotal: 27.7s\tremaining: 2m 5s\n",
      "127:\tlearn: 0.8717974\ttotal: 27.9s\tremaining: 2m 4s\n",
      "128:\tlearn: 0.8714362\ttotal: 28.2s\tremaining: 2m 4s\n",
      "129:\tlearn: 0.8712169\ttotal: 28.4s\tremaining: 2m 4s\n",
      "130:\tlearn: 0.8717401\ttotal: 28.6s\tremaining: 2m 4s\n",
      "131:\tlearn: 0.8723156\ttotal: 28.8s\tremaining: 2m 4s\n",
      "132:\tlearn: 0.8724695\ttotal: 29s\tremaining: 2m 3s\n",
      "133:\tlearn: 0.8724871\ttotal: 29.3s\tremaining: 2m 3s\n",
      "134:\tlearn: 0.8725366\ttotal: 29.5s\tremaining: 2m 3s\n",
      "135:\tlearn: 0.8729319\ttotal: 29.7s\tremaining: 2m 3s\n",
      "136:\tlearn: 0.8730605\ttotal: 29.9s\tremaining: 2m 2s\n",
      "137:\tlearn: 0.8738900\ttotal: 30.1s\tremaining: 2m 2s\n",
      "138:\tlearn: 0.8742294\ttotal: 30.4s\tremaining: 2m 2s\n",
      "139:\tlearn: 0.8750607\ttotal: 30.6s\tremaining: 2m 2s\n",
      "140:\tlearn: 0.8749151\ttotal: 30.8s\tremaining: 2m 2s\n",
      "141:\tlearn: 0.8756731\ttotal: 31s\tremaining: 2m 1s\n",
      "142:\tlearn: 0.8758493\ttotal: 31.3s\tremaining: 2m 1s\n",
      "143:\tlearn: 0.8759160\ttotal: 31.5s\tremaining: 2m 1s\n",
      "144:\tlearn: 0.8759825\ttotal: 31.7s\tremaining: 2m 1s\n",
      "145:\tlearn: 0.8770806\ttotal: 31.9s\tremaining: 2m 1s\n",
      "146:\tlearn: 0.8774381\ttotal: 32.1s\tremaining: 2m\n",
      "147:\tlearn: 0.8776085\ttotal: 32.3s\tremaining: 2m\n",
      "148:\tlearn: 0.8775164\ttotal: 32.6s\tremaining: 2m\n",
      "149:\tlearn: 0.8780393\ttotal: 32.8s\tremaining: 2m\n",
      "150:\tlearn: 0.8782263\ttotal: 33s\tremaining: 1m 59s\n",
      "151:\tlearn: 0.8781837\ttotal: 33.2s\tremaining: 1m 59s\n",
      "152:\tlearn: 0.8786217\ttotal: 33.4s\tremaining: 1m 59s\n",
      "153:\tlearn: 0.8782761\ttotal: 33.6s\tremaining: 1m 59s\n",
      "154:\tlearn: 0.8786643\ttotal: 33.9s\tremaining: 1m 59s\n",
      "155:\tlearn: 0.8785128\ttotal: 34.1s\tremaining: 1m 58s\n",
      "156:\tlearn: 0.8787614\ttotal: 34.3s\tremaining: 1m 58s\n",
      "157:\tlearn: 0.8794877\ttotal: 34.5s\tremaining: 1m 58s\n",
      "158:\tlearn: 0.8798448\ttotal: 34.7s\tremaining: 1m 58s\n",
      "159:\tlearn: 0.8805782\ttotal: 34.9s\tremaining: 1m 57s\n",
      "160:\tlearn: 0.8806680\ttotal: 35.2s\tremaining: 1m 57s\n",
      "161:\tlearn: 0.8806253\ttotal: 35.4s\tremaining: 1m 57s\n",
      "162:\tlearn: 0.8807028\ttotal: 35.6s\tremaining: 1m 57s\n",
      "163:\tlearn: 0.8806832\ttotal: 35.8s\tremaining: 1m 56s\n",
      "164:\tlearn: 0.8813592\ttotal: 36s\tremaining: 1m 56s\n",
      "165:\tlearn: 0.8810367\ttotal: 36.2s\tremaining: 1m 56s\n",
      "166:\tlearn: 0.8807375\ttotal: 36.4s\tremaining: 1m 56s\n",
      "167:\tlearn: 0.8813510\ttotal: 36.7s\tremaining: 1m 56s\n",
      "168:\tlearn: 0.8812424\ttotal: 36.9s\tremaining: 1m 55s\n",
      "169:\tlearn: 0.8819647\ttotal: 37.1s\tremaining: 1m 55s\n",
      "170:\tlearn: 0.8824928\ttotal: 37.3s\tremaining: 1m 55s\n",
      "171:\tlearn: 0.8821245\ttotal: 37.5s\tremaining: 1m 55s\n",
      "172:\tlearn: 0.8823929\ttotal: 37.7s\tremaining: 1m 54s\n",
      "173:\tlearn: 0.8828330\ttotal: 37.9s\tremaining: 1m 54s\n",
      "174:\tlearn: 0.8832468\ttotal: 38.2s\tremaining: 1m 54s\n",
      "175:\tlearn: 0.8835493\ttotal: 38.4s\tremaining: 1m 54s\n",
      "176:\tlearn: 0.8832177\ttotal: 38.6s\tremaining: 1m 54s\n",
      "177:\tlearn: 0.8832039\ttotal: 38.8s\tremaining: 1m 53s\n",
      "178:\tlearn: 0.8828925\ttotal: 39s\tremaining: 1m 53s\n",
      "179:\tlearn: 0.8829126\ttotal: 39.2s\tremaining: 1m 53s\n",
      "180:\tlearn: 0.8829896\ttotal: 39.4s\tremaining: 1m 53s\n",
      "181:\tlearn: 0.8832064\ttotal: 39.6s\tremaining: 1m 52s\n",
      "182:\tlearn: 0.8837232\ttotal: 39.9s\tremaining: 1m 52s\n",
      "183:\tlearn: 0.8840256\ttotal: 40.1s\tremaining: 1m 52s\n",
      "184:\tlearn: 0.8841023\ttotal: 40.3s\tremaining: 1m 52s\n",
      "185:\tlearn: 0.8849120\ttotal: 40.5s\tremaining: 1m 51s\n",
      "186:\tlearn: 0.8848579\ttotal: 40.7s\tremaining: 1m 51s\n",
      "187:\tlearn: 0.8850630\ttotal: 40.9s\tremaining: 1m 51s\n",
      "188:\tlearn: 0.8853540\ttotal: 41.2s\tremaining: 1m 51s\n",
      "189:\tlearn: 0.8852030\ttotal: 41.4s\tremaining: 1m 51s\n",
      "190:\tlearn: 0.8851060\ttotal: 41.6s\tremaining: 1m 50s\n",
      "191:\tlearn: 0.8849437\ttotal: 41.8s\tremaining: 1m 50s\n",
      "192:\tlearn: 0.8852459\ttotal: 42s\tremaining: 1m 50s\n",
      "193:\tlearn: 0.8852682\ttotal: 42.2s\tremaining: 1m 50s\n",
      "194:\tlearn: 0.8852984\ttotal: 42.5s\tremaining: 1m 49s\n",
      "195:\tlearn: 0.8857628\ttotal: 42.7s\tremaining: 1m 49s\n",
      "196:\tlearn: 0.8858279\ttotal: 42.9s\tremaining: 1m 49s\n",
      "197:\tlearn: 0.8864540\ttotal: 43.1s\tremaining: 1m 49s\n",
      "198:\tlearn: 0.8863680\ttotal: 43.3s\tremaining: 1m 49s\n",
      "199:\tlearn: 0.8871546\ttotal: 43.5s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.8867989\ttotal: 43.7s\tremaining: 1m 48s\n",
      "201:\tlearn: 0.8872297\ttotal: 43.9s\tremaining: 1m 48s\n",
      "202:\tlearn: 0.8873813\ttotal: 44.2s\tremaining: 1m 48s\n",
      "203:\tlearn: 0.8870374\ttotal: 44.4s\tremaining: 1m 47s\n",
      "204:\tlearn: 0.8872741\ttotal: 44.6s\tremaining: 1m 47s\n",
      "205:\tlearn: 0.8874243\ttotal: 44.8s\tremaining: 1m 47s\n",
      "206:\tlearn: 0.8879198\ttotal: 45s\tremaining: 1m 47s\n",
      "207:\tlearn: 0.8879193\ttotal: 45.2s\tremaining: 1m 47s\n",
      "208:\tlearn: 0.8879732\ttotal: 45.5s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.8880380\ttotal: 45.7s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.8886196\ttotal: 45.9s\tremaining: 1m 46s\n",
      "211:\tlearn: 0.8889858\ttotal: 46.1s\tremaining: 1m 46s\n",
      "212:\tlearn: 0.8891367\ttotal: 46.3s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.8895676\ttotal: 46.5s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.8895137\ttotal: 46.7s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.8897290\ttotal: 47s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.8899336\ttotal: 47.2s\tremaining: 1m 45s\n",
      "217:\tlearn: 0.8902350\ttotal: 47.4s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.8906015\ttotal: 47.6s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.8906447\ttotal: 47.8s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.8909241\ttotal: 48s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.8911400\ttotal: 48.3s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.8911937\ttotal: 48.5s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.8917099\ttotal: 48.7s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.8918382\ttotal: 48.9s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.8919351\ttotal: 49.1s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.8919678\ttotal: 49.3s\tremaining: 1m 42s\n",
      "227:\tlearn: 0.8922570\ttotal: 49.5s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.8921170\ttotal: 49.8s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.8923643\ttotal: 50s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.8920515\ttotal: 50.2s\tremaining: 1m 41s\n",
      "231:\tlearn: 0.8924299\ttotal: 50.4s\tremaining: 1m 41s\n",
      "232:\tlearn: 0.8928070\ttotal: 50.6s\tremaining: 1m 41s\n",
      "233:\tlearn: 0.8932171\ttotal: 50.9s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.8930025\ttotal: 51.1s\tremaining: 1m 41s\n",
      "235:\tlearn: 0.8932500\ttotal: 51.3s\tremaining: 1m 40s\n",
      "236:\tlearn: 0.8933243\ttotal: 51.5s\tremaining: 1m 40s\n",
      "237:\tlearn: 0.8934192\ttotal: 51.7s\tremaining: 1m 40s\n",
      "238:\tlearn: 0.8935820\ttotal: 51.9s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.8939343\ttotal: 52.1s\tremaining: 1m 39s\n",
      "240:\tlearn: 0.8937406\ttotal: 52.4s\tremaining: 1m 39s\n",
      "241:\tlearn: 0.8944821\ttotal: 52.6s\tremaining: 1m 39s\n",
      "242:\tlearn: 0.8945687\ttotal: 52.8s\tremaining: 1m 39s\n",
      "243:\tlearn: 0.8951191\ttotal: 53s\tremaining: 1m 39s\n",
      "244:\tlearn: 0.8953331\ttotal: 53.2s\tremaining: 1m 38s\n",
      "245:\tlearn: 0.8957607\ttotal: 53.4s\tremaining: 1m 38s\n",
      "246:\tlearn: 0.8960945\ttotal: 53.6s\tremaining: 1m 38s\n",
      "247:\tlearn: 0.8962346\ttotal: 53.9s\tremaining: 1m 38s\n",
      "248:\tlearn: 0.8962680\ttotal: 54.1s\tremaining: 1m 37s\n",
      "249:\tlearn: 0.8961177\ttotal: 54.3s\tremaining: 1m 37s\n",
      "250:\tlearn: 0.8966652\ttotal: 54.5s\tremaining: 1m 37s\n",
      "251:\tlearn: 0.8968688\ttotal: 54.7s\tremaining: 1m 37s\n",
      "252:\tlearn: 0.8968054\ttotal: 54.9s\tremaining: 1m 37s\n",
      "253:\tlearn: 0.8968054\ttotal: 55.1s\tremaining: 1m 36s\n",
      "254:\tlearn: 0.8969257\ttotal: 55.4s\tremaining: 1m 36s\n",
      "255:\tlearn: 0.8971963\ttotal: 55.6s\tremaining: 1m 36s\n",
      "256:\tlearn: 0.8971827\ttotal: 55.8s\tremaining: 1m 36s\n",
      "257:\tlearn: 0.8970524\ttotal: 56s\tremaining: 1m 35s\n",
      "258:\tlearn: 0.8975265\ttotal: 56.2s\tremaining: 1m 35s\n",
      "259:\tlearn: 0.8975265\ttotal: 56.4s\tremaining: 1m 35s\n",
      "260:\tlearn: 0.8973428\ttotal: 56.7s\tremaining: 1m 35s\n",
      "261:\tlearn: 0.8972460\ttotal: 56.9s\tremaining: 1m 35s\n",
      "262:\tlearn: 0.8972696\ttotal: 57.1s\tremaining: 1m 34s\n",
      "263:\tlearn: 0.8972832\ttotal: 57.3s\tremaining: 1m 34s\n",
      "264:\tlearn: 0.8974731\ttotal: 57.5s\tremaining: 1m 34s\n",
      "265:\tlearn: 0.8977537\ttotal: 57.7s\tremaining: 1m 34s\n",
      "266:\tlearn: 0.8978070\ttotal: 58s\tremaining: 1m 33s\n",
      "267:\tlearn: 0.8980679\ttotal: 58.2s\tremaining: 1m 33s\n",
      "268:\tlearn: 0.8981984\ttotal: 58.4s\tremaining: 1m 33s\n",
      "269:\tlearn: 0.8982911\ttotal: 58.6s\tremaining: 1m 33s\n",
      "270:\tlearn: 0.8985044\ttotal: 58.8s\tremaining: 1m 33s\n",
      "271:\tlearn: 0.8986980\ttotal: 59s\tremaining: 1m 32s\n",
      "272:\tlearn: 0.8989787\ttotal: 59.3s\tremaining: 1m 32s\n",
      "273:\tlearn: 0.8991723\ttotal: 59.5s\tremaining: 1m 32s\n",
      "274:\tlearn: 0.8995451\ttotal: 59.7s\tremaining: 1m 32s\n",
      "275:\tlearn: 0.8999419\ttotal: 59.9s\tremaining: 1m 32s\n",
      "276:\tlearn: 0.8999419\ttotal: 1m\tremaining: 1m 31s\n",
      "277:\tlearn: 0.8999952\ttotal: 1m\tremaining: 1m 31s\n",
      "278:\tlearn: 0.9001451\ttotal: 1m\tremaining: 1m 31s\n",
      "279:\tlearn: 0.9003290\ttotal: 1m\tremaining: 1m 31s\n",
      "280:\tlearn: 0.9006821\ttotal: 1m\tremaining: 1m 30s\n",
      "281:\tlearn: 0.9006917\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "282:\tlearn: 0.9007981\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "283:\tlearn: 0.9008077\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "284:\tlearn: 0.9006917\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "285:\tlearn: 0.9008320\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "286:\tlearn: 0.9010883\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "287:\tlearn: 0.9013689\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "288:\tlearn: 0.9016687\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "289:\tlearn: 0.9016005\ttotal: 1m 2s\tremaining: 1m 28s\n",
      "290:\tlearn: 0.9016497\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "291:\tlearn: 0.9019589\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "292:\tlearn: 0.9018906\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "293:\tlearn: 0.9020215\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "294:\tlearn: 0.9020556\ttotal: 1m 3s\tremaining: 1m 27s\n",
      "295:\tlearn: 0.9021524\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "296:\tlearn: 0.9020556\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "297:\tlearn: 0.9024331\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "298:\tlearn: 0.9026985\ttotal: 1m 4s\tremaining: 1m 26s\n",
      "299:\tlearn: 0.9021960\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "300:\tlearn: 0.9027139\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "301:\tlearn: 0.9027234\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "302:\tlearn: 0.9029356\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "303:\tlearn: 0.9030324\ttotal: 1m 5s\tremaining: 1m 25s\n",
      "304:\tlearn: 0.9028140\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "305:\tlearn: 0.9029168\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "306:\tlearn: 0.9032788\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "307:\tlearn: 0.9034536\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "308:\tlearn: 0.9033569\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "309:\tlearn: 0.9034693\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "310:\tlearn: 0.9034162\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "311:\tlearn: 0.9033382\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "312:\tlearn: 0.9036034\ttotal: 1m 7s\tremaining: 1m 23s\n",
      "313:\tlearn: 0.9036722\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "314:\tlearn: 0.9035067\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "315:\tlearn: 0.9037531\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "316:\tlearn: 0.9037811\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "317:\tlearn: 0.9037281\ttotal: 1m 8s\tremaining: 1m 22s\n",
      "318:\tlearn: 0.9036314\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "319:\tlearn: 0.9039559\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "320:\tlearn: 0.9039996\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "321:\tlearn: 0.9040433\ttotal: 1m 9s\tremaining: 1m 21s\n",
      "322:\tlearn: 0.9045960\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "323:\tlearn: 0.9046237\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "324:\tlearn: 0.9044118\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "325:\tlearn: 0.9039001\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "326:\tlearn: 0.9041997\ttotal: 1m 10s\tremaining: 1m 20s\n",
      "327:\tlearn: 0.9046145\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "328:\tlearn: 0.9046398\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "329:\tlearn: 0.9047734\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "330:\tlearn: 0.9048448\ttotal: 1m 11s\tremaining: 1m 19s\n",
      "331:\tlearn: 0.9051349\ttotal: 1m 11s\tremaining: 1m 19s\n",
      "332:\tlearn: 0.9052937\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "333:\tlearn: 0.9053375\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "334:\tlearn: 0.9050566\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "335:\tlearn: 0.9052591\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "336:\tlearn: 0.9052153\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "337:\tlearn: 0.9051878\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "338:\tlearn: 0.9052937\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "339:\tlearn: 0.9054342\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "340:\tlearn: 0.9054433\ttotal: 1m 13s\tremaining: 1m 17s\n",
      "341:\tlearn: 0.9053191\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "342:\tlearn: 0.9055308\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "343:\tlearn: 0.9058209\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "344:\tlearn: 0.9056458\ttotal: 1m 14s\tremaining: 1m 16s\n",
      "345:\tlearn: 0.9060416\ttotal: 1m 14s\tremaining: 1m 16s\n",
      "346:\tlearn: 0.9061911\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "347:\tlearn: 0.9063225\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "348:\tlearn: 0.9066744\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "349:\tlearn: 0.9068317\ttotal: 1m 15s\tremaining: 1m 15s\n",
      "350:\tlearn: 0.9065145\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "351:\tlearn: 0.9069182\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "352:\tlearn: 0.9071028\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "353:\tlearn: 0.9073931\ttotal: 1m 16s\tremaining: 1m 14s\n",
      "354:\tlearn: 0.9075955\ttotal: 1m 16s\tremaining: 1m 14s\n",
      "355:\tlearn: 0.9074719\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "356:\tlearn: 0.9075948\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "357:\tlearn: 0.9077102\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "358:\tlearn: 0.9078241\ttotal: 1m 17s\tremaining: 1m 13s\n",
      "359:\tlearn: 0.9078769\ttotal: 1m 17s\tremaining: 1m 13s\n",
      "360:\tlearn: 0.9080704\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "361:\tlearn: 0.9082551\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "362:\tlearn: 0.9082640\ttotal: 1m 18s\tremaining: 1m 12s\n",
      "363:\tlearn: 0.9081761\ttotal: 1m 18s\tremaining: 1m 12s\n",
      "364:\tlearn: 0.9081499\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "365:\tlearn: 0.9081939\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "366:\tlearn: 0.9082112\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "367:\tlearn: 0.9084224\ttotal: 1m 19s\tremaining: 1m 11s\n",
      "368:\tlearn: 0.9085720\ttotal: 1m 19s\tremaining: 1m 11s\n",
      "369:\tlearn: 0.9086068\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "370:\tlearn: 0.9086948\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "371:\tlearn: 0.9089589\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "372:\tlearn: 0.9090381\ttotal: 1m 20s\tremaining: 1m 10s\n",
      "373:\tlearn: 0.9091789\ttotal: 1m 20s\tremaining: 1m 10s\n",
      "374:\tlearn: 0.9091173\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "375:\tlearn: 0.9094692\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "376:\tlearn: 0.9093109\ttotal: 1m 21s\tremaining: 1m 9s\n",
      "377:\tlearn: 0.9096012\ttotal: 1m 21s\tremaining: 1m 9s\n",
      "378:\tlearn: 0.9096365\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "379:\tlearn: 0.9098210\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "380:\tlearn: 0.9100232\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "381:\tlearn: 0.9103048\ttotal: 1m 22s\tremaining: 1m 8s\n",
      "382:\tlearn: 0.9103135\ttotal: 1m 22s\tremaining: 1m 8s\n",
      "383:\tlearn: 0.9101733\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "384:\tlearn: 0.9102173\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "385:\tlearn: 0.9102173\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "386:\tlearn: 0.9108949\ttotal: 1m 23s\tremaining: 1m 7s\n",
      "387:\tlearn: 0.9110003\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "388:\tlearn: 0.9110186\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "389:\tlearn: 0.9112294\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "390:\tlearn: 0.9112380\ttotal: 1m 24s\tremaining: 1m 6s\n",
      "391:\tlearn: 0.9111584\ttotal: 1m 24s\tremaining: 1m 6s\n",
      "392:\tlearn: 0.9117305\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "393:\tlearn: 0.9115541\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "394:\tlearn: 0.9116950\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "395:\tlearn: 0.9117035\ttotal: 1m 25s\tremaining: 1m 5s\n",
      "396:\tlearn: 0.9120906\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "397:\tlearn: 0.9123452\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "398:\tlearn: 0.9121602\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "399:\tlearn: 0.9125115\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "400:\tlearn: 0.9127134\ttotal: 1m 26s\tremaining: 1m 4s\n",
      "401:\tlearn: 0.9125115\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "402:\tlearn: 0.9126965\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "403:\tlearn: 0.9128270\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "404:\tlearn: 0.9130309\ttotal: 1m 27s\tremaining: 1m 3s\n",
      "405:\tlearn: 0.9130393\ttotal: 1m 27s\tremaining: 1m 3s\n",
      "406:\tlearn: 0.9127303\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "407:\tlearn: 0.9129594\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "408:\tlearn: 0.9133021\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "409:\tlearn: 0.9134513\ttotal: 1m 28s\tremaining: 1m 2s\n",
      "410:\tlearn: 0.9134346\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "411:\tlearn: 0.9133295\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "412:\tlearn: 0.9133378\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "413:\tlearn: 0.9135313\ttotal: 1m 29s\tremaining: 1m 1s\n",
      "414:\tlearn: 0.9136722\ttotal: 1m 29s\tremaining: 1m 1s\n",
      "415:\tlearn: 0.9138381\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "416:\tlearn: 0.9141558\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "417:\tlearn: 0.9144266\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "418:\tlearn: 0.9142415\ttotal: 1m 30s\tremaining: 1m\n",
      "419:\tlearn: 0.9143658\ttotal: 1m 30s\tremaining: 1m\n",
      "420:\tlearn: 0.9142083\ttotal: 1m 31s\tremaining: 1m\n",
      "421:\tlearn: 0.9144101\ttotal: 1m 31s\tremaining: 1m\n",
      "422:\tlearn: 0.9142691\ttotal: 1m 31s\tremaining: 60s\n",
      "423:\tlearn: 0.9144101\ttotal: 1m 31s\tremaining: 59.8s\n",
      "424:\tlearn: 0.9147444\ttotal: 1m 32s\tremaining: 59.6s\n",
      "425:\tlearn: 0.9149543\ttotal: 1m 32s\tremaining: 59.3s\n",
      "426:\tlearn: 0.9148329\ttotal: 1m 32s\tremaining: 59.1s\n",
      "427:\tlearn: 0.9149739\ttotal: 1m 32s\tremaining: 58.9s\n",
      "428:\tlearn: 0.9151035\ttotal: 1m 32s\tremaining: 58.7s\n",
      "429:\tlearn: 0.9152002\ttotal: 1m 33s\tremaining: 58.5s\n",
      "430:\tlearn: 0.9154739\ttotal: 1m 33s\tremaining: 58.3s\n",
      "431:\tlearn: 0.9156149\ttotal: 1m 33s\tremaining: 58s\n",
      "432:\tlearn: 0.9156592\ttotal: 1m 33s\tremaining: 57.8s\n",
      "433:\tlearn: 0.9156230\ttotal: 1m 33s\tremaining: 57.6s\n",
      "434:\tlearn: 0.9160460\ttotal: 1m 34s\tremaining: 57.4s\n",
      "435:\tlearn: 0.9161990\ttotal: 1m 34s\tremaining: 57.2s\n",
      "436:\tlearn: 0.9163562\ttotal: 1m 34s\tremaining: 57s\n",
      "437:\tlearn: 0.9162152\ttotal: 1m 34s\tremaining: 56.7s\n",
      "438:\tlearn: 0.9163281\ttotal: 1m 35s\tremaining: 56.5s\n",
      "439:\tlearn: 0.9160017\ttotal: 1m 35s\tremaining: 56.3s\n",
      "440:\tlearn: 0.9160704\ttotal: 1m 35s\tremaining: 56.1s\n",
      "441:\tlearn: 0.9164329\ttotal: 1m 35s\tremaining: 55.9s\n",
      "442:\tlearn: 0.9167231\ttotal: 1m 35s\tremaining: 55.7s\n",
      "443:\tlearn: 0.9163886\ttotal: 1m 36s\tremaining: 55.4s\n",
      "444:\tlearn: 0.9167150\ttotal: 1m 36s\tremaining: 55.2s\n",
      "445:\tlearn: 0.9166989\ttotal: 1m 36s\tremaining: 55s\n",
      "446:\tlearn: 0.9169368\ttotal: 1m 36s\tremaining: 54.8s\n",
      "447:\tlearn: 0.9169368\ttotal: 1m 37s\tremaining: 54.6s\n",
      "448:\tlearn: 0.9173398\ttotal: 1m 37s\tremaining: 54.4s\n",
      "449:\tlearn: 0.9175333\ttotal: 1m 37s\tremaining: 54.2s\n",
      "450:\tlearn: 0.9176664\ttotal: 1m 37s\tremaining: 53.9s\n",
      "451:\tlearn: 0.9178679\ttotal: 1m 37s\tremaining: 53.7s\n",
      "452:\tlearn: 0.9181137\ttotal: 1m 38s\tremaining: 53.5s\n",
      "453:\tlearn: 0.9178235\ttotal: 1m 38s\tremaining: 53.3s\n",
      "454:\tlearn: 0.9180328\ttotal: 1m 38s\tremaining: 53.1s\n",
      "455:\tlearn: 0.9180328\ttotal: 1m 38s\tremaining: 52.8s\n",
      "456:\tlearn: 0.9181216\ttotal: 1m 38s\tremaining: 52.6s\n",
      "457:\tlearn: 0.9182785\ttotal: 1m 39s\tremaining: 52.4s\n",
      "458:\tlearn: 0.9182420\ttotal: 1m 39s\tremaining: 52.2s\n",
      "459:\tlearn: 0.9182104\ttotal: 1m 39s\tremaining: 52s\n",
      "460:\tlearn: 0.9184197\ttotal: 1m 39s\tremaining: 51.8s\n",
      "461:\tlearn: 0.9185765\ttotal: 1m 40s\tremaining: 51.5s\n",
      "462:\tlearn: 0.9184275\ttotal: 1m 40s\tremaining: 51.3s\n",
      "463:\tlearn: 0.9187385\ttotal: 1m 40s\tremaining: 51.1s\n",
      "464:\tlearn: 0.9190000\ttotal: 1m 40s\tremaining: 50.9s\n",
      "465:\tlearn: 0.9190444\ttotal: 1m 40s\tremaining: 50.7s\n",
      "466:\tlearn: 0.9191045\ttotal: 1m 41s\tremaining: 50.5s\n",
      "467:\tlearn: 0.9194991\ttotal: 1m 41s\tremaining: 50.2s\n",
      "468:\tlearn: 0.9193580\ttotal: 1m 41s\tremaining: 50s\n",
      "469:\tlearn: 0.9196169\ttotal: 1m 41s\tremaining: 49.8s\n",
      "470:\tlearn: 0.9197059\ttotal: 1m 42s\tremaining: 49.6s\n",
      "471:\tlearn: 0.9198626\ttotal: 1m 42s\tremaining: 49.4s\n",
      "472:\tlearn: 0.9198182\ttotal: 1m 42s\tremaining: 49.2s\n",
      "473:\tlearn: 0.9200039\ttotal: 1m 42s\tremaining: 48.9s\n",
      "474:\tlearn: 0.9202341\ttotal: 1m 42s\tremaining: 48.7s\n",
      "475:\tlearn: 0.9200193\ttotal: 1m 43s\tremaining: 48.5s\n",
      "476:\tlearn: 0.9201161\ttotal: 1m 43s\tremaining: 48.3s\n",
      "477:\tlearn: 0.9202496\ttotal: 1m 43s\tremaining: 48.1s\n",
      "478:\tlearn: 0.9205397\ttotal: 1m 43s\tremaining: 47.9s\n",
      "479:\tlearn: 0.9206288\ttotal: 1m 43s\tremaining: 47.6s\n",
      "480:\tlearn: 0.9206288\ttotal: 1m 44s\tremaining: 47.4s\n",
      "481:\tlearn: 0.9207178\ttotal: 1m 44s\tremaining: 47.2s\n",
      "482:\tlearn: 0.9207102\ttotal: 1m 44s\tremaining: 47s\n",
      "483:\tlearn: 0.9207624\ttotal: 1m 44s\tremaining: 46.8s\n",
      "484:\tlearn: 0.9205612\ttotal: 1m 45s\tremaining: 46.6s\n",
      "485:\tlearn: 0.9207102\ttotal: 1m 45s\tremaining: 46.3s\n",
      "486:\tlearn: 0.9205244\ttotal: 1m 45s\tremaining: 46.1s\n",
      "487:\tlearn: 0.9208744\ttotal: 1m 45s\tremaining: 45.9s\n",
      "488:\tlearn: 0.9210157\ttotal: 1m 45s\tremaining: 45.7s\n",
      "489:\tlearn: 0.9211570\ttotal: 1m 46s\tremaining: 45.5s\n",
      "490:\tlearn: 0.9212092\ttotal: 1m 46s\tremaining: 45.3s\n",
      "491:\tlearn: 0.9215885\ttotal: 1m 46s\tremaining: 45s\n",
      "492:\tlearn: 0.9216113\ttotal: 1m 46s\tremaining: 44.8s\n",
      "493:\tlearn: 0.9217450\ttotal: 1m 46s\tremaining: 44.6s\n",
      "494:\tlearn: 0.9218493\ttotal: 1m 47s\tremaining: 44.4s\n",
      "495:\tlearn: 0.9217896\ttotal: 1m 47s\tremaining: 44.2s\n",
      "496:\tlearn: 0.9216483\ttotal: 1m 47s\tremaining: 44s\n",
      "497:\tlearn: 0.9218342\ttotal: 1m 47s\tremaining: 43.7s\n",
      "498:\tlearn: 0.9219014\ttotal: 1m 48s\tremaining: 43.5s\n",
      "499:\tlearn: 0.9222588\ttotal: 1m 48s\tremaining: 43.3s\n",
      "500:\tlearn: 0.9221991\ttotal: 1m 48s\tremaining: 43.1s\n",
      "501:\tlearn: 0.9221470\ttotal: 1m 48s\tremaining: 42.9s\n",
      "502:\tlearn: 0.9223925\ttotal: 1m 48s\tremaining: 42.7s\n",
      "503:\tlearn: 0.9224742\ttotal: 1m 49s\tremaining: 42.4s\n",
      "504:\tlearn: 0.9227644\ttotal: 1m 49s\tremaining: 42.2s\n",
      "505:\tlearn: 0.9227048\ttotal: 1m 49s\tremaining: 42s\n",
      "506:\tlearn: 0.9226081\ttotal: 1m 49s\tremaining: 41.8s\n",
      "507:\tlearn: 0.9226602\ttotal: 1m 49s\tremaining: 41.6s\n",
      "508:\tlearn: 0.9227123\ttotal: 1m 50s\tremaining: 41.4s\n",
      "509:\tlearn: 0.9228983\ttotal: 1m 50s\tremaining: 41.1s\n",
      "510:\tlearn: 0.9228165\ttotal: 1m 50s\tremaining: 40.9s\n",
      "511:\tlearn: 0.9227123\ttotal: 1m 50s\tremaining: 40.7s\n",
      "512:\tlearn: 0.9227048\ttotal: 1m 51s\tremaining: 40.5s\n",
      "513:\tlearn: 0.9228016\ttotal: 1m 51s\tremaining: 40.3s\n",
      "514:\tlearn: 0.9230918\ttotal: 1m 51s\tremaining: 40.1s\n",
      "515:\tlearn: 0.9229355\ttotal: 1m 51s\tremaining: 39.8s\n",
      "516:\tlearn: 0.9230769\ttotal: 1m 51s\tremaining: 39.6s\n",
      "517:\tlearn: 0.9233151\ttotal: 1m 52s\tremaining: 39.4s\n",
      "518:\tlearn: 0.9231885\ttotal: 1m 52s\tremaining: 39.2s\n",
      "519:\tlearn: 0.9236870\ttotal: 1m 52s\tremaining: 39s\n",
      "520:\tlearn: 0.9234563\ttotal: 1m 52s\tremaining: 38.8s\n",
      "521:\tlearn: 0.9234043\ttotal: 1m 53s\tremaining: 38.5s\n",
      "522:\tlearn: 0.9234862\ttotal: 1m 53s\tremaining: 38.3s\n",
      "523:\tlearn: 0.9235755\ttotal: 1m 53s\tremaining: 38.1s\n",
      "524:\tlearn: 0.9236427\ttotal: 1m 53s\tremaining: 37.9s\n",
      "525:\tlearn: 0.9234862\ttotal: 1m 53s\tremaining: 37.7s\n",
      "526:\tlearn: 0.9234489\ttotal: 1m 54s\tremaining: 37.5s\n",
      "527:\tlearn: 0.9235010\ttotal: 1m 54s\tremaining: 37.2s\n",
      "528:\tlearn: 0.9237018\ttotal: 1m 54s\tremaining: 37s\n",
      "529:\tlearn: 0.9238805\ttotal: 1m 54s\tremaining: 36.8s\n",
      "530:\tlearn: 0.9239025\ttotal: 1m 54s\tremaining: 36.6s\n",
      "531:\tlearn: 0.9241853\ttotal: 1m 55s\tremaining: 36.4s\n",
      "532:\tlearn: 0.9241779\ttotal: 1m 55s\tremaining: 36.2s\n",
      "533:\tlearn: 0.9244161\ttotal: 1m 55s\tremaining: 35.9s\n",
      "534:\tlearn: 0.9245575\ttotal: 1m 55s\tremaining: 35.7s\n",
      "535:\tlearn: 0.9245648\ttotal: 1m 56s\tremaining: 35.5s\n",
      "536:\tlearn: 0.9245502\ttotal: 1m 56s\tremaining: 35.3s\n",
      "537:\tlearn: 0.9244909\ttotal: 1m 56s\tremaining: 35.1s\n",
      "538:\tlearn: 0.9245876\ttotal: 1m 56s\tremaining: 34.9s\n",
      "539:\tlearn: 0.9244982\ttotal: 1m 56s\tremaining: 34.6s\n",
      "540:\tlearn: 0.9247884\ttotal: 1m 57s\tremaining: 34.4s\n",
      "541:\tlearn: 0.9247957\ttotal: 1m 57s\tremaining: 34.2s\n",
      "542:\tlearn: 0.9249673\ttotal: 1m 57s\tremaining: 34s\n",
      "543:\tlearn: 0.9249371\ttotal: 1m 57s\tremaining: 33.8s\n",
      "544:\tlearn: 0.9251898\ttotal: 1m 58s\tremaining: 33.6s\n",
      "545:\tlearn: 0.9254208\ttotal: 1m 58s\tremaining: 33.3s\n",
      "546:\tlearn: 0.9253760\ttotal: 1m 58s\tremaining: 33.1s\n",
      "547:\tlearn: 0.9255695\ttotal: 1m 58s\tremaining: 32.9s\n",
      "548:\tlearn: 0.9256662\ttotal: 1m 58s\tremaining: 32.7s\n",
      "549:\tlearn: 0.9255839\ttotal: 1m 59s\tremaining: 32.5s\n",
      "550:\tlearn: 0.9257701\ttotal: 1m 59s\tremaining: 32.3s\n",
      "551:\tlearn: 0.9258292\ttotal: 1m 59s\tremaining: 32s\n",
      "552:\tlearn: 0.9255839\ttotal: 1m 59s\tremaining: 31.8s\n",
      "553:\tlearn: 0.9256878\ttotal: 1m 59s\tremaining: 31.6s\n",
      "554:\tlearn: 0.9256574\ttotal: 2m\tremaining: 31.4s\n",
      "555:\tlearn: 0.9258579\ttotal: 2m\tremaining: 31.2s\n",
      "556:\tlearn: 0.9260960\ttotal: 2m\tremaining: 31s\n",
      "557:\tlearn: 0.9262374\ttotal: 2m\tremaining: 30.7s\n",
      "558:\tlearn: 0.9261336\ttotal: 2m 1s\tremaining: 30.5s\n",
      "559:\tlearn: 0.9264094\ttotal: 2m 1s\tremaining: 30.3s\n",
      "560:\tlearn: 0.9265957\ttotal: 2m 1s\tremaining: 30.1s\n",
      "561:\tlearn: 0.9267373\ttotal: 2m 1s\tremaining: 29.9s\n",
      "562:\tlearn: 0.9267302\ttotal: 2m 1s\tremaining: 29.7s\n",
      "563:\tlearn: 0.9268269\ttotal: 2m 2s\tremaining: 29.4s\n",
      "564:\tlearn: 0.9267821\ttotal: 2m 2s\tremaining: 29.2s\n",
      "565:\tlearn: 0.9268128\ttotal: 2m 2s\tremaining: 29s\n",
      "566:\tlearn: 0.9271171\ttotal: 2m 2s\tremaining: 28.8s\n",
      "567:\tlearn: 0.9269685\ttotal: 2m 2s\tremaining: 28.6s\n",
      "568:\tlearn: 0.9268788\ttotal: 2m 3s\tremaining: 28.4s\n",
      "569:\tlearn: 0.9273554\ttotal: 2m 3s\tremaining: 28.1s\n",
      "570:\tlearn: 0.9272279\ttotal: 2m 3s\tremaining: 27.9s\n",
      "571:\tlearn: 0.9274283\ttotal: 2m 3s\tremaining: 27.7s\n",
      "572:\tlearn: 0.9275180\ttotal: 2m 4s\tremaining: 27.5s\n",
      "573:\tlearn: 0.9272798\ttotal: 2m 4s\tremaining: 27.3s\n",
      "574:\tlearn: 0.9272349\ttotal: 2m 4s\tremaining: 27.1s\n",
      "575:\tlearn: 0.9274802\ttotal: 2m 4s\tremaining: 26.8s\n",
      "576:\tlearn: 0.9276974\ttotal: 2m 4s\tremaining: 26.6s\n",
      "577:\tlearn: 0.9276736\ttotal: 2m 5s\tremaining: 26.4s\n",
      "578:\tlearn: 0.9276596\ttotal: 2m 5s\tremaining: 26.2s\n",
      "579:\tlearn: 0.9277633\ttotal: 2m 5s\tremaining: 26s\n",
      "580:\tlearn: 0.9278221\ttotal: 2m 5s\tremaining: 25.8s\n",
      "581:\tlearn: 0.9279188\ttotal: 2m 6s\tremaining: 25.5s\n",
      "582:\tlearn: 0.9279567\ttotal: 2m 6s\tremaining: 25.3s\n",
      "583:\tlearn: 0.9281431\ttotal: 2m 6s\tremaining: 25.1s\n",
      "584:\tlearn: 0.9283504\ttotal: 2m 6s\tremaining: 24.9s\n",
      "585:\tlearn: 0.9284022\ttotal: 2m 6s\tremaining: 24.7s\n",
      "586:\tlearn: 0.9283953\ttotal: 2m 7s\tremaining: 24.5s\n",
      "587:\tlearn: 0.9281640\ttotal: 2m 7s\tremaining: 24.2s\n",
      "588:\tlearn: 0.9283125\ttotal: 2m 7s\tremaining: 24s\n",
      "589:\tlearn: 0.9284022\ttotal: 2m 7s\tremaining: 23.8s\n",
      "590:\tlearn: 0.9284920\ttotal: 2m 7s\tremaining: 23.6s\n",
      "591:\tlearn: 0.9285438\ttotal: 2m 8s\tremaining: 23.4s\n",
      "592:\tlearn: 0.9287752\ttotal: 2m 8s\tremaining: 23.2s\n",
      "593:\tlearn: 0.9287683\ttotal: 2m 8s\tremaining: 22.9s\n",
      "594:\tlearn: 0.9288650\ttotal: 2m 8s\tremaining: 22.7s\n",
      "595:\tlearn: 0.9288650\ttotal: 2m 9s\tremaining: 22.5s\n",
      "596:\tlearn: 0.9289100\ttotal: 2m 9s\tremaining: 22.3s\n",
      "597:\tlearn: 0.9289480\ttotal: 2m 9s\tremaining: 22.1s\n",
      "598:\tlearn: 0.9291278\ttotal: 2m 9s\tremaining: 21.9s\n",
      "599:\tlearn: 0.9289929\ttotal: 2m 9s\tremaining: 21.6s\n",
      "600:\tlearn: 0.9294180\ttotal: 2m 10s\tremaining: 21.4s\n",
      "601:\tlearn: 0.9293213\ttotal: 2m 10s\tremaining: 21.2s\n",
      "602:\tlearn: 0.9293213\ttotal: 2m 10s\tremaining: 21s\n",
      "603:\tlearn: 0.9295597\ttotal: 2m 10s\tremaining: 20.8s\n",
      "604:\tlearn: 0.9294630\ttotal: 2m 10s\tremaining: 20.6s\n",
      "605:\tlearn: 0.9295080\ttotal: 2m 11s\tremaining: 20.3s\n",
      "606:\tlearn: 0.9295080\ttotal: 2m 11s\tremaining: 20.1s\n",
      "607:\tlearn: 0.9297465\ttotal: 2m 11s\tremaining: 19.9s\n",
      "608:\tlearn: 0.9298364\ttotal: 2m 11s\tremaining: 19.7s\n",
      "609:\tlearn: 0.9299332\ttotal: 2m 12s\tremaining: 19.5s\n",
      "610:\tlearn: 0.9299018\ttotal: 2m 12s\tremaining: 19.3s\n",
      "611:\tlearn: 0.9301853\ttotal: 2m 12s\tremaining: 19s\n",
      "612:\tlearn: 0.9305072\ttotal: 2m 12s\tremaining: 18.8s\n",
      "613:\tlearn: 0.9302753\ttotal: 2m 12s\tremaining: 18.6s\n",
      "614:\tlearn: 0.9303654\ttotal: 2m 13s\tremaining: 18.4s\n",
      "615:\tlearn: 0.9302821\ttotal: 2m 13s\tremaining: 18.2s\n",
      "616:\tlearn: 0.9302821\ttotal: 2m 13s\tremaining: 18s\n",
      "617:\tlearn: 0.9304689\ttotal: 2m 13s\tremaining: 17.8s\n",
      "618:\tlearn: 0.9306423\ttotal: 2m 13s\tremaining: 17.5s\n",
      "619:\tlearn: 0.9307458\ttotal: 2m 14s\tremaining: 17.3s\n",
      "620:\tlearn: 0.9308876\ttotal: 2m 14s\tremaining: 17.1s\n",
      "621:\tlearn: 0.9308292\ttotal: 2m 14s\tremaining: 16.9s\n",
      "622:\tlearn: 0.9309327\ttotal: 2m 14s\tremaining: 16.7s\n",
      "623:\tlearn: 0.9311329\ttotal: 2m 15s\tremaining: 16.4s\n",
      "624:\tlearn: 0.9311129\ttotal: 2m 15s\tremaining: 16.2s\n",
      "625:\tlearn: 0.9312933\ttotal: 2m 15s\tremaining: 16s\n",
      "626:\tlearn: 0.9312098\ttotal: 2m 15s\tremaining: 15.8s\n",
      "627:\tlearn: 0.9312548\ttotal: 2m 15s\tremaining: 15.6s\n",
      "628:\tlearn: 0.9314936\ttotal: 2m 16s\tremaining: 15.4s\n",
      "629:\tlearn: 0.9312999\ttotal: 2m 16s\tremaining: 15.2s\n",
      "630:\tlearn: 0.9313583\ttotal: 2m 16s\tremaining: 14.9s\n",
      "631:\tlearn: 0.9313968\ttotal: 2m 16s\tremaining: 14.7s\n",
      "632:\tlearn: 0.9315519\ttotal: 2m 17s\tremaining: 14.5s\n",
      "633:\tlearn: 0.9315453\ttotal: 2m 17s\tremaining: 14.3s\n",
      "634:\tlearn: 0.9316488\ttotal: 2m 17s\tremaining: 14.1s\n",
      "635:\tlearn: 0.9315519\ttotal: 2m 17s\tremaining: 13.9s\n",
      "636:\tlearn: 0.9315135\ttotal: 2m 17s\tremaining: 13.6s\n",
      "637:\tlearn: 0.9317456\ttotal: 2m 18s\tremaining: 13.4s\n",
      "638:\tlearn: 0.9316872\ttotal: 2m 18s\tremaining: 13.2s\n",
      "639:\tlearn: 0.9316872\ttotal: 2m 18s\tremaining: 13s\n",
      "640:\tlearn: 0.9315970\ttotal: 2m 18s\tremaining: 12.8s\n",
      "641:\tlearn: 0.9317390\ttotal: 2m 18s\tremaining: 12.6s\n",
      "642:\tlearn: 0.9317907\ttotal: 2m 19s\tremaining: 12.3s\n",
      "643:\tlearn: 0.9318424\ttotal: 2m 19s\tremaining: 12.1s\n",
      "644:\tlearn: 0.9320229\ttotal: 2m 19s\tremaining: 11.9s\n",
      "645:\tlearn: 0.9321197\ttotal: 2m 19s\tremaining: 11.7s\n",
      "646:\tlearn: 0.9320680\ttotal: 2m 20s\tremaining: 11.5s\n",
      "647:\tlearn: 0.9322296\ttotal: 2m 20s\tremaining: 11.3s\n",
      "648:\tlearn: 0.9322748\ttotal: 2m 20s\tremaining: 11s\n",
      "649:\tlearn: 0.9322748\ttotal: 2m 20s\tremaining: 10.8s\n",
      "650:\tlearn: 0.9323134\ttotal: 2m 20s\tremaining: 10.6s\n",
      "651:\tlearn: 0.9323585\ttotal: 2m 21s\tremaining: 10.4s\n",
      "652:\tlearn: 0.9324553\ttotal: 2m 21s\tremaining: 10.2s\n",
      "653:\tlearn: 0.9324102\ttotal: 2m 21s\tremaining: 9.95s\n",
      "654:\tlearn: 0.9327975\ttotal: 2m 21s\tremaining: 9.74s\n",
      "655:\tlearn: 0.9328362\ttotal: 2m 21s\tremaining: 9.52s\n",
      "656:\tlearn: 0.9328362\ttotal: 2m 22s\tremaining: 9.3s\n",
      "657:\tlearn: 0.9328814\ttotal: 2m 22s\tremaining: 9.09s\n",
      "658:\tlearn: 0.9327393\ttotal: 2m 22s\tremaining: 8.87s\n",
      "659:\tlearn: 0.9329330\ttotal: 2m 22s\tremaining: 8.65s\n",
      "660:\tlearn: 0.9327328\ttotal: 2m 23s\tremaining: 8.44s\n",
      "661:\tlearn: 0.9329265\ttotal: 2m 23s\tremaining: 8.22s\n",
      "662:\tlearn: 0.9329782\ttotal: 2m 23s\tremaining: 8.01s\n",
      "663:\tlearn: 0.9328362\ttotal: 2m 23s\tremaining: 7.79s\n",
      "664:\tlearn: 0.9329330\ttotal: 2m 23s\tremaining: 7.57s\n",
      "665:\tlearn: 0.9330751\ttotal: 2m 24s\tremaining: 7.36s\n",
      "666:\tlearn: 0.9329782\ttotal: 2m 24s\tremaining: 7.14s\n",
      "667:\tlearn: 0.9329330\ttotal: 2m 24s\tremaining: 6.92s\n",
      "668:\tlearn: 0.9329847\ttotal: 2m 24s\tremaining: 6.71s\n",
      "669:\tlearn: 0.9329265\ttotal: 2m 24s\tremaining: 6.49s\n",
      "670:\tlearn: 0.9328814\ttotal: 2m 25s\tremaining: 6.28s\n",
      "671:\tlearn: 0.9329782\ttotal: 2m 25s\tremaining: 6.06s\n",
      "672:\tlearn: 0.9332236\ttotal: 2m 25s\tremaining: 5.84s\n",
      "673:\tlearn: 0.9331010\ttotal: 2m 25s\tremaining: 5.63s\n",
      "674:\tlearn: 0.9330945\ttotal: 2m 26s\tremaining: 5.41s\n",
      "675:\tlearn: 0.9332300\ttotal: 2m 26s\tremaining: 5.19s\n",
      "676:\tlearn: 0.9331784\ttotal: 2m 26s\tremaining: 4.98s\n",
      "677:\tlearn: 0.9332236\ttotal: 2m 26s\tremaining: 4.76s\n",
      "678:\tlearn: 0.9331267\ttotal: 2m 26s\tremaining: 4.54s\n",
      "679:\tlearn: 0.9332365\ttotal: 2m 27s\tremaining: 4.33s\n",
      "680:\tlearn: 0.9333721\ttotal: 2m 27s\tremaining: 4.11s\n",
      "681:\tlearn: 0.9334173\ttotal: 2m 27s\tremaining: 3.9s\n",
      "682:\tlearn: 0.9334689\ttotal: 2m 27s\tremaining: 3.68s\n",
      "683:\tlearn: 0.9335077\ttotal: 2m 28s\tremaining: 3.46s\n",
      "684:\tlearn: 0.9337014\ttotal: 2m 28s\tremaining: 3.25s\n",
      "685:\tlearn: 0.9336497\ttotal: 2m 28s\tremaining: 3.03s\n",
      "686:\tlearn: 0.9337530\ttotal: 2m 28s\tremaining: 2.81s\n",
      "687:\tlearn: 0.9337659\ttotal: 2m 28s\tremaining: 2.6s\n",
      "688:\tlearn: 0.9339659\ttotal: 2m 29s\tremaining: 2.38s\n",
      "689:\tlearn: 0.9338691\ttotal: 2m 29s\tremaining: 2.16s\n",
      "690:\tlearn: 0.9336690\ttotal: 2m 29s\tremaining: 1.95s\n",
      "691:\tlearn: 0.9338627\ttotal: 2m 29s\tremaining: 1.73s\n",
      "692:\tlearn: 0.9339595\ttotal: 2m 30s\tremaining: 1.51s\n",
      "693:\tlearn: 0.9339595\ttotal: 2m 30s\tremaining: 1.3s\n",
      "694:\tlearn: 0.9338175\ttotal: 2m 30s\tremaining: 1.08s\n",
      "695:\tlearn: 0.9339207\ttotal: 2m 30s\tremaining: 866ms\n",
      "696:\tlearn: 0.9340755\ttotal: 2m 30s\tremaining: 650ms\n",
      "697:\tlearn: 0.9339787\ttotal: 2m 31s\tremaining: 433ms\n",
      "698:\tlearn: 0.9340691\ttotal: 2m 31s\tremaining: 216ms\n",
      "699:\tlearn: 0.9341207\ttotal: 2m 31s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=8, eval_metric=F1, iterations=700, l2_leaf_reg=3, leaf_estimation_method=Newton, learning_rate=0.01, random_strength=1; total time= 2.5min\n",
      "0:\tlearn: 0.6547126\ttotal: 234ms\tremaining: 2m 43s\n",
      "1:\tlearn: 0.7057741\ttotal: 451ms\tremaining: 2m 37s\n",
      "2:\tlearn: 0.7170106\ttotal: 666ms\tremaining: 2m 34s\n",
      "3:\tlearn: 0.7297166\ttotal: 880ms\tremaining: 2m 33s\n",
      "4:\tlearn: 0.7394146\ttotal: 1.1s\tremaining: 2m 32s\n",
      "5:\tlearn: 0.7448576\ttotal: 1.31s\tremaining: 2m 31s\n",
      "6:\tlearn: 0.7551717\ttotal: 1.53s\tremaining: 2m 31s\n",
      "7:\tlearn: 0.7593323\ttotal: 1.75s\tremaining: 2m 31s\n",
      "8:\tlearn: 0.7694253\ttotal: 1.96s\tremaining: 2m 30s\n",
      "9:\tlearn: 0.7769433\ttotal: 2.18s\tremaining: 2m 30s\n",
      "10:\tlearn: 0.7810055\ttotal: 2.39s\tremaining: 2m 29s\n",
      "11:\tlearn: 0.7856933\ttotal: 2.61s\tremaining: 2m 29s\n",
      "12:\tlearn: 0.7879114\ttotal: 2.83s\tremaining: 2m 29s\n",
      "13:\tlearn: 0.7906499\ttotal: 3.04s\tremaining: 2m 29s\n",
      "14:\tlearn: 0.7957472\ttotal: 3.27s\tremaining: 2m 29s\n",
      "15:\tlearn: 0.7963570\ttotal: 3.49s\tremaining: 2m 29s\n",
      "16:\tlearn: 0.7979763\ttotal: 3.71s\tremaining: 2m 28s\n",
      "17:\tlearn: 0.7989019\ttotal: 3.93s\tremaining: 2m 28s\n",
      "18:\tlearn: 0.8009602\ttotal: 4.14s\tremaining: 2m 28s\n",
      "19:\tlearn: 0.8008224\ttotal: 4.36s\tremaining: 2m 28s\n",
      "20:\tlearn: 0.8055433\ttotal: 4.58s\tremaining: 2m 28s\n",
      "21:\tlearn: 0.8075886\ttotal: 4.8s\tremaining: 2m 27s\n",
      "22:\tlearn: 0.8083329\ttotal: 5.02s\tremaining: 2m 27s\n",
      "23:\tlearn: 0.8085169\ttotal: 5.23s\tremaining: 2m 27s\n",
      "24:\tlearn: 0.8082387\ttotal: 5.45s\tremaining: 2m 27s\n",
      "25:\tlearn: 0.8100457\ttotal: 5.66s\tremaining: 2m 26s\n",
      "26:\tlearn: 0.8122417\ttotal: 5.88s\tremaining: 2m 26s\n",
      "27:\tlearn: 0.8146581\ttotal: 6.1s\tremaining: 2m 26s\n",
      "28:\tlearn: 0.8139295\ttotal: 6.32s\tremaining: 2m 26s\n",
      "29:\tlearn: 0.8151211\ttotal: 6.54s\tremaining: 2m 25s\n",
      "30:\tlearn: 0.8168433\ttotal: 6.75s\tremaining: 2m 25s\n",
      "31:\tlearn: 0.8163947\ttotal: 6.97s\tremaining: 2m 25s\n",
      "32:\tlearn: 0.8178472\ttotal: 7.18s\tremaining: 2m 25s\n",
      "33:\tlearn: 0.8200402\ttotal: 7.4s\tremaining: 2m 24s\n",
      "34:\tlearn: 0.8188899\ttotal: 7.61s\tremaining: 2m 24s\n",
      "35:\tlearn: 0.8197766\ttotal: 7.82s\tremaining: 2m 24s\n",
      "36:\tlearn: 0.8220925\ttotal: 8.04s\tremaining: 2m 24s\n",
      "37:\tlearn: 0.8229228\ttotal: 8.26s\tremaining: 2m 23s\n",
      "38:\tlearn: 0.8243330\ttotal: 8.48s\tremaining: 2m 23s\n",
      "39:\tlearn: 0.8253329\ttotal: 8.7s\tremaining: 2m 23s\n",
      "40:\tlearn: 0.8264674\ttotal: 8.92s\tremaining: 2m 23s\n",
      "41:\tlearn: 0.8265853\ttotal: 9.13s\tremaining: 2m 23s\n",
      "42:\tlearn: 0.8271343\ttotal: 9.35s\tremaining: 2m 22s\n",
      "43:\tlearn: 0.8283733\ttotal: 9.57s\tremaining: 2m 22s\n",
      "44:\tlearn: 0.8302352\ttotal: 9.79s\tremaining: 2m 22s\n",
      "45:\tlearn: 0.8304734\ttotal: 10s\tremaining: 2m 22s\n",
      "46:\tlearn: 0.8313241\ttotal: 10.2s\tremaining: 2m 22s\n",
      "47:\tlearn: 0.8325439\ttotal: 10.5s\tremaining: 2m 21s\n",
      "48:\tlearn: 0.8336042\ttotal: 10.7s\tremaining: 2m 21s\n",
      "49:\tlearn: 0.8349897\ttotal: 10.9s\tremaining: 2m 21s\n",
      "50:\tlearn: 0.8348023\ttotal: 11.1s\tremaining: 2m 21s\n",
      "51:\tlearn: 0.8357797\ttotal: 11.3s\tremaining: 2m 21s\n",
      "52:\tlearn: 0.8363547\ttotal: 11.6s\tremaining: 2m 21s\n",
      "53:\tlearn: 0.8364693\ttotal: 11.8s\tremaining: 2m 20s\n",
      "54:\tlearn: 0.8376886\ttotal: 12s\tremaining: 2m 20s\n",
      "55:\tlearn: 0.8385317\ttotal: 12.2s\tremaining: 2m 20s\n",
      "56:\tlearn: 0.8411768\ttotal: 12.4s\tremaining: 2m 20s\n",
      "57:\tlearn: 0.8407555\ttotal: 12.7s\tremaining: 2m 20s\n",
      "58:\tlearn: 0.8411510\ttotal: 12.9s\tremaining: 2m 19s\n",
      "59:\tlearn: 0.8416901\ttotal: 13.1s\tremaining: 2m 19s\n",
      "60:\tlearn: 0.8414934\ttotal: 13.3s\tremaining: 2m 19s\n",
      "61:\tlearn: 0.8434020\ttotal: 13.5s\tremaining: 2m 19s\n",
      "62:\tlearn: 0.8441379\ttotal: 13.8s\tremaining: 2m 19s\n",
      "63:\tlearn: 0.8427840\ttotal: 14s\tremaining: 2m 18s\n",
      "64:\tlearn: 0.8447639\ttotal: 14.2s\tremaining: 2m 18s\n",
      "65:\tlearn: 0.8449193\ttotal: 14.4s\tremaining: 2m 18s\n",
      "66:\tlearn: 0.8454004\ttotal: 14.6s\tremaining: 2m 18s\n",
      "67:\tlearn: 0.8454125\ttotal: 14.9s\tremaining: 2m 18s\n",
      "68:\tlearn: 0.8464489\ttotal: 15.1s\tremaining: 2m 17s\n",
      "69:\tlearn: 0.8461425\ttotal: 15.3s\tremaining: 2m 17s\n",
      "70:\tlearn: 0.8458436\ttotal: 15.5s\tremaining: 2m 17s\n",
      "71:\tlearn: 0.8463280\ttotal: 15.7s\tremaining: 2m 17s\n",
      "72:\tlearn: 0.8457261\ttotal: 16s\tremaining: 2m 17s\n",
      "73:\tlearn: 0.8466463\ttotal: 16.2s\tremaining: 2m 16s\n",
      "74:\tlearn: 0.8475394\ttotal: 16.4s\tremaining: 2m 16s\n",
      "75:\tlearn: 0.8479630\ttotal: 16.6s\tremaining: 2m 16s\n",
      "76:\tlearn: 0.8502729\ttotal: 16.8s\tremaining: 2m 16s\n",
      "77:\tlearn: 0.8505849\ttotal: 17s\tremaining: 2m 15s\n",
      "78:\tlearn: 0.8510178\ttotal: 17.3s\tremaining: 2m 15s\n",
      "79:\tlearn: 0.8523767\ttotal: 17.5s\tremaining: 2m 15s\n",
      "80:\tlearn: 0.8524897\ttotal: 17.7s\tremaining: 2m 15s\n",
      "81:\tlearn: 0.8523007\ttotal: 17.9s\tremaining: 2m 15s\n",
      "82:\tlearn: 0.8531034\ttotal: 18.1s\tremaining: 2m 14s\n",
      "83:\tlearn: 0.8527704\ttotal: 18.3s\tremaining: 2m 14s\n",
      "84:\tlearn: 0.8528818\ttotal: 18.6s\tremaining: 2m 14s\n",
      "85:\tlearn: 0.8538541\ttotal: 18.8s\tremaining: 2m 14s\n",
      "86:\tlearn: 0.8537005\ttotal: 19s\tremaining: 2m 13s\n",
      "87:\tlearn: 0.8544855\ttotal: 19.2s\tremaining: 2m 13s\n",
      "88:\tlearn: 0.8546983\ttotal: 19.4s\tremaining: 2m 13s\n",
      "89:\tlearn: 0.8546437\ttotal: 19.6s\tremaining: 2m 13s\n",
      "90:\tlearn: 0.8545874\ttotal: 19.8s\tremaining: 2m 12s\n",
      "91:\tlearn: 0.8552470\ttotal: 20.1s\tremaining: 2m 12s\n",
      "92:\tlearn: 0.8563145\ttotal: 20.3s\tremaining: 2m 12s\n",
      "93:\tlearn: 0.8571569\ttotal: 20.5s\tremaining: 2m 12s\n",
      "94:\tlearn: 0.8583906\ttotal: 20.7s\tremaining: 2m 11s\n",
      "95:\tlearn: 0.8580256\ttotal: 20.9s\tremaining: 2m 11s\n",
      "96:\tlearn: 0.8581376\ttotal: 21.1s\tremaining: 2m 11s\n",
      "97:\tlearn: 0.8583615\ttotal: 21.4s\tremaining: 2m 11s\n",
      "98:\tlearn: 0.8584184\ttotal: 21.6s\tremaining: 2m 11s\n",
      "99:\tlearn: 0.8579417\ttotal: 21.8s\tremaining: 2m 10s\n",
      "100:\tlearn: 0.8586423\ttotal: 22s\tremaining: 2m 10s\n",
      "101:\tlearn: 0.8584314\ttotal: 22.2s\tremaining: 2m 10s\n",
      "102:\tlearn: 0.8595674\ttotal: 22.4s\tremaining: 2m 10s\n",
      "103:\tlearn: 0.8593298\ttotal: 22.7s\tremaining: 2m 9s\n",
      "104:\tlearn: 0.8598764\ttotal: 22.9s\tremaining: 2m 9s\n",
      "105:\tlearn: 0.8595674\ttotal: 23.1s\tremaining: 2m 9s\n",
      "106:\tlearn: 0.8597627\ttotal: 23.3s\tremaining: 2m 9s\n",
      "107:\tlearn: 0.8601845\ttotal: 23.5s\tremaining: 2m 8s\n",
      "108:\tlearn: 0.8607856\ttotal: 23.7s\tremaining: 2m 8s\n",
      "109:\tlearn: 0.8607893\ttotal: 24s\tremaining: 2m 8s\n",
      "110:\tlearn: 0.8614328\ttotal: 24.2s\tremaining: 2m 8s\n",
      "111:\tlearn: 0.8621315\ttotal: 24.4s\tremaining: 2m 8s\n",
      "112:\tlearn: 0.8634314\ttotal: 24.6s\tremaining: 2m 7s\n",
      "113:\tlearn: 0.8634647\ttotal: 24.8s\tremaining: 2m 7s\n",
      "114:\tlearn: 0.8644750\ttotal: 25.1s\tremaining: 2m 7s\n",
      "115:\tlearn: 0.8646528\ttotal: 25.3s\tremaining: 2m 7s\n",
      "116:\tlearn: 0.8647748\ttotal: 25.5s\tremaining: 2m 6s\n",
      "117:\tlearn: 0.8648039\ttotal: 25.7s\tremaining: 2m 6s\n",
      "118:\tlearn: 0.8650159\ttotal: 25.9s\tremaining: 2m 6s\n",
      "119:\tlearn: 0.8647641\ttotal: 26.1s\tremaining: 2m 6s\n",
      "120:\tlearn: 0.8655882\ttotal: 26.3s\tremaining: 2m 6s\n",
      "121:\tlearn: 0.8665948\ttotal: 26.5s\tremaining: 2m 5s\n",
      "122:\tlearn: 0.8668561\ttotal: 26.8s\tremaining: 2m 5s\n",
      "123:\tlearn: 0.8674439\ttotal: 27s\tremaining: 2m 5s\n",
      "124:\tlearn: 0.8677601\ttotal: 27.2s\tremaining: 2m 5s\n",
      "125:\tlearn: 0.8689608\ttotal: 27.4s\tremaining: 2m 4s\n",
      "126:\tlearn: 0.8696418\ttotal: 27.6s\tremaining: 2m 4s\n",
      "127:\tlearn: 0.8697781\ttotal: 27.8s\tremaining: 2m 4s\n",
      "128:\tlearn: 0.8704638\ttotal: 28.1s\tremaining: 2m 4s\n",
      "129:\tlearn: 0.8706044\ttotal: 28.3s\tremaining: 2m 3s\n",
      "130:\tlearn: 0.8716593\ttotal: 28.5s\tremaining: 2m 3s\n",
      "131:\tlearn: 0.8719781\ttotal: 28.7s\tremaining: 2m 3s\n",
      "132:\tlearn: 0.8715691\ttotal: 28.9s\tremaining: 2m 3s\n",
      "133:\tlearn: 0.8719229\ttotal: 29.1s\tremaining: 2m 3s\n",
      "134:\tlearn: 0.8723321\ttotal: 29.4s\tremaining: 2m 2s\n",
      "135:\tlearn: 0.8733359\ttotal: 29.6s\tremaining: 2m 2s\n",
      "136:\tlearn: 0.8734227\ttotal: 29.8s\tremaining: 2m 2s\n",
      "137:\tlearn: 0.8735396\ttotal: 30s\tremaining: 2m 2s\n",
      "138:\tlearn: 0.8732711\ttotal: 30.2s\tremaining: 2m 1s\n",
      "139:\tlearn: 0.8736070\ttotal: 30.4s\tremaining: 2m 1s\n",
      "140:\tlearn: 0.8735823\ttotal: 30.6s\tremaining: 2m 1s\n",
      "141:\tlearn: 0.8735464\ttotal: 30.9s\tremaining: 2m 1s\n",
      "142:\tlearn: 0.8741812\ttotal: 31.1s\tremaining: 2m 1s\n",
      "143:\tlearn: 0.8744318\ttotal: 31.3s\tremaining: 2m\n",
      "144:\tlearn: 0.8749633\ttotal: 31.5s\tremaining: 2m\n",
      "145:\tlearn: 0.8748533\ttotal: 31.7s\tremaining: 2m\n",
      "146:\tlearn: 0.8757269\ttotal: 31.9s\tremaining: 2m\n",
      "147:\tlearn: 0.8757876\ttotal: 32.2s\tremaining: 1m 59s\n",
      "148:\tlearn: 0.8758119\ttotal: 32.4s\tremaining: 1m 59s\n",
      "149:\tlearn: 0.8756472\ttotal: 32.6s\tremaining: 1m 59s\n",
      "150:\tlearn: 0.8754090\ttotal: 32.8s\tremaining: 1m 59s\n",
      "151:\tlearn: 0.8757506\ttotal: 33s\tremaining: 1m 59s\n",
      "152:\tlearn: 0.8764956\ttotal: 33.3s\tremaining: 1m 58s\n",
      "153:\tlearn: 0.8765933\ttotal: 33.5s\tremaining: 1m 58s\n",
      "154:\tlearn: 0.8770012\ttotal: 33.7s\tremaining: 1m 58s\n",
      "155:\tlearn: 0.8768555\ttotal: 33.9s\tremaining: 1m 58s\n",
      "156:\tlearn: 0.8776536\ttotal: 34.1s\tremaining: 1m 58s\n",
      "157:\tlearn: 0.8783415\ttotal: 34.4s\tremaining: 1m 57s\n",
      "158:\tlearn: 0.8787982\ttotal: 34.6s\tremaining: 1m 57s\n",
      "159:\tlearn: 0.8787051\ttotal: 34.8s\tremaining: 1m 57s\n",
      "160:\tlearn: 0.8783224\ttotal: 35s\tremaining: 1m 57s\n",
      "161:\tlearn: 0.8779702\ttotal: 35.2s\tremaining: 1m 56s\n",
      "162:\tlearn: 0.8790244\ttotal: 35.4s\tremaining: 1m 56s\n",
      "163:\tlearn: 0.8791220\ttotal: 35.7s\tremaining: 1m 56s\n",
      "164:\tlearn: 0.8806167\ttotal: 35.9s\tremaining: 1m 56s\n",
      "165:\tlearn: 0.8802264\ttotal: 36.1s\tremaining: 1m 56s\n",
      "166:\tlearn: 0.8805657\ttotal: 36.3s\tremaining: 1m 55s\n",
      "167:\tlearn: 0.8808386\ttotal: 36.5s\tremaining: 1m 55s\n",
      "168:\tlearn: 0.8809245\ttotal: 36.7s\tremaining: 1m 55s\n",
      "169:\tlearn: 0.8810650\ttotal: 37s\tremaining: 1m 55s\n",
      "170:\tlearn: 0.8807062\ttotal: 37.2s\tremaining: 1m 55s\n",
      "171:\tlearn: 0.8807098\ttotal: 37.4s\tremaining: 1m 54s\n",
      "172:\tlearn: 0.8811114\ttotal: 37.6s\tremaining: 1m 54s\n",
      "173:\tlearn: 0.8811693\ttotal: 37.8s\tremaining: 1m 54s\n",
      "174:\tlearn: 0.8814436\ttotal: 38s\tremaining: 1m 54s\n",
      "175:\tlearn: 0.8815328\ttotal: 38.2s\tremaining: 1m 53s\n",
      "176:\tlearn: 0.8823071\ttotal: 38.5s\tremaining: 1m 53s\n",
      "177:\tlearn: 0.8828346\ttotal: 38.7s\tremaining: 1m 53s\n",
      "178:\tlearn: 0.8831409\ttotal: 38.9s\tremaining: 1m 53s\n",
      "179:\tlearn: 0.8836620\ttotal: 39.1s\tremaining: 1m 53s\n",
      "180:\tlearn: 0.8835443\ttotal: 39.3s\tremaining: 1m 52s\n",
      "181:\tlearn: 0.8838477\ttotal: 39.6s\tremaining: 1m 52s\n",
      "182:\tlearn: 0.8841306\ttotal: 39.8s\tremaining: 1m 52s\n",
      "183:\tlearn: 0.8845405\ttotal: 40s\tremaining: 1m 52s\n",
      "184:\tlearn: 0.8846491\ttotal: 40.2s\tremaining: 1m 51s\n",
      "185:\tlearn: 0.8850703\ttotal: 40.4s\tremaining: 1m 51s\n",
      "186:\tlearn: 0.8853497\ttotal: 40.6s\tremaining: 1m 51s\n",
      "187:\tlearn: 0.8858995\ttotal: 40.9s\tremaining: 1m 51s\n",
      "188:\tlearn: 0.8860846\ttotal: 41.1s\tremaining: 1m 51s\n",
      "189:\tlearn: 0.8855111\ttotal: 41.3s\tremaining: 1m 50s\n",
      "190:\tlearn: 0.8858243\ttotal: 41.5s\tremaining: 1m 50s\n",
      "191:\tlearn: 0.8856739\ttotal: 41.7s\tremaining: 1m 50s\n",
      "192:\tlearn: 0.8864212\ttotal: 41.9s\tremaining: 1m 50s\n",
      "193:\tlearn: 0.8866702\ttotal: 42.1s\tremaining: 1m 49s\n",
      "194:\tlearn: 0.8868981\ttotal: 42.4s\tremaining: 1m 49s\n",
      "195:\tlearn: 0.8872224\ttotal: 42.6s\tremaining: 1m 49s\n",
      "196:\tlearn: 0.8874604\ttotal: 42.8s\tremaining: 1m 49s\n",
      "197:\tlearn: 0.8877313\ttotal: 43s\tremaining: 1m 49s\n",
      "198:\tlearn: 0.8873411\ttotal: 43.2s\tremaining: 1m 48s\n",
      "199:\tlearn: 0.8877094\ttotal: 43.4s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.8879361\ttotal: 43.7s\tremaining: 1m 48s\n",
      "201:\tlearn: 0.8881422\ttotal: 43.9s\tremaining: 1m 48s\n",
      "202:\tlearn: 0.8891810\ttotal: 44.1s\tremaining: 1m 47s\n",
      "203:\tlearn: 0.8892135\ttotal: 44.3s\tremaining: 1m 47s\n",
      "204:\tlearn: 0.8890079\ttotal: 44.5s\tremaining: 1m 47s\n",
      "205:\tlearn: 0.8892459\ttotal: 44.7s\tremaining: 1m 47s\n",
      "206:\tlearn: 0.8892134\ttotal: 44.9s\tremaining: 1m 47s\n",
      "207:\tlearn: 0.8893538\ttotal: 45.2s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.8892567\ttotal: 45.4s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.8896461\ttotal: 45.6s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.8894296\ttotal: 45.8s\tremaining: 1m 46s\n",
      "211:\tlearn: 0.8899051\ttotal: 46s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.8897216\ttotal: 46.3s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.8902297\ttotal: 46.5s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.8901976\ttotal: 46.7s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.8904250\ttotal: 46.9s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.8906835\ttotal: 47.1s\tremaining: 1m 44s\n",
      "217:\tlearn: 0.8908242\ttotal: 47.3s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.8906950\ttotal: 47.6s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.8912578\ttotal: 47.8s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.8909551\ttotal: 48s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.8911922\ttotal: 48.2s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.8916999\ttotal: 48.4s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.8918511\ttotal: 48.6s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.8918288\ttotal: 48.9s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.8922060\ttotal: 49.1s\tremaining: 1m 42s\n",
      "226:\tlearn: 0.8922823\ttotal: 49.3s\tremaining: 1m 42s\n",
      "227:\tlearn: 0.8926383\ttotal: 49.5s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.8926922\ttotal: 49.7s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.8922493\ttotal: 50s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.8926905\ttotal: 50.2s\tremaining: 1m 41s\n",
      "231:\tlearn: 0.8927235\ttotal: 50.4s\tremaining: 1m 41s\n",
      "232:\tlearn: 0.8924318\ttotal: 50.6s\tremaining: 1m 41s\n",
      "233:\tlearn: 0.8931869\ttotal: 50.8s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.8937287\ttotal: 51s\tremaining: 1m 40s\n",
      "235:\tlearn: 0.8940056\ttotal: 51.2s\tremaining: 1m 40s\n",
      "236:\tlearn: 0.8938922\ttotal: 51.5s\tremaining: 1m 40s\n",
      "237:\tlearn: 0.8948622\ttotal: 51.7s\tremaining: 1m 40s\n",
      "238:\tlearn: 0.8950131\ttotal: 51.9s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.8950695\ttotal: 52.1s\tremaining: 1m 39s\n",
      "240:\tlearn: 0.8950029\ttotal: 52.3s\tremaining: 1m 39s\n",
      "241:\tlearn: 0.8951409\ttotal: 52.5s\tremaining: 1m 39s\n",
      "242:\tlearn: 0.8950770\ttotal: 52.7s\tremaining: 1m 39s\n",
      "243:\tlearn: 0.8957908\ttotal: 53s\tremaining: 1m 38s\n",
      "244:\tlearn: 0.8963071\ttotal: 53.2s\tremaining: 1m 38s\n",
      "245:\tlearn: 0.8966858\ttotal: 53.4s\tremaining: 1m 38s\n",
      "246:\tlearn: 0.8972253\ttotal: 53.6s\tremaining: 1m 38s\n",
      "247:\tlearn: 0.8974733\ttotal: 53.8s\tremaining: 1m 38s\n",
      "248:\tlearn: 0.8976378\ttotal: 54.1s\tremaining: 1m 37s\n",
      "249:\tlearn: 0.8974334\ttotal: 54.3s\tremaining: 1m 37s\n",
      "250:\tlearn: 0.8978461\ttotal: 54.5s\tremaining: 1m 37s\n",
      "251:\tlearn: 0.8980703\ttotal: 54.7s\tremaining: 1m 37s\n",
      "252:\tlearn: 0.8980505\ttotal: 54.9s\tremaining: 1m 37s\n",
      "253:\tlearn: 0.8982211\ttotal: 55.1s\tremaining: 1m 36s\n",
      "254:\tlearn: 0.8983422\ttotal: 55.3s\tremaining: 1m 36s\n",
      "255:\tlearn: 0.8985127\ttotal: 55.6s\tremaining: 1m 36s\n",
      "256:\tlearn: 0.8987846\ttotal: 55.8s\tremaining: 1m 36s\n",
      "257:\tlearn: 0.8993002\ttotal: 56s\tremaining: 1m 35s\n",
      "258:\tlearn: 0.8989791\ttotal: 56.2s\tremaining: 1m 35s\n",
      "259:\tlearn: 0.8986874\ttotal: 56.4s\tremaining: 1m 35s\n",
      "260:\tlearn: 0.8989114\ttotal: 56.6s\tremaining: 1m 35s\n",
      "261:\tlearn: 0.8991004\ttotal: 56.8s\tremaining: 1m 35s\n",
      "262:\tlearn: 0.8989693\ttotal: 57.1s\tremaining: 1m 34s\n",
      "263:\tlearn: 0.8995722\ttotal: 57.3s\tremaining: 1m 34s\n",
      "264:\tlearn: 0.8994359\ttotal: 57.5s\tremaining: 1m 34s\n",
      "265:\tlearn: 0.8997132\ttotal: 57.7s\tremaining: 1m 34s\n",
      "266:\tlearn: 0.9002965\ttotal: 57.9s\tremaining: 1m 33s\n",
      "267:\tlearn: 0.9000583\ttotal: 58.2s\tremaining: 1m 33s\n",
      "268:\tlearn: 0.9008019\ttotal: 58.4s\tremaining: 1m 33s\n",
      "269:\tlearn: 0.9008895\ttotal: 58.6s\tremaining: 1m 33s\n",
      "270:\tlearn: 0.9014577\ttotal: 58.8s\tremaining: 1m 33s\n",
      "271:\tlearn: 0.9011854\ttotal: 59s\tremaining: 1m 32s\n",
      "272:\tlearn: 0.9017397\ttotal: 59.2s\tremaining: 1m 32s\n",
      "273:\tlearn: 0.9013414\ttotal: 59.4s\tremaining: 1m 32s\n",
      "274:\tlearn: 0.9009473\ttotal: 59.7s\tremaining: 1m 32s\n",
      "275:\tlearn: 0.9009622\ttotal: 59.9s\tremaining: 1m 32s\n",
      "276:\tlearn: 0.9010786\ttotal: 1m\tremaining: 1m 31s\n",
      "277:\tlearn: 0.9015796\ttotal: 1m\tremaining: 1m 31s\n",
      "278:\tlearn: 0.9015015\ttotal: 1m\tremaining: 1m 31s\n",
      "279:\tlearn: 0.9014194\ttotal: 1m\tremaining: 1m 31s\n",
      "280:\tlearn: 0.9015947\ttotal: 1m 1s\tremaining: 1m 31s\n",
      "281:\tlearn: 0.9018139\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "282:\tlearn: 0.9019837\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "283:\tlearn: 0.9020466\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "284:\tlearn: 0.9021723\ttotal: 1m 1s\tremaining: 1m 30s\n",
      "285:\tlearn: 0.9022257\ttotal: 1m 2s\tremaining: 1m 30s\n",
      "286:\tlearn: 0.9020942\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "287:\tlearn: 0.9026050\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "288:\tlearn: 0.9031976\ttotal: 1m 2s\tremaining: 1m 29s\n",
      "289:\tlearn: 0.9031255\ttotal: 1m 3s\tremaining: 1m 29s\n",
      "290:\tlearn: 0.9035676\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "291:\tlearn: 0.9032854\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "292:\tlearn: 0.9032854\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "293:\tlearn: 0.9033920\ttotal: 1m 3s\tremaining: 1m 28s\n",
      "294:\tlearn: 0.9037023\ttotal: 1m 4s\tremaining: 1m 28s\n",
      "295:\tlearn: 0.9036929\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "296:\tlearn: 0.9037901\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "297:\tlearn: 0.9042134\ttotal: 1m 4s\tremaining: 1m 27s\n",
      "298:\tlearn: 0.9041881\ttotal: 1m 5s\tremaining: 1m 27s\n",
      "299:\tlearn: 0.9041442\ttotal: 1m 5s\tremaining: 1m 27s\n",
      "300:\tlearn: 0.9039751\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "301:\tlearn: 0.9043639\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "302:\tlearn: 0.9046115\ttotal: 1m 5s\tremaining: 1m 26s\n",
      "303:\tlearn: 0.9045930\ttotal: 1m 6s\tremaining: 1m 26s\n",
      "304:\tlearn: 0.9045954\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "305:\tlearn: 0.9047804\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "306:\tlearn: 0.9048151\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "307:\tlearn: 0.9046902\ttotal: 1m 7s\tremaining: 1m 25s\n",
      "308:\tlearn: 0.9049308\ttotal: 1m 7s\tremaining: 1m 25s\n",
      "309:\tlearn: 0.9047966\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "310:\tlearn: 0.9050002\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "311:\tlearn: 0.9050002\ttotal: 1m 7s\tremaining: 1m 24s\n",
      "312:\tlearn: 0.9057429\ttotal: 1m 8s\tremaining: 1m 24s\n",
      "313:\tlearn: 0.9058401\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "314:\tlearn: 0.9060784\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "315:\tlearn: 0.9065643\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "316:\tlearn: 0.9069349\ttotal: 1m 8s\tremaining: 1m 23s\n",
      "317:\tlearn: 0.9070061\ttotal: 1m 9s\tremaining: 1m 23s\n",
      "318:\tlearn: 0.9070762\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "319:\tlearn: 0.9071824\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "320:\tlearn: 0.9075352\ttotal: 1m 9s\tremaining: 1m 22s\n",
      "321:\tlearn: 0.9077738\ttotal: 1m 10s\tremaining: 1m 22s\n",
      "322:\tlearn: 0.9076946\ttotal: 1m 10s\tremaining: 1m 22s\n",
      "323:\tlearn: 0.9076497\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "324:\tlearn: 0.9077028\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "325:\tlearn: 0.9080035\ttotal: 1m 10s\tremaining: 1m 21s\n",
      "326:\tlearn: 0.9082332\ttotal: 1m 11s\tremaining: 1m 21s\n",
      "327:\tlearn: 0.9080739\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "328:\tlearn: 0.9081891\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "329:\tlearn: 0.9083925\ttotal: 1m 11s\tremaining: 1m 20s\n",
      "330:\tlearn: 0.9084719\ttotal: 1m 12s\tremaining: 1m 20s\n",
      "331:\tlearn: 0.9087284\ttotal: 1m 12s\tremaining: 1m 20s\n",
      "332:\tlearn: 0.9090555\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "333:\tlearn: 0.9089052\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "334:\tlearn: 0.9092059\ttotal: 1m 12s\tremaining: 1m 19s\n",
      "335:\tlearn: 0.9092589\ttotal: 1m 13s\tremaining: 1m 19s\n",
      "336:\tlearn: 0.9095331\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "337:\tlearn: 0.9094888\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "338:\tlearn: 0.9094004\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "339:\tlearn: 0.9098867\ttotal: 1m 13s\tremaining: 1m 18s\n",
      "340:\tlearn: 0.9097540\ttotal: 1m 14s\tremaining: 1m 18s\n",
      "341:\tlearn: 0.9097009\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "342:\tlearn: 0.9098337\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "343:\tlearn: 0.9098424\ttotal: 1m 14s\tremaining: 1m 17s\n",
      "344:\tlearn: 0.9097982\ttotal: 1m 15s\tremaining: 1m 17s\n",
      "345:\tlearn: 0.9098779\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "346:\tlearn: 0.9100282\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "347:\tlearn: 0.9100190\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "348:\tlearn: 0.9098775\ttotal: 1m 15s\tremaining: 1m 16s\n",
      "349:\tlearn: 0.9102845\ttotal: 1m 16s\tremaining: 1m 16s\n",
      "350:\tlearn: 0.9103375\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "351:\tlearn: 0.9105675\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "352:\tlearn: 0.9107794\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "353:\tlearn: 0.9105406\ttotal: 1m 16s\tremaining: 1m 15s\n",
      "354:\tlearn: 0.9108680\ttotal: 1m 17s\tremaining: 1m 15s\n",
      "355:\tlearn: 0.9110625\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "356:\tlearn: 0.9108593\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "357:\tlearn: 0.9109469\ttotal: 1m 17s\tremaining: 1m 14s\n",
      "358:\tlearn: 0.9106735\ttotal: 1m 18s\tremaining: 1m 14s\n",
      "359:\tlearn: 0.9105588\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "360:\tlearn: 0.9107890\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "361:\tlearn: 0.9111338\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "362:\tlearn: 0.9110808\ttotal: 1m 18s\tremaining: 1m 13s\n",
      "363:\tlearn: 0.9112225\ttotal: 1m 19s\tremaining: 1m 13s\n",
      "364:\tlearn: 0.9110279\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "365:\tlearn: 0.9111511\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "366:\tlearn: 0.9112927\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "367:\tlearn: 0.9111079\ttotal: 1m 20s\tremaining: 1m 12s\n",
      "368:\tlearn: 0.9114170\ttotal: 1m 20s\tremaining: 1m 12s\n",
      "369:\tlearn: 0.9114872\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "370:\tlearn: 0.9111770\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "371:\tlearn: 0.9113358\ttotal: 1m 20s\tremaining: 1m 11s\n",
      "372:\tlearn: 0.9113358\ttotal: 1m 21s\tremaining: 1m 11s\n",
      "373:\tlearn: 0.9116546\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "374:\tlearn: 0.9117790\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "375:\tlearn: 0.9117261\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "376:\tlearn: 0.9117790\ttotal: 1m 21s\tremaining: 1m 10s\n",
      "377:\tlearn: 0.9121766\ttotal: 1m 22s\tremaining: 1m 10s\n",
      "378:\tlearn: 0.9121937\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "379:\tlearn: 0.9123456\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "380:\tlearn: 0.9123541\ttotal: 1m 22s\tremaining: 1m 9s\n",
      "381:\tlearn: 0.9123541\ttotal: 1m 23s\tremaining: 1m 9s\n",
      "382:\tlearn: 0.9124514\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "383:\tlearn: 0.9126903\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "384:\tlearn: 0.9125845\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "385:\tlearn: 0.9127262\ttotal: 1m 23s\tremaining: 1m 8s\n",
      "386:\tlearn: 0.9129906\ttotal: 1m 24s\tremaining: 1m 8s\n",
      "387:\tlearn: 0.9131048\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "388:\tlearn: 0.9129991\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "389:\tlearn: 0.9132465\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "390:\tlearn: 0.9133268\ttotal: 1m 24s\tremaining: 1m 7s\n",
      "391:\tlearn: 0.9134241\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "392:\tlearn: 0.9135214\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "393:\tlearn: 0.9136439\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "394:\tlearn: 0.9135298\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "395:\tlearn: 0.9134325\ttotal: 1m 26s\tremaining: 1m 6s\n",
      "396:\tlearn: 0.9137076\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "397:\tlearn: 0.9135214\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "398:\tlearn: 0.9135466\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "399:\tlearn: 0.9136631\ttotal: 1m 26s\tremaining: 1m 5s\n",
      "400:\tlearn: 0.9136992\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "401:\tlearn: 0.9136463\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "402:\tlearn: 0.9137352\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "403:\tlearn: 0.9140078\ttotal: 1m 27s\tremaining: 1m 4s\n",
      "404:\tlearn: 0.9139466\ttotal: 1m 28s\tremaining: 1m 4s\n",
      "405:\tlearn: 0.9140271\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "406:\tlearn: 0.9137881\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "407:\tlearn: 0.9139021\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "408:\tlearn: 0.9139550\ttotal: 1m 28s\tremaining: 1m 3s\n",
      "409:\tlearn: 0.9141579\ttotal: 1m 29s\tremaining: 1m 3s\n",
      "410:\tlearn: 0.9142190\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "411:\tlearn: 0.9143079\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "412:\tlearn: 0.9146525\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "413:\tlearn: 0.9148998\ttotal: 1m 29s\tremaining: 1m 2s\n",
      "414:\tlearn: 0.9150943\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "415:\tlearn: 0.9149609\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "416:\tlearn: 0.9151751\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "417:\tlearn: 0.9154224\ttotal: 1m 30s\tremaining: 1m 1s\n",
      "418:\tlearn: 0.9156334\ttotal: 1m 31s\tremaining: 1m 1s\n",
      "419:\tlearn: 0.9157751\ttotal: 1m 31s\tremaining: 1m\n",
      "420:\tlearn: 0.9160142\ttotal: 1m 31s\tremaining: 1m\n",
      "421:\tlearn: 0.9160224\ttotal: 1m 31s\tremaining: 1m\n",
      "422:\tlearn: 0.9162533\ttotal: 1m 31s\tremaining: 1m\n",
      "423:\tlearn: 0.9163505\ttotal: 1m 32s\tremaining: 60s\n",
      "424:\tlearn: 0.9163424\ttotal: 1m 32s\tremaining: 59.7s\n",
      "425:\tlearn: 0.9163505\ttotal: 1m 32s\tremaining: 59.5s\n",
      "426:\tlearn: 0.9167396\ttotal: 1m 32s\tremaining: 59.3s\n",
      "427:\tlearn: 0.9169584\ttotal: 1m 32s\tremaining: 59.1s\n",
      "428:\tlearn: 0.9170841\ttotal: 1m 33s\tremaining: 58.9s\n",
      "429:\tlearn: 0.9170233\ttotal: 1m 33s\tremaining: 58.6s\n",
      "430:\tlearn: 0.9169868\ttotal: 1m 33s\tremaining: 58.4s\n",
      "431:\tlearn: 0.9169868\ttotal: 1m 33s\tremaining: 58.2s\n",
      "432:\tlearn: 0.9169342\ttotal: 1m 34s\tremaining: 58s\n",
      "433:\tlearn: 0.9170314\ttotal: 1m 34s\tremaining: 57.8s\n",
      "434:\tlearn: 0.9174365\ttotal: 1m 34s\tremaining: 57.6s\n",
      "435:\tlearn: 0.9173188\ttotal: 1m 34s\tremaining: 57.3s\n",
      "436:\tlearn: 0.9174365\ttotal: 1m 34s\tremaining: 57.1s\n",
      "437:\tlearn: 0.9175258\ttotal: 1m 35s\tremaining: 56.9s\n",
      "438:\tlearn: 0.9176391\ttotal: 1m 35s\tremaining: 56.7s\n",
      "439:\tlearn: 0.9175338\ttotal: 1m 35s\tremaining: 56.5s\n",
      "440:\tlearn: 0.9173232\ttotal: 1m 35s\tremaining: 56.3s\n",
      "441:\tlearn: 0.9180408\ttotal: 1m 36s\tremaining: 56s\n",
      "442:\tlearn: 0.9178175\ttotal: 1m 36s\tremaining: 55.8s\n",
      "443:\tlearn: 0.9176963\ttotal: 1m 36s\tremaining: 55.6s\n",
      "444:\tlearn: 0.9177409\ttotal: 1m 36s\tremaining: 55.4s\n",
      "445:\tlearn: 0.9179068\ttotal: 1m 36s\tremaining: 55.2s\n",
      "446:\tlearn: 0.9180487\ttotal: 1m 37s\tremaining: 55s\n",
      "447:\tlearn: 0.9179881\ttotal: 1m 37s\tremaining: 54.7s\n",
      "448:\tlearn: 0.9182274\ttotal: 1m 37s\tremaining: 54.5s\n",
      "449:\tlearn: 0.9181747\ttotal: 1m 37s\tremaining: 54.3s\n",
      "450:\tlearn: 0.9183693\ttotal: 1m 37s\tremaining: 54.1s\n",
      "451:\tlearn: 0.9183614\ttotal: 1m 38s\tremaining: 53.9s\n",
      "452:\tlearn: 0.9185034\ttotal: 1m 38s\tremaining: 53.6s\n",
      "453:\tlearn: 0.9187427\ttotal: 1m 38s\tremaining: 53.4s\n",
      "454:\tlearn: 0.9186296\ttotal: 1m 38s\tremaining: 53.2s\n",
      "455:\tlearn: 0.9185481\ttotal: 1m 39s\tremaining: 53s\n",
      "456:\tlearn: 0.9187506\ttotal: 1m 39s\tremaining: 52.8s\n",
      "457:\tlearn: 0.9186454\ttotal: 1m 39s\tremaining: 52.5s\n",
      "458:\tlearn: 0.9189373\ttotal: 1m 39s\tremaining: 52.3s\n",
      "459:\tlearn: 0.9190872\ttotal: 1m 39s\tremaining: 52.1s\n",
      "460:\tlearn: 0.9194317\ttotal: 1m 40s\tremaining: 51.9s\n",
      "461:\tlearn: 0.9192897\ttotal: 1m 40s\tremaining: 51.7s\n",
      "462:\tlearn: 0.9191845\ttotal: 1m 40s\tremaining: 51.5s\n",
      "463:\tlearn: 0.9193949\ttotal: 1m 40s\tremaining: 51.2s\n",
      "464:\tlearn: 0.9196633\ttotal: 1m 40s\tremaining: 51s\n",
      "465:\tlearn: 0.9195503\ttotal: 1m 41s\tremaining: 50.8s\n",
      "466:\tlearn: 0.9195425\ttotal: 1m 41s\tremaining: 50.6s\n",
      "467:\tlearn: 0.9195581\ttotal: 1m 41s\tremaining: 50.4s\n",
      "468:\tlearn: 0.9194765\ttotal: 1m 41s\tremaining: 50.2s\n",
      "469:\tlearn: 0.9196846\ttotal: 1m 42s\tremaining: 49.9s\n",
      "470:\tlearn: 0.9197002\ttotal: 1m 42s\tremaining: 49.7s\n",
      "471:\tlearn: 0.9195581\ttotal: 1m 42s\tremaining: 49.5s\n",
      "472:\tlearn: 0.9200078\ttotal: 1m 42s\tremaining: 49.3s\n",
      "473:\tlearn: 0.9203368\ttotal: 1m 42s\tremaining: 49.1s\n",
      "474:\tlearn: 0.9203893\ttotal: 1m 43s\tremaining: 48.9s\n",
      "475:\tlearn: 0.9203290\ttotal: 1m 43s\tremaining: 48.6s\n",
      "476:\tlearn: 0.9204418\ttotal: 1m 43s\tremaining: 48.4s\n",
      "477:\tlearn: 0.9206890\ttotal: 1m 43s\tremaining: 48.2s\n",
      "478:\tlearn: 0.9206365\ttotal: 1m 43s\tremaining: 48s\n",
      "479:\tlearn: 0.9205021\ttotal: 1m 44s\tremaining: 47.8s\n",
      "480:\tlearn: 0.9205098\ttotal: 1m 44s\tremaining: 47.5s\n",
      "481:\tlearn: 0.9207569\ttotal: 1m 44s\tremaining: 47.3s\n",
      "482:\tlearn: 0.9205994\ttotal: 1m 44s\tremaining: 47.1s\n",
      "483:\tlearn: 0.9210411\ttotal: 1m 45s\tremaining: 46.9s\n",
      "484:\tlearn: 0.9210859\ttotal: 1m 45s\tremaining: 46.7s\n",
      "485:\tlearn: 0.9210257\ttotal: 1m 45s\tremaining: 46.5s\n",
      "486:\tlearn: 0.9210859\ttotal: 1m 45s\tremaining: 46.2s\n",
      "487:\tlearn: 0.9210411\ttotal: 1m 45s\tremaining: 46s\n",
      "488:\tlearn: 0.9210859\ttotal: 1m 46s\tremaining: 45.8s\n",
      "489:\tlearn: 0.9211614\ttotal: 1m 46s\tremaining: 45.6s\n",
      "490:\tlearn: 0.9214456\ttotal: 1m 46s\tremaining: 45.4s\n",
      "491:\tlearn: 0.9213855\ttotal: 1m 46s\tremaining: 45.2s\n",
      "492:\tlearn: 0.9215352\ttotal: 1m 47s\tremaining: 44.9s\n",
      "493:\tlearn: 0.9215581\ttotal: 1m 47s\tremaining: 44.7s\n",
      "494:\tlearn: 0.9215057\ttotal: 1m 47s\tremaining: 44.5s\n",
      "495:\tlearn: 0.9214828\ttotal: 1m 47s\tremaining: 44.3s\n",
      "496:\tlearn: 0.9214981\ttotal: 1m 47s\tremaining: 44.1s\n",
      "497:\tlearn: 0.9214981\ttotal: 1m 48s\tremaining: 43.8s\n",
      "498:\tlearn: 0.9216402\ttotal: 1m 48s\tremaining: 43.6s\n",
      "499:\tlearn: 0.9215505\ttotal: 1m 48s\tremaining: 43.4s\n",
      "500:\tlearn: 0.9214084\ttotal: 1m 48s\tremaining: 43.2s\n",
      "501:\tlearn: 0.9215057\ttotal: 1m 48s\tremaining: 43s\n",
      "502:\tlearn: 0.9216554\ttotal: 1m 49s\tremaining: 42.8s\n",
      "503:\tlearn: 0.9216478\ttotal: 1m 49s\tremaining: 42.5s\n",
      "504:\tlearn: 0.9217527\ttotal: 1m 49s\tremaining: 42.3s\n",
      "505:\tlearn: 0.9220224\ttotal: 1m 49s\tremaining: 42.1s\n",
      "506:\tlearn: 0.9222168\ttotal: 1m 50s\tremaining: 41.9s\n",
      "507:\tlearn: 0.9222244\ttotal: 1m 50s\tremaining: 41.7s\n",
      "508:\tlearn: 0.9224712\ttotal: 1m 50s\tremaining: 41.4s\n",
      "509:\tlearn: 0.9225982\ttotal: 1m 50s\tremaining: 41.2s\n",
      "510:\tlearn: 0.9222989\ttotal: 1m 50s\tremaining: 41s\n",
      "511:\tlearn: 0.9226954\ttotal: 1m 51s\tremaining: 40.8s\n",
      "512:\tlearn: 0.9229348\ttotal: 1m 51s\tremaining: 40.6s\n",
      "513:\tlearn: 0.9230844\ttotal: 1m 51s\tremaining: 40.4s\n",
      "514:\tlearn: 0.9231966\ttotal: 1m 51s\tremaining: 40.1s\n",
      "515:\tlearn: 0.9230021\ttotal: 1m 51s\tremaining: 39.9s\n",
      "516:\tlearn: 0.9229498\ttotal: 1m 52s\tremaining: 39.7s\n",
      "517:\tlearn: 0.9228301\ttotal: 1m 52s\tremaining: 39.5s\n",
      "518:\tlearn: 0.9229797\ttotal: 1m 52s\tremaining: 39.3s\n",
      "519:\tlearn: 0.9231293\ttotal: 1m 52s\tremaining: 39s\n",
      "520:\tlearn: 0.9234659\ttotal: 1m 53s\tremaining: 38.8s\n",
      "521:\tlearn: 0.9232789\ttotal: 1m 53s\tremaining: 38.6s\n",
      "522:\tlearn: 0.9233238\ttotal: 1m 53s\tremaining: 38.4s\n",
      "523:\tlearn: 0.9234285\ttotal: 1m 53s\tremaining: 38.2s\n",
      "524:\tlearn: 0.9234734\ttotal: 1m 53s\tremaining: 38s\n",
      "525:\tlearn: 0.9235257\ttotal: 1m 54s\tremaining: 37.7s\n",
      "526:\tlearn: 0.9236975\ttotal: 1m 54s\tremaining: 37.5s\n",
      "527:\tlearn: 0.9239146\ttotal: 1m 54s\tremaining: 37.3s\n",
      "528:\tlearn: 0.9238396\ttotal: 1m 54s\tremaining: 37.1s\n",
      "529:\tlearn: 0.9238771\ttotal: 1m 54s\tremaining: 36.9s\n",
      "530:\tlearn: 0.9242137\ttotal: 1m 55s\tremaining: 36.7s\n",
      "531:\tlearn: 0.9242358\ttotal: 1m 55s\tremaining: 36.4s\n",
      "532:\tlearn: 0.9241165\ttotal: 1m 55s\tremaining: 36.2s\n",
      "533:\tlearn: 0.9243559\ttotal: 1m 55s\tremaining: 36s\n",
      "534:\tlearn: 0.9244384\ttotal: 1m 56s\tremaining: 35.8s\n",
      "535:\tlearn: 0.9247521\ttotal: 1m 56s\tremaining: 35.6s\n",
      "536:\tlearn: 0.9248870\ttotal: 1m 56s\tremaining: 35.4s\n",
      "537:\tlearn: 0.9250437\ttotal: 1m 56s\tremaining: 35.1s\n",
      "538:\tlearn: 0.9249538\ttotal: 1m 56s\tremaining: 34.9s\n",
      "539:\tlearn: 0.9252904\ttotal: 1m 57s\tremaining: 34.7s\n",
      "540:\tlearn: 0.9254326\ttotal: 1m 57s\tremaining: 34.5s\n",
      "541:\tlearn: 0.9253354\ttotal: 1m 57s\tremaining: 34.3s\n",
      "542:\tlearn: 0.9254921\ttotal: 1m 57s\tremaining: 34s\n",
      "543:\tlearn: 0.9255821\ttotal: 1m 57s\tremaining: 33.8s\n",
      "544:\tlearn: 0.9257315\ttotal: 1m 58s\tremaining: 33.6s\n",
      "545:\tlearn: 0.9259331\ttotal: 1m 58s\tremaining: 33.4s\n",
      "546:\tlearn: 0.9258881\ttotal: 1m 58s\tremaining: 33.2s\n",
      "547:\tlearn: 0.9259637\ttotal: 1m 58s\tremaining: 33s\n",
      "548:\tlearn: 0.9259187\ttotal: 1m 59s\tremaining: 32.8s\n",
      "549:\tlearn: 0.9260825\ttotal: 1m 59s\tremaining: 32.5s\n",
      "550:\tlearn: 0.9260375\ttotal: 1m 59s\tremaining: 32.3s\n",
      "551:\tlearn: 0.9259781\ttotal: 1m 59s\tremaining: 32.1s\n",
      "552:\tlearn: 0.9259925\ttotal: 1m 59s\tremaining: 31.9s\n",
      "553:\tlearn: 0.9259709\ttotal: 2m\tremaining: 31.7s\n",
      "554:\tlearn: 0.9260988\ttotal: 2m\tremaining: 31.5s\n",
      "555:\tlearn: 0.9260159\ttotal: 2m\tremaining: 31.2s\n",
      "556:\tlearn: 0.9265257\ttotal: 2m\tremaining: 31s\n",
      "557:\tlearn: 0.9265328\ttotal: 2m 1s\tremaining: 30.8s\n",
      "558:\tlearn: 0.9269597\ttotal: 2m 1s\tremaining: 30.6s\n",
      "559:\tlearn: 0.9269218\ttotal: 2m 1s\tremaining: 30.4s\n",
      "560:\tlearn: 0.9270119\ttotal: 2m 1s\tremaining: 30.2s\n",
      "561:\tlearn: 0.9270641\ttotal: 2m 1s\tremaining: 29.9s\n",
      "562:\tlearn: 0.9269597\ttotal: 2m 2s\tremaining: 29.7s\n",
      "563:\tlearn: 0.9270570\ttotal: 2m 2s\tremaining: 29.5s\n",
      "564:\tlearn: 0.9273727\ttotal: 2m 2s\tremaining: 29.3s\n",
      "565:\tlearn: 0.9273276\ttotal: 2m 2s\tremaining: 29.1s\n",
      "566:\tlearn: 0.9272374\ttotal: 2m 3s\tremaining: 28.9s\n",
      "567:\tlearn: 0.9270879\ttotal: 2m 3s\tremaining: 28.6s\n",
      "568:\tlearn: 0.9272444\ttotal: 2m 3s\tremaining: 28.4s\n",
      "569:\tlearn: 0.9273417\ttotal: 2m 3s\tremaining: 28.2s\n",
      "570:\tlearn: 0.9273868\ttotal: 2m 3s\tremaining: 28s\n",
      "571:\tlearn: 0.9273797\ttotal: 2m 4s\tremaining: 27.8s\n",
      "572:\tlearn: 0.9272754\ttotal: 2m 4s\tremaining: 27.6s\n",
      "573:\tlearn: 0.9275461\ttotal: 2m 4s\tremaining: 27.3s\n",
      "574:\tlearn: 0.9274558\ttotal: 2m 4s\tremaining: 27.1s\n",
      "575:\tlearn: 0.9277548\ttotal: 2m 4s\tremaining: 26.9s\n",
      "576:\tlearn: 0.9278902\ttotal: 2m 5s\tremaining: 26.7s\n",
      "577:\tlearn: 0.9280989\ttotal: 2m 5s\tremaining: 26.5s\n",
      "578:\tlearn: 0.9281300\ttotal: 2m 5s\tremaining: 26.3s\n",
      "579:\tlearn: 0.9280397\ttotal: 2m 5s\tremaining: 26s\n",
      "580:\tlearn: 0.9283838\ttotal: 2m 6s\tremaining: 25.8s\n",
      "581:\tlearn: 0.9282343\ttotal: 2m 6s\tremaining: 25.6s\n",
      "582:\tlearn: 0.9281300\ttotal: 2m 6s\tremaining: 25.4s\n",
      "583:\tlearn: 0.9283559\ttotal: 2m 6s\tremaining: 25.2s\n",
      "584:\tlearn: 0.9279284\ttotal: 2m 6s\tremaining: 25s\n",
      "585:\tlearn: 0.9279875\ttotal: 2m 7s\tremaining: 24.7s\n",
      "586:\tlearn: 0.9282725\ttotal: 2m 7s\tremaining: 24.5s\n",
      "587:\tlearn: 0.9285262\ttotal: 2m 7s\tremaining: 24.3s\n",
      "588:\tlearn: 0.9283247\ttotal: 2m 7s\tremaining: 24.1s\n",
      "589:\tlearn: 0.9285853\ttotal: 2m 8s\tremaining: 23.9s\n",
      "590:\tlearn: 0.9285853\ttotal: 2m 8s\tremaining: 23.7s\n",
      "591:\tlearn: 0.9287799\ttotal: 2m 8s\tremaining: 23.4s\n",
      "592:\tlearn: 0.9287938\ttotal: 2m 8s\tremaining: 23.2s\n",
      "593:\tlearn: 0.9286062\ttotal: 2m 8s\tremaining: 23s\n",
      "594:\tlearn: 0.9287799\ttotal: 2m 9s\tremaining: 22.8s\n",
      "595:\tlearn: 0.9287278\ttotal: 2m 9s\tremaining: 22.6s\n",
      "596:\tlearn: 0.9285402\ttotal: 2m 9s\tremaining: 22.4s\n",
      "597:\tlearn: 0.9289676\ttotal: 2m 9s\tremaining: 22.1s\n",
      "598:\tlearn: 0.9290649\ttotal: 2m 9s\tremaining: 21.9s\n",
      "599:\tlearn: 0.9292005\ttotal: 2m 10s\tremaining: 21.7s\n",
      "600:\tlearn: 0.9293952\ttotal: 2m 10s\tremaining: 21.5s\n",
      "601:\tlearn: 0.9293499\ttotal: 2m 10s\tremaining: 21.3s\n",
      "602:\tlearn: 0.9294993\ttotal: 2m 10s\tremaining: 21.1s\n",
      "603:\tlearn: 0.9294541\ttotal: 2m 11s\tremaining: 20.8s\n",
      "604:\tlearn: 0.9295967\ttotal: 2m 11s\tremaining: 20.6s\n",
      "605:\tlearn: 0.9294541\ttotal: 2m 11s\tremaining: 20.4s\n",
      "606:\tlearn: 0.9296035\ttotal: 2m 11s\tremaining: 20.2s\n",
      "607:\tlearn: 0.9296624\ttotal: 2m 11s\tremaining: 20s\n",
      "608:\tlearn: 0.9299022\ttotal: 2m 12s\tremaining: 19.7s\n",
      "609:\tlearn: 0.9299159\ttotal: 2m 12s\tremaining: 19.5s\n",
      "610:\tlearn: 0.9297597\ttotal: 2m 12s\tremaining: 19.3s\n",
      "611:\tlearn: 0.9298570\ttotal: 2m 12s\tremaining: 19.1s\n",
      "612:\tlearn: 0.9299022\ttotal: 2m 13s\tremaining: 18.9s\n",
      "613:\tlearn: 0.9297913\ttotal: 2m 13s\tremaining: 18.7s\n",
      "614:\tlearn: 0.9300379\ttotal: 2m 13s\tremaining: 18.4s\n",
      "615:\tlearn: 0.9301285\ttotal: 2m 13s\tremaining: 18.2s\n",
      "616:\tlearn: 0.9301737\ttotal: 2m 13s\tremaining: 18s\n",
      "617:\tlearn: 0.9301873\ttotal: 2m 14s\tremaining: 17.8s\n",
      "618:\tlearn: 0.9302009\ttotal: 2m 14s\tremaining: 17.6s\n",
      "619:\tlearn: 0.9303751\ttotal: 2m 14s\tremaining: 17.4s\n",
      "620:\tlearn: 0.9301941\ttotal: 2m 14s\tremaining: 17.1s\n",
      "621:\tlearn: 0.9302914\ttotal: 2m 14s\tremaining: 16.9s\n",
      "622:\tlearn: 0.9302846\ttotal: 2m 15s\tremaining: 16.7s\n",
      "623:\tlearn: 0.9304475\ttotal: 2m 15s\tremaining: 16.5s\n",
      "624:\tlearn: 0.9302529\ttotal: 2m 15s\tremaining: 16.3s\n",
      "625:\tlearn: 0.9302982\ttotal: 2m 15s\tremaining: 16.1s\n",
      "626:\tlearn: 0.9303434\ttotal: 2m 16s\tremaining: 15.8s\n",
      "627:\tlearn: 0.9305380\ttotal: 2m 16s\tremaining: 15.6s\n",
      "628:\tlearn: 0.9306420\ttotal: 2m 16s\tremaining: 15.4s\n",
      "629:\tlearn: 0.9307258\ttotal: 2m 16s\tremaining: 15.2s\n",
      "630:\tlearn: 0.9306353\ttotal: 2m 16s\tremaining: 15s\n",
      "631:\tlearn: 0.9309271\ttotal: 2m 17s\tremaining: 14.8s\n",
      "632:\tlearn: 0.9308298\ttotal: 2m 17s\tremaining: 14.5s\n",
      "633:\tlearn: 0.9308751\ttotal: 2m 17s\tremaining: 14.3s\n",
      "634:\tlearn: 0.9311150\ttotal: 2m 17s\tremaining: 14.1s\n",
      "635:\tlearn: 0.9313096\ttotal: 2m 18s\tremaining: 13.9s\n",
      "636:\tlearn: 0.9314909\ttotal: 2m 18s\tremaining: 13.7s\n",
      "637:\tlearn: 0.9316921\ttotal: 2m 18s\tremaining: 13.5s\n",
      "638:\tlearn: 0.9317375\ttotal: 2m 18s\tremaining: 13.3s\n",
      "639:\tlearn: 0.9318348\ttotal: 2m 19s\tremaining: 13s\n",
      "640:\tlearn: 0.9317507\ttotal: 2m 19s\tremaining: 12.8s\n",
      "641:\tlearn: 0.9318934\ttotal: 2m 19s\tremaining: 12.6s\n",
      "642:\tlearn: 0.9321333\ttotal: 2m 19s\tremaining: 12.4s\n",
      "643:\tlearn: 0.9322438\ttotal: 2m 19s\tremaining: 12.2s\n",
      "644:\tlearn: 0.9322957\ttotal: 2m 20s\tremaining: 11.9s\n",
      "645:\tlearn: 0.9324581\ttotal: 2m 20s\tremaining: 11.7s\n",
      "646:\tlearn: 0.9325553\ttotal: 2m 20s\tremaining: 11.5s\n",
      "647:\tlearn: 0.9327045\ttotal: 2m 20s\tremaining: 11.3s\n",
      "648:\tlearn: 0.9328082\ttotal: 2m 20s\tremaining: 11.1s\n",
      "649:\tlearn: 0.9327045\ttotal: 2m 21s\tremaining: 10.9s\n",
      "650:\tlearn: 0.9329185\ttotal: 2m 21s\tremaining: 10.6s\n",
      "651:\tlearn: 0.9331518\ttotal: 2m 21s\tremaining: 10.4s\n",
      "652:\tlearn: 0.9332037\ttotal: 2m 21s\tremaining: 10.2s\n",
      "653:\tlearn: 0.9331388\ttotal: 2m 22s\tremaining: 9.99s\n",
      "654:\tlearn: 0.9332361\ttotal: 2m 22s\tremaining: 9.77s\n",
      "655:\tlearn: 0.9332944\ttotal: 2m 22s\tremaining: 9.56s\n",
      "656:\tlearn: 0.9334306\ttotal: 2m 22s\tremaining: 9.34s\n",
      "657:\tlearn: 0.9334435\ttotal: 2m 22s\tremaining: 9.12s\n",
      "658:\tlearn: 0.9335797\ttotal: 2m 23s\tremaining: 8.9s\n",
      "659:\tlearn: 0.9337288\ttotal: 2m 23s\tremaining: 8.69s\n",
      "660:\tlearn: 0.9334760\ttotal: 2m 23s\tremaining: 8.47s\n",
      "661:\tlearn: 0.9337159\ttotal: 2m 23s\tremaining: 8.25s\n",
      "662:\tlearn: 0.9338521\ttotal: 2m 24s\tremaining: 8.04s\n",
      "663:\tlearn: 0.9338003\ttotal: 2m 24s\tremaining: 7.82s\n",
      "664:\tlearn: 0.9338650\ttotal: 2m 24s\tremaining: 7.6s\n",
      "665:\tlearn: 0.9339104\ttotal: 2m 24s\tremaining: 7.39s\n",
      "666:\tlearn: 0.9339558\ttotal: 2m 24s\tremaining: 7.17s\n",
      "667:\tlearn: 0.9339623\ttotal: 2m 25s\tremaining: 6.95s\n",
      "668:\tlearn: 0.9341376\ttotal: 2m 25s\tremaining: 6.73s\n",
      "669:\tlearn: 0.9341958\ttotal: 2m 25s\tremaining: 6.52s\n",
      "670:\tlearn: 0.9342931\ttotal: 2m 25s\tremaining: 6.3s\n",
      "671:\tlearn: 0.9341178\ttotal: 2m 26s\tremaining: 6.08s\n",
      "672:\tlearn: 0.9342995\ttotal: 2m 26s\tremaining: 5.87s\n",
      "673:\tlearn: 0.9346040\ttotal: 2m 26s\tremaining: 5.65s\n",
      "674:\tlearn: 0.9346040\ttotal: 2m 26s\tremaining: 5.43s\n",
      "675:\tlearn: 0.9345585\ttotal: 2m 26s\tremaining: 5.21s\n",
      "676:\tlearn: 0.9346167\ttotal: 2m 27s\tremaining: 5s\n",
      "677:\tlearn: 0.9348439\ttotal: 2m 27s\tremaining: 4.78s\n",
      "678:\tlearn: 0.9347594\ttotal: 2m 27s\tremaining: 4.56s\n",
      "679:\tlearn: 0.9349412\ttotal: 2m 27s\tremaining: 4.34s\n",
      "680:\tlearn: 0.9349866\ttotal: 2m 27s\tremaining: 4.13s\n",
      "681:\tlearn: 0.9348957\ttotal: 2m 28s\tremaining: 3.91s\n",
      "682:\tlearn: 0.9351874\ttotal: 2m 28s\tremaining: 3.69s\n",
      "683:\tlearn: 0.9351874\ttotal: 2m 28s\tremaining: 3.48s\n",
      "684:\tlearn: 0.9352266\ttotal: 2m 28s\tremaining: 3.26s\n",
      "685:\tlearn: 0.9353176\ttotal: 2m 29s\tremaining: 3.04s\n",
      "686:\tlearn: 0.9351357\ttotal: 2m 29s\tremaining: 2.82s\n",
      "687:\tlearn: 0.9352721\ttotal: 2m 29s\tremaining: 2.61s\n",
      "688:\tlearn: 0.9353239\ttotal: 2m 29s\tremaining: 2.39s\n",
      "689:\tlearn: 0.9355058\ttotal: 2m 29s\tremaining: 2.17s\n",
      "690:\tlearn: 0.9355513\ttotal: 2m 30s\tremaining: 1.96s\n",
      "691:\tlearn: 0.9357977\ttotal: 2m 30s\tremaining: 1.74s\n",
      "692:\tlearn: 0.9357977\ttotal: 2m 30s\tremaining: 1.52s\n",
      "693:\tlearn: 0.9360771\ttotal: 2m 30s\tremaining: 1.3s\n",
      "694:\tlearn: 0.9361288\ttotal: 2m 30s\tremaining: 1.09s\n",
      "695:\tlearn: 0.9360440\ttotal: 2m 31s\tremaining: 869ms\n",
      "696:\tlearn: 0.9360440\ttotal: 2m 31s\tremaining: 652ms\n",
      "697:\tlearn: 0.9359012\ttotal: 2m 31s\tremaining: 434ms\n",
      "698:\tlearn: 0.9359984\ttotal: 2m 31s\tremaining: 217ms\n",
      "699:\tlearn: 0.9360502\ttotal: 2m 32s\tremaining: 0us\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=8, eval_metric=F1, iterations=700, l2_leaf_reg=3, leaf_estimation_method=Newton, learning_rate=0.01, random_strength=1; total time= 2.5min\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=10, eval_metric=AUC, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Exact, learning_rate=0.7, random_strength=0.5; total time=   0.0s\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=10, eval_metric=AUC, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Exact, learning_rate=0.7, random_strength=0.5; total time=   0.0s\n",
      "[CV] END auto_class_weights=None, bagging_temperature=0.1, border_count=160, depth=10, eval_metric=AUC, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Exact, learning_rate=0.7, random_strength=0.5; total time=   0.0s\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=14, eval_metric=Logloss, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Exact, learning_rate=0.1, random_strength=0; total time=   0.0s\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=14, eval_metric=Logloss, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Exact, learning_rate=0.1, random_strength=0; total time=   0.0s\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0, border_count=128, depth=14, eval_metric=Logloss, iterations=600, l2_leaf_reg=9, leaf_estimation_method=Exact, learning_rate=0.1, random_strength=0; total time=   0.0s\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=64, depth=9, eval_metric=Precision, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=5; total time=   0.0s\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=64, depth=9, eval_metric=Precision, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=5; total time=   0.2s\n",
      "[CV] END auto_class_weights=None, bagging_temperature=5, border_count=64, depth=9, eval_metric=Precision, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Exact, learning_rate=0.3, random_strength=5; total time=   0.0s\n",
      "0:\tlearn: 0.7969225\ttotal: 30.8ms\tremaining: 12.3s\n",
      "1:\tlearn: 0.6451711\ttotal: 64.1ms\tremaining: 12.8s\n",
      "2:\tlearn: 0.6283661\ttotal: 95.6ms\tremaining: 12.6s\n",
      "3:\tlearn: 0.6415266\ttotal: 128ms\tremaining: 12.6s\n",
      "4:\tlearn: 0.6524600\ttotal: 158ms\tremaining: 12.5s\n",
      "5:\tlearn: 0.6448674\ttotal: 189ms\tremaining: 12.4s\n",
      "6:\tlearn: 0.6493217\ttotal: 222ms\tremaining: 12.5s\n",
      "7:\tlearn: 0.6577242\ttotal: 255ms\tremaining: 12.5s\n",
      "8:\tlearn: 0.6591415\ttotal: 288ms\tremaining: 12.5s\n",
      "9:\tlearn: 0.6467908\ttotal: 322ms\tremaining: 12.5s\n",
      "10:\tlearn: 0.6568131\ttotal: 353ms\tremaining: 12.5s\n",
      "11:\tlearn: 0.6581292\ttotal: 386ms\tremaining: 12.5s\n",
      "12:\tlearn: 0.6644058\ttotal: 418ms\tremaining: 12.5s\n",
      "13:\tlearn: 0.6694675\ttotal: 449ms\tremaining: 12.4s\n",
      "14:\tlearn: 0.6663292\ttotal: 483ms\tremaining: 12.4s\n",
      "15:\tlearn: 0.6686576\ttotal: 515ms\tremaining: 12.3s\n",
      "16:\tlearn: 0.6671391\ttotal: 545ms\tremaining: 12.3s\n",
      "17:\tlearn: 0.6712897\ttotal: 575ms\tremaining: 12.2s\n",
      "18:\tlearn: 0.6696700\ttotal: 609ms\tremaining: 12.2s\n",
      "19:\tlearn: 0.6684552\ttotal: 639ms\tremaining: 12.1s\n",
      "20:\tlearn: 0.6691638\ttotal: 672ms\tremaining: 12.1s\n",
      "21:\tlearn: 0.6673416\ttotal: 704ms\tremaining: 12.1s\n",
      "22:\tlearn: 0.6679490\ttotal: 738ms\tremaining: 12.1s\n",
      "23:\tlearn: 0.6719984\ttotal: 769ms\tremaining: 12s\n",
      "24:\tlearn: 0.6743268\ttotal: 797ms\tremaining: 12s\n",
      "25:\tlearn: 0.6769589\ttotal: 828ms\tremaining: 11.9s\n",
      "26:\tlearn: 0.6828305\ttotal: 858ms\tremaining: 11.9s\n",
      "27:\tlearn: 0.6864750\ttotal: 889ms\tremaining: 11.8s\n",
      "28:\tlearn: 0.6817169\ttotal: 922ms\tremaining: 11.8s\n",
      "29:\tlearn: 0.6837416\ttotal: 956ms\tremaining: 11.8s\n",
      "30:\tlearn: 0.6847540\ttotal: 987ms\tremaining: 11.7s\n",
      "31:\tlearn: 0.6818182\ttotal: 1.02s\tremaining: 11.7s\n",
      "32:\tlearn: 0.6873861\ttotal: 1.05s\tremaining: 11.7s\n",
      "33:\tlearn: 0.6895120\ttotal: 1.08s\tremaining: 11.6s\n",
      "34:\tlearn: 0.6920429\ttotal: 1.11s\tremaining: 11.6s\n",
      "35:\tlearn: 0.6949787\ttotal: 1.15s\tremaining: 11.6s\n",
      "36:\tlearn: 0.6940676\ttotal: 1.18s\tremaining: 11.6s\n",
      "37:\tlearn: 0.6907269\ttotal: 1.22s\tremaining: 11.6s\n",
      "38:\tlearn: 0.6939664\ttotal: 1.25s\tremaining: 11.5s\n",
      "39:\tlearn: 0.6922454\ttotal: 1.28s\tremaining: 11.5s\n",
      "40:\tlearn: 0.6918405\ttotal: 1.31s\tremaining: 11.5s\n",
      "41:\tlearn: 0.6907269\ttotal: 1.34s\tremaining: 11.4s\n",
      "42:\tlearn: 0.6911318\ttotal: 1.38s\tremaining: 11.4s\n",
      "43:\tlearn: 0.6915367\ttotal: 1.41s\tremaining: 11.4s\n",
      "44:\tlearn: 0.6915367\ttotal: 1.44s\tremaining: 11.4s\n",
      "45:\tlearn: 0.6909293\ttotal: 1.48s\tremaining: 11.4s\n",
      "46:\tlearn: 0.6975096\ttotal: 1.51s\tremaining: 11.4s\n",
      "47:\tlearn: 0.6940676\ttotal: 1.55s\tremaining: 11.3s\n",
      "48:\tlearn: 0.6947763\ttotal: 1.58s\tremaining: 11.3s\n",
      "49:\tlearn: 0.6955862\ttotal: 1.61s\tremaining: 11.3s\n",
      "50:\tlearn: 0.6985220\ttotal: 1.64s\tremaining: 11.2s\n",
      "51:\tlearn: 0.6987244\ttotal: 1.67s\tremaining: 11.2s\n",
      "52:\tlearn: 0.7034825\ttotal: 1.71s\tremaining: 11.2s\n",
      "53:\tlearn: 0.7021664\ttotal: 1.74s\tremaining: 11.2s\n",
      "54:\tlearn: 0.6999393\ttotal: 1.77s\tremaining: 11.1s\n",
      "55:\tlearn: 0.7027738\ttotal: 1.8s\tremaining: 11.1s\n",
      "56:\tlearn: 0.7043936\ttotal: 1.84s\tremaining: 11.1s\n",
      "57:\tlearn: 0.7059121\ttotal: 1.87s\tremaining: 11s\n",
      "58:\tlearn: 0.7045961\ttotal: 1.9s\tremaining: 11s\n",
      "59:\tlearn: 0.7056084\ttotal: 1.93s\tremaining: 10.9s\n",
      "60:\tlearn: 0.7046973\ttotal: 1.96s\tremaining: 10.9s\n",
      "61:\tlearn: 0.7039887\ttotal: 2s\tremaining: 10.9s\n",
      "62:\tlearn: 0.7046973\ttotal: 2.03s\tremaining: 10.8s\n",
      "63:\tlearn: 0.7042924\ttotal: 2.06s\tremaining: 10.8s\n",
      "64:\tlearn: 0.7045961\ttotal: 2.09s\tremaining: 10.8s\n",
      "65:\tlearn: 0.7042924\ttotal: 2.12s\tremaining: 10.7s\n",
      "66:\tlearn: 0.7047985\ttotal: 2.15s\tremaining: 10.7s\n",
      "67:\tlearn: 0.7044948\ttotal: 2.19s\tremaining: 10.7s\n",
      "68:\tlearn: 0.7037862\ttotal: 2.22s\tremaining: 10.7s\n",
      "69:\tlearn: 0.7043936\ttotal: 2.25s\tremaining: 10.6s\n",
      "70:\tlearn: 0.7047985\ttotal: 2.29s\tremaining: 10.6s\n",
      "71:\tlearn: 0.7061146\ttotal: 2.32s\tremaining: 10.6s\n",
      "72:\tlearn: 0.7063171\ttotal: 2.35s\tremaining: 10.5s\n",
      "73:\tlearn: 0.7081393\ttotal: 2.38s\tremaining: 10.5s\n",
      "74:\tlearn: 0.7070257\ttotal: 2.41s\tremaining: 10.4s\n",
      "75:\tlearn: 0.7057097\ttotal: 2.44s\tremaining: 10.4s\n",
      "76:\tlearn: 0.7060134\ttotal: 2.48s\tremaining: 10.4s\n",
      "77:\tlearn: 0.7058109\ttotal: 2.51s\tremaining: 10.4s\n",
      "78:\tlearn: 0.7056084\ttotal: 2.54s\tremaining: 10.3s\n",
      "79:\tlearn: 0.7082405\ttotal: 2.57s\tremaining: 10.3s\n",
      "80:\tlearn: 0.7103665\ttotal: 2.61s\tremaining: 10.3s\n",
      "81:\tlearn: 0.7112776\ttotal: 2.64s\tremaining: 10.2s\n",
      "82:\tlearn: 0.7123912\ttotal: 2.67s\tremaining: 10.2s\n",
      "83:\tlearn: 0.7114801\ttotal: 2.7s\tremaining: 10.2s\n",
      "84:\tlearn: 0.7126949\ttotal: 2.73s\tremaining: 10.1s\n",
      "85:\tlearn: 0.7144159\ttotal: 2.77s\tremaining: 10.1s\n",
      "86:\tlearn: 0.7156307\ttotal: 2.8s\tremaining: 10.1s\n",
      "87:\tlearn: 0.7133023\ttotal: 2.83s\tremaining: 10s\n",
      "88:\tlearn: 0.7139097\ttotal: 2.87s\tremaining: 10s\n",
      "89:\tlearn: 0.7167443\ttotal: 2.9s\tremaining: 9.97s\n",
      "90:\tlearn: 0.7162381\ttotal: 2.93s\tremaining: 9.94s\n",
      "91:\tlearn: 0.7149220\ttotal: 2.96s\tremaining: 9.9s\n",
      "92:\tlearn: 0.7143146\ttotal: 2.99s\tremaining: 9.86s\n",
      "93:\tlearn: 0.7142134\ttotal: 3.02s\tremaining: 9.84s\n",
      "94:\tlearn: 0.7148208\ttotal: 3.05s\tremaining: 9.8s\n",
      "95:\tlearn: 0.7175542\ttotal: 3.08s\tremaining: 9.77s\n",
      "96:\tlearn: 0.7166430\ttotal: 3.12s\tremaining: 9.73s\n",
      "97:\tlearn: 0.7137072\ttotal: 3.15s\tremaining: 9.71s\n",
      "98:\tlearn: 0.7142134\ttotal: 3.18s\tremaining: 9.67s\n",
      "99:\tlearn: 0.7143146\ttotal: 3.21s\tremaining: 9.63s\n",
      "100:\tlearn: 0.7154282\ttotal: 3.24s\tremaining: 9.6s\n",
      "101:\tlearn: 0.7147196\ttotal: 3.27s\tremaining: 9.56s\n",
      "102:\tlearn: 0.7135048\ttotal: 3.3s\tremaining: 9.52s\n",
      "103:\tlearn: 0.7150233\ttotal: 3.34s\tremaining: 9.5s\n",
      "104:\tlearn: 0.7154282\ttotal: 3.37s\tremaining: 9.46s\n",
      "105:\tlearn: 0.7138085\ttotal: 3.4s\tremaining: 9.43s\n",
      "106:\tlearn: 0.7145171\ttotal: 3.43s\tremaining: 9.39s\n",
      "107:\tlearn: 0.7137072\ttotal: 3.46s\tremaining: 9.36s\n",
      "108:\tlearn: 0.7143146\ttotal: 3.49s\tremaining: 9.32s\n",
      "109:\tlearn: 0.7158332\ttotal: 3.52s\tremaining: 9.29s\n",
      "110:\tlearn: 0.7137072\ttotal: 3.55s\tremaining: 9.25s\n",
      "111:\tlearn: 0.7126949\ttotal: 3.59s\tremaining: 9.24s\n",
      "112:\tlearn: 0.7121887\ttotal: 3.63s\tremaining: 9.21s\n",
      "113:\tlearn: 0.7128973\ttotal: 3.65s\tremaining: 9.17s\n",
      "114:\tlearn: 0.7141122\ttotal: 3.69s\tremaining: 9.13s\n",
      "115:\tlearn: 0.7134035\ttotal: 3.72s\tremaining: 9.1s\n",
      "116:\tlearn: 0.7142134\ttotal: 3.75s\tremaining: 9.07s\n",
      "117:\tlearn: 0.7138085\ttotal: 3.78s\tremaining: 9.04s\n",
      "118:\tlearn: 0.7135048\ttotal: 3.81s\tremaining: 9.01s\n",
      "119:\tlearn: 0.7139097\ttotal: 3.85s\tremaining: 8.98s\n",
      "120:\tlearn: 0.7145171\ttotal: 3.88s\tremaining: 8.94s\n",
      "121:\tlearn: 0.7146183\ttotal: 3.91s\tremaining: 8.91s\n",
      "122:\tlearn: 0.7135048\ttotal: 3.95s\tremaining: 8.89s\n",
      "123:\tlearn: 0.7138085\ttotal: 3.98s\tremaining: 8.85s\n",
      "124:\tlearn: 0.7126949\ttotal: 4.01s\tremaining: 8.82s\n",
      "125:\tlearn: 0.7108726\ttotal: 4.04s\tremaining: 8.79s\n",
      "126:\tlearn: 0.7125936\ttotal: 4.08s\tremaining: 8.76s\n",
      "127:\tlearn: 0.7118850\ttotal: 4.11s\tremaining: 8.73s\n",
      "128:\tlearn: 0.7119862\ttotal: 4.14s\tremaining: 8.7s\n",
      "129:\tlearn: 0.7135048\ttotal: 4.17s\tremaining: 8.66s\n",
      "130:\tlearn: 0.7123912\ttotal: 4.2s\tremaining: 8.63s\n",
      "131:\tlearn: 0.7148208\ttotal: 4.23s\tremaining: 8.59s\n",
      "132:\tlearn: 0.7152258\ttotal: 4.26s\tremaining: 8.56s\n",
      "133:\tlearn: 0.7176554\ttotal: 4.29s\tremaining: 8.52s\n",
      "134:\tlearn: 0.7168455\ttotal: 4.33s\tremaining: 8.49s\n",
      "135:\tlearn: 0.7153270\ttotal: 4.36s\tremaining: 8.46s\n",
      "136:\tlearn: 0.7146183\ttotal: 4.39s\tremaining: 8.44s\n",
      "137:\tlearn: 0.7139097\ttotal: 4.42s\tremaining: 8.4s\n",
      "138:\tlearn: 0.7147196\ttotal: 4.45s\tremaining: 8.36s\n",
      "139:\tlearn: 0.7137072\ttotal: 4.48s\tremaining: 8.33s\n",
      "140:\tlearn: 0.7144159\ttotal: 4.52s\tremaining: 8.3s\n",
      "141:\tlearn: 0.7141122\ttotal: 4.55s\tremaining: 8.27s\n",
      "142:\tlearn: 0.7159344\ttotal: 4.58s\tremaining: 8.23s\n",
      "143:\tlearn: 0.7161369\ttotal: 4.61s\tremaining: 8.2s\n",
      "144:\tlearn: 0.7161369\ttotal: 4.64s\tremaining: 8.16s\n",
      "145:\tlearn: 0.7172505\ttotal: 4.67s\tremaining: 8.13s\n",
      "146:\tlearn: 0.7174529\ttotal: 4.7s\tremaining: 8.1s\n",
      "147:\tlearn: 0.7182628\ttotal: 4.73s\tremaining: 8.06s\n",
      "148:\tlearn: 0.7188702\ttotal: 4.77s\tremaining: 8.03s\n",
      "149:\tlearn: 0.7187690\ttotal: 4.8s\tremaining: 7.99s\n",
      "150:\tlearn: 0.7188702\ttotal: 4.83s\tremaining: 7.96s\n",
      "151:\tlearn: 0.7188702\ttotal: 4.86s\tremaining: 7.92s\n",
      "152:\tlearn: 0.7188702\ttotal: 4.89s\tremaining: 7.89s\n",
      "153:\tlearn: 0.7186677\ttotal: 4.92s\tremaining: 7.86s\n",
      "154:\tlearn: 0.7176554\ttotal: 4.95s\tremaining: 7.83s\n",
      "155:\tlearn: 0.7200850\ttotal: 4.99s\tremaining: 7.8s\n",
      "156:\tlearn: 0.7193764\ttotal: 5.01s\tremaining: 7.76s\n",
      "157:\tlearn: 0.7189715\ttotal: 5.04s\tremaining: 7.73s\n",
      "158:\tlearn: 0.7184653\ttotal: 5.08s\tremaining: 7.69s\n",
      "159:\tlearn: 0.7193764\ttotal: 5.11s\tremaining: 7.66s\n",
      "160:\tlearn: 0.7205912\ttotal: 5.14s\tremaining: 7.63s\n",
      "161:\tlearn: 0.7214011\ttotal: 5.17s\tremaining: 7.6s\n",
      "162:\tlearn: 0.7211986\ttotal: 5.21s\tremaining: 7.57s\n",
      "163:\tlearn: 0.7205912\ttotal: 5.24s\tremaining: 7.53s\n",
      "164:\tlearn: 0.7210974\ttotal: 5.26s\tremaining: 7.5s\n",
      "165:\tlearn: 0.7215023\ttotal: 5.29s\tremaining: 7.46s\n",
      "166:\tlearn: 0.7215023\ttotal: 5.32s\tremaining: 7.43s\n",
      "167:\tlearn: 0.7203887\ttotal: 5.35s\tremaining: 7.39s\n",
      "168:\tlearn: 0.7201863\ttotal: 5.39s\tremaining: 7.36s\n",
      "169:\tlearn: 0.7206924\ttotal: 5.42s\tremaining: 7.33s\n",
      "170:\tlearn: 0.7201863\ttotal: 5.45s\tremaining: 7.29s\n",
      "171:\tlearn: 0.7192752\ttotal: 5.48s\tremaining: 7.26s\n",
      "172:\tlearn: 0.7199838\ttotal: 5.51s\tremaining: 7.23s\n",
      "173:\tlearn: 0.7197813\ttotal: 5.54s\tremaining: 7.2s\n",
      "174:\tlearn: 0.7190727\ttotal: 5.57s\tremaining: 7.16s\n",
      "175:\tlearn: 0.7193764\ttotal: 5.6s\tremaining: 7.13s\n",
      "176:\tlearn: 0.7197813\ttotal: 5.64s\tremaining: 7.1s\n",
      "177:\tlearn: 0.7209962\ttotal: 5.67s\tremaining: 7.07s\n",
      "178:\tlearn: 0.7211986\ttotal: 5.71s\tremaining: 7.04s\n",
      "179:\tlearn: 0.7208949\ttotal: 5.74s\tremaining: 7.01s\n",
      "180:\tlearn: 0.7220085\ttotal: 5.77s\tremaining: 6.98s\n",
      "181:\tlearn: 0.7217048\ttotal: 5.8s\tremaining: 6.95s\n",
      "182:\tlearn: 0.7206924\ttotal: 5.83s\tremaining: 6.92s\n",
      "183:\tlearn: 0.7183640\ttotal: 5.87s\tremaining: 6.89s\n",
      "184:\tlearn: 0.7186677\ttotal: 5.9s\tremaining: 6.86s\n",
      "185:\tlearn: 0.7183640\ttotal: 5.93s\tremaining: 6.83s\n",
      "186:\tlearn: 0.7182628\ttotal: 5.96s\tremaining: 6.79s\n",
      "187:\tlearn: 0.7170480\ttotal: 6s\tremaining: 6.76s\n",
      "188:\tlearn: 0.7170480\ttotal: 6.03s\tremaining: 6.73s\n",
      "189:\tlearn: 0.7168455\ttotal: 6.06s\tremaining: 6.7s\n",
      "190:\tlearn: 0.7181616\ttotal: 6.09s\tremaining: 6.67s\n",
      "191:\tlearn: 0.7184653\ttotal: 6.12s\tremaining: 6.63s\n",
      "192:\tlearn: 0.7177566\ttotal: 6.16s\tremaining: 6.6s\n",
      "193:\tlearn: 0.7170480\ttotal: 6.19s\tremaining: 6.57s\n",
      "194:\tlearn: 0.7178579\ttotal: 6.22s\tremaining: 6.54s\n",
      "195:\tlearn: 0.7176554\ttotal: 6.25s\tremaining: 6.5s\n",
      "196:\tlearn: 0.7192752\ttotal: 6.28s\tremaining: 6.47s\n",
      "197:\tlearn: 0.7185665\ttotal: 6.31s\tremaining: 6.44s\n",
      "198:\tlearn: 0.7186677\ttotal: 6.35s\tremaining: 6.41s\n",
      "199:\tlearn: 0.7178579\ttotal: 6.38s\tremaining: 6.38s\n",
      "200:\tlearn: 0.7185665\ttotal: 6.41s\tremaining: 6.34s\n",
      "201:\tlearn: 0.7177566\ttotal: 6.44s\tremaining: 6.31s\n",
      "202:\tlearn: 0.7185665\ttotal: 6.47s\tremaining: 6.28s\n",
      "203:\tlearn: 0.7176554\ttotal: 6.5s\tremaining: 6.25s\n",
      "204:\tlearn: 0.7170480\ttotal: 6.54s\tremaining: 6.22s\n",
      "205:\tlearn: 0.7188702\ttotal: 6.57s\tremaining: 6.18s\n",
      "206:\tlearn: 0.7186677\ttotal: 6.6s\tremaining: 6.15s\n",
      "207:\tlearn: 0.7193764\ttotal: 6.63s\tremaining: 6.12s\n",
      "208:\tlearn: 0.7199838\ttotal: 6.66s\tremaining: 6.08s\n",
      "209:\tlearn: 0.7187690\ttotal: 6.69s\tremaining: 6.05s\n",
      "210:\tlearn: 0.7194776\ttotal: 6.72s\tremaining: 6.02s\n",
      "211:\tlearn: 0.7177566\ttotal: 6.75s\tremaining: 5.99s\n",
      "212:\tlearn: 0.7181616\ttotal: 6.79s\tremaining: 5.96s\n",
      "213:\tlearn: 0.7179591\ttotal: 6.82s\tremaining: 5.92s\n",
      "214:\tlearn: 0.7179591\ttotal: 6.85s\tremaining: 5.89s\n",
      "215:\tlearn: 0.7169468\ttotal: 6.88s\tremaining: 5.86s\n",
      "216:\tlearn: 0.7173517\ttotal: 6.91s\tremaining: 5.83s\n",
      "217:\tlearn: 0.7184653\ttotal: 6.94s\tremaining: 5.8s\n",
      "218:\tlearn: 0.7189715\ttotal: 6.97s\tremaining: 5.76s\n",
      "219:\tlearn: 0.7190727\ttotal: 7s\tremaining: 5.73s\n",
      "220:\tlearn: 0.7203887\ttotal: 7.04s\tremaining: 5.7s\n",
      "221:\tlearn: 0.7191739\ttotal: 7.07s\tremaining: 5.67s\n",
      "222:\tlearn: 0.7190727\ttotal: 7.1s\tremaining: 5.63s\n",
      "223:\tlearn: 0.7197813\ttotal: 7.13s\tremaining: 5.6s\n",
      "224:\tlearn: 0.7189715\ttotal: 7.16s\tremaining: 5.57s\n",
      "225:\tlearn: 0.7208949\ttotal: 7.2s\tremaining: 5.54s\n",
      "226:\tlearn: 0.7198826\ttotal: 7.23s\tremaining: 5.51s\n",
      "227:\tlearn: 0.7215023\ttotal: 7.26s\tremaining: 5.48s\n",
      "228:\tlearn: 0.7207937\ttotal: 7.29s\tremaining: 5.45s\n",
      "229:\tlearn: 0.7206924\ttotal: 7.32s\tremaining: 5.41s\n",
      "230:\tlearn: 0.7215023\ttotal: 7.36s\tremaining: 5.38s\n",
      "231:\tlearn: 0.7218060\ttotal: 7.4s\tremaining: 5.36s\n",
      "232:\tlearn: 0.7218060\ttotal: 7.43s\tremaining: 5.33s\n",
      "233:\tlearn: 0.7215023\ttotal: 7.47s\tremaining: 5.3s\n",
      "234:\tlearn: 0.7218060\ttotal: 7.5s\tremaining: 5.26s\n",
      "235:\tlearn: 0.7222110\ttotal: 7.53s\tremaining: 5.23s\n",
      "236:\tlearn: 0.7222110\ttotal: 7.56s\tremaining: 5.2s\n",
      "237:\tlearn: 0.7217048\ttotal: 7.59s\tremaining: 5.17s\n",
      "238:\tlearn: 0.7229196\ttotal: 7.62s\tremaining: 5.13s\n",
      "239:\tlearn: 0.7227171\ttotal: 7.65s\tremaining: 5.1s\n",
      "240:\tlearn: 0.7237295\ttotal: 7.68s\tremaining: 5.07s\n",
      "241:\tlearn: 0.7244381\ttotal: 7.71s\tremaining: 5.04s\n",
      "242:\tlearn: 0.7243369\ttotal: 7.74s\tremaining: 5s\n",
      "243:\tlearn: 0.7247419\ttotal: 7.77s\tremaining: 4.97s\n",
      "244:\tlearn: 0.7265641\ttotal: 7.81s\tremaining: 4.94s\n",
      "245:\tlearn: 0.7261591\ttotal: 7.84s\tremaining: 4.91s\n",
      "246:\tlearn: 0.7261591\ttotal: 7.87s\tremaining: 4.87s\n",
      "247:\tlearn: 0.7258554\ttotal: 7.9s\tremaining: 4.84s\n",
      "248:\tlearn: 0.7265641\ttotal: 7.93s\tremaining: 4.81s\n",
      "249:\tlearn: 0.7257542\ttotal: 7.96s\tremaining: 4.78s\n",
      "250:\tlearn: 0.7262604\ttotal: 7.99s\tremaining: 4.74s\n",
      "251:\tlearn: 0.7271715\ttotal: 8.02s\tremaining: 4.71s\n",
      "252:\tlearn: 0.7261591\ttotal: 8.06s\tremaining: 4.68s\n",
      "253:\tlearn: 0.7251468\ttotal: 8.09s\tremaining: 4.65s\n",
      "254:\tlearn: 0.7259567\ttotal: 8.13s\tremaining: 4.62s\n",
      "255:\tlearn: 0.7265641\ttotal: 8.16s\tremaining: 4.59s\n",
      "256:\tlearn: 0.7267666\ttotal: 8.19s\tremaining: 4.56s\n",
      "257:\tlearn: 0.7266653\ttotal: 8.22s\tremaining: 4.52s\n",
      "258:\tlearn: 0.7260579\ttotal: 8.25s\tremaining: 4.49s\n",
      "259:\tlearn: 0.7262604\ttotal: 8.28s\tremaining: 4.46s\n",
      "260:\tlearn: 0.7269690\ttotal: 8.31s\tremaining: 4.43s\n",
      "261:\tlearn: 0.7274752\ttotal: 8.35s\tremaining: 4.4s\n",
      "262:\tlearn: 0.7260579\ttotal: 8.38s\tremaining: 4.36s\n",
      "263:\tlearn: 0.7273740\ttotal: 8.41s\tremaining: 4.33s\n",
      "264:\tlearn: 0.7282851\ttotal: 8.44s\tremaining: 4.3s\n",
      "265:\tlearn: 0.7298036\ttotal: 8.47s\tremaining: 4.27s\n",
      "266:\tlearn: 0.7297024\ttotal: 8.5s\tremaining: 4.23s\n",
      "267:\tlearn: 0.7307147\ttotal: 8.54s\tremaining: 4.2s\n",
      "268:\tlearn: 0.7306135\ttotal: 8.57s\tremaining: 4.17s\n",
      "269:\tlearn: 0.7303098\ttotal: 8.6s\tremaining: 4.14s\n",
      "270:\tlearn: 0.7294999\ttotal: 8.63s\tremaining: 4.11s\n",
      "271:\tlearn: 0.7302085\ttotal: 8.66s\tremaining: 4.08s\n",
      "272:\tlearn: 0.7307147\ttotal: 8.7s\tremaining: 4.04s\n",
      "273:\tlearn: 0.7329419\ttotal: 8.73s\tremaining: 4.01s\n",
      "274:\tlearn: 0.7331444\ttotal: 8.76s\tremaining: 3.98s\n",
      "275:\tlearn: 0.7324357\ttotal: 8.79s\tremaining: 3.95s\n",
      "276:\tlearn: 0.7317271\ttotal: 8.82s\tremaining: 3.92s\n",
      "277:\tlearn: 0.7320308\ttotal: 8.85s\tremaining: 3.88s\n",
      "278:\tlearn: 0.7310184\ttotal: 8.88s\tremaining: 3.85s\n",
      "279:\tlearn: 0.7314234\ttotal: 8.91s\tremaining: 3.82s\n",
      "280:\tlearn: 0.7310184\ttotal: 8.94s\tremaining: 3.79s\n",
      "281:\tlearn: 0.7302085\ttotal: 8.98s\tremaining: 3.76s\n",
      "282:\tlearn: 0.7283863\ttotal: 9.01s\tremaining: 3.72s\n",
      "283:\tlearn: 0.7286900\ttotal: 9.04s\tremaining: 3.69s\n",
      "284:\tlearn: 0.7288925\ttotal: 9.07s\tremaining: 3.66s\n",
      "285:\tlearn: 0.7291962\ttotal: 9.1s\tremaining: 3.63s\n",
      "286:\tlearn: 0.7301073\ttotal: 9.13s\tremaining: 3.6s\n",
      "287:\tlearn: 0.7302085\ttotal: 9.17s\tremaining: 3.56s\n",
      "288:\tlearn: 0.7303098\ttotal: 9.2s\tremaining: 3.53s\n",
      "289:\tlearn: 0.7302085\ttotal: 9.23s\tremaining: 3.5s\n",
      "290:\tlearn: 0.7297024\ttotal: 9.26s\tremaining: 3.47s\n",
      "291:\tlearn: 0.7306135\ttotal: 9.29s\tremaining: 3.44s\n",
      "292:\tlearn: 0.7303098\ttotal: 9.32s\tremaining: 3.4s\n",
      "293:\tlearn: 0.7297024\ttotal: 9.35s\tremaining: 3.37s\n",
      "294:\tlearn: 0.7301073\ttotal: 9.38s\tremaining: 3.34s\n",
      "295:\tlearn: 0.7321320\ttotal: 9.41s\tremaining: 3.31s\n",
      "296:\tlearn: 0.7321320\ttotal: 9.44s\tremaining: 3.27s\n",
      "297:\tlearn: 0.7320308\ttotal: 9.47s\tremaining: 3.24s\n",
      "298:\tlearn: 0.7319295\ttotal: 9.51s\tremaining: 3.21s\n",
      "299:\tlearn: 0.7321320\ttotal: 9.54s\tremaining: 3.18s\n",
      "300:\tlearn: 0.7326382\ttotal: 9.57s\tremaining: 3.15s\n",
      "301:\tlearn: 0.7326382\ttotal: 9.6s\tremaining: 3.12s\n",
      "302:\tlearn: 0.7329419\ttotal: 9.63s\tremaining: 3.08s\n",
      "303:\tlearn: 0.7335493\ttotal: 9.67s\tremaining: 3.05s\n",
      "304:\tlearn: 0.7332456\ttotal: 9.69s\tremaining: 3.02s\n",
      "305:\tlearn: 0.7344604\ttotal: 9.73s\tremaining: 2.99s\n",
      "306:\tlearn: 0.7343592\ttotal: 9.77s\tremaining: 2.96s\n",
      "307:\tlearn: 0.7341567\ttotal: 9.8s\tremaining: 2.93s\n",
      "308:\tlearn: 0.7341567\ttotal: 9.83s\tremaining: 2.9s\n",
      "309:\tlearn: 0.7337518\ttotal: 9.86s\tremaining: 2.86s\n",
      "310:\tlearn: 0.7340555\ttotal: 9.89s\tremaining: 2.83s\n",
      "311:\tlearn: 0.7334481\ttotal: 9.92s\tremaining: 2.8s\n",
      "312:\tlearn: 0.7341567\ttotal: 9.95s\tremaining: 2.77s\n",
      "313:\tlearn: 0.7334481\ttotal: 9.98s\tremaining: 2.73s\n",
      "314:\tlearn: 0.7335493\ttotal: 10s\tremaining: 2.7s\n",
      "315:\tlearn: 0.7334481\ttotal: 10s\tremaining: 2.67s\n",
      "316:\tlearn: 0.7344604\ttotal: 10.1s\tremaining: 2.64s\n",
      "317:\tlearn: 0.7339542\ttotal: 10.1s\tremaining: 2.6s\n",
      "318:\tlearn: 0.7348654\ttotal: 10.1s\tremaining: 2.57s\n",
      "319:\tlearn: 0.7354728\ttotal: 10.2s\tremaining: 2.54s\n",
      "320:\tlearn: 0.7357765\ttotal: 10.2s\tremaining: 2.51s\n",
      "321:\tlearn: 0.7368901\ttotal: 10.2s\tremaining: 2.48s\n",
      "322:\tlearn: 0.7376999\ttotal: 10.3s\tremaining: 2.44s\n",
      "323:\tlearn: 0.7371938\ttotal: 10.3s\tremaining: 2.41s\n",
      "324:\tlearn: 0.7367888\ttotal: 10.3s\tremaining: 2.38s\n",
      "325:\tlearn: 0.7375987\ttotal: 10.3s\tremaining: 2.35s\n",
      "326:\tlearn: 0.7371938\ttotal: 10.4s\tremaining: 2.32s\n",
      "327:\tlearn: 0.7373962\ttotal: 10.4s\tremaining: 2.29s\n",
      "328:\tlearn: 0.7379024\ttotal: 10.4s\tremaining: 2.25s\n",
      "329:\tlearn: 0.7376999\ttotal: 10.5s\tremaining: 2.22s\n",
      "330:\tlearn: 0.7386111\ttotal: 10.5s\tremaining: 2.19s\n",
      "331:\tlearn: 0.7374975\ttotal: 10.5s\tremaining: 2.16s\n",
      "332:\tlearn: 0.7379024\ttotal: 10.6s\tremaining: 2.13s\n",
      "333:\tlearn: 0.7374975\ttotal: 10.6s\tremaining: 2.1s\n",
      "334:\tlearn: 0.7371938\ttotal: 10.6s\tremaining: 2.06s\n",
      "335:\tlearn: 0.7371938\ttotal: 10.7s\tremaining: 2.03s\n",
      "336:\tlearn: 0.7372950\ttotal: 10.7s\tremaining: 2s\n",
      "337:\tlearn: 0.7369913\ttotal: 10.7s\tremaining: 1.97s\n",
      "338:\tlearn: 0.7363839\ttotal: 10.8s\tremaining: 1.94s\n",
      "339:\tlearn: 0.7387123\ttotal: 10.8s\tremaining: 1.9s\n",
      "340:\tlearn: 0.7383073\ttotal: 10.8s\tremaining: 1.87s\n",
      "341:\tlearn: 0.7378012\ttotal: 10.9s\tremaining: 1.84s\n",
      "342:\tlearn: 0.7388135\ttotal: 10.9s\tremaining: 1.81s\n",
      "343:\tlearn: 0.7384086\ttotal: 10.9s\tremaining: 1.78s\n",
      "344:\tlearn: 0.7383073\ttotal: 10.9s\tremaining: 1.74s\n",
      "345:\tlearn: 0.7386111\ttotal: 11s\tremaining: 1.71s\n",
      "346:\tlearn: 0.7388135\ttotal: 11s\tremaining: 1.68s\n",
      "347:\tlearn: 0.7390160\ttotal: 11s\tremaining: 1.65s\n",
      "348:\tlearn: 0.7371938\ttotal: 11.1s\tremaining: 1.62s\n",
      "349:\tlearn: 0.7391172\ttotal: 11.1s\tremaining: 1.59s\n",
      "350:\tlearn: 0.7390160\ttotal: 11.1s\tremaining: 1.55s\n",
      "351:\tlearn: 0.7391172\ttotal: 11.2s\tremaining: 1.52s\n",
      "352:\tlearn: 0.7402308\ttotal: 11.2s\tremaining: 1.49s\n",
      "353:\tlearn: 0.7398259\ttotal: 11.2s\tremaining: 1.46s\n",
      "354:\tlearn: 0.7400283\ttotal: 11.3s\tremaining: 1.43s\n",
      "355:\tlearn: 0.7413444\ttotal: 11.3s\tremaining: 1.4s\n",
      "356:\tlearn: 0.7415469\ttotal: 11.3s\tremaining: 1.36s\n",
      "357:\tlearn: 0.7414456\ttotal: 11.4s\tremaining: 1.33s\n",
      "358:\tlearn: 0.7408382\ttotal: 11.4s\tremaining: 1.3s\n",
      "359:\tlearn: 0.7408382\ttotal: 11.4s\tremaining: 1.27s\n",
      "360:\tlearn: 0.7415469\ttotal: 11.4s\tremaining: 1.24s\n",
      "361:\tlearn: 0.7411419\ttotal: 11.5s\tremaining: 1.2s\n",
      "362:\tlearn: 0.7420530\ttotal: 11.5s\tremaining: 1.17s\n",
      "363:\tlearn: 0.7415469\ttotal: 11.5s\tremaining: 1.14s\n",
      "364:\tlearn: 0.7412432\ttotal: 11.6s\tremaining: 1.11s\n",
      "365:\tlearn: 0.7412432\ttotal: 11.6s\tremaining: 1.08s\n",
      "366:\tlearn: 0.7420530\ttotal: 11.6s\tremaining: 1.04s\n",
      "367:\tlearn: 0.7416481\ttotal: 11.7s\tremaining: 1.01s\n",
      "368:\tlearn: 0.7415469\ttotal: 11.7s\tremaining: 982ms\n",
      "369:\tlearn: 0.7409395\ttotal: 11.7s\tremaining: 951ms\n",
      "370:\tlearn: 0.7403321\ttotal: 11.8s\tremaining: 919ms\n",
      "371:\tlearn: 0.7403321\ttotal: 11.8s\tremaining: 887ms\n",
      "372:\tlearn: 0.7406358\ttotal: 11.8s\tremaining: 856ms\n",
      "373:\tlearn: 0.7412432\ttotal: 11.8s\tremaining: 824ms\n",
      "374:\tlearn: 0.7425592\ttotal: 11.9s\tremaining: 792ms\n",
      "375:\tlearn: 0.7413444\ttotal: 11.9s\tremaining: 760ms\n",
      "376:\tlearn: 0.7414456\ttotal: 11.9s\tremaining: 729ms\n",
      "377:\tlearn: 0.7427617\ttotal: 12s\tremaining: 697ms\n",
      "378:\tlearn: 0.7421543\ttotal: 12s\tremaining: 665ms\n",
      "379:\tlearn: 0.7426605\ttotal: 12s\tremaining: 634ms\n",
      "380:\tlearn: 0.7429642\ttotal: 12.1s\tremaining: 602ms\n",
      "381:\tlearn: 0.7432679\ttotal: 12.1s\tremaining: 570ms\n",
      "382:\tlearn: 0.7432679\ttotal: 12.1s\tremaining: 538ms\n",
      "383:\tlearn: 0.7433691\ttotal: 12.2s\tremaining: 507ms\n",
      "384:\tlearn: 0.7428629\ttotal: 12.2s\tremaining: 475ms\n",
      "385:\tlearn: 0.7431666\ttotal: 12.2s\tremaining: 444ms\n",
      "386:\tlearn: 0.7434703\ttotal: 12.3s\tremaining: 412ms\n",
      "387:\tlearn: 0.7434703\ttotal: 12.3s\tremaining: 380ms\n",
      "388:\tlearn: 0.7434703\ttotal: 12.3s\tremaining: 349ms\n",
      "389:\tlearn: 0.7435716\ttotal: 12.4s\tremaining: 317ms\n",
      "390:\tlearn: 0.7430654\ttotal: 12.4s\tremaining: 285ms\n",
      "391:\tlearn: 0.7428629\ttotal: 12.4s\tremaining: 253ms\n",
      "392:\tlearn: 0.7428629\ttotal: 12.4s\tremaining: 222ms\n",
      "393:\tlearn: 0.7437740\ttotal: 12.5s\tremaining: 190ms\n",
      "394:\tlearn: 0.7441790\ttotal: 12.5s\tremaining: 158ms\n",
      "395:\tlearn: 0.7434703\ttotal: 12.5s\tremaining: 127ms\n",
      "396:\tlearn: 0.7439765\ttotal: 12.6s\tremaining: 95ms\n",
      "397:\tlearn: 0.7432679\ttotal: 12.6s\tremaining: 63.3ms\n",
      "398:\tlearn: 0.7428629\ttotal: 12.6s\tremaining: 31.7ms\n",
      "399:\tlearn: 0.7441790\ttotal: 12.7s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=64, depth=3, eval_metric=Recall, iterations=400, l2_leaf_reg=9, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=2; total time=  13.1s\n",
      "0:\tlearn: 0.6127759\ttotal: 34.2ms\tremaining: 13.6s\n",
      "1:\tlearn: 0.5361409\ttotal: 64.2ms\tremaining: 12.8s\n",
      "2:\tlearn: 0.5508200\ttotal: 95.2ms\tremaining: 12.6s\n",
      "3:\tlearn: 0.6180401\ttotal: 125ms\tremaining: 12.4s\n",
      "4:\tlearn: 0.6246204\ttotal: 157ms\tremaining: 12.4s\n",
      "5:\tlearn: 0.6326179\ttotal: 190ms\tremaining: 12.4s\n",
      "6:\tlearn: 0.6228994\ttotal: 226ms\tremaining: 12.7s\n",
      "7:\tlearn: 0.6312006\ttotal: 262ms\tremaining: 12.9s\n",
      "8:\tlearn: 0.6307957\ttotal: 296ms\tremaining: 12.8s\n",
      "9:\tlearn: 0.6431464\ttotal: 325ms\tremaining: 12.7s\n",
      "10:\tlearn: 0.6409192\ttotal: 356ms\tremaining: 12.6s\n",
      "11:\tlearn: 0.6513464\ttotal: 386ms\tremaining: 12.5s\n",
      "12:\tlearn: 0.6570156\ttotal: 417ms\tremaining: 12.4s\n",
      "13:\tlearn: 0.6555983\ttotal: 449ms\tremaining: 12.4s\n",
      "14:\tlearn: 0.6636971\ttotal: 484ms\tremaining: 12.4s\n",
      "15:\tlearn: 0.6679490\ttotal: 517ms\tremaining: 12.4s\n",
      "16:\tlearn: 0.6634946\ttotal: 551ms\tremaining: 12.4s\n",
      "17:\tlearn: 0.6694675\ttotal: 584ms\tremaining: 12.4s\n",
      "18:\tlearn: 0.6769589\ttotal: 615ms\tremaining: 12.3s\n",
      "19:\tlearn: 0.6814132\ttotal: 652ms\tremaining: 12.4s\n",
      "20:\tlearn: 0.6824256\ttotal: 681ms\tremaining: 12.3s\n",
      "21:\tlearn: 0.6817169\ttotal: 713ms\tremaining: 12.2s\n",
      "22:\tlearn: 0.6852602\ttotal: 744ms\tremaining: 12.2s\n",
      "23:\tlearn: 0.6872849\ttotal: 775ms\tremaining: 12.1s\n",
      "24:\tlearn: 0.6865762\ttotal: 805ms\tremaining: 12.1s\n",
      "25:\tlearn: 0.6894108\ttotal: 838ms\tremaining: 12.1s\n",
      "26:\tlearn: 0.6873861\ttotal: 867ms\tremaining: 12s\n",
      "27:\tlearn: 0.6906256\ttotal: 898ms\tremaining: 11.9s\n",
      "28:\tlearn: 0.6873861\ttotal: 929ms\tremaining: 11.9s\n",
      "29:\tlearn: 0.6847540\ttotal: 964ms\tremaining: 11.9s\n",
      "30:\tlearn: 0.6889046\ttotal: 996ms\tremaining: 11.9s\n",
      "31:\tlearn: 0.6870824\ttotal: 1.03s\tremaining: 11.8s\n",
      "32:\tlearn: 0.6840454\ttotal: 1.06s\tremaining: 11.8s\n",
      "33:\tlearn: 0.6845515\ttotal: 1.09s\tremaining: 11.7s\n",
      "34:\tlearn: 0.6870824\ttotal: 1.12s\tremaining: 11.7s\n",
      "35:\tlearn: 0.6859688\ttotal: 1.16s\tremaining: 11.7s\n",
      "36:\tlearn: 0.6850577\ttotal: 1.19s\tremaining: 11.7s\n",
      "37:\tlearn: 0.6842478\ttotal: 1.22s\tremaining: 11.6s\n",
      "38:\tlearn: 0.6859688\ttotal: 1.25s\tremaining: 11.6s\n",
      "39:\tlearn: 0.6901195\ttotal: 1.28s\tremaining: 11.6s\n",
      "40:\tlearn: 0.6856651\ttotal: 1.32s\tremaining: 11.5s\n",
      "41:\tlearn: 0.6890059\ttotal: 1.35s\tremaining: 11.5s\n",
      "42:\tlearn: 0.6851589\ttotal: 1.38s\tremaining: 11.5s\n",
      "43:\tlearn: 0.6904232\ttotal: 1.41s\tremaining: 11.4s\n",
      "44:\tlearn: 0.6933590\ttotal: 1.44s\tremaining: 11.4s\n",
      "45:\tlearn: 0.6939664\ttotal: 1.47s\tremaining: 11.3s\n",
      "46:\tlearn: 0.6953837\ttotal: 1.5s\tremaining: 11.3s\n",
      "47:\tlearn: 0.6968010\ttotal: 1.53s\tremaining: 11.3s\n",
      "48:\tlearn: 0.6991294\ttotal: 1.57s\tremaining: 11.2s\n",
      "49:\tlearn: 0.6982183\ttotal: 1.6s\tremaining: 11.2s\n",
      "50:\tlearn: 0.6982183\ttotal: 1.63s\tremaining: 11.2s\n",
      "51:\tlearn: 0.6969022\ttotal: 1.67s\tremaining: 11.2s\n",
      "52:\tlearn: 0.7013565\ttotal: 1.7s\tremaining: 11.1s\n",
      "53:\tlearn: 0.6993318\ttotal: 1.73s\tremaining: 11.1s\n",
      "54:\tlearn: 0.6965985\ttotal: 1.77s\tremaining: 11.1s\n",
      "55:\tlearn: 0.6972059\ttotal: 1.8s\tremaining: 11.1s\n",
      "56:\tlearn: 0.6953837\ttotal: 1.83s\tremaining: 11s\n",
      "57:\tlearn: 0.6983195\ttotal: 1.86s\tremaining: 11s\n",
      "58:\tlearn: 0.6994331\ttotal: 1.9s\tremaining: 11s\n",
      "59:\tlearn: 0.6990281\ttotal: 1.93s\tremaining: 10.9s\n",
      "60:\tlearn: 0.6985220\ttotal: 1.96s\tremaining: 10.9s\n",
      "61:\tlearn: 0.7006479\ttotal: 1.99s\tremaining: 10.9s\n",
      "62:\tlearn: 0.6992306\ttotal: 2.02s\tremaining: 10.8s\n",
      "63:\tlearn: 0.6969022\ttotal: 2.06s\tremaining: 10.8s\n",
      "64:\tlearn: 0.7006479\ttotal: 2.09s\tremaining: 10.8s\n",
      "65:\tlearn: 0.6987244\ttotal: 2.12s\tremaining: 10.7s\n",
      "66:\tlearn: 0.6987244\ttotal: 2.15s\tremaining: 10.7s\n",
      "67:\tlearn: 0.7006479\ttotal: 2.18s\tremaining: 10.7s\n",
      "68:\tlearn: 0.7005467\ttotal: 2.21s\tremaining: 10.6s\n",
      "69:\tlearn: 0.7010528\ttotal: 2.24s\tremaining: 10.6s\n",
      "70:\tlearn: 0.7008504\ttotal: 2.28s\tremaining: 10.6s\n",
      "71:\tlearn: 0.6972059\ttotal: 2.31s\tremaining: 10.5s\n",
      "72:\tlearn: 0.6974084\ttotal: 2.35s\tremaining: 10.5s\n",
      "73:\tlearn: 0.6964973\ttotal: 2.38s\tremaining: 10.5s\n",
      "74:\tlearn: 0.6984207\ttotal: 2.41s\tremaining: 10.4s\n",
      "75:\tlearn: 0.6966997\ttotal: 2.44s\tremaining: 10.4s\n",
      "76:\tlearn: 0.6962948\ttotal: 2.48s\tremaining: 10.4s\n",
      "77:\tlearn: 0.6996356\ttotal: 2.5s\tremaining: 10.3s\n",
      "78:\tlearn: 0.6999393\ttotal: 2.54s\tremaining: 10.3s\n",
      "79:\tlearn: 0.7031788\ttotal: 2.57s\tremaining: 10.3s\n",
      "80:\tlearn: 0.7009516\ttotal: 2.6s\tremaining: 10.2s\n",
      "81:\tlearn: 0.6989269\ttotal: 2.63s\tremaining: 10.2s\n",
      "82:\tlearn: 0.6998380\ttotal: 2.67s\tremaining: 10.2s\n",
      "83:\tlearn: 0.6999393\ttotal: 2.7s\tremaining: 10.1s\n",
      "84:\tlearn: 0.7000405\ttotal: 2.73s\tremaining: 10.1s\n",
      "85:\tlearn: 0.7018627\ttotal: 2.76s\tremaining: 10.1s\n",
      "86:\tlearn: 0.7042924\ttotal: 2.8s\tremaining: 10.1s\n",
      "87:\tlearn: 0.7020652\ttotal: 2.83s\tremaining: 10s\n",
      "88:\tlearn: 0.7011541\ttotal: 2.86s\tremaining: 10s\n",
      "89:\tlearn: 0.7034825\ttotal: 2.89s\tremaining: 9.96s\n",
      "90:\tlearn: 0.7040899\ttotal: 2.92s\tremaining: 9.93s\n",
      "91:\tlearn: 0.7018627\ttotal: 2.96s\tremaining: 9.9s\n",
      "92:\tlearn: 0.7021664\ttotal: 2.99s\tremaining: 9.88s\n",
      "93:\tlearn: 0.7013565\ttotal: 3.03s\tremaining: 9.85s\n",
      "94:\tlearn: 0.7008504\ttotal: 3.06s\tremaining: 9.82s\n",
      "95:\tlearn: 0.7002430\ttotal: 3.09s\tremaining: 9.79s\n",
      "96:\tlearn: 0.7002430\ttotal: 3.12s\tremaining: 9.76s\n",
      "97:\tlearn: 0.7005467\ttotal: 3.15s\tremaining: 9.72s\n",
      "98:\tlearn: 0.7018627\ttotal: 3.18s\tremaining: 9.68s\n",
      "99:\tlearn: 0.7005467\ttotal: 3.21s\tremaining: 9.65s\n",
      "100:\tlearn: 0.6991294\ttotal: 3.24s\tremaining: 9.61s\n",
      "101:\tlearn: 0.7020652\ttotal: 3.28s\tremaining: 9.57s\n",
      "102:\tlearn: 0.7020652\ttotal: 3.31s\tremaining: 9.54s\n",
      "103:\tlearn: 0.7035837\ttotal: 3.34s\tremaining: 9.51s\n",
      "104:\tlearn: 0.7021664\ttotal: 3.37s\tremaining: 9.46s\n",
      "105:\tlearn: 0.7024701\ttotal: 3.4s\tremaining: 9.43s\n",
      "106:\tlearn: 0.7008504\ttotal: 3.43s\tremaining: 9.4s\n",
      "107:\tlearn: 0.7008504\ttotal: 3.47s\tremaining: 9.38s\n",
      "108:\tlearn: 0.7004454\ttotal: 3.5s\tremaining: 9.36s\n",
      "109:\tlearn: 0.7018627\ttotal: 3.54s\tremaining: 9.32s\n",
      "110:\tlearn: 0.7023689\ttotal: 3.57s\tremaining: 9.28s\n",
      "111:\tlearn: 0.7021664\ttotal: 3.6s\tremaining: 9.25s\n",
      "112:\tlearn: 0.7012553\ttotal: 3.63s\tremaining: 9.22s\n",
      "113:\tlearn: 0.7009516\ttotal: 3.66s\tremaining: 9.19s\n",
      "114:\tlearn: 0.7020652\ttotal: 3.69s\tremaining: 9.15s\n",
      "115:\tlearn: 0.7010528\ttotal: 3.73s\tremaining: 9.12s\n",
      "116:\tlearn: 0.7036850\ttotal: 3.76s\tremaining: 9.09s\n",
      "117:\tlearn: 0.7042924\ttotal: 3.79s\tremaining: 9.05s\n",
      "118:\tlearn: 0.7046973\ttotal: 3.82s\tremaining: 9.02s\n",
      "119:\tlearn: 0.7063171\ttotal: 3.85s\tremaining: 8.99s\n",
      "120:\tlearn: 0.7039887\ttotal: 3.88s\tremaining: 8.96s\n",
      "121:\tlearn: 0.7059121\ttotal: 3.91s\tremaining: 8.92s\n",
      "122:\tlearn: 0.7058109\ttotal: 3.95s\tremaining: 8.89s\n",
      "123:\tlearn: 0.7066208\ttotal: 3.98s\tremaining: 8.85s\n",
      "124:\tlearn: 0.7070257\ttotal: 4.01s\tremaining: 8.82s\n",
      "125:\tlearn: 0.7068232\ttotal: 4.04s\tremaining: 8.79s\n",
      "126:\tlearn: 0.7047985\ttotal: 4.07s\tremaining: 8.75s\n",
      "127:\tlearn: 0.7058109\ttotal: 4.1s\tremaining: 8.72s\n",
      "128:\tlearn: 0.7069245\ttotal: 4.13s\tremaining: 8.68s\n",
      "129:\tlearn: 0.7069245\ttotal: 4.16s\tremaining: 8.64s\n",
      "130:\tlearn: 0.7066208\ttotal: 4.19s\tremaining: 8.6s\n",
      "131:\tlearn: 0.7082405\ttotal: 4.22s\tremaining: 8.57s\n",
      "132:\tlearn: 0.7071269\ttotal: 4.25s\tremaining: 8.53s\n",
      "133:\tlearn: 0.7074307\ttotal: 4.28s\tremaining: 8.5s\n",
      "134:\tlearn: 0.7082405\ttotal: 4.31s\tremaining: 8.47s\n",
      "135:\tlearn: 0.7088479\ttotal: 4.35s\tremaining: 8.44s\n",
      "136:\tlearn: 0.7080381\ttotal: 4.38s\tremaining: 8.41s\n",
      "137:\tlearn: 0.7093541\ttotal: 4.41s\tremaining: 8.38s\n",
      "138:\tlearn: 0.7086455\ttotal: 4.45s\tremaining: 8.35s\n",
      "139:\tlearn: 0.7098603\ttotal: 4.48s\tremaining: 8.32s\n",
      "140:\tlearn: 0.7097591\ttotal: 4.51s\tremaining: 8.28s\n",
      "141:\tlearn: 0.7097591\ttotal: 4.54s\tremaining: 8.25s\n",
      "142:\tlearn: 0.7106702\ttotal: 4.57s\tremaining: 8.21s\n",
      "143:\tlearn: 0.7113788\ttotal: 4.6s\tremaining: 8.18s\n",
      "144:\tlearn: 0.7122899\ttotal: 4.63s\tremaining: 8.15s\n",
      "145:\tlearn: 0.7116825\ttotal: 4.67s\tremaining: 8.12s\n",
      "146:\tlearn: 0.7114801\ttotal: 4.7s\tremaining: 8.09s\n",
      "147:\tlearn: 0.7111764\ttotal: 4.73s\tremaining: 8.05s\n",
      "148:\tlearn: 0.7122899\ttotal: 4.76s\tremaining: 8.02s\n",
      "149:\tlearn: 0.7119862\ttotal: 4.79s\tremaining: 7.99s\n",
      "150:\tlearn: 0.7107714\ttotal: 4.82s\tremaining: 7.95s\n",
      "151:\tlearn: 0.7121887\ttotal: 4.85s\tremaining: 7.92s\n",
      "152:\tlearn: 0.7109739\ttotal: 4.88s\tremaining: 7.88s\n",
      "153:\tlearn: 0.7108726\ttotal: 4.91s\tremaining: 7.85s\n",
      "154:\tlearn: 0.7114801\ttotal: 4.95s\tremaining: 7.82s\n",
      "155:\tlearn: 0.7113788\ttotal: 4.98s\tremaining: 7.79s\n",
      "156:\tlearn: 0.7097591\ttotal: 5.01s\tremaining: 7.76s\n",
      "157:\tlearn: 0.7104677\ttotal: 5.04s\tremaining: 7.72s\n",
      "158:\tlearn: 0.7111764\ttotal: 5.07s\tremaining: 7.68s\n",
      "159:\tlearn: 0.7128973\ttotal: 5.1s\tremaining: 7.66s\n",
      "160:\tlearn: 0.7122899\ttotal: 5.13s\tremaining: 7.62s\n",
      "161:\tlearn: 0.7127961\ttotal: 5.16s\tremaining: 7.59s\n",
      "162:\tlearn: 0.7135048\ttotal: 5.2s\tremaining: 7.56s\n",
      "163:\tlearn: 0.7147196\ttotal: 5.23s\tremaining: 7.52s\n",
      "164:\tlearn: 0.7138085\ttotal: 5.26s\tremaining: 7.49s\n",
      "165:\tlearn: 0.7154282\ttotal: 5.29s\tremaining: 7.46s\n",
      "166:\tlearn: 0.7148208\ttotal: 5.32s\tremaining: 7.43s\n",
      "167:\tlearn: 0.7148208\ttotal: 5.36s\tremaining: 7.4s\n",
      "168:\tlearn: 0.7137072\ttotal: 5.39s\tremaining: 7.36s\n",
      "169:\tlearn: 0.7140109\ttotal: 5.42s\tremaining: 7.34s\n",
      "170:\tlearn: 0.7155295\ttotal: 5.46s\tremaining: 7.31s\n",
      "171:\tlearn: 0.7143146\ttotal: 5.49s\tremaining: 7.28s\n",
      "172:\tlearn: 0.7144159\ttotal: 5.52s\tremaining: 7.24s\n",
      "173:\tlearn: 0.7151245\ttotal: 5.55s\tremaining: 7.21s\n",
      "174:\tlearn: 0.7147196\ttotal: 5.58s\tremaining: 7.18s\n",
      "175:\tlearn: 0.7149220\ttotal: 5.62s\tremaining: 7.15s\n",
      "176:\tlearn: 0.7150233\ttotal: 5.65s\tremaining: 7.12s\n",
      "177:\tlearn: 0.7150233\ttotal: 5.68s\tremaining: 7.09s\n",
      "178:\tlearn: 0.7146183\ttotal: 5.71s\tremaining: 7.06s\n",
      "179:\tlearn: 0.7146183\ttotal: 5.75s\tremaining: 7.02s\n",
      "180:\tlearn: 0.7128973\ttotal: 5.77s\tremaining: 6.99s\n",
      "181:\tlearn: 0.7125936\ttotal: 5.81s\tremaining: 6.95s\n",
      "182:\tlearn: 0.7137072\ttotal: 5.84s\tremaining: 6.92s\n",
      "183:\tlearn: 0.7138085\ttotal: 5.87s\tremaining: 6.89s\n",
      "184:\tlearn: 0.7143146\ttotal: 5.9s\tremaining: 6.85s\n",
      "185:\tlearn: 0.7148208\ttotal: 5.93s\tremaining: 6.82s\n",
      "186:\tlearn: 0.7144159\ttotal: 5.96s\tremaining: 6.79s\n",
      "187:\tlearn: 0.7153270\ttotal: 5.99s\tremaining: 6.76s\n",
      "188:\tlearn: 0.7154282\ttotal: 6.02s\tremaining: 6.72s\n",
      "189:\tlearn: 0.7148208\ttotal: 6.05s\tremaining: 6.69s\n",
      "190:\tlearn: 0.7148208\ttotal: 6.08s\tremaining: 6.66s\n",
      "191:\tlearn: 0.7154282\ttotal: 6.11s\tremaining: 6.62s\n",
      "192:\tlearn: 0.7148208\ttotal: 6.14s\tremaining: 6.59s\n",
      "193:\tlearn: 0.7138085\ttotal: 6.17s\tremaining: 6.56s\n",
      "194:\tlearn: 0.7140109\ttotal: 6.21s\tremaining: 6.53s\n",
      "195:\tlearn: 0.7140109\ttotal: 6.24s\tremaining: 6.49s\n",
      "196:\tlearn: 0.7145171\ttotal: 6.27s\tremaining: 6.46s\n",
      "197:\tlearn: 0.7151245\ttotal: 6.3s\tremaining: 6.43s\n",
      "198:\tlearn: 0.7155295\ttotal: 6.33s\tremaining: 6.4s\n",
      "199:\tlearn: 0.7163393\ttotal: 6.37s\tremaining: 6.37s\n",
      "200:\tlearn: 0.7157319\ttotal: 6.4s\tremaining: 6.33s\n",
      "201:\tlearn: 0.7158332\ttotal: 6.43s\tremaining: 6.3s\n",
      "202:\tlearn: 0.7166430\ttotal: 6.46s\tremaining: 6.27s\n",
      "203:\tlearn: 0.7171492\ttotal: 6.5s\tremaining: 6.24s\n",
      "204:\tlearn: 0.7175542\ttotal: 6.53s\tremaining: 6.21s\n",
      "205:\tlearn: 0.7192752\ttotal: 6.55s\tremaining: 6.17s\n",
      "206:\tlearn: 0.7176554\ttotal: 6.59s\tremaining: 6.14s\n",
      "207:\tlearn: 0.7176554\ttotal: 6.62s\tremaining: 6.11s\n",
      "208:\tlearn: 0.7182628\ttotal: 6.65s\tremaining: 6.08s\n",
      "209:\tlearn: 0.7177566\ttotal: 6.68s\tremaining: 6.05s\n",
      "210:\tlearn: 0.7170480\ttotal: 6.71s\tremaining: 6.01s\n",
      "211:\tlearn: 0.7160356\ttotal: 6.75s\tremaining: 5.98s\n",
      "212:\tlearn: 0.7176554\ttotal: 6.78s\tremaining: 5.95s\n",
      "213:\tlearn: 0.7157319\ttotal: 6.81s\tremaining: 5.92s\n",
      "214:\tlearn: 0.7153270\ttotal: 6.84s\tremaining: 5.89s\n",
      "215:\tlearn: 0.7153270\ttotal: 6.87s\tremaining: 5.86s\n",
      "216:\tlearn: 0.7167443\ttotal: 6.9s\tremaining: 5.82s\n",
      "217:\tlearn: 0.7170480\ttotal: 6.93s\tremaining: 5.79s\n",
      "218:\tlearn: 0.7175542\ttotal: 6.97s\tremaining: 5.76s\n",
      "219:\tlearn: 0.7183640\ttotal: 7s\tremaining: 5.73s\n",
      "220:\tlearn: 0.7174529\ttotal: 7.03s\tremaining: 5.7s\n",
      "221:\tlearn: 0.7168455\ttotal: 7.07s\tremaining: 5.67s\n",
      "222:\tlearn: 0.7169468\ttotal: 7.1s\tremaining: 5.63s\n",
      "223:\tlearn: 0.7168455\ttotal: 7.13s\tremaining: 5.6s\n",
      "224:\tlearn: 0.7163393\ttotal: 7.16s\tremaining: 5.57s\n",
      "225:\tlearn: 0.7164406\ttotal: 7.19s\tremaining: 5.54s\n",
      "226:\tlearn: 0.7185665\ttotal: 7.22s\tremaining: 5.5s\n",
      "227:\tlearn: 0.7180603\ttotal: 7.25s\tremaining: 5.47s\n",
      "228:\tlearn: 0.7177566\ttotal: 7.28s\tremaining: 5.44s\n",
      "229:\tlearn: 0.7190727\ttotal: 7.32s\tremaining: 5.41s\n",
      "230:\tlearn: 0.7178579\ttotal: 7.35s\tremaining: 5.37s\n",
      "231:\tlearn: 0.7178579\ttotal: 7.38s\tremaining: 5.34s\n",
      "232:\tlearn: 0.7188702\ttotal: 7.41s\tremaining: 5.31s\n",
      "233:\tlearn: 0.7180603\ttotal: 7.44s\tremaining: 5.28s\n",
      "234:\tlearn: 0.7174529\ttotal: 7.47s\tremaining: 5.24s\n",
      "235:\tlearn: 0.7173517\ttotal: 7.5s\tremaining: 5.21s\n",
      "236:\tlearn: 0.7164406\ttotal: 7.53s\tremaining: 5.18s\n",
      "237:\tlearn: 0.7166430\ttotal: 7.56s\tremaining: 5.14s\n",
      "238:\tlearn: 0.7165418\ttotal: 7.59s\tremaining: 5.11s\n",
      "239:\tlearn: 0.7169468\ttotal: 7.62s\tremaining: 5.08s\n",
      "240:\tlearn: 0.7171492\ttotal: 7.65s\tremaining: 5.05s\n",
      "241:\tlearn: 0.7169468\ttotal: 7.68s\tremaining: 5.01s\n",
      "242:\tlearn: 0.7179591\ttotal: 7.71s\tremaining: 4.98s\n",
      "243:\tlearn: 0.7187690\ttotal: 7.74s\tremaining: 4.95s\n",
      "244:\tlearn: 0.7178579\ttotal: 7.77s\tremaining: 4.92s\n",
      "245:\tlearn: 0.7186677\ttotal: 7.8s\tremaining: 4.88s\n",
      "246:\tlearn: 0.7185665\ttotal: 7.83s\tremaining: 4.85s\n",
      "247:\tlearn: 0.7184653\ttotal: 7.86s\tremaining: 4.82s\n",
      "248:\tlearn: 0.7185665\ttotal: 7.9s\tremaining: 4.79s\n",
      "249:\tlearn: 0.7191739\ttotal: 7.93s\tremaining: 4.76s\n",
      "250:\tlearn: 0.7180603\ttotal: 7.96s\tremaining: 4.73s\n",
      "251:\tlearn: 0.7183640\ttotal: 7.99s\tremaining: 4.69s\n",
      "252:\tlearn: 0.7175542\ttotal: 8.02s\tremaining: 4.66s\n",
      "253:\tlearn: 0.7184653\ttotal: 8.05s\tremaining: 4.63s\n",
      "254:\tlearn: 0.7183640\ttotal: 8.08s\tremaining: 4.6s\n",
      "255:\tlearn: 0.7187690\ttotal: 8.11s\tremaining: 4.56s\n",
      "256:\tlearn: 0.7190727\ttotal: 8.15s\tremaining: 4.53s\n",
      "257:\tlearn: 0.7179591\ttotal: 8.18s\tremaining: 4.5s\n",
      "258:\tlearn: 0.7178579\ttotal: 8.22s\tremaining: 4.47s\n",
      "259:\tlearn: 0.7179591\ttotal: 8.25s\tremaining: 4.44s\n",
      "260:\tlearn: 0.7196801\ttotal: 8.28s\tremaining: 4.41s\n",
      "261:\tlearn: 0.7196801\ttotal: 8.31s\tremaining: 4.38s\n",
      "262:\tlearn: 0.7199838\ttotal: 8.34s\tremaining: 4.34s\n",
      "263:\tlearn: 0.7191739\ttotal: 8.37s\tremaining: 4.31s\n",
      "264:\tlearn: 0.7207937\ttotal: 8.4s\tremaining: 4.28s\n",
      "265:\tlearn: 0.7188702\ttotal: 8.43s\tremaining: 4.25s\n",
      "266:\tlearn: 0.7194776\ttotal: 8.46s\tremaining: 4.22s\n",
      "267:\tlearn: 0.7197813\ttotal: 8.49s\tremaining: 4.18s\n",
      "268:\tlearn: 0.7191739\ttotal: 8.53s\tremaining: 4.15s\n",
      "269:\tlearn: 0.7193764\ttotal: 8.56s\tremaining: 4.12s\n",
      "270:\tlearn: 0.7189715\ttotal: 8.59s\tremaining: 4.09s\n",
      "271:\tlearn: 0.7191739\ttotal: 8.63s\tremaining: 4.06s\n",
      "272:\tlearn: 0.7190727\ttotal: 8.66s\tremaining: 4.03s\n",
      "273:\tlearn: 0.7184653\ttotal: 8.69s\tremaining: 4s\n",
      "274:\tlearn: 0.7191739\ttotal: 8.72s\tremaining: 3.96s\n",
      "275:\tlearn: 0.7189715\ttotal: 8.76s\tremaining: 3.93s\n",
      "276:\tlearn: 0.7190727\ttotal: 8.79s\tremaining: 3.9s\n",
      "277:\tlearn: 0.7200850\ttotal: 8.82s\tremaining: 3.87s\n",
      "278:\tlearn: 0.7201863\ttotal: 8.85s\tremaining: 3.84s\n",
      "279:\tlearn: 0.7202875\ttotal: 8.88s\tremaining: 3.81s\n",
      "280:\tlearn: 0.7205912\ttotal: 8.91s\tremaining: 3.77s\n",
      "281:\tlearn: 0.7207937\ttotal: 8.95s\tremaining: 3.74s\n",
      "282:\tlearn: 0.7203887\ttotal: 8.98s\tremaining: 3.71s\n",
      "283:\tlearn: 0.7207937\ttotal: 9.01s\tremaining: 3.68s\n",
      "284:\tlearn: 0.7207937\ttotal: 9.04s\tremaining: 3.65s\n",
      "285:\tlearn: 0.7203887\ttotal: 9.07s\tremaining: 3.61s\n",
      "286:\tlearn: 0.7226159\ttotal: 9.1s\tremaining: 3.58s\n",
      "287:\tlearn: 0.7219073\ttotal: 9.13s\tremaining: 3.55s\n",
      "288:\tlearn: 0.7222110\ttotal: 9.16s\tremaining: 3.52s\n",
      "289:\tlearn: 0.7223122\ttotal: 9.19s\tremaining: 3.49s\n",
      "290:\tlearn: 0.7223122\ttotal: 9.23s\tremaining: 3.46s\n",
      "291:\tlearn: 0.7228184\ttotal: 9.26s\tremaining: 3.42s\n",
      "292:\tlearn: 0.7236283\ttotal: 9.29s\tremaining: 3.39s\n",
      "293:\tlearn: 0.7235270\ttotal: 9.32s\tremaining: 3.36s\n",
      "294:\tlearn: 0.7233246\ttotal: 9.35s\tremaining: 3.33s\n",
      "295:\tlearn: 0.7232233\ttotal: 9.38s\tremaining: 3.29s\n",
      "296:\tlearn: 0.7222110\ttotal: 9.41s\tremaining: 3.26s\n",
      "297:\tlearn: 0.7244381\ttotal: 9.44s\tremaining: 3.23s\n",
      "298:\tlearn: 0.7243369\ttotal: 9.47s\tremaining: 3.2s\n",
      "299:\tlearn: 0.7246406\ttotal: 9.5s\tremaining: 3.17s\n",
      "300:\tlearn: 0.7249443\ttotal: 9.53s\tremaining: 3.13s\n",
      "301:\tlearn: 0.7245394\ttotal: 9.56s\tremaining: 3.1s\n",
      "302:\tlearn: 0.7244381\ttotal: 9.59s\tremaining: 3.07s\n",
      "303:\tlearn: 0.7258554\ttotal: 9.62s\tremaining: 3.04s\n",
      "304:\tlearn: 0.7245394\ttotal: 9.65s\tremaining: 3.01s\n",
      "305:\tlearn: 0.7263616\ttotal: 9.68s\tremaining: 2.97s\n",
      "306:\tlearn: 0.7256530\ttotal: 9.72s\tremaining: 2.94s\n",
      "307:\tlearn: 0.7265641\ttotal: 9.74s\tremaining: 2.91s\n",
      "308:\tlearn: 0.7253493\ttotal: 9.78s\tremaining: 2.88s\n",
      "309:\tlearn: 0.7246406\ttotal: 9.8s\tremaining: 2.85s\n",
      "310:\tlearn: 0.7257542\ttotal: 9.84s\tremaining: 2.81s\n",
      "311:\tlearn: 0.7273740\ttotal: 9.87s\tremaining: 2.78s\n",
      "312:\tlearn: 0.7278801\ttotal: 9.9s\tremaining: 2.75s\n",
      "313:\tlearn: 0.7283863\ttotal: 9.93s\tremaining: 2.72s\n",
      "314:\tlearn: 0.7296011\ttotal: 9.96s\tremaining: 2.69s\n",
      "315:\tlearn: 0.7308160\ttotal: 9.99s\tremaining: 2.66s\n",
      "316:\tlearn: 0.7309172\ttotal: 10s\tremaining: 2.62s\n",
      "317:\tlearn: 0.7312209\ttotal: 10.1s\tremaining: 2.59s\n",
      "318:\tlearn: 0.7310184\ttotal: 10.1s\tremaining: 2.56s\n",
      "319:\tlearn: 0.7310184\ttotal: 10.1s\tremaining: 2.53s\n",
      "320:\tlearn: 0.7306135\ttotal: 10.1s\tremaining: 2.5s\n",
      "321:\tlearn: 0.7314234\ttotal: 10.2s\tremaining: 2.47s\n",
      "322:\tlearn: 0.7307147\ttotal: 10.2s\tremaining: 2.43s\n",
      "323:\tlearn: 0.7306135\ttotal: 10.2s\tremaining: 2.4s\n",
      "324:\tlearn: 0.7313221\ttotal: 10.3s\tremaining: 2.37s\n",
      "325:\tlearn: 0.7311197\ttotal: 10.3s\tremaining: 2.34s\n",
      "326:\tlearn: 0.7304110\ttotal: 10.3s\tremaining: 2.31s\n",
      "327:\tlearn: 0.7308160\ttotal: 10.4s\tremaining: 2.27s\n",
      "328:\tlearn: 0.7313221\ttotal: 10.4s\tremaining: 2.24s\n",
      "329:\tlearn: 0.7316258\ttotal: 10.4s\tremaining: 2.21s\n",
      "330:\tlearn: 0.7323345\ttotal: 10.5s\tremaining: 2.18s\n",
      "331:\tlearn: 0.7324357\ttotal: 10.5s\tremaining: 2.15s\n",
      "332:\tlearn: 0.7322332\ttotal: 10.5s\tremaining: 2.12s\n",
      "333:\tlearn: 0.7321320\ttotal: 10.6s\tremaining: 2.08s\n",
      "334:\tlearn: 0.7327394\ttotal: 10.6s\tremaining: 2.05s\n",
      "335:\tlearn: 0.7331444\ttotal: 10.6s\tremaining: 2.02s\n",
      "336:\tlearn: 0.7330431\ttotal: 10.6s\tremaining: 1.99s\n",
      "337:\tlearn: 0.7342579\ttotal: 10.7s\tremaining: 1.96s\n",
      "338:\tlearn: 0.7335493\ttotal: 10.7s\tremaining: 1.93s\n",
      "339:\tlearn: 0.7339542\ttotal: 10.7s\tremaining: 1.9s\n",
      "340:\tlearn: 0.7339542\ttotal: 10.8s\tremaining: 1.86s\n",
      "341:\tlearn: 0.7341567\ttotal: 10.8s\tremaining: 1.83s\n",
      "342:\tlearn: 0.7343592\ttotal: 10.8s\tremaining: 1.8s\n",
      "343:\tlearn: 0.7342579\ttotal: 10.9s\tremaining: 1.77s\n",
      "344:\tlearn: 0.7346629\ttotal: 10.9s\tremaining: 1.74s\n",
      "345:\tlearn: 0.7348654\ttotal: 10.9s\tremaining: 1.71s\n",
      "346:\tlearn: 0.7340555\ttotal: 11s\tremaining: 1.67s\n",
      "347:\tlearn: 0.7339542\ttotal: 11s\tremaining: 1.64s\n",
      "348:\tlearn: 0.7347641\ttotal: 11s\tremaining: 1.61s\n",
      "349:\tlearn: 0.7347641\ttotal: 11.1s\tremaining: 1.58s\n",
      "350:\tlearn: 0.7346629\ttotal: 11.1s\tremaining: 1.55s\n",
      "351:\tlearn: 0.7350678\ttotal: 11.1s\tremaining: 1.52s\n",
      "352:\tlearn: 0.7358777\ttotal: 11.2s\tremaining: 1.48s\n",
      "353:\tlearn: 0.7356752\ttotal: 11.2s\tremaining: 1.45s\n",
      "354:\tlearn: 0.7362826\ttotal: 11.2s\tremaining: 1.42s\n",
      "355:\tlearn: 0.7365864\ttotal: 11.3s\tremaining: 1.39s\n",
      "356:\tlearn: 0.7354728\ttotal: 11.3s\tremaining: 1.36s\n",
      "357:\tlearn: 0.7355740\ttotal: 11.3s\tremaining: 1.33s\n",
      "358:\tlearn: 0.7359789\ttotal: 11.3s\tremaining: 1.29s\n",
      "359:\tlearn: 0.7373962\ttotal: 11.4s\tremaining: 1.26s\n",
      "360:\tlearn: 0.7366876\ttotal: 11.4s\tremaining: 1.23s\n",
      "361:\tlearn: 0.7369913\ttotal: 11.4s\tremaining: 1.2s\n",
      "362:\tlearn: 0.7366876\ttotal: 11.5s\tremaining: 1.17s\n",
      "363:\tlearn: 0.7363839\ttotal: 11.5s\tremaining: 1.14s\n",
      "364:\tlearn: 0.7364851\ttotal: 11.5s\tremaining: 1.1s\n",
      "365:\tlearn: 0.7359789\ttotal: 11.6s\tremaining: 1.07s\n",
      "366:\tlearn: 0.7358777\ttotal: 11.6s\tremaining: 1.04s\n",
      "367:\tlearn: 0.7359789\ttotal: 11.6s\tremaining: 1.01s\n",
      "368:\tlearn: 0.7361814\ttotal: 11.7s\tremaining: 980ms\n",
      "369:\tlearn: 0.7363839\ttotal: 11.7s\tremaining: 948ms\n",
      "370:\tlearn: 0.7365864\ttotal: 11.7s\tremaining: 917ms\n",
      "371:\tlearn: 0.7371938\ttotal: 11.8s\tremaining: 885ms\n",
      "372:\tlearn: 0.7379024\ttotal: 11.8s\tremaining: 853ms\n",
      "373:\tlearn: 0.7380036\ttotal: 11.8s\tremaining: 822ms\n",
      "374:\tlearn: 0.7378012\ttotal: 11.9s\tremaining: 790ms\n",
      "375:\tlearn: 0.7379024\ttotal: 11.9s\tremaining: 759ms\n",
      "376:\tlearn: 0.7370925\ttotal: 11.9s\tremaining: 727ms\n",
      "377:\tlearn: 0.7383073\ttotal: 11.9s\tremaining: 695ms\n",
      "378:\tlearn: 0.7380036\ttotal: 12s\tremaining: 664ms\n",
      "379:\tlearn: 0.7380036\ttotal: 12s\tremaining: 632ms\n",
      "380:\tlearn: 0.7380036\ttotal: 12s\tremaining: 601ms\n",
      "381:\tlearn: 0.7380036\ttotal: 12.1s\tremaining: 569ms\n",
      "382:\tlearn: 0.7390160\ttotal: 12.1s\tremaining: 537ms\n",
      "383:\tlearn: 0.7388135\ttotal: 12.1s\tremaining: 506ms\n",
      "384:\tlearn: 0.7402308\ttotal: 12.2s\tremaining: 474ms\n",
      "385:\tlearn: 0.7407370\ttotal: 12.2s\tremaining: 442ms\n",
      "386:\tlearn: 0.7409395\ttotal: 12.2s\tremaining: 411ms\n",
      "387:\tlearn: 0.7402308\ttotal: 12.3s\tremaining: 379ms\n",
      "388:\tlearn: 0.7415469\ttotal: 12.3s\tremaining: 348ms\n",
      "389:\tlearn: 0.7412432\ttotal: 12.3s\tremaining: 316ms\n",
      "390:\tlearn: 0.7410407\ttotal: 12.4s\tremaining: 284ms\n",
      "391:\tlearn: 0.7421543\ttotal: 12.4s\tremaining: 253ms\n",
      "392:\tlearn: 0.7416481\ttotal: 12.4s\tremaining: 221ms\n",
      "393:\tlearn: 0.7417493\ttotal: 12.4s\tremaining: 189ms\n",
      "394:\tlearn: 0.7410407\ttotal: 12.5s\tremaining: 158ms\n",
      "395:\tlearn: 0.7412432\ttotal: 12.5s\tremaining: 126ms\n",
      "396:\tlearn: 0.7421543\ttotal: 12.5s\tremaining: 94.7ms\n",
      "397:\tlearn: 0.7423568\ttotal: 12.6s\tremaining: 63.1ms\n",
      "398:\tlearn: 0.7427617\ttotal: 12.6s\tremaining: 31.6ms\n",
      "399:\tlearn: 0.7423568\ttotal: 12.6s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=64, depth=3, eval_metric=Recall, iterations=400, l2_leaf_reg=9, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=2; total time=  13.0s\n",
      "0:\tlearn: 0.6109536\ttotal: 34ms\tremaining: 13.6s\n",
      "1:\tlearn: 0.5530472\ttotal: 70.2ms\tremaining: 14s\n",
      "2:\tlearn: 0.5910103\ttotal: 102ms\tremaining: 13.5s\n",
      "3:\tlearn: 0.6070055\ttotal: 135ms\tremaining: 13.4s\n",
      "4:\tlearn: 0.5915165\ttotal: 168ms\tremaining: 13.3s\n",
      "5:\tlearn: 0.6202673\ttotal: 200ms\tremaining: 13.1s\n",
      "6:\tlearn: 0.6116623\ttotal: 231ms\tremaining: 13s\n",
      "7:\tlearn: 0.6126746\ttotal: 265ms\tremaining: 13s\n",
      "8:\tlearn: 0.6097388\ttotal: 297ms\tremaining: 12.9s\n",
      "9:\tlearn: 0.6165216\ttotal: 330ms\tremaining: 12.9s\n",
      "10:\tlearn: 0.6072079\ttotal: 363ms\tremaining: 12.8s\n",
      "11:\tlearn: 0.6111561\ttotal: 395ms\tremaining: 12.8s\n",
      "12:\tlearn: 0.6144969\ttotal: 425ms\tremaining: 12.7s\n",
      "13:\tlearn: 0.6092326\ttotal: 454ms\tremaining: 12.5s\n",
      "14:\tlearn: 0.6296821\ttotal: 488ms\tremaining: 12.5s\n",
      "15:\tlearn: 0.6276574\ttotal: 520ms\tremaining: 12.5s\n",
      "16:\tlearn: 0.6389957\ttotal: 553ms\tremaining: 12.5s\n",
      "17:\tlearn: 0.6358575\ttotal: 586ms\tremaining: 12.4s\n",
      "18:\tlearn: 0.6387933\ttotal: 614ms\tremaining: 12.3s\n",
      "19:\tlearn: 0.6300871\ttotal: 647ms\tremaining: 12.3s\n",
      "20:\tlearn: 0.6281636\ttotal: 680ms\tremaining: 12.3s\n",
      "21:\tlearn: 0.6372748\ttotal: 711ms\tremaining: 12.2s\n",
      "22:\tlearn: 0.6398056\ttotal: 743ms\tremaining: 12.2s\n",
      "23:\tlearn: 0.6524600\ttotal: 774ms\tremaining: 12.1s\n",
      "24:\tlearn: 0.6503341\ttotal: 807ms\tremaining: 12.1s\n",
      "25:\tlearn: 0.6527637\ttotal: 840ms\tremaining: 12.1s\n",
      "26:\tlearn: 0.6591415\ttotal: 873ms\tremaining: 12.1s\n",
      "27:\tlearn: 0.6607613\ttotal: 904ms\tremaining: 12s\n",
      "28:\tlearn: 0.6575218\ttotal: 937ms\tremaining: 12s\n",
      "29:\tlearn: 0.6571168\ttotal: 970ms\tremaining: 12s\n",
      "30:\tlearn: 0.6572181\ttotal: 999ms\tremaining: 11.9s\n",
      "31:\tlearn: 0.6574205\ttotal: 1.03s\tremaining: 11.9s\n",
      "32:\tlearn: 0.6627860\ttotal: 1.07s\tremaining: 11.9s\n",
      "33:\tlearn: 0.6637983\ttotal: 1.1s\tremaining: 11.8s\n",
      "34:\tlearn: 0.6603563\ttotal: 1.13s\tremaining: 11.8s\n",
      "35:\tlearn: 0.6621786\ttotal: 1.17s\tremaining: 11.8s\n",
      "36:\tlearn: 0.6608625\ttotal: 1.2s\tremaining: 11.8s\n",
      "37:\tlearn: 0.6620773\ttotal: 1.23s\tremaining: 11.7s\n",
      "38:\tlearn: 0.6625835\ttotal: 1.26s\tremaining: 11.7s\n",
      "39:\tlearn: 0.6655193\ttotal: 1.3s\tremaining: 11.7s\n",
      "40:\tlearn: 0.6675440\ttotal: 1.33s\tremaining: 11.6s\n",
      "41:\tlearn: 0.6700749\ttotal: 1.36s\tremaining: 11.6s\n",
      "42:\tlearn: 0.6683539\ttotal: 1.39s\tremaining: 11.6s\n",
      "43:\tlearn: 0.6684552\ttotal: 1.42s\tremaining: 11.5s\n",
      "44:\tlearn: 0.6699737\ttotal: 1.45s\tremaining: 11.5s\n",
      "45:\tlearn: 0.6730107\ttotal: 1.49s\tremaining: 11.4s\n",
      "46:\tlearn: 0.6755416\ttotal: 1.52s\tremaining: 11.4s\n",
      "47:\tlearn: 0.6737194\ttotal: 1.55s\tremaining: 11.4s\n",
      "48:\tlearn: 0.6701761\ttotal: 1.59s\tremaining: 11.4s\n",
      "49:\tlearn: 0.6707836\ttotal: 1.62s\tremaining: 11.4s\n",
      "50:\tlearn: 0.6712897\ttotal: 1.66s\tremaining: 11.4s\n",
      "51:\tlearn: 0.6698724\ttotal: 1.69s\tremaining: 11.3s\n",
      "52:\tlearn: 0.6699737\ttotal: 1.73s\tremaining: 11.3s\n",
      "53:\tlearn: 0.6716947\ttotal: 1.76s\tremaining: 11.3s\n",
      "54:\tlearn: 0.6709860\ttotal: 1.79s\tremaining: 11.2s\n",
      "55:\tlearn: 0.6724033\ttotal: 1.83s\tremaining: 11.2s\n",
      "56:\tlearn: 0.6714922\ttotal: 1.86s\tremaining: 11.2s\n",
      "57:\tlearn: 0.6692650\ttotal: 1.9s\tremaining: 11.2s\n",
      "58:\tlearn: 0.6742256\ttotal: 1.93s\tremaining: 11.1s\n",
      "59:\tlearn: 0.6759465\ttotal: 1.96s\tremaining: 11.1s\n",
      "60:\tlearn: 0.6785787\ttotal: 1.99s\tremaining: 11.1s\n",
      "61:\tlearn: 0.6758453\ttotal: 2.02s\tremaining: 11s\n",
      "62:\tlearn: 0.6792873\ttotal: 2.05s\tremaining: 11s\n",
      "63:\tlearn: 0.6781737\ttotal: 2.08s\tremaining: 10.9s\n",
      "64:\tlearn: 0.6827293\ttotal: 2.12s\tremaining: 10.9s\n",
      "65:\tlearn: 0.6836404\ttotal: 2.15s\tremaining: 10.9s\n",
      "66:\tlearn: 0.6825268\ttotal: 2.18s\tremaining: 10.8s\n",
      "67:\tlearn: 0.6815145\ttotal: 2.21s\tremaining: 10.8s\n",
      "68:\tlearn: 0.6808058\ttotal: 2.24s\tremaining: 10.8s\n",
      "69:\tlearn: 0.6780725\ttotal: 2.27s\tremaining: 10.7s\n",
      "70:\tlearn: 0.6764527\ttotal: 2.31s\tremaining: 10.7s\n",
      "71:\tlearn: 0.6744280\ttotal: 2.34s\tremaining: 10.7s\n",
      "72:\tlearn: 0.6739218\ttotal: 2.37s\tremaining: 10.6s\n",
      "73:\tlearn: 0.6772626\ttotal: 2.4s\tremaining: 10.6s\n",
      "74:\tlearn: 0.6778700\ttotal: 2.43s\tremaining: 10.5s\n",
      "75:\tlearn: 0.6776675\ttotal: 2.46s\tremaining: 10.5s\n",
      "76:\tlearn: 0.6760478\ttotal: 2.5s\tremaining: 10.5s\n",
      "77:\tlearn: 0.6756428\ttotal: 2.52s\tremaining: 10.4s\n",
      "78:\tlearn: 0.6726058\ttotal: 2.56s\tremaining: 10.4s\n",
      "79:\tlearn: 0.6701761\ttotal: 2.59s\tremaining: 10.3s\n",
      "80:\tlearn: 0.6742256\ttotal: 2.62s\tremaining: 10.3s\n",
      "81:\tlearn: 0.6771614\ttotal: 2.65s\tremaining: 10.3s\n",
      "82:\tlearn: 0.6772626\ttotal: 2.68s\tremaining: 10.2s\n",
      "83:\tlearn: 0.6770601\ttotal: 2.71s\tremaining: 10.2s\n",
      "84:\tlearn: 0.6761490\ttotal: 2.74s\tremaining: 10.2s\n",
      "85:\tlearn: 0.6784774\ttotal: 2.77s\tremaining: 10.1s\n",
      "86:\tlearn: 0.6774651\ttotal: 2.81s\tremaining: 10.1s\n",
      "87:\tlearn: 0.6764527\ttotal: 2.84s\tremaining: 10.1s\n",
      "88:\tlearn: 0.6772626\ttotal: 2.87s\tremaining: 10s\n",
      "89:\tlearn: 0.6787811\ttotal: 2.9s\tremaining: 10s\n",
      "90:\tlearn: 0.6784774\ttotal: 2.94s\tremaining: 9.97s\n",
      "91:\tlearn: 0.6804009\ttotal: 2.97s\tremaining: 9.93s\n",
      "92:\tlearn: 0.6847540\ttotal: 3s\tremaining: 9.89s\n",
      "93:\tlearn: 0.6814132\ttotal: 3.03s\tremaining: 9.86s\n",
      "94:\tlearn: 0.6839441\ttotal: 3.06s\tremaining: 9.83s\n",
      "95:\tlearn: 0.6844503\ttotal: 3.09s\tremaining: 9.8s\n",
      "96:\tlearn: 0.6844503\ttotal: 3.13s\tremaining: 9.77s\n",
      "97:\tlearn: 0.6857663\ttotal: 3.16s\tremaining: 9.73s\n",
      "98:\tlearn: 0.6852602\ttotal: 3.19s\tremaining: 9.7s\n",
      "99:\tlearn: 0.6878923\ttotal: 3.22s\tremaining: 9.66s\n",
      "100:\tlearn: 0.6875886\ttotal: 3.25s\tremaining: 9.63s\n",
      "101:\tlearn: 0.6855639\ttotal: 3.29s\tremaining: 9.6s\n",
      "102:\tlearn: 0.6876898\ttotal: 3.32s\tremaining: 9.56s\n",
      "103:\tlearn: 0.6879935\ttotal: 3.35s\tremaining: 9.53s\n",
      "104:\tlearn: 0.6873861\ttotal: 3.38s\tremaining: 9.5s\n",
      "105:\tlearn: 0.6866775\ttotal: 3.41s\tremaining: 9.47s\n",
      "106:\tlearn: 0.6872849\ttotal: 3.44s\tremaining: 9.43s\n",
      "107:\tlearn: 0.6862725\ttotal: 3.47s\tremaining: 9.39s\n",
      "108:\tlearn: 0.6883985\ttotal: 3.5s\tremaining: 9.36s\n",
      "109:\tlearn: 0.6872849\ttotal: 3.54s\tremaining: 9.33s\n",
      "110:\tlearn: 0.6857663\ttotal: 3.57s\tremaining: 9.3s\n",
      "111:\tlearn: 0.6870824\ttotal: 3.6s\tremaining: 9.27s\n",
      "112:\tlearn: 0.6879935\ttotal: 3.63s\tremaining: 9.23s\n",
      "113:\tlearn: 0.6874873\ttotal: 3.66s\tremaining: 9.19s\n",
      "114:\tlearn: 0.6881960\ttotal: 3.69s\tremaining: 9.16s\n",
      "115:\tlearn: 0.6897145\ttotal: 3.73s\tremaining: 9.13s\n",
      "116:\tlearn: 0.6901195\ttotal: 3.76s\tremaining: 9.1s\n",
      "117:\tlearn: 0.6882972\ttotal: 3.79s\tremaining: 9.06s\n",
      "118:\tlearn: 0.6891071\ttotal: 3.83s\tremaining: 9.03s\n",
      "119:\tlearn: 0.6907269\ttotal: 3.86s\tremaining: 9s\n",
      "120:\tlearn: 0.6904232\ttotal: 3.89s\tremaining: 8.97s\n",
      "121:\tlearn: 0.6917392\ttotal: 3.92s\tremaining: 8.94s\n",
      "122:\tlearn: 0.6905244\ttotal: 3.96s\tremaining: 8.91s\n",
      "123:\tlearn: 0.6920429\ttotal: 3.99s\tremaining: 8.88s\n",
      "124:\tlearn: 0.6911318\ttotal: 4.02s\tremaining: 8.85s\n",
      "125:\tlearn: 0.6928528\ttotal: 4.06s\tremaining: 8.82s\n",
      "126:\tlearn: 0.6926503\ttotal: 4.09s\tremaining: 8.8s\n",
      "127:\tlearn: 0.6939664\ttotal: 4.13s\tremaining: 8.77s\n",
      "128:\tlearn: 0.6934602\ttotal: 4.15s\tremaining: 8.73s\n",
      "129:\tlearn: 0.6935614\ttotal: 4.18s\tremaining: 8.69s\n",
      "130:\tlearn: 0.6928528\ttotal: 4.22s\tremaining: 8.66s\n",
      "131:\tlearn: 0.6928528\ttotal: 4.25s\tremaining: 8.63s\n",
      "132:\tlearn: 0.6922454\ttotal: 4.29s\tremaining: 8.6s\n",
      "133:\tlearn: 0.6906256\ttotal: 4.32s\tremaining: 8.58s\n",
      "134:\tlearn: 0.6934602\ttotal: 4.35s\tremaining: 8.54s\n",
      "135:\tlearn: 0.6937639\ttotal: 4.39s\tremaining: 8.52s\n",
      "136:\tlearn: 0.6942701\ttotal: 4.42s\tremaining: 8.48s\n",
      "137:\tlearn: 0.6944726\ttotal: 4.45s\tremaining: 8.45s\n",
      "138:\tlearn: 0.6945738\ttotal: 4.48s\tremaining: 8.42s\n",
      "139:\tlearn: 0.6948775\ttotal: 4.51s\tremaining: 8.38s\n",
      "140:\tlearn: 0.6929540\ttotal: 4.54s\tremaining: 8.34s\n",
      "141:\tlearn: 0.6936627\ttotal: 4.58s\tremaining: 8.31s\n",
      "142:\tlearn: 0.6947763\ttotal: 4.61s\tremaining: 8.28s\n",
      "143:\tlearn: 0.6952824\ttotal: 4.64s\tremaining: 8.25s\n",
      "144:\tlearn: 0.6925491\ttotal: 4.67s\tremaining: 8.21s\n",
      "145:\tlearn: 0.6951812\ttotal: 4.7s\tremaining: 8.18s\n",
      "146:\tlearn: 0.6947763\ttotal: 4.73s\tremaining: 8.15s\n",
      "147:\tlearn: 0.6944726\ttotal: 4.77s\tremaining: 8.12s\n",
      "148:\tlearn: 0.6942701\ttotal: 4.8s\tremaining: 8.08s\n",
      "149:\tlearn: 0.6929540\ttotal: 4.83s\tremaining: 8.05s\n",
      "150:\tlearn: 0.6912330\ttotal: 4.86s\tremaining: 8.02s\n",
      "151:\tlearn: 0.6915367\ttotal: 4.89s\tremaining: 7.97s\n",
      "152:\tlearn: 0.6903219\ttotal: 4.92s\tremaining: 7.94s\n",
      "153:\tlearn: 0.6913343\ttotal: 4.95s\tremaining: 7.91s\n",
      "154:\tlearn: 0.6910306\ttotal: 4.98s\tremaining: 7.88s\n",
      "155:\tlearn: 0.6915367\ttotal: 5.01s\tremaining: 7.84s\n",
      "156:\tlearn: 0.6910306\ttotal: 5.05s\tremaining: 7.81s\n",
      "157:\tlearn: 0.6914355\ttotal: 5.08s\tremaining: 7.79s\n",
      "158:\tlearn: 0.6910306\ttotal: 5.11s\tremaining: 7.75s\n",
      "159:\tlearn: 0.6913343\ttotal: 5.14s\tremaining: 7.72s\n",
      "160:\tlearn: 0.6915367\ttotal: 5.18s\tremaining: 7.69s\n",
      "161:\tlearn: 0.6912330\ttotal: 5.21s\tremaining: 7.66s\n",
      "162:\tlearn: 0.6915367\ttotal: 5.24s\tremaining: 7.62s\n",
      "163:\tlearn: 0.6934602\ttotal: 5.28s\tremaining: 7.59s\n",
      "164:\tlearn: 0.6930553\ttotal: 5.31s\tremaining: 7.56s\n",
      "165:\tlearn: 0.6943713\ttotal: 5.34s\tremaining: 7.53s\n",
      "166:\tlearn: 0.6965985\ttotal: 5.37s\tremaining: 7.49s\n",
      "167:\tlearn: 0.6965985\ttotal: 5.41s\tremaining: 7.46s\n",
      "168:\tlearn: 0.6965985\ttotal: 5.44s\tremaining: 7.43s\n",
      "169:\tlearn: 0.6965985\ttotal: 5.47s\tremaining: 7.4s\n",
      "170:\tlearn: 0.6974084\ttotal: 5.5s\tremaining: 7.37s\n",
      "171:\tlearn: 0.6975096\ttotal: 5.53s\tremaining: 7.33s\n",
      "172:\tlearn: 0.6984207\ttotal: 5.56s\tremaining: 7.29s\n",
      "173:\tlearn: 0.6984207\ttotal: 5.59s\tremaining: 7.26s\n",
      "174:\tlearn: 0.6965985\ttotal: 5.63s\tremaining: 7.23s\n",
      "175:\tlearn: 0.6964973\ttotal: 5.66s\tremaining: 7.2s\n",
      "176:\tlearn: 0.6974084\ttotal: 5.7s\tremaining: 7.18s\n",
      "177:\tlearn: 0.6981170\ttotal: 5.73s\tremaining: 7.15s\n",
      "178:\tlearn: 0.6984207\ttotal: 5.76s\tremaining: 7.12s\n",
      "179:\tlearn: 0.6983195\ttotal: 5.79s\tremaining: 7.08s\n",
      "180:\tlearn: 0.6988257\ttotal: 5.83s\tremaining: 7.05s\n",
      "181:\tlearn: 0.7000405\ttotal: 5.86s\tremaining: 7.02s\n",
      "182:\tlearn: 0.7005467\ttotal: 5.89s\tremaining: 6.99s\n",
      "183:\tlearn: 0.7007491\ttotal: 5.92s\tremaining: 6.95s\n",
      "184:\tlearn: 0.7013565\ttotal: 5.96s\tremaining: 6.92s\n",
      "185:\tlearn: 0.7024701\ttotal: 5.99s\tremaining: 6.89s\n",
      "186:\tlearn: 0.7019640\ttotal: 6.02s\tremaining: 6.85s\n",
      "187:\tlearn: 0.7038874\ttotal: 6.05s\tremaining: 6.82s\n",
      "188:\tlearn: 0.7035837\ttotal: 6.08s\tremaining: 6.79s\n",
      "189:\tlearn: 0.7035837\ttotal: 6.11s\tremaining: 6.76s\n",
      "190:\tlearn: 0.7036850\ttotal: 6.14s\tremaining: 6.72s\n",
      "191:\tlearn: 0.7040899\ttotal: 6.18s\tremaining: 6.69s\n",
      "192:\tlearn: 0.7042924\ttotal: 6.21s\tremaining: 6.66s\n",
      "193:\tlearn: 0.7028751\ttotal: 6.24s\tremaining: 6.62s\n",
      "194:\tlearn: 0.7042924\ttotal: 6.27s\tremaining: 6.59s\n",
      "195:\tlearn: 0.7042924\ttotal: 6.3s\tremaining: 6.56s\n",
      "196:\tlearn: 0.7040899\ttotal: 6.33s\tremaining: 6.52s\n",
      "197:\tlearn: 0.7044948\ttotal: 6.36s\tremaining: 6.49s\n",
      "198:\tlearn: 0.7053047\ttotal: 6.39s\tremaining: 6.45s\n",
      "199:\tlearn: 0.7048998\ttotal: 6.42s\tremaining: 6.42s\n",
      "200:\tlearn: 0.7043936\ttotal: 6.46s\tremaining: 6.39s\n",
      "201:\tlearn: 0.7047985\ttotal: 6.49s\tremaining: 6.36s\n",
      "202:\tlearn: 0.7044948\ttotal: 6.52s\tremaining: 6.33s\n",
      "203:\tlearn: 0.7040899\ttotal: 6.55s\tremaining: 6.29s\n",
      "204:\tlearn: 0.7039887\ttotal: 6.58s\tremaining: 6.26s\n",
      "205:\tlearn: 0.7047985\ttotal: 6.61s\tremaining: 6.23s\n",
      "206:\tlearn: 0.7047985\ttotal: 6.65s\tremaining: 6.2s\n",
      "207:\tlearn: 0.7037862\ttotal: 6.68s\tremaining: 6.17s\n",
      "208:\tlearn: 0.7036850\ttotal: 6.71s\tremaining: 6.13s\n",
      "209:\tlearn: 0.7035837\ttotal: 6.74s\tremaining: 6.1s\n",
      "210:\tlearn: 0.7050010\ttotal: 6.78s\tremaining: 6.07s\n",
      "211:\tlearn: 0.7071269\ttotal: 6.8s\tremaining: 6.03s\n",
      "212:\tlearn: 0.7058109\ttotal: 6.84s\tremaining: 6s\n",
      "213:\tlearn: 0.7068232\ttotal: 6.87s\tremaining: 5.97s\n",
      "214:\tlearn: 0.7086455\ttotal: 6.9s\tremaining: 5.94s\n",
      "215:\tlearn: 0.7091517\ttotal: 6.93s\tremaining: 5.91s\n",
      "216:\tlearn: 0.7098603\ttotal: 6.96s\tremaining: 5.87s\n",
      "217:\tlearn: 0.7097591\ttotal: 7s\tremaining: 5.84s\n",
      "218:\tlearn: 0.7107714\ttotal: 7.04s\tremaining: 5.82s\n",
      "219:\tlearn: 0.7109739\ttotal: 7.07s\tremaining: 5.79s\n",
      "220:\tlearn: 0.7109739\ttotal: 7.1s\tremaining: 5.75s\n",
      "221:\tlearn: 0.7137072\ttotal: 7.13s\tremaining: 5.72s\n",
      "222:\tlearn: 0.7128973\ttotal: 7.17s\tremaining: 5.69s\n",
      "223:\tlearn: 0.7134035\ttotal: 7.2s\tremaining: 5.66s\n",
      "224:\tlearn: 0.7134035\ttotal: 7.23s\tremaining: 5.62s\n",
      "225:\tlearn: 0.7134035\ttotal: 7.26s\tremaining: 5.59s\n",
      "226:\tlearn: 0.7114801\ttotal: 7.29s\tremaining: 5.56s\n",
      "227:\tlearn: 0.7108726\ttotal: 7.32s\tremaining: 5.52s\n",
      "228:\tlearn: 0.7110751\ttotal: 7.35s\tremaining: 5.49s\n",
      "229:\tlearn: 0.7114801\ttotal: 7.38s\tremaining: 5.46s\n",
      "230:\tlearn: 0.7112776\ttotal: 7.41s\tremaining: 5.42s\n",
      "231:\tlearn: 0.7115813\ttotal: 7.45s\tremaining: 5.39s\n",
      "232:\tlearn: 0.7114801\ttotal: 7.47s\tremaining: 5.36s\n",
      "233:\tlearn: 0.7107714\ttotal: 7.51s\tremaining: 5.32s\n",
      "234:\tlearn: 0.7108726\ttotal: 7.53s\tremaining: 5.29s\n",
      "235:\tlearn: 0.7100628\ttotal: 7.57s\tremaining: 5.26s\n",
      "236:\tlearn: 0.7101640\ttotal: 7.6s\tremaining: 5.22s\n",
      "237:\tlearn: 0.7104677\ttotal: 7.63s\tremaining: 5.19s\n",
      "238:\tlearn: 0.7110751\ttotal: 7.66s\tremaining: 5.16s\n",
      "239:\tlearn: 0.7107714\ttotal: 7.69s\tremaining: 5.13s\n",
      "240:\tlearn: 0.7097591\ttotal: 7.72s\tremaining: 5.09s\n",
      "241:\tlearn: 0.7094554\ttotal: 7.76s\tremaining: 5.06s\n",
      "242:\tlearn: 0.7099615\ttotal: 7.79s\tremaining: 5.03s\n",
      "243:\tlearn: 0.7113788\ttotal: 7.82s\tremaining: 5s\n",
      "244:\tlearn: 0.7118850\ttotal: 7.85s\tremaining: 4.97s\n",
      "245:\tlearn: 0.7120875\ttotal: 7.88s\tremaining: 4.93s\n",
      "246:\tlearn: 0.7124924\ttotal: 7.91s\tremaining: 4.9s\n",
      "247:\tlearn: 0.7104677\ttotal: 7.94s\tremaining: 4.87s\n",
      "248:\tlearn: 0.7114801\ttotal: 7.97s\tremaining: 4.83s\n",
      "249:\tlearn: 0.7133023\ttotal: 8s\tremaining: 4.8s\n",
      "250:\tlearn: 0.7132011\ttotal: 8.04s\tremaining: 4.77s\n",
      "251:\tlearn: 0.7119862\ttotal: 8.07s\tremaining: 4.74s\n",
      "252:\tlearn: 0.7125936\ttotal: 8.11s\tremaining: 4.71s\n",
      "253:\tlearn: 0.7128973\ttotal: 8.13s\tremaining: 4.68s\n",
      "254:\tlearn: 0.7127961\ttotal: 8.17s\tremaining: 4.64s\n",
      "255:\tlearn: 0.7143146\ttotal: 8.2s\tremaining: 4.61s\n",
      "256:\tlearn: 0.7144159\ttotal: 8.23s\tremaining: 4.58s\n",
      "257:\tlearn: 0.7151245\ttotal: 8.26s\tremaining: 4.54s\n",
      "258:\tlearn: 0.7146183\ttotal: 8.29s\tremaining: 4.51s\n",
      "259:\tlearn: 0.7140109\ttotal: 8.33s\tremaining: 4.48s\n",
      "260:\tlearn: 0.7148208\ttotal: 8.36s\tremaining: 4.45s\n",
      "261:\tlearn: 0.7156307\ttotal: 8.39s\tremaining: 4.42s\n",
      "262:\tlearn: 0.7163393\ttotal: 8.42s\tremaining: 4.39s\n",
      "263:\tlearn: 0.7170480\ttotal: 8.45s\tremaining: 4.35s\n",
      "264:\tlearn: 0.7179591\ttotal: 8.48s\tremaining: 4.32s\n",
      "265:\tlearn: 0.7173517\ttotal: 8.51s\tremaining: 4.29s\n",
      "266:\tlearn: 0.7176554\ttotal: 8.54s\tremaining: 4.25s\n",
      "267:\tlearn: 0.7167443\ttotal: 8.57s\tremaining: 4.22s\n",
      "268:\tlearn: 0.7170480\ttotal: 8.6s\tremaining: 4.19s\n",
      "269:\tlearn: 0.7178579\ttotal: 8.63s\tremaining: 4.16s\n",
      "270:\tlearn: 0.7165418\ttotal: 8.66s\tremaining: 4.12s\n",
      "271:\tlearn: 0.7171492\ttotal: 8.7s\tremaining: 4.09s\n",
      "272:\tlearn: 0.7166430\ttotal: 8.73s\tremaining: 4.06s\n",
      "273:\tlearn: 0.7166430\ttotal: 8.76s\tremaining: 4.03s\n",
      "274:\tlearn: 0.7166430\ttotal: 8.79s\tremaining: 4s\n",
      "275:\tlearn: 0.7175542\ttotal: 8.82s\tremaining: 3.96s\n",
      "276:\tlearn: 0.7170480\ttotal: 8.85s\tremaining: 3.93s\n",
      "277:\tlearn: 0.7171492\ttotal: 8.88s\tremaining: 3.9s\n",
      "278:\tlearn: 0.7179591\ttotal: 8.92s\tremaining: 3.87s\n",
      "279:\tlearn: 0.7182628\ttotal: 8.94s\tremaining: 3.83s\n",
      "280:\tlearn: 0.7182628\ttotal: 8.98s\tremaining: 3.8s\n",
      "281:\tlearn: 0.7178579\ttotal: 9.01s\tremaining: 3.77s\n",
      "282:\tlearn: 0.7175542\ttotal: 9.04s\tremaining: 3.74s\n",
      "283:\tlearn: 0.7176554\ttotal: 9.07s\tremaining: 3.7s\n",
      "284:\tlearn: 0.7175542\ttotal: 9.1s\tremaining: 3.67s\n",
      "285:\tlearn: 0.7188702\ttotal: 9.13s\tremaining: 3.64s\n",
      "286:\tlearn: 0.7186677\ttotal: 9.16s\tremaining: 3.61s\n",
      "287:\tlearn: 0.7190727\ttotal: 9.19s\tremaining: 3.57s\n",
      "288:\tlearn: 0.7191739\ttotal: 9.22s\tremaining: 3.54s\n",
      "289:\tlearn: 0.7189715\ttotal: 9.25s\tremaining: 3.51s\n",
      "290:\tlearn: 0.7188702\ttotal: 9.28s\tremaining: 3.48s\n",
      "291:\tlearn: 0.7186677\ttotal: 9.31s\tremaining: 3.44s\n",
      "292:\tlearn: 0.7185665\ttotal: 9.34s\tremaining: 3.41s\n",
      "293:\tlearn: 0.7188702\ttotal: 9.37s\tremaining: 3.38s\n",
      "294:\tlearn: 0.7188702\ttotal: 9.4s\tremaining: 3.35s\n",
      "295:\tlearn: 0.7203887\ttotal: 9.43s\tremaining: 3.31s\n",
      "296:\tlearn: 0.7206924\ttotal: 9.46s\tremaining: 3.28s\n",
      "297:\tlearn: 0.7208949\ttotal: 9.5s\tremaining: 3.25s\n",
      "298:\tlearn: 0.7214011\ttotal: 9.53s\tremaining: 3.22s\n",
      "299:\tlearn: 0.7222110\ttotal: 9.56s\tremaining: 3.19s\n",
      "300:\tlearn: 0.7222110\ttotal: 9.59s\tremaining: 3.15s\n",
      "301:\tlearn: 0.7219073\ttotal: 9.62s\tremaining: 3.12s\n",
      "302:\tlearn: 0.7224134\ttotal: 9.65s\tremaining: 3.09s\n",
      "303:\tlearn: 0.7224134\ttotal: 9.68s\tremaining: 3.06s\n",
      "304:\tlearn: 0.7223122\ttotal: 9.72s\tremaining: 3.03s\n",
      "305:\tlearn: 0.7216036\ttotal: 9.75s\tremaining: 3s\n",
      "306:\tlearn: 0.7214011\ttotal: 9.78s\tremaining: 2.96s\n",
      "307:\tlearn: 0.7222110\ttotal: 9.81s\tremaining: 2.93s\n",
      "308:\tlearn: 0.7225147\ttotal: 9.84s\tremaining: 2.9s\n",
      "309:\tlearn: 0.7235270\ttotal: 9.88s\tremaining: 2.87s\n",
      "310:\tlearn: 0.7234258\ttotal: 9.91s\tremaining: 2.83s\n",
      "311:\tlearn: 0.7245394\ttotal: 9.94s\tremaining: 2.8s\n",
      "312:\tlearn: 0.7245394\ttotal: 9.97s\tremaining: 2.77s\n",
      "313:\tlearn: 0.7235270\ttotal: 10s\tremaining: 2.74s\n",
      "314:\tlearn: 0.7235270\ttotal: 10s\tremaining: 2.71s\n",
      "315:\tlearn: 0.7232233\ttotal: 10.1s\tremaining: 2.68s\n",
      "316:\tlearn: 0.7222110\ttotal: 10.1s\tremaining: 2.65s\n",
      "317:\tlearn: 0.7219073\ttotal: 10.1s\tremaining: 2.61s\n",
      "318:\tlearn: 0.7226159\ttotal: 10.2s\tremaining: 2.58s\n",
      "319:\tlearn: 0.7228184\ttotal: 10.2s\tremaining: 2.55s\n",
      "320:\tlearn: 0.7237295\ttotal: 10.2s\tremaining: 2.52s\n",
      "321:\tlearn: 0.7241344\ttotal: 10.3s\tremaining: 2.48s\n",
      "322:\tlearn: 0.7245394\ttotal: 10.3s\tremaining: 2.45s\n",
      "323:\tlearn: 0.7244381\ttotal: 10.3s\tremaining: 2.42s\n",
      "324:\tlearn: 0.7248431\ttotal: 10.3s\tremaining: 2.39s\n",
      "325:\tlearn: 0.7242357\ttotal: 10.4s\tremaining: 2.36s\n",
      "326:\tlearn: 0.7243369\ttotal: 10.4s\tremaining: 2.33s\n",
      "327:\tlearn: 0.7240332\ttotal: 10.5s\tremaining: 2.29s\n",
      "328:\tlearn: 0.7246406\ttotal: 10.5s\tremaining: 2.26s\n",
      "329:\tlearn: 0.7244381\ttotal: 10.5s\tremaining: 2.23s\n",
      "330:\tlearn: 0.7243369\ttotal: 10.6s\tremaining: 2.2s\n",
      "331:\tlearn: 0.7242357\ttotal: 10.6s\tremaining: 2.17s\n",
      "332:\tlearn: 0.7243369\ttotal: 10.6s\tremaining: 2.14s\n",
      "333:\tlearn: 0.7253493\ttotal: 10.6s\tremaining: 2.1s\n",
      "334:\tlearn: 0.7245394\ttotal: 10.7s\tremaining: 2.07s\n",
      "335:\tlearn: 0.7241344\ttotal: 10.7s\tremaining: 2.04s\n",
      "336:\tlearn: 0.7253493\ttotal: 10.7s\tremaining: 2.01s\n",
      "337:\tlearn: 0.7249443\ttotal: 10.8s\tremaining: 1.98s\n",
      "338:\tlearn: 0.7252480\ttotal: 10.8s\tremaining: 1.95s\n",
      "339:\tlearn: 0.7258554\ttotal: 10.8s\tremaining: 1.91s\n",
      "340:\tlearn: 0.7257542\ttotal: 10.9s\tremaining: 1.88s\n",
      "341:\tlearn: 0.7261591\ttotal: 10.9s\tremaining: 1.85s\n",
      "342:\tlearn: 0.7265641\ttotal: 11s\tremaining: 1.82s\n",
      "343:\tlearn: 0.7259567\ttotal: 11s\tremaining: 1.79s\n",
      "344:\tlearn: 0.7269690\ttotal: 11s\tremaining: 1.75s\n",
      "345:\tlearn: 0.7266653\ttotal: 11s\tremaining: 1.72s\n",
      "346:\tlearn: 0.7277789\ttotal: 11.1s\tremaining: 1.69s\n",
      "347:\tlearn: 0.7281838\ttotal: 11.1s\tremaining: 1.66s\n",
      "348:\tlearn: 0.7280826\ttotal: 11.1s\tremaining: 1.63s\n",
      "349:\tlearn: 0.7272727\ttotal: 11.2s\tremaining: 1.59s\n",
      "350:\tlearn: 0.7271715\ttotal: 11.2s\tremaining: 1.56s\n",
      "351:\tlearn: 0.7279814\ttotal: 11.2s\tremaining: 1.53s\n",
      "352:\tlearn: 0.7279814\ttotal: 11.3s\tremaining: 1.5s\n",
      "353:\tlearn: 0.7277789\ttotal: 11.3s\tremaining: 1.47s\n",
      "354:\tlearn: 0.7280826\ttotal: 11.3s\tremaining: 1.44s\n",
      "355:\tlearn: 0.7271715\ttotal: 11.4s\tremaining: 1.4s\n",
      "356:\tlearn: 0.7276777\ttotal: 11.4s\tremaining: 1.37s\n",
      "357:\tlearn: 0.7278801\ttotal: 11.4s\tremaining: 1.34s\n",
      "358:\tlearn: 0.7290950\ttotal: 11.5s\tremaining: 1.31s\n",
      "359:\tlearn: 0.7298036\ttotal: 11.5s\tremaining: 1.28s\n",
      "360:\tlearn: 0.7308160\ttotal: 11.5s\tremaining: 1.24s\n",
      "361:\tlearn: 0.7298036\ttotal: 11.6s\tremaining: 1.21s\n",
      "362:\tlearn: 0.7290950\ttotal: 11.6s\tremaining: 1.18s\n",
      "363:\tlearn: 0.7301073\ttotal: 11.6s\tremaining: 1.15s\n",
      "364:\tlearn: 0.7289937\ttotal: 11.7s\tremaining: 1.12s\n",
      "365:\tlearn: 0.7284875\ttotal: 11.7s\tremaining: 1.08s\n",
      "366:\tlearn: 0.7285888\ttotal: 11.7s\tremaining: 1.05s\n",
      "367:\tlearn: 0.7291962\ttotal: 11.7s\tremaining: 1.02s\n",
      "368:\tlearn: 0.7290950\ttotal: 11.8s\tremaining: 990ms\n",
      "369:\tlearn: 0.7296011\ttotal: 11.8s\tremaining: 957ms\n",
      "370:\tlearn: 0.7300061\ttotal: 11.8s\tremaining: 925ms\n",
      "371:\tlearn: 0.7294999\ttotal: 11.9s\tremaining: 894ms\n",
      "372:\tlearn: 0.7298036\ttotal: 11.9s\tremaining: 862ms\n",
      "373:\tlearn: 0.7299048\ttotal: 11.9s\tremaining: 830ms\n",
      "374:\tlearn: 0.7298036\ttotal: 12s\tremaining: 798ms\n",
      "375:\tlearn: 0.7300061\ttotal: 12s\tremaining: 766ms\n",
      "376:\tlearn: 0.7303098\ttotal: 12s\tremaining: 734ms\n",
      "377:\tlearn: 0.7305122\ttotal: 12.1s\tremaining: 702ms\n",
      "378:\tlearn: 0.7306135\ttotal: 12.1s\tremaining: 670ms\n",
      "379:\tlearn: 0.7305122\ttotal: 12.1s\tremaining: 638ms\n",
      "380:\tlearn: 0.7313221\ttotal: 12.2s\tremaining: 606ms\n",
      "381:\tlearn: 0.7307147\ttotal: 12.2s\tremaining: 574ms\n",
      "382:\tlearn: 0.7304110\ttotal: 12.2s\tremaining: 543ms\n",
      "383:\tlearn: 0.7301073\ttotal: 12.3s\tremaining: 511ms\n",
      "384:\tlearn: 0.7297024\ttotal: 12.3s\tremaining: 479ms\n",
      "385:\tlearn: 0.7308160\ttotal: 12.3s\tremaining: 447ms\n",
      "386:\tlearn: 0.7321320\ttotal: 12.4s\tremaining: 415ms\n",
      "387:\tlearn: 0.7329419\ttotal: 12.4s\tremaining: 383ms\n",
      "388:\tlearn: 0.7327394\ttotal: 12.4s\tremaining: 351ms\n",
      "389:\tlearn: 0.7338530\ttotal: 12.5s\tremaining: 319ms\n",
      "390:\tlearn: 0.7331444\ttotal: 12.5s\tremaining: 287ms\n",
      "391:\tlearn: 0.7319295\ttotal: 12.5s\tremaining: 255ms\n",
      "392:\tlearn: 0.7331444\ttotal: 12.5s\tremaining: 224ms\n",
      "393:\tlearn: 0.7333468\ttotal: 12.6s\tremaining: 192ms\n",
      "394:\tlearn: 0.7329419\ttotal: 12.6s\tremaining: 160ms\n",
      "395:\tlearn: 0.7322332\ttotal: 12.6s\tremaining: 128ms\n",
      "396:\tlearn: 0.7330431\ttotal: 12.7s\tremaining: 95.8ms\n",
      "397:\tlearn: 0.7330431\ttotal: 12.7s\tremaining: 63.8ms\n",
      "398:\tlearn: 0.7335493\ttotal: 12.7s\tremaining: 31.9ms\n",
      "399:\tlearn: 0.7333468\ttotal: 12.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=0.1, border_count=64, depth=3, eval_metric=Recall, iterations=400, l2_leaf_reg=9, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=2; total time=  13.2s\n",
      "0:\tlearn: 0.6559670\ttotal: 59.9ms\tremaining: 17.9s\n",
      "1:\tlearn: 0.6249748\ttotal: 111ms\tremaining: 16.6s\n",
      "2:\tlearn: 0.6565470\ttotal: 158ms\tremaining: 15.6s\n",
      "3:\tlearn: 0.6607448\ttotal: 209ms\tremaining: 15.5s\n",
      "4:\tlearn: 0.6754108\ttotal: 267ms\tremaining: 15.7s\n",
      "5:\tlearn: 0.6762667\ttotal: 318ms\tremaining: 15.6s\n",
      "6:\tlearn: 0.6814901\ttotal: 370ms\tremaining: 15.5s\n",
      "7:\tlearn: 0.6907751\ttotal: 417ms\tremaining: 15.2s\n",
      "8:\tlearn: 0.7033573\ttotal: 476ms\tremaining: 15.4s\n",
      "9:\tlearn: 0.7089232\ttotal: 529ms\tremaining: 15.3s\n",
      "10:\tlearn: 0.7134282\ttotal: 584ms\tremaining: 15.3s\n",
      "11:\tlearn: 0.7186515\ttotal: 639ms\tremaining: 15.3s\n",
      "12:\tlearn: 0.7215958\ttotal: 689ms\tremaining: 15.2s\n",
      "13:\tlearn: 0.7263031\ttotal: 742ms\tremaining: 15.1s\n",
      "14:\tlearn: 0.7300617\ttotal: 788ms\tremaining: 15s\n",
      "15:\tlearn: 0.7303579\ttotal: 840ms\tremaining: 14.9s\n",
      "16:\tlearn: 0.7318150\ttotal: 884ms\tremaining: 14.7s\n",
      "17:\tlearn: 0.7342471\ttotal: 936ms\tremaining: 14.7s\n",
      "18:\tlearn: 0.7356737\ttotal: 984ms\tremaining: 14.6s\n",
      "19:\tlearn: 0.7413256\ttotal: 1.03s\tremaining: 14.5s\n",
      "20:\tlearn: 0.7434743\ttotal: 1.08s\tremaining: 14.3s\n",
      "21:\tlearn: 0.7464479\ttotal: 1.13s\tremaining: 14.3s\n",
      "22:\tlearn: 0.7470265\ttotal: 1.18s\tremaining: 14.2s\n",
      "23:\tlearn: 0.7481914\ttotal: 1.24s\tremaining: 14.3s\n",
      "24:\tlearn: 0.7485771\ttotal: 1.3s\tremaining: 14.3s\n",
      "25:\tlearn: 0.7518234\ttotal: 1.35s\tremaining: 14.2s\n",
      "26:\tlearn: 0.7545137\ttotal: 1.4s\tremaining: 14.2s\n",
      "27:\tlearn: 0.7557260\ttotal: 1.45s\tremaining: 14.1s\n",
      "28:\tlearn: 0.7566409\ttotal: 1.5s\tremaining: 14s\n",
      "29:\tlearn: 0.7582489\ttotal: 1.54s\tremaining: 13.9s\n",
      "30:\tlearn: 0.7615146\ttotal: 1.59s\tremaining: 13.8s\n",
      "31:\tlearn: 0.7634780\ttotal: 1.65s\tremaining: 13.8s\n",
      "32:\tlearn: 0.7643140\ttotal: 1.71s\tremaining: 13.8s\n",
      "33:\tlearn: 0.7670739\ttotal: 1.76s\tremaining: 13.8s\n",
      "34:\tlearn: 0.7677303\ttotal: 1.82s\tremaining: 13.8s\n",
      "35:\tlearn: 0.7717560\ttotal: 1.87s\tremaining: 13.7s\n",
      "36:\tlearn: 0.7717315\ttotal: 1.92s\tremaining: 13.6s\n",
      "37:\tlearn: 0.7747522\ttotal: 1.97s\tremaining: 13.6s\n",
      "38:\tlearn: 0.7760240\ttotal: 2.02s\tremaining: 13.5s\n",
      "39:\tlearn: 0.7768900\ttotal: 2.06s\tremaining: 13.4s\n",
      "40:\tlearn: 0.7778000\ttotal: 2.11s\tremaining: 13.3s\n",
      "41:\tlearn: 0.7789842\ttotal: 2.16s\tremaining: 13.3s\n",
      "42:\tlearn: 0.7808459\ttotal: 2.21s\tremaining: 13.2s\n",
      "43:\tlearn: 0.7820532\ttotal: 2.26s\tremaining: 13.2s\n",
      "44:\tlearn: 0.7824740\ttotal: 2.31s\tremaining: 13.1s\n",
      "45:\tlearn: 0.7847596\ttotal: 2.36s\tremaining: 13s\n",
      "46:\tlearn: 0.7867497\ttotal: 2.41s\tremaining: 13s\n",
      "47:\tlearn: 0.7874102\ttotal: 2.46s\tremaining: 12.9s\n",
      "48:\tlearn: 0.7896104\ttotal: 2.51s\tremaining: 12.9s\n",
      "49:\tlearn: 0.7909322\ttotal: 2.56s\tremaining: 12.8s\n",
      "50:\tlearn: 0.7916229\ttotal: 2.61s\tremaining: 12.8s\n",
      "51:\tlearn: 0.7928811\ttotal: 2.66s\tremaining: 12.7s\n",
      "52:\tlearn: 0.7941603\ttotal: 2.71s\tremaining: 12.6s\n",
      "53:\tlearn: 0.7955420\ttotal: 2.76s\tremaining: 12.6s\n",
      "54:\tlearn: 0.7965195\ttotal: 2.81s\tremaining: 12.5s\n",
      "55:\tlearn: 0.7954818\ttotal: 2.86s\tremaining: 12.4s\n",
      "56:\tlearn: 0.7975405\ttotal: 2.9s\tremaining: 12.4s\n",
      "57:\tlearn: 0.7984787\ttotal: 2.95s\tremaining: 12.3s\n",
      "58:\tlearn: 0.7981202\ttotal: 3s\tremaining: 12.2s\n",
      "59:\tlearn: 0.7996998\ttotal: 3.05s\tremaining: 12.2s\n",
      "60:\tlearn: 0.8001600\ttotal: 3.1s\tremaining: 12.1s\n",
      "61:\tlearn: 0.8010194\ttotal: 3.15s\tremaining: 12.1s\n",
      "62:\tlearn: 0.8022165\ttotal: 3.2s\tremaining: 12s\n",
      "63:\tlearn: 0.8023528\ttotal: 3.25s\tremaining: 12s\n",
      "64:\tlearn: 0.8044899\ttotal: 3.3s\tremaining: 11.9s\n",
      "65:\tlearn: 0.8053906\ttotal: 3.35s\tremaining: 11.9s\n",
      "66:\tlearn: 0.8064870\ttotal: 3.4s\tremaining: 11.8s\n",
      "67:\tlearn: 0.8072872\ttotal: 3.46s\tremaining: 11.8s\n",
      "68:\tlearn: 0.8090660\ttotal: 3.5s\tremaining: 11.7s\n",
      "69:\tlearn: 0.8089026\ttotal: 3.55s\tremaining: 11.7s\n",
      "70:\tlearn: 0.8089305\ttotal: 3.6s\tremaining: 11.6s\n",
      "71:\tlearn: 0.8096093\ttotal: 3.65s\tremaining: 11.6s\n",
      "72:\tlearn: 0.8107461\ttotal: 3.7s\tremaining: 11.5s\n",
      "73:\tlearn: 0.8097255\ttotal: 3.76s\tremaining: 11.5s\n",
      "74:\tlearn: 0.8112822\ttotal: 3.81s\tremaining: 11.4s\n",
      "75:\tlearn: 0.8124005\ttotal: 3.86s\tremaining: 11.4s\n",
      "76:\tlearn: 0.8130381\ttotal: 3.91s\tremaining: 11.3s\n",
      "77:\tlearn: 0.8124969\ttotal: 3.96s\tremaining: 11.3s\n",
      "78:\tlearn: 0.8133719\ttotal: 4.01s\tremaining: 11.2s\n",
      "79:\tlearn: 0.8137465\ttotal: 4.06s\tremaining: 11.2s\n",
      "80:\tlearn: 0.8158327\ttotal: 4.11s\tremaining: 11.1s\n",
      "81:\tlearn: 0.8158838\ttotal: 4.16s\tremaining: 11s\n",
      "82:\tlearn: 0.8181321\ttotal: 4.2s\tremaining: 11s\n",
      "83:\tlearn: 0.8185709\ttotal: 4.25s\tremaining: 10.9s\n",
      "84:\tlearn: 0.8199165\ttotal: 4.29s\tremaining: 10.9s\n",
      "85:\tlearn: 0.8196396\ttotal: 4.34s\tremaining: 10.8s\n",
      "86:\tlearn: 0.8205995\ttotal: 4.38s\tremaining: 10.7s\n",
      "87:\tlearn: 0.8207627\ttotal: 4.43s\tremaining: 10.7s\n",
      "88:\tlearn: 0.8208161\ttotal: 4.48s\tremaining: 10.6s\n",
      "89:\tlearn: 0.8208540\ttotal: 4.53s\tremaining: 10.6s\n",
      "90:\tlearn: 0.8209429\ttotal: 4.57s\tremaining: 10.5s\n",
      "91:\tlearn: 0.8228753\ttotal: 4.63s\tremaining: 10.5s\n",
      "92:\tlearn: 0.8237807\ttotal: 4.68s\tremaining: 10.4s\n",
      "93:\tlearn: 0.8244116\ttotal: 4.73s\tremaining: 10.4s\n",
      "94:\tlearn: 0.8245405\ttotal: 4.77s\tremaining: 10.3s\n",
      "95:\tlearn: 0.8259898\ttotal: 4.83s\tremaining: 10.3s\n",
      "96:\tlearn: 0.8261064\ttotal: 4.88s\tremaining: 10.2s\n",
      "97:\tlearn: 0.8281553\ttotal: 4.93s\tremaining: 10.2s\n",
      "98:\tlearn: 0.8285658\ttotal: 4.98s\tremaining: 10.1s\n",
      "99:\tlearn: 0.8293337\ttotal: 5.03s\tremaining: 10.1s\n",
      "100:\tlearn: 0.8298475\ttotal: 5.08s\tremaining: 10s\n",
      "101:\tlearn: 0.8313815\ttotal: 5.13s\tremaining: 9.96s\n",
      "102:\tlearn: 0.8314729\ttotal: 5.18s\tremaining: 9.92s\n",
      "103:\tlearn: 0.8325729\ttotal: 5.23s\tremaining: 9.86s\n",
      "104:\tlearn: 0.8326304\ttotal: 5.28s\tremaining: 9.81s\n",
      "105:\tlearn: 0.8343510\ttotal: 5.33s\tremaining: 9.76s\n",
      "106:\tlearn: 0.8351528\ttotal: 5.38s\tremaining: 9.71s\n",
      "107:\tlearn: 0.8357068\ttotal: 5.43s\tremaining: 9.65s\n",
      "108:\tlearn: 0.8362176\ttotal: 5.48s\tremaining: 9.61s\n",
      "109:\tlearn: 0.8367438\ttotal: 5.53s\tremaining: 9.55s\n",
      "110:\tlearn: 0.8362825\ttotal: 5.58s\tremaining: 9.5s\n",
      "111:\tlearn: 0.8373798\ttotal: 5.63s\tremaining: 9.45s\n",
      "112:\tlearn: 0.8378499\ttotal: 5.68s\tremaining: 9.4s\n",
      "113:\tlearn: 0.8393752\ttotal: 5.73s\tremaining: 9.35s\n",
      "114:\tlearn: 0.8400574\ttotal: 5.78s\tremaining: 9.29s\n",
      "115:\tlearn: 0.8403902\ttotal: 5.83s\tremaining: 9.24s\n",
      "116:\tlearn: 0.8421469\ttotal: 5.88s\tremaining: 9.19s\n",
      "117:\tlearn: 0.8429123\ttotal: 5.92s\tremaining: 9.14s\n",
      "118:\tlearn: 0.8445829\ttotal: 5.97s\tremaining: 9.08s\n",
      "119:\tlearn: 0.8454159\ttotal: 6.02s\tremaining: 9.03s\n",
      "120:\tlearn: 0.8442315\ttotal: 6.07s\tremaining: 8.98s\n",
      "121:\tlearn: 0.8463665\ttotal: 6.12s\tremaining: 8.93s\n",
      "122:\tlearn: 0.8461462\ttotal: 6.17s\tremaining: 8.88s\n",
      "123:\tlearn: 0.8476769\ttotal: 6.22s\tremaining: 8.82s\n",
      "124:\tlearn: 0.8491973\ttotal: 6.26s\tremaining: 8.77s\n",
      "125:\tlearn: 0.8499703\ttotal: 6.31s\tremaining: 8.71s\n",
      "126:\tlearn: 0.8507654\ttotal: 6.36s\tremaining: 8.67s\n",
      "127:\tlearn: 0.8520733\ttotal: 6.41s\tremaining: 8.61s\n",
      "128:\tlearn: 0.8523878\ttotal: 6.46s\tremaining: 8.56s\n",
      "129:\tlearn: 0.8545490\ttotal: 6.5s\tremaining: 8.51s\n",
      "130:\tlearn: 0.8549023\ttotal: 6.56s\tremaining: 8.46s\n",
      "131:\tlearn: 0.8558057\ttotal: 6.6s\tremaining: 8.4s\n",
      "132:\tlearn: 0.8558066\ttotal: 6.66s\tremaining: 8.36s\n",
      "133:\tlearn: 0.8556224\ttotal: 6.71s\tremaining: 8.31s\n",
      "134:\tlearn: 0.8573682\ttotal: 6.76s\tremaining: 8.26s\n",
      "135:\tlearn: 0.8576353\ttotal: 6.8s\tremaining: 8.2s\n",
      "136:\tlearn: 0.8581424\ttotal: 6.86s\tremaining: 8.16s\n",
      "137:\tlearn: 0.8597753\ttotal: 6.91s\tremaining: 8.11s\n",
      "138:\tlearn: 0.8601154\ttotal: 6.96s\tremaining: 8.06s\n",
      "139:\tlearn: 0.8615218\ttotal: 7.01s\tremaining: 8.01s\n",
      "140:\tlearn: 0.8616052\ttotal: 7.05s\tremaining: 7.96s\n",
      "141:\tlearn: 0.8624612\ttotal: 7.1s\tremaining: 7.9s\n",
      "142:\tlearn: 0.8637818\ttotal: 7.15s\tremaining: 7.85s\n",
      "143:\tlearn: 0.8644393\ttotal: 7.2s\tremaining: 7.8s\n",
      "144:\tlearn: 0.8652880\ttotal: 7.24s\tremaining: 7.74s\n",
      "145:\tlearn: 0.8652776\ttotal: 7.29s\tremaining: 7.7s\n",
      "146:\tlearn: 0.8659611\ttotal: 7.34s\tremaining: 7.64s\n",
      "147:\tlearn: 0.8671590\ttotal: 7.39s\tremaining: 7.59s\n",
      "148:\tlearn: 0.8673168\ttotal: 7.44s\tremaining: 7.54s\n",
      "149:\tlearn: 0.8677666\ttotal: 7.49s\tremaining: 7.49s\n",
      "150:\tlearn: 0.8695438\ttotal: 7.54s\tremaining: 7.44s\n",
      "151:\tlearn: 0.8708948\ttotal: 7.59s\tremaining: 7.39s\n",
      "152:\tlearn: 0.8715578\ttotal: 7.64s\tremaining: 7.34s\n",
      "153:\tlearn: 0.8721634\ttotal: 7.69s\tremaining: 7.29s\n",
      "154:\tlearn: 0.8721131\ttotal: 7.73s\tremaining: 7.24s\n",
      "155:\tlearn: 0.8724998\ttotal: 7.78s\tremaining: 7.18s\n",
      "156:\tlearn: 0.8731145\ttotal: 7.83s\tremaining: 7.13s\n",
      "157:\tlearn: 0.8747229\ttotal: 7.88s\tremaining: 7.08s\n",
      "158:\tlearn: 0.8750985\ttotal: 7.92s\tremaining: 7.03s\n",
      "159:\tlearn: 0.8760827\ttotal: 7.97s\tremaining: 6.97s\n",
      "160:\tlearn: 0.8762927\ttotal: 8.02s\tremaining: 6.92s\n",
      "161:\tlearn: 0.8770997\ttotal: 8.07s\tremaining: 6.88s\n",
      "162:\tlearn: 0.8767285\ttotal: 8.12s\tremaining: 6.83s\n",
      "163:\tlearn: 0.8776334\ttotal: 8.17s\tremaining: 6.77s\n",
      "164:\tlearn: 0.8780128\ttotal: 8.21s\tremaining: 6.72s\n",
      "165:\tlearn: 0.8786030\ttotal: 8.26s\tremaining: 6.67s\n",
      "166:\tlearn: 0.8791425\ttotal: 8.31s\tremaining: 6.62s\n",
      "167:\tlearn: 0.8802516\ttotal: 8.36s\tremaining: 6.57s\n",
      "168:\tlearn: 0.8800787\ttotal: 8.4s\tremaining: 6.51s\n",
      "169:\tlearn: 0.8810460\ttotal: 8.45s\tremaining: 6.46s\n",
      "170:\tlearn: 0.8812392\ttotal: 8.5s\tremaining: 6.41s\n",
      "171:\tlearn: 0.8817426\ttotal: 8.55s\tremaining: 6.36s\n",
      "172:\tlearn: 0.8824888\ttotal: 8.59s\tremaining: 6.31s\n",
      "173:\tlearn: 0.8827376\ttotal: 8.65s\tremaining: 6.26s\n",
      "174:\tlearn: 0.8827261\ttotal: 8.7s\tremaining: 6.21s\n",
      "175:\tlearn: 0.8832981\ttotal: 8.74s\tremaining: 6.16s\n",
      "176:\tlearn: 0.8836912\ttotal: 8.79s\tremaining: 6.11s\n",
      "177:\tlearn: 0.8845342\ttotal: 8.84s\tremaining: 6.06s\n",
      "178:\tlearn: 0.8845322\ttotal: 8.88s\tremaining: 6s\n",
      "179:\tlearn: 0.8858533\ttotal: 8.94s\tremaining: 5.96s\n",
      "180:\tlearn: 0.8869787\ttotal: 8.98s\tremaining: 5.91s\n",
      "181:\tlearn: 0.8864530\ttotal: 9.03s\tremaining: 5.86s\n",
      "182:\tlearn: 0.8874042\ttotal: 9.08s\tremaining: 5.8s\n",
      "183:\tlearn: 0.8878188\ttotal: 9.13s\tremaining: 5.75s\n",
      "184:\tlearn: 0.8881792\ttotal: 9.17s\tremaining: 5.7s\n",
      "185:\tlearn: 0.8882885\ttotal: 9.22s\tremaining: 5.65s\n",
      "186:\tlearn: 0.8891292\ttotal: 9.27s\tremaining: 5.6s\n",
      "187:\tlearn: 0.8893253\ttotal: 9.31s\tremaining: 5.55s\n",
      "188:\tlearn: 0.8901876\ttotal: 9.37s\tremaining: 5.5s\n",
      "189:\tlearn: 0.8903403\ttotal: 9.41s\tremaining: 5.45s\n",
      "190:\tlearn: 0.8908859\ttotal: 9.46s\tremaining: 5.4s\n",
      "191:\tlearn: 0.8917936\ttotal: 9.51s\tremaining: 5.35s\n",
      "192:\tlearn: 0.8922759\ttotal: 9.56s\tremaining: 5.3s\n",
      "193:\tlearn: 0.8925270\ttotal: 9.61s\tremaining: 5.25s\n",
      "194:\tlearn: 0.8935103\ttotal: 9.65s\tremaining: 5.2s\n",
      "195:\tlearn: 0.8946256\ttotal: 9.7s\tremaining: 5.15s\n",
      "196:\tlearn: 0.8940563\ttotal: 9.75s\tremaining: 5.1s\n",
      "197:\tlearn: 0.8953083\ttotal: 9.8s\tremaining: 5.05s\n",
      "198:\tlearn: 0.8954271\ttotal: 9.85s\tremaining: 5s\n",
      "199:\tlearn: 0.8964772\ttotal: 9.89s\tremaining: 4.95s\n",
      "200:\tlearn: 0.8978730\ttotal: 9.95s\tremaining: 4.9s\n",
      "201:\tlearn: 0.8981877\ttotal: 10s\tremaining: 4.85s\n",
      "202:\tlearn: 0.8987429\ttotal: 10s\tremaining: 4.8s\n",
      "203:\tlearn: 0.8995925\ttotal: 10.1s\tremaining: 4.75s\n",
      "204:\tlearn: 0.8995826\ttotal: 10.1s\tremaining: 4.7s\n",
      "205:\tlearn: 0.9004418\ttotal: 10.2s\tremaining: 4.65s\n",
      "206:\tlearn: 0.9011399\ttotal: 10.2s\tremaining: 4.6s\n",
      "207:\tlearn: 0.9012036\ttotal: 10.3s\tremaining: 4.55s\n",
      "208:\tlearn: 0.9015192\ttotal: 10.3s\tremaining: 4.5s\n",
      "209:\tlearn: 0.9017199\ttotal: 10.4s\tremaining: 4.45s\n",
      "210:\tlearn: 0.9016893\ttotal: 10.4s\tremaining: 4.4s\n",
      "211:\tlearn: 0.9022689\ttotal: 10.5s\tremaining: 4.35s\n",
      "212:\tlearn: 0.9026236\ttotal: 10.5s\tremaining: 4.3s\n",
      "213:\tlearn: 0.9032765\ttotal: 10.6s\tremaining: 4.25s\n",
      "214:\tlearn: 0.9037772\ttotal: 10.6s\tremaining: 4.2s\n",
      "215:\tlearn: 0.9040813\ttotal: 10.7s\tremaining: 4.15s\n",
      "216:\tlearn: 0.9043410\ttotal: 10.7s\tremaining: 4.1s\n",
      "217:\tlearn: 0.9051949\ttotal: 10.8s\tremaining: 4.05s\n",
      "218:\tlearn: 0.9056696\ttotal: 10.8s\tremaining: 4s\n",
      "219:\tlearn: 0.9055176\ttotal: 10.9s\tremaining: 3.95s\n",
      "220:\tlearn: 0.9057049\ttotal: 10.9s\tremaining: 3.9s\n",
      "221:\tlearn: 0.9063037\ttotal: 11s\tremaining: 3.85s\n",
      "222:\tlearn: 0.9066614\ttotal: 11s\tremaining: 3.8s\n",
      "223:\tlearn: 0.9073665\ttotal: 11.1s\tremaining: 3.75s\n",
      "224:\tlearn: 0.9077241\ttotal: 11.1s\tremaining: 3.7s\n",
      "225:\tlearn: 0.9076530\ttotal: 11.2s\tremaining: 3.65s\n",
      "226:\tlearn: 0.9085818\ttotal: 11.2s\tremaining: 3.6s\n",
      "227:\tlearn: 0.9095107\ttotal: 11.3s\tremaining: 3.55s\n",
      "228:\tlearn: 0.9098328\ttotal: 11.3s\tremaining: 3.5s\n",
      "229:\tlearn: 0.9100295\ttotal: 11.4s\tremaining: 3.45s\n",
      "230:\tlearn: 0.9104045\ttotal: 11.4s\tremaining: 3.41s\n",
      "231:\tlearn: 0.9104756\ttotal: 11.4s\tremaining: 3.35s\n",
      "232:\tlearn: 0.9110215\ttotal: 11.5s\tremaining: 3.31s\n",
      "233:\tlearn: 0.9114048\ttotal: 11.5s\tremaining: 3.25s\n",
      "234:\tlearn: 0.9117979\ttotal: 11.6s\tremaining: 3.21s\n",
      "235:\tlearn: 0.9118702\ttotal: 11.6s\tremaining: 3.16s\n",
      "236:\tlearn: 0.9126185\ttotal: 11.7s\tremaining: 3.11s\n",
      "237:\tlearn: 0.9134322\ttotal: 11.7s\tremaining: 3.06s\n",
      "238:\tlearn: 0.9134152\ttotal: 11.8s\tremaining: 3.01s\n",
      "239:\tlearn: 0.9140303\ttotal: 11.8s\tremaining: 2.96s\n",
      "240:\tlearn: 0.9137245\ttotal: 11.9s\tremaining: 2.91s\n",
      "241:\tlearn: 0.9142969\ttotal: 11.9s\tremaining: 2.86s\n",
      "242:\tlearn: 0.9142885\ttotal: 12s\tremaining: 2.81s\n",
      "243:\tlearn: 0.9150577\ttotal: 12s\tremaining: 2.76s\n",
      "244:\tlearn: 0.9156638\ttotal: 12.1s\tremaining: 2.71s\n",
      "245:\tlearn: 0.9161100\ttotal: 12.1s\tremaining: 2.66s\n",
      "246:\tlearn: 0.9158071\ttotal: 12.2s\tremaining: 2.61s\n",
      "247:\tlearn: 0.9164743\ttotal: 12.2s\tremaining: 2.56s\n",
      "248:\tlearn: 0.9164047\ttotal: 12.3s\tremaining: 2.51s\n",
      "249:\tlearn: 0.9164825\ttotal: 12.3s\tremaining: 2.46s\n",
      "250:\tlearn: 0.9167771\ttotal: 12.4s\tremaining: 2.42s\n",
      "251:\tlearn: 0.9169611\ttotal: 12.4s\tremaining: 2.37s\n",
      "252:\tlearn: 0.9178687\ttotal: 12.5s\tremaining: 2.31s\n",
      "253:\tlearn: 0.9183112\ttotal: 12.5s\tremaining: 2.27s\n",
      "254:\tlearn: 0.9188022\ttotal: 12.6s\tremaining: 2.22s\n",
      "255:\tlearn: 0.9189614\ttotal: 12.6s\tremaining: 2.17s\n",
      "256:\tlearn: 0.9187889\ttotal: 12.7s\tremaining: 2.12s\n",
      "257:\tlearn: 0.9191418\ttotal: 12.7s\tremaining: 2.07s\n",
      "258:\tlearn: 0.9194894\ttotal: 12.8s\tremaining: 2.02s\n",
      "259:\tlearn: 0.9195211\ttotal: 12.8s\tremaining: 1.97s\n",
      "260:\tlearn: 0.9200569\ttotal: 12.8s\tremaining: 1.92s\n",
      "261:\tlearn: 0.9206599\ttotal: 12.9s\tremaining: 1.87s\n",
      "262:\tlearn: 0.9213549\ttotal: 12.9s\tremaining: 1.82s\n",
      "263:\tlearn: 0.9214387\ttotal: 13s\tremaining: 1.77s\n",
      "264:\tlearn: 0.9217861\ttotal: 13s\tremaining: 1.72s\n",
      "265:\tlearn: 0.9223596\ttotal: 13.1s\tremaining: 1.67s\n",
      "266:\tlearn: 0.9223520\ttotal: 13.2s\tremaining: 1.63s\n",
      "267:\tlearn: 0.9225255\ttotal: 13.2s\tremaining: 1.58s\n",
      "268:\tlearn: 0.9228504\ttotal: 13.2s\tremaining: 1.53s\n",
      "269:\tlearn: 0.9233109\ttotal: 13.3s\tremaining: 1.48s\n",
      "270:\tlearn: 0.9239152\ttotal: 13.3s\tremaining: 1.43s\n",
      "271:\tlearn: 0.9241332\ttotal: 13.4s\tremaining: 1.38s\n",
      "272:\tlearn: 0.9241867\ttotal: 13.4s\tremaining: 1.33s\n",
      "273:\tlearn: 0.9239910\ttotal: 13.5s\tremaining: 1.28s\n",
      "274:\tlearn: 0.9241867\ttotal: 13.5s\tremaining: 1.23s\n",
      "275:\tlearn: 0.9241948\ttotal: 13.6s\tremaining: 1.18s\n",
      "276:\tlearn: 0.9243681\ttotal: 13.6s\tremaining: 1.13s\n",
      "277:\tlearn: 0.9246858\ttotal: 13.7s\tremaining: 1.08s\n",
      "278:\tlearn: 0.9249583\ttotal: 13.7s\tremaining: 1.03s\n",
      "279:\tlearn: 0.9253204\ttotal: 13.8s\tremaining: 985ms\n",
      "280:\tlearn: 0.9255241\ttotal: 13.8s\tremaining: 935ms\n",
      "281:\tlearn: 0.9257586\ttotal: 13.9s\tremaining: 886ms\n",
      "282:\tlearn: 0.9265587\ttotal: 13.9s\tremaining: 837ms\n",
      "283:\tlearn: 0.9267023\ttotal: 14s\tremaining: 788ms\n",
      "284:\tlearn: 0.9274110\ttotal: 14s\tremaining: 738ms\n",
      "285:\tlearn: 0.9271978\ttotal: 14.1s\tremaining: 689ms\n",
      "286:\tlearn: 0.9278391\ttotal: 14.1s\tremaining: 640ms\n",
      "287:\tlearn: 0.9282175\ttotal: 14.2s\tremaining: 590ms\n",
      "288:\tlearn: 0.9284067\ttotal: 14.2s\tremaining: 541ms\n",
      "289:\tlearn: 0.9288378\ttotal: 14.3s\tremaining: 492ms\n",
      "290:\tlearn: 0.9290025\ttotal: 14.3s\tremaining: 443ms\n",
      "291:\tlearn: 0.9292196\ttotal: 14.4s\tremaining: 393ms\n",
      "292:\tlearn: 0.9292196\ttotal: 14.4s\tremaining: 344ms\n",
      "293:\tlearn: 0.9292969\ttotal: 14.5s\tremaining: 295ms\n",
      "294:\tlearn: 0.9297419\ttotal: 14.5s\tremaining: 246ms\n",
      "295:\tlearn: 0.9298220\ttotal: 14.6s\tremaining: 197ms\n",
      "296:\tlearn: 0.9299063\ttotal: 14.6s\tremaining: 148ms\n",
      "297:\tlearn: 0.9299063\ttotal: 14.7s\tremaining: 98.3ms\n",
      "298:\tlearn: 0.9298676\ttotal: 14.7s\tremaining: 49.2ms\n",
      "299:\tlearn: 0.9298813\ttotal: 14.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0.1, border_count=160, depth=5, eval_metric=F1, iterations=300, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=2; total time=  15.5s\n",
      "0:\tlearn: 0.6505367\ttotal: 55.3ms\tremaining: 16.5s\n",
      "1:\tlearn: 0.6263769\ttotal: 103ms\tremaining: 15.4s\n",
      "2:\tlearn: 0.6613496\ttotal: 150ms\tremaining: 14.8s\n",
      "3:\tlearn: 0.6788885\ttotal: 197ms\tremaining: 14.6s\n",
      "4:\tlearn: 0.6873120\ttotal: 251ms\tremaining: 14.8s\n",
      "5:\tlearn: 0.7009185\ttotal: 303ms\tremaining: 14.8s\n",
      "6:\tlearn: 0.7064877\ttotal: 355ms\tremaining: 14.8s\n",
      "7:\tlearn: 0.7182925\ttotal: 406ms\tremaining: 14.8s\n",
      "8:\tlearn: 0.7215253\ttotal: 458ms\tremaining: 14.8s\n",
      "9:\tlearn: 0.7231689\ttotal: 509ms\tremaining: 14.8s\n",
      "10:\tlearn: 0.7246893\ttotal: 558ms\tremaining: 14.6s\n",
      "11:\tlearn: 0.7322866\ttotal: 605ms\tremaining: 14.5s\n",
      "12:\tlearn: 0.7344223\ttotal: 656ms\tremaining: 14.5s\n",
      "13:\tlearn: 0.7389787\ttotal: 708ms\tremaining: 14.5s\n",
      "14:\tlearn: 0.7399023\ttotal: 758ms\tremaining: 14.4s\n",
      "15:\tlearn: 0.7442092\ttotal: 807ms\tremaining: 14.3s\n",
      "16:\tlearn: 0.7447878\ttotal: 857ms\tremaining: 14.3s\n",
      "17:\tlearn: 0.7477388\ttotal: 912ms\tremaining: 14.3s\n",
      "18:\tlearn: 0.7492331\ttotal: 960ms\tremaining: 14.2s\n",
      "19:\tlearn: 0.7504332\ttotal: 1.01s\tremaining: 14.1s\n",
      "20:\tlearn: 0.7528585\ttotal: 1.06s\tremaining: 14.1s\n",
      "21:\tlearn: 0.7546479\ttotal: 1.11s\tremaining: 14s\n",
      "22:\tlearn: 0.7553517\ttotal: 1.16s\tremaining: 13.9s\n",
      "23:\tlearn: 0.7567113\ttotal: 1.21s\tremaining: 13.9s\n",
      "24:\tlearn: 0.7587600\ttotal: 1.26s\tremaining: 13.8s\n",
      "25:\tlearn: 0.7596007\ttotal: 1.31s\tremaining: 13.8s\n",
      "26:\tlearn: 0.7597364\ttotal: 1.36s\tremaining: 13.8s\n",
      "27:\tlearn: 0.7641081\ttotal: 1.41s\tremaining: 13.7s\n",
      "28:\tlearn: 0.7673752\ttotal: 1.46s\tremaining: 13.7s\n",
      "29:\tlearn: 0.7690860\ttotal: 1.51s\tremaining: 13.6s\n",
      "30:\tlearn: 0.7710796\ttotal: 1.56s\tremaining: 13.5s\n",
      "31:\tlearn: 0.7721669\ttotal: 1.61s\tremaining: 13.5s\n",
      "32:\tlearn: 0.7735013\ttotal: 1.65s\tremaining: 13.4s\n",
      "33:\tlearn: 0.7749459\ttotal: 1.7s\tremaining: 13.3s\n",
      "34:\tlearn: 0.7743683\ttotal: 1.75s\tremaining: 13.3s\n",
      "35:\tlearn: 0.7745784\ttotal: 1.8s\tremaining: 13.2s\n",
      "36:\tlearn: 0.7770310\ttotal: 1.85s\tremaining: 13.2s\n",
      "37:\tlearn: 0.7784218\ttotal: 1.9s\tremaining: 13.1s\n",
      "38:\tlearn: 0.7803113\ttotal: 1.95s\tremaining: 13.1s\n",
      "39:\tlearn: 0.7817496\ttotal: 2.01s\tremaining: 13.1s\n",
      "40:\tlearn: 0.7842262\ttotal: 2.06s\tremaining: 13s\n",
      "41:\tlearn: 0.7850114\ttotal: 2.11s\tremaining: 13s\n",
      "42:\tlearn: 0.7861191\ttotal: 2.16s\tremaining: 12.9s\n",
      "43:\tlearn: 0.7872457\ttotal: 2.21s\tremaining: 12.9s\n",
      "44:\tlearn: 0.7887016\ttotal: 2.27s\tremaining: 12.8s\n",
      "45:\tlearn: 0.7896045\ttotal: 2.31s\tremaining: 12.8s\n",
      "46:\tlearn: 0.7901014\ttotal: 2.37s\tremaining: 12.7s\n",
      "47:\tlearn: 0.7926501\ttotal: 2.42s\tremaining: 12.7s\n",
      "48:\tlearn: 0.7928071\ttotal: 2.46s\tremaining: 12.6s\n",
      "49:\tlearn: 0.7950539\ttotal: 2.52s\tremaining: 12.6s\n",
      "50:\tlearn: 0.7963792\ttotal: 2.56s\tremaining: 12.5s\n",
      "51:\tlearn: 0.7984268\ttotal: 2.62s\tremaining: 12.5s\n",
      "52:\tlearn: 0.7980310\ttotal: 2.66s\tremaining: 12.4s\n",
      "53:\tlearn: 0.7981109\ttotal: 2.71s\tremaining: 12.4s\n",
      "54:\tlearn: 0.7987068\ttotal: 2.76s\tremaining: 12.3s\n",
      "55:\tlearn: 0.7995624\ttotal: 2.82s\tremaining: 12.3s\n",
      "56:\tlearn: 0.7985859\ttotal: 2.87s\tremaining: 12.2s\n",
      "57:\tlearn: 0.8002587\ttotal: 2.91s\tremaining: 12.1s\n",
      "58:\tlearn: 0.8011527\ttotal: 2.96s\tremaining: 12.1s\n",
      "59:\tlearn: 0.8021694\ttotal: 3.01s\tremaining: 12s\n",
      "60:\tlearn: 0.8029212\ttotal: 3.05s\tremaining: 12s\n",
      "61:\tlearn: 0.8049289\ttotal: 3.11s\tremaining: 11.9s\n",
      "62:\tlearn: 0.8052116\ttotal: 3.15s\tremaining: 11.9s\n",
      "63:\tlearn: 0.8067753\ttotal: 3.2s\tremaining: 11.8s\n",
      "64:\tlearn: 0.8070559\ttotal: 3.26s\tremaining: 11.8s\n",
      "65:\tlearn: 0.8074781\ttotal: 3.31s\tremaining: 11.7s\n",
      "66:\tlearn: 0.8073595\ttotal: 3.37s\tremaining: 11.7s\n",
      "67:\tlearn: 0.8076369\ttotal: 3.42s\tremaining: 11.7s\n",
      "68:\tlearn: 0.8107196\ttotal: 3.47s\tremaining: 11.6s\n",
      "69:\tlearn: 0.8114087\ttotal: 3.52s\tremaining: 11.6s\n",
      "70:\tlearn: 0.8120689\ttotal: 3.58s\tremaining: 11.5s\n",
      "71:\tlearn: 0.8134921\ttotal: 3.63s\tremaining: 11.5s\n",
      "72:\tlearn: 0.8149325\ttotal: 3.68s\tremaining: 11.5s\n",
      "73:\tlearn: 0.8162597\ttotal: 3.74s\tremaining: 11.4s\n",
      "74:\tlearn: 0.8165352\ttotal: 3.79s\tremaining: 11.4s\n",
      "75:\tlearn: 0.8169909\ttotal: 3.84s\tremaining: 11.3s\n",
      "76:\tlearn: 0.8177311\ttotal: 3.9s\tremaining: 11.3s\n",
      "77:\tlearn: 0.8181638\ttotal: 3.94s\tremaining: 11.2s\n",
      "78:\tlearn: 0.8178749\ttotal: 3.99s\tremaining: 11.2s\n",
      "79:\tlearn: 0.8199652\ttotal: 4.04s\tremaining: 11.1s\n",
      "80:\tlearn: 0.8204848\ttotal: 4.09s\tremaining: 11.1s\n",
      "81:\tlearn: 0.8210192\ttotal: 4.14s\tremaining: 11s\n",
      "82:\tlearn: 0.8223391\ttotal: 4.19s\tremaining: 11s\n",
      "83:\tlearn: 0.8226134\ttotal: 4.24s\tremaining: 10.9s\n",
      "84:\tlearn: 0.8224846\ttotal: 4.29s\tremaining: 10.9s\n",
      "85:\tlearn: 0.8237514\ttotal: 4.34s\tremaining: 10.8s\n",
      "86:\tlearn: 0.8241191\ttotal: 4.39s\tremaining: 10.8s\n",
      "87:\tlearn: 0.8251241\ttotal: 4.44s\tremaining: 10.7s\n",
      "88:\tlearn: 0.8252012\ttotal: 4.49s\tremaining: 10.6s\n",
      "89:\tlearn: 0.8257027\ttotal: 4.53s\tremaining: 10.6s\n",
      "90:\tlearn: 0.8278087\ttotal: 4.58s\tremaining: 10.5s\n",
      "91:\tlearn: 0.8279148\ttotal: 4.63s\tremaining: 10.5s\n",
      "92:\tlearn: 0.8286125\ttotal: 4.68s\tremaining: 10.4s\n",
      "93:\tlearn: 0.8294377\ttotal: 4.73s\tremaining: 10.4s\n",
      "94:\tlearn: 0.8305219\ttotal: 4.77s\tremaining: 10.3s\n",
      "95:\tlearn: 0.8310683\ttotal: 4.82s\tremaining: 10.2s\n",
      "96:\tlearn: 0.8308120\ttotal: 4.86s\tremaining: 10.2s\n",
      "97:\tlearn: 0.8303514\ttotal: 4.91s\tremaining: 10.1s\n",
      "98:\tlearn: 0.8309140\ttotal: 4.96s\tremaining: 10.1s\n",
      "99:\tlearn: 0.8313438\ttotal: 5.02s\tremaining: 10s\n",
      "100:\tlearn: 0.8325330\ttotal: 5.07s\tremaining: 9.98s\n",
      "101:\tlearn: 0.8331355\ttotal: 5.11s\tremaining: 9.93s\n",
      "102:\tlearn: 0.8347525\ttotal: 5.17s\tremaining: 9.88s\n",
      "103:\tlearn: 0.8368366\ttotal: 5.22s\tremaining: 9.83s\n",
      "104:\tlearn: 0.8360972\ttotal: 5.27s\tremaining: 9.78s\n",
      "105:\tlearn: 0.8371656\ttotal: 5.32s\tremaining: 9.73s\n",
      "106:\tlearn: 0.8378966\ttotal: 5.37s\tremaining: 9.68s\n",
      "107:\tlearn: 0.8383044\ttotal: 5.42s\tremaining: 9.63s\n",
      "108:\tlearn: 0.8390350\ttotal: 5.46s\tremaining: 9.57s\n",
      "109:\tlearn: 0.8406327\ttotal: 5.51s\tremaining: 9.53s\n",
      "110:\tlearn: 0.8414706\ttotal: 5.56s\tremaining: 9.47s\n",
      "111:\tlearn: 0.8419387\ttotal: 5.61s\tremaining: 9.41s\n",
      "112:\tlearn: 0.8422353\ttotal: 5.66s\tremaining: 9.36s\n",
      "113:\tlearn: 0.8432651\ttotal: 5.7s\tremaining: 9.31s\n",
      "114:\tlearn: 0.8441283\ttotal: 5.75s\tremaining: 9.26s\n",
      "115:\tlearn: 0.8452234\ttotal: 5.8s\tremaining: 9.21s\n",
      "116:\tlearn: 0.8467233\ttotal: 5.85s\tremaining: 9.15s\n",
      "117:\tlearn: 0.8484460\ttotal: 5.9s\tremaining: 9.1s\n",
      "118:\tlearn: 0.8485387\ttotal: 5.95s\tremaining: 9.05s\n",
      "119:\tlearn: 0.8495933\ttotal: 6s\tremaining: 9s\n",
      "120:\tlearn: 0.8499951\ttotal: 6.04s\tremaining: 8.94s\n",
      "121:\tlearn: 0.8496248\ttotal: 6.09s\tremaining: 8.89s\n",
      "122:\tlearn: 0.8501381\ttotal: 6.14s\tremaining: 8.83s\n",
      "123:\tlearn: 0.8519012\ttotal: 6.19s\tremaining: 8.79s\n",
      "124:\tlearn: 0.8522520\ttotal: 6.24s\tremaining: 8.74s\n",
      "125:\tlearn: 0.8524105\ttotal: 6.29s\tremaining: 8.68s\n",
      "126:\tlearn: 0.8531151\ttotal: 6.33s\tremaining: 8.63s\n",
      "127:\tlearn: 0.8540599\ttotal: 6.38s\tremaining: 8.58s\n",
      "128:\tlearn: 0.8549754\ttotal: 6.43s\tremaining: 8.53s\n",
      "129:\tlearn: 0.8556376\ttotal: 6.48s\tremaining: 8.47s\n",
      "130:\tlearn: 0.8562703\ttotal: 6.53s\tremaining: 8.42s\n",
      "131:\tlearn: 0.8570585\ttotal: 6.58s\tremaining: 8.37s\n",
      "132:\tlearn: 0.8586480\ttotal: 6.63s\tremaining: 8.32s\n",
      "133:\tlearn: 0.8590002\ttotal: 6.68s\tremaining: 8.27s\n",
      "134:\tlearn: 0.8609526\ttotal: 6.73s\tremaining: 8.23s\n",
      "135:\tlearn: 0.8614203\ttotal: 6.78s\tremaining: 8.18s\n",
      "136:\tlearn: 0.8616036\ttotal: 6.83s\tremaining: 8.13s\n",
      "137:\tlearn: 0.8622371\ttotal: 6.88s\tremaining: 8.08s\n",
      "138:\tlearn: 0.8630387\ttotal: 6.93s\tremaining: 8.03s\n",
      "139:\tlearn: 0.8643617\ttotal: 6.98s\tremaining: 7.98s\n",
      "140:\tlearn: 0.8643859\ttotal: 7.03s\tremaining: 7.93s\n",
      "141:\tlearn: 0.8658038\ttotal: 7.08s\tremaining: 7.87s\n",
      "142:\tlearn: 0.8661355\ttotal: 7.13s\tremaining: 7.82s\n",
      "143:\tlearn: 0.8674237\ttotal: 7.17s\tremaining: 7.77s\n",
      "144:\tlearn: 0.8673715\ttotal: 7.22s\tremaining: 7.72s\n",
      "145:\tlearn: 0.8681508\ttotal: 7.26s\tremaining: 7.66s\n",
      "146:\tlearn: 0.8689072\ttotal: 7.31s\tremaining: 7.61s\n",
      "147:\tlearn: 0.8697489\ttotal: 7.36s\tremaining: 7.56s\n",
      "148:\tlearn: 0.8704414\ttotal: 7.41s\tremaining: 7.51s\n",
      "149:\tlearn: 0.8708632\ttotal: 7.46s\tremaining: 7.46s\n",
      "150:\tlearn: 0.8719081\ttotal: 7.51s\tremaining: 7.41s\n",
      "151:\tlearn: 0.8721318\ttotal: 7.56s\tremaining: 7.36s\n",
      "152:\tlearn: 0.8736218\ttotal: 7.61s\tremaining: 7.31s\n",
      "153:\tlearn: 0.8738673\ttotal: 7.66s\tremaining: 7.26s\n",
      "154:\tlearn: 0.8743389\ttotal: 7.71s\tremaining: 7.21s\n",
      "155:\tlearn: 0.8759789\ttotal: 7.75s\tremaining: 7.16s\n",
      "156:\tlearn: 0.8762614\ttotal: 7.8s\tremaining: 7.11s\n",
      "157:\tlearn: 0.8763043\ttotal: 7.85s\tremaining: 7.06s\n",
      "158:\tlearn: 0.8766654\ttotal: 7.9s\tremaining: 7.01s\n",
      "159:\tlearn: 0.8770143\ttotal: 7.95s\tremaining: 6.95s\n",
      "160:\tlearn: 0.8772703\ttotal: 8s\tremaining: 6.9s\n",
      "161:\tlearn: 0.8782613\ttotal: 8.04s\tremaining: 6.85s\n",
      "162:\tlearn: 0.8788308\ttotal: 8.1s\tremaining: 6.81s\n",
      "163:\tlearn: 0.8783302\ttotal: 8.14s\tremaining: 6.75s\n",
      "164:\tlearn: 0.8785257\ttotal: 8.2s\tremaining: 6.71s\n",
      "165:\tlearn: 0.8788383\ttotal: 8.24s\tremaining: 6.65s\n",
      "166:\tlearn: 0.8794090\ttotal: 8.29s\tremaining: 6.6s\n",
      "167:\tlearn: 0.8792370\ttotal: 8.34s\tremaining: 6.55s\n",
      "168:\tlearn: 0.8800078\ttotal: 8.39s\tremaining: 6.5s\n",
      "169:\tlearn: 0.8800117\ttotal: 8.44s\tremaining: 6.45s\n",
      "170:\tlearn: 0.8802424\ttotal: 8.48s\tremaining: 6.4s\n",
      "171:\tlearn: 0.8813725\ttotal: 8.53s\tremaining: 6.35s\n",
      "172:\tlearn: 0.8817183\ttotal: 8.58s\tremaining: 6.3s\n",
      "173:\tlearn: 0.8819105\ttotal: 8.63s\tremaining: 6.25s\n",
      "174:\tlearn: 0.8825195\ttotal: 8.67s\tremaining: 6.2s\n",
      "175:\tlearn: 0.8836278\ttotal: 8.72s\tremaining: 6.14s\n",
      "176:\tlearn: 0.8826144\ttotal: 8.77s\tremaining: 6.09s\n",
      "177:\tlearn: 0.8833325\ttotal: 8.82s\tremaining: 6.04s\n",
      "178:\tlearn: 0.8846060\ttotal: 8.87s\tremaining: 5.99s\n",
      "179:\tlearn: 0.8854939\ttotal: 8.91s\tremaining: 5.94s\n",
      "180:\tlearn: 0.8865688\ttotal: 8.96s\tremaining: 5.89s\n",
      "181:\tlearn: 0.8872628\ttotal: 9.01s\tremaining: 5.84s\n",
      "182:\tlearn: 0.8880328\ttotal: 9.06s\tremaining: 5.79s\n",
      "183:\tlearn: 0.8878049\ttotal: 9.11s\tremaining: 5.74s\n",
      "184:\tlearn: 0.8887697\ttotal: 9.16s\tremaining: 5.69s\n",
      "185:\tlearn: 0.8897557\ttotal: 9.21s\tremaining: 5.64s\n",
      "186:\tlearn: 0.8904825\ttotal: 9.26s\tremaining: 5.59s\n",
      "187:\tlearn: 0.8912175\ttotal: 9.31s\tremaining: 5.54s\n",
      "188:\tlearn: 0.8917154\ttotal: 9.36s\tremaining: 5.49s\n",
      "189:\tlearn: 0.8913266\ttotal: 9.41s\tremaining: 5.45s\n",
      "190:\tlearn: 0.8920737\ttotal: 9.46s\tremaining: 5.4s\n",
      "191:\tlearn: 0.8925072\ttotal: 9.51s\tremaining: 5.35s\n",
      "192:\tlearn: 0.8933392\ttotal: 9.56s\tremaining: 5.3s\n",
      "193:\tlearn: 0.8933288\ttotal: 9.61s\tremaining: 5.25s\n",
      "194:\tlearn: 0.8937497\ttotal: 9.65s\tremaining: 5.2s\n",
      "195:\tlearn: 0.8939903\ttotal: 9.7s\tremaining: 5.15s\n",
      "196:\tlearn: 0.8939261\ttotal: 9.74s\tremaining: 5.09s\n",
      "197:\tlearn: 0.8937665\ttotal: 9.79s\tremaining: 5.04s\n",
      "198:\tlearn: 0.8948061\ttotal: 9.84s\tremaining: 4.99s\n",
      "199:\tlearn: 0.8953273\ttotal: 9.88s\tremaining: 4.94s\n",
      "200:\tlearn: 0.8955733\ttotal: 9.93s\tremaining: 4.89s\n",
      "201:\tlearn: 0.8954016\ttotal: 9.99s\tremaining: 4.84s\n",
      "202:\tlearn: 0.8963534\ttotal: 10s\tremaining: 4.8s\n",
      "203:\tlearn: 0.8969047\ttotal: 10.1s\tremaining: 4.75s\n",
      "204:\tlearn: 0.8974122\ttotal: 10.1s\tremaining: 4.69s\n",
      "205:\tlearn: 0.8977981\ttotal: 10.2s\tremaining: 4.64s\n",
      "206:\tlearn: 0.8982118\ttotal: 10.2s\tremaining: 4.6s\n",
      "207:\tlearn: 0.8983431\ttotal: 10.3s\tremaining: 4.55s\n",
      "208:\tlearn: 0.8978757\ttotal: 10.3s\tremaining: 4.5s\n",
      "209:\tlearn: 0.8982613\ttotal: 10.4s\tremaining: 4.45s\n",
      "210:\tlearn: 0.8988162\ttotal: 10.4s\tremaining: 4.4s\n",
      "211:\tlearn: 0.8992354\ttotal: 10.5s\tremaining: 4.35s\n",
      "212:\tlearn: 0.8996884\ttotal: 10.5s\tremaining: 4.3s\n",
      "213:\tlearn: 0.9006281\ttotal: 10.6s\tremaining: 4.25s\n",
      "214:\tlearn: 0.9008132\ttotal: 10.6s\tremaining: 4.2s\n",
      "215:\tlearn: 0.9007544\ttotal: 10.7s\tremaining: 4.14s\n",
      "216:\tlearn: 0.9015140\ttotal: 10.7s\tremaining: 4.09s\n",
      "217:\tlearn: 0.9017431\ttotal: 10.8s\tremaining: 4.05s\n",
      "218:\tlearn: 0.9025316\ttotal: 10.8s\tremaining: 4s\n",
      "219:\tlearn: 0.9026824\ttotal: 10.9s\tremaining: 3.95s\n",
      "220:\tlearn: 0.9029745\ttotal: 10.9s\tremaining: 3.9s\n",
      "221:\tlearn: 0.9035681\ttotal: 11s\tremaining: 3.85s\n",
      "222:\tlearn: 0.9041456\ttotal: 11s\tremaining: 3.8s\n",
      "223:\tlearn: 0.9053370\ttotal: 11.1s\tremaining: 3.75s\n",
      "224:\tlearn: 0.9055942\ttotal: 11.1s\tremaining: 3.7s\n",
      "225:\tlearn: 0.9060795\ttotal: 11.2s\tremaining: 3.65s\n",
      "226:\tlearn: 0.9060262\ttotal: 11.2s\tremaining: 3.6s\n",
      "227:\tlearn: 0.9060720\ttotal: 11.2s\tremaining: 3.55s\n",
      "228:\tlearn: 0.9065498\ttotal: 11.3s\tremaining: 3.5s\n",
      "229:\tlearn: 0.9067809\ttotal: 11.3s\tremaining: 3.45s\n",
      "230:\tlearn: 0.9069133\ttotal: 11.4s\tremaining: 3.4s\n",
      "231:\tlearn: 0.9068861\ttotal: 11.4s\tremaining: 3.36s\n",
      "232:\tlearn: 0.9071964\ttotal: 11.5s\tremaining: 3.31s\n",
      "233:\tlearn: 0.9069926\ttotal: 11.5s\tremaining: 3.26s\n",
      "234:\tlearn: 0.9072948\ttotal: 11.6s\tremaining: 3.21s\n",
      "235:\tlearn: 0.9076047\ttotal: 11.6s\tremaining: 3.16s\n",
      "236:\tlearn: 0.9081528\ttotal: 11.7s\tremaining: 3.11s\n",
      "237:\tlearn: 0.9088874\ttotal: 11.7s\tremaining: 3.06s\n",
      "238:\tlearn: 0.9085953\ttotal: 11.8s\tremaining: 3.01s\n",
      "239:\tlearn: 0.9096394\ttotal: 11.8s\tremaining: 2.96s\n",
      "240:\tlearn: 0.9098520\ttotal: 11.9s\tremaining: 2.91s\n",
      "241:\tlearn: 0.9103213\ttotal: 11.9s\tremaining: 2.86s\n",
      "242:\tlearn: 0.9102595\ttotal: 12s\tremaining: 2.81s\n",
      "243:\tlearn: 0.9111447\ttotal: 12s\tremaining: 2.76s\n",
      "244:\tlearn: 0.9111533\ttotal: 12.1s\tremaining: 2.71s\n",
      "245:\tlearn: 0.9116401\ttotal: 12.1s\tremaining: 2.66s\n",
      "246:\tlearn: 0.9122414\ttotal: 12.2s\tremaining: 2.61s\n",
      "247:\tlearn: 0.9123644\ttotal: 12.2s\tremaining: 2.56s\n",
      "248:\tlearn: 0.9127471\ttotal: 12.3s\tremaining: 2.51s\n",
      "249:\tlearn: 0.9126582\ttotal: 12.3s\tremaining: 2.46s\n",
      "250:\tlearn: 0.9128340\ttotal: 12.4s\tremaining: 2.41s\n",
      "251:\tlearn: 0.9136680\ttotal: 12.4s\tremaining: 2.36s\n",
      "252:\tlearn: 0.9140298\ttotal: 12.5s\tremaining: 2.31s\n",
      "253:\tlearn: 0.9141800\ttotal: 12.5s\tremaining: 2.27s\n",
      "254:\tlearn: 0.9144276\ttotal: 12.6s\tremaining: 2.21s\n",
      "255:\tlearn: 0.9148170\ttotal: 12.6s\tremaining: 2.17s\n",
      "256:\tlearn: 0.9149537\ttotal: 12.7s\tremaining: 2.12s\n",
      "257:\tlearn: 0.9151618\ttotal: 12.7s\tremaining: 2.07s\n",
      "258:\tlearn: 0.9153352\ttotal: 12.8s\tremaining: 2.02s\n",
      "259:\tlearn: 0.9157695\ttotal: 12.8s\tremaining: 1.97s\n",
      "260:\tlearn: 0.9158915\ttotal: 12.9s\tremaining: 1.92s\n",
      "261:\tlearn: 0.9164841\ttotal: 12.9s\tremaining: 1.87s\n",
      "262:\tlearn: 0.9168898\ttotal: 13s\tremaining: 1.82s\n",
      "263:\tlearn: 0.9169833\ttotal: 13s\tremaining: 1.77s\n",
      "264:\tlearn: 0.9171335\ttotal: 13s\tremaining: 1.72s\n",
      "265:\tlearn: 0.9176448\ttotal: 13.1s\tremaining: 1.67s\n",
      "266:\tlearn: 0.9178316\ttotal: 13.1s\tremaining: 1.62s\n",
      "267:\tlearn: 0.9183822\ttotal: 13.2s\tremaining: 1.57s\n",
      "268:\tlearn: 0.9185481\ttotal: 13.2s\tremaining: 1.52s\n",
      "269:\tlearn: 0.9188452\ttotal: 13.3s\tremaining: 1.48s\n",
      "270:\tlearn: 0.9189663\ttotal: 13.3s\tremaining: 1.43s\n",
      "271:\tlearn: 0.9197002\ttotal: 13.4s\tremaining: 1.38s\n",
      "272:\tlearn: 0.9202006\ttotal: 13.4s\tremaining: 1.33s\n",
      "273:\tlearn: 0.9202299\ttotal: 13.5s\tremaining: 1.28s\n",
      "274:\tlearn: 0.9205808\ttotal: 13.5s\tremaining: 1.23s\n",
      "275:\tlearn: 0.9205963\ttotal: 13.6s\tremaining: 1.18s\n",
      "276:\tlearn: 0.9212103\ttotal: 13.6s\tremaining: 1.13s\n",
      "277:\tlearn: 0.9216154\ttotal: 13.7s\tremaining: 1.08s\n",
      "278:\tlearn: 0.9222596\ttotal: 13.7s\tremaining: 1.03s\n",
      "279:\tlearn: 0.9222747\ttotal: 13.8s\tremaining: 984ms\n",
      "280:\tlearn: 0.9226794\ttotal: 13.8s\tremaining: 935ms\n",
      "281:\tlearn: 0.9231219\ttotal: 13.9s\tremaining: 886ms\n",
      "282:\tlearn: 0.9235194\ttotal: 13.9s\tremaining: 836ms\n",
      "283:\tlearn: 0.9233169\ttotal: 14s\tremaining: 787ms\n",
      "284:\tlearn: 0.9236396\ttotal: 14s\tremaining: 738ms\n",
      "285:\tlearn: 0.9236846\ttotal: 14.1s\tremaining: 689ms\n",
      "286:\tlearn: 0.9241870\ttotal: 14.1s\tremaining: 640ms\n",
      "287:\tlearn: 0.9244795\ttotal: 14.2s\tremaining: 590ms\n",
      "288:\tlearn: 0.9244418\ttotal: 14.2s\tremaining: 541ms\n",
      "289:\tlearn: 0.9250414\ttotal: 14.3s\tremaining: 492ms\n",
      "290:\tlearn: 0.9251840\ttotal: 14.3s\tremaining: 443ms\n",
      "291:\tlearn: 0.9251389\ttotal: 14.4s\tremaining: 394ms\n",
      "292:\tlearn: 0.9256118\ttotal: 14.4s\tremaining: 344ms\n",
      "293:\tlearn: 0.9262347\ttotal: 14.5s\tremaining: 295ms\n",
      "294:\tlearn: 0.9265201\ttotal: 14.5s\tremaining: 246ms\n",
      "295:\tlearn: 0.9267722\ttotal: 14.6s\tremaining: 197ms\n",
      "296:\tlearn: 0.9274021\ttotal: 14.6s\tremaining: 148ms\n",
      "297:\tlearn: 0.9276111\ttotal: 14.7s\tremaining: 98.4ms\n",
      "298:\tlearn: 0.9283799\ttotal: 14.7s\tremaining: 49.2ms\n",
      "299:\tlearn: 0.9283137\ttotal: 14.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0.1, border_count=160, depth=5, eval_metric=F1, iterations=300, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=2; total time=  15.3s\n",
      "0:\tlearn: 0.6176113\ttotal: 55.6ms\tremaining: 16.6s\n",
      "1:\tlearn: 0.6105218\ttotal: 99.8ms\tremaining: 14.9s\n",
      "2:\tlearn: 0.6582423\ttotal: 146ms\tremaining: 14.5s\n",
      "3:\tlearn: 0.6728981\ttotal: 199ms\tremaining: 14.7s\n",
      "4:\tlearn: 0.6721555\ttotal: 246ms\tremaining: 14.5s\n",
      "5:\tlearn: 0.6852842\ttotal: 299ms\tremaining: 14.7s\n",
      "6:\tlearn: 0.6882813\ttotal: 353ms\tremaining: 14.8s\n",
      "7:\tlearn: 0.6962809\ttotal: 404ms\tremaining: 14.7s\n",
      "8:\tlearn: 0.7057408\ttotal: 455ms\tremaining: 14.7s\n",
      "9:\tlearn: 0.7141487\ttotal: 510ms\tremaining: 14.8s\n",
      "10:\tlearn: 0.7150980\ttotal: 565ms\tremaining: 14.8s\n",
      "11:\tlearn: 0.7226754\ttotal: 618ms\tremaining: 14.8s\n",
      "12:\tlearn: 0.7291974\ttotal: 668ms\tremaining: 14.7s\n",
      "13:\tlearn: 0.7342168\ttotal: 717ms\tremaining: 14.6s\n",
      "14:\tlearn: 0.7359871\ttotal: 766ms\tremaining: 14.6s\n",
      "15:\tlearn: 0.7402702\ttotal: 818ms\tremaining: 14.5s\n",
      "16:\tlearn: 0.7447335\ttotal: 874ms\tremaining: 14.5s\n",
      "17:\tlearn: 0.7470680\ttotal: 931ms\tremaining: 14.6s\n",
      "18:\tlearn: 0.7500251\ttotal: 979ms\tremaining: 14.5s\n",
      "19:\tlearn: 0.7506673\ttotal: 1.03s\tremaining: 14.4s\n",
      "20:\tlearn: 0.7551297\ttotal: 1.08s\tremaining: 14.3s\n",
      "21:\tlearn: 0.7576336\ttotal: 1.13s\tremaining: 14.3s\n",
      "22:\tlearn: 0.7632904\ttotal: 1.18s\tremaining: 14.2s\n",
      "23:\tlearn: 0.7639827\ttotal: 1.23s\tremaining: 14.1s\n",
      "24:\tlearn: 0.7630389\ttotal: 1.28s\tremaining: 14s\n",
      "25:\tlearn: 0.7675351\ttotal: 1.32s\tremaining: 14s\n",
      "26:\tlearn: 0.7681574\ttotal: 1.38s\tremaining: 13.9s\n",
      "27:\tlearn: 0.7687296\ttotal: 1.43s\tremaining: 13.9s\n",
      "28:\tlearn: 0.7691073\ttotal: 1.47s\tremaining: 13.8s\n",
      "29:\tlearn: 0.7709441\ttotal: 1.53s\tremaining: 13.7s\n",
      "30:\tlearn: 0.7722802\ttotal: 1.58s\tremaining: 13.7s\n",
      "31:\tlearn: 0.7748145\ttotal: 1.63s\tremaining: 13.6s\n",
      "32:\tlearn: 0.7765483\ttotal: 1.68s\tremaining: 13.6s\n",
      "33:\tlearn: 0.7770713\ttotal: 1.72s\tremaining: 13.5s\n",
      "34:\tlearn: 0.7770599\ttotal: 1.77s\tremaining: 13.4s\n",
      "35:\tlearn: 0.7817127\ttotal: 1.82s\tremaining: 13.3s\n",
      "36:\tlearn: 0.7827697\ttotal: 1.87s\tremaining: 13.3s\n",
      "37:\tlearn: 0.7833866\ttotal: 1.92s\tremaining: 13.3s\n",
      "38:\tlearn: 0.7837973\ttotal: 1.97s\tremaining: 13.2s\n",
      "39:\tlearn: 0.7840681\ttotal: 2.02s\tremaining: 13.1s\n",
      "40:\tlearn: 0.7852386\ttotal: 2.07s\tremaining: 13.1s\n",
      "41:\tlearn: 0.7856571\ttotal: 2.11s\tremaining: 13s\n",
      "42:\tlearn: 0.7869132\ttotal: 2.16s\tremaining: 12.9s\n",
      "43:\tlearn: 0.7881190\ttotal: 2.21s\tremaining: 12.9s\n",
      "44:\tlearn: 0.7882194\ttotal: 2.27s\tremaining: 12.9s\n",
      "45:\tlearn: 0.7871305\ttotal: 2.32s\tremaining: 12.8s\n",
      "46:\tlearn: 0.7875622\ttotal: 2.37s\tremaining: 12.8s\n",
      "47:\tlearn: 0.7870696\ttotal: 2.41s\tremaining: 12.7s\n",
      "48:\tlearn: 0.7898012\ttotal: 2.46s\tremaining: 12.6s\n",
      "49:\tlearn: 0.7906510\ttotal: 2.51s\tremaining: 12.6s\n",
      "50:\tlearn: 0.7917022\ttotal: 2.56s\tremaining: 12.5s\n",
      "51:\tlearn: 0.7929860\ttotal: 2.61s\tremaining: 12.4s\n",
      "52:\tlearn: 0.7945494\ttotal: 2.66s\tremaining: 12.4s\n",
      "53:\tlearn: 0.7951699\ttotal: 2.71s\tremaining: 12.4s\n",
      "54:\tlearn: 0.7960513\ttotal: 2.76s\tremaining: 12.3s\n",
      "55:\tlearn: 0.7960134\ttotal: 2.81s\tremaining: 12.2s\n",
      "56:\tlearn: 0.7953908\ttotal: 2.85s\tremaining: 12.2s\n",
      "57:\tlearn: 0.7960912\ttotal: 2.9s\tremaining: 12.1s\n",
      "58:\tlearn: 0.7970978\ttotal: 2.95s\tremaining: 12.1s\n",
      "59:\tlearn: 0.7985590\ttotal: 3s\tremaining: 12s\n",
      "60:\tlearn: 0.7994995\ttotal: 3.05s\tremaining: 11.9s\n",
      "61:\tlearn: 0.8003399\ttotal: 3.1s\tremaining: 11.9s\n",
      "62:\tlearn: 0.8013391\ttotal: 3.15s\tremaining: 11.8s\n",
      "63:\tlearn: 0.8019584\ttotal: 3.19s\tremaining: 11.8s\n",
      "64:\tlearn: 0.8055791\ttotal: 3.24s\tremaining: 11.7s\n",
      "65:\tlearn: 0.8049412\ttotal: 3.29s\tremaining: 11.7s\n",
      "66:\tlearn: 0.8055763\ttotal: 3.34s\tremaining: 11.6s\n",
      "67:\tlearn: 0.8060266\ttotal: 3.39s\tremaining: 11.6s\n",
      "68:\tlearn: 0.8065447\ttotal: 3.44s\tremaining: 11.5s\n",
      "69:\tlearn: 0.8064259\ttotal: 3.48s\tremaining: 11.4s\n",
      "70:\tlearn: 0.8085804\ttotal: 3.53s\tremaining: 11.4s\n",
      "71:\tlearn: 0.8084578\ttotal: 3.58s\tremaining: 11.3s\n",
      "72:\tlearn: 0.8099354\ttotal: 3.63s\tremaining: 11.3s\n",
      "73:\tlearn: 0.8115438\ttotal: 3.68s\tremaining: 11.2s\n",
      "74:\tlearn: 0.8123697\ttotal: 3.73s\tremaining: 11.2s\n",
      "75:\tlearn: 0.8120965\ttotal: 3.78s\tremaining: 11.1s\n",
      "76:\tlearn: 0.8129282\ttotal: 3.82s\tremaining: 11.1s\n",
      "77:\tlearn: 0.8141233\ttotal: 3.88s\tremaining: 11s\n",
      "78:\tlearn: 0.8152303\ttotal: 3.92s\tremaining: 11s\n",
      "79:\tlearn: 0.8171979\ttotal: 3.98s\tremaining: 10.9s\n",
      "80:\tlearn: 0.8173325\ttotal: 4.03s\tremaining: 10.9s\n",
      "81:\tlearn: 0.8176219\ttotal: 4.08s\tremaining: 10.8s\n",
      "82:\tlearn: 0.8171840\ttotal: 4.13s\tremaining: 10.8s\n",
      "83:\tlearn: 0.8188327\ttotal: 4.18s\tremaining: 10.7s\n",
      "84:\tlearn: 0.8188186\ttotal: 4.22s\tremaining: 10.7s\n",
      "85:\tlearn: 0.8209096\ttotal: 4.27s\tremaining: 10.6s\n",
      "86:\tlearn: 0.8214781\ttotal: 4.32s\tremaining: 10.6s\n",
      "87:\tlearn: 0.8215558\ttotal: 4.36s\tremaining: 10.5s\n",
      "88:\tlearn: 0.8219178\ttotal: 4.41s\tremaining: 10.5s\n",
      "89:\tlearn: 0.8214869\ttotal: 4.46s\tremaining: 10.4s\n",
      "90:\tlearn: 0.8229306\ttotal: 4.51s\tremaining: 10.4s\n",
      "91:\tlearn: 0.8236518\ttotal: 4.56s\tremaining: 10.3s\n",
      "92:\tlearn: 0.8253748\ttotal: 4.61s\tremaining: 10.3s\n",
      "93:\tlearn: 0.8259274\ttotal: 4.66s\tremaining: 10.2s\n",
      "94:\tlearn: 0.8263265\ttotal: 4.71s\tremaining: 10.2s\n",
      "95:\tlearn: 0.8270759\ttotal: 4.76s\tremaining: 10.1s\n",
      "96:\tlearn: 0.8294062\ttotal: 4.81s\tremaining: 10.1s\n",
      "97:\tlearn: 0.8306700\ttotal: 4.85s\tremaining: 10s\n",
      "98:\tlearn: 0.8319365\ttotal: 4.9s\tremaining: 9.95s\n",
      "99:\tlearn: 0.8318961\ttotal: 4.95s\tremaining: 9.91s\n",
      "100:\tlearn: 0.8346792\ttotal: 5s\tremaining: 9.86s\n",
      "101:\tlearn: 0.8354719\ttotal: 5.05s\tremaining: 9.8s\n",
      "102:\tlearn: 0.8363636\ttotal: 5.09s\tremaining: 9.74s\n",
      "103:\tlearn: 0.8375501\ttotal: 5.15s\tremaining: 9.7s\n",
      "104:\tlearn: 0.8376636\ttotal: 5.19s\tremaining: 9.64s\n",
      "105:\tlearn: 0.8385946\ttotal: 5.24s\tremaining: 9.59s\n",
      "106:\tlearn: 0.8396357\ttotal: 5.29s\tremaining: 9.54s\n",
      "107:\tlearn: 0.8394732\ttotal: 5.34s\tremaining: 9.49s\n",
      "108:\tlearn: 0.8410455\ttotal: 5.39s\tremaining: 9.44s\n",
      "109:\tlearn: 0.8413643\ttotal: 5.44s\tremaining: 9.39s\n",
      "110:\tlearn: 0.8428140\ttotal: 5.49s\tremaining: 9.35s\n",
      "111:\tlearn: 0.8426054\ttotal: 5.54s\tremaining: 9.29s\n",
      "112:\tlearn: 0.8439386\ttotal: 5.59s\tremaining: 9.24s\n",
      "113:\tlearn: 0.8448515\ttotal: 5.64s\tremaining: 9.2s\n",
      "114:\tlearn: 0.8452546\ttotal: 5.69s\tremaining: 9.15s\n",
      "115:\tlearn: 0.8454384\ttotal: 5.73s\tremaining: 9.09s\n",
      "116:\tlearn: 0.8477529\ttotal: 5.78s\tremaining: 9.04s\n",
      "117:\tlearn: 0.8481639\ttotal: 5.83s\tremaining: 9s\n",
      "118:\tlearn: 0.8488838\ttotal: 5.88s\tremaining: 8.94s\n",
      "119:\tlearn: 0.8496066\ttotal: 5.93s\tremaining: 8.89s\n",
      "120:\tlearn: 0.8503290\ttotal: 5.97s\tremaining: 8.84s\n",
      "121:\tlearn: 0.8509037\ttotal: 6.02s\tremaining: 8.79s\n",
      "122:\tlearn: 0.8524850\ttotal: 6.07s\tremaining: 8.74s\n",
      "123:\tlearn: 0.8540016\ttotal: 6.12s\tremaining: 8.69s\n",
      "124:\tlearn: 0.8540182\ttotal: 6.17s\tremaining: 8.64s\n",
      "125:\tlearn: 0.8559699\ttotal: 6.22s\tremaining: 8.59s\n",
      "126:\tlearn: 0.8562386\ttotal: 6.27s\tremaining: 8.54s\n",
      "127:\tlearn: 0.8566485\ttotal: 6.32s\tremaining: 8.49s\n",
      "128:\tlearn: 0.8575523\ttotal: 6.37s\tremaining: 8.44s\n",
      "129:\tlearn: 0.8572841\ttotal: 6.41s\tremaining: 8.39s\n",
      "130:\tlearn: 0.8584845\ttotal: 6.46s\tremaining: 8.34s\n",
      "131:\tlearn: 0.8587370\ttotal: 6.51s\tremaining: 8.28s\n",
      "132:\tlearn: 0.8591320\ttotal: 6.56s\tremaining: 8.23s\n",
      "133:\tlearn: 0.8603308\ttotal: 6.61s\tremaining: 8.18s\n",
      "134:\tlearn: 0.8603297\ttotal: 6.65s\tremaining: 8.13s\n",
      "135:\tlearn: 0.8609069\ttotal: 6.7s\tremaining: 8.08s\n",
      "136:\tlearn: 0.8625419\ttotal: 6.75s\tremaining: 8.03s\n",
      "137:\tlearn: 0.8632618\ttotal: 6.8s\tremaining: 7.98s\n",
      "138:\tlearn: 0.8631901\ttotal: 6.85s\tremaining: 7.93s\n",
      "139:\tlearn: 0.8642378\ttotal: 6.9s\tremaining: 7.88s\n",
      "140:\tlearn: 0.8652279\ttotal: 6.94s\tremaining: 7.83s\n",
      "141:\tlearn: 0.8652735\ttotal: 6.99s\tremaining: 7.78s\n",
      "142:\tlearn: 0.8657940\ttotal: 7.04s\tremaining: 7.73s\n",
      "143:\tlearn: 0.8670389\ttotal: 7.09s\tremaining: 7.68s\n",
      "144:\tlearn: 0.8678221\ttotal: 7.13s\tremaining: 7.63s\n",
      "145:\tlearn: 0.8683379\ttotal: 7.18s\tremaining: 7.57s\n",
      "146:\tlearn: 0.8695781\ttotal: 7.23s\tremaining: 7.53s\n",
      "147:\tlearn: 0.8706765\ttotal: 7.28s\tremaining: 7.47s\n",
      "148:\tlearn: 0.8715343\ttotal: 7.33s\tremaining: 7.42s\n",
      "149:\tlearn: 0.8719416\ttotal: 7.37s\tremaining: 7.37s\n",
      "150:\tlearn: 0.8729227\ttotal: 7.42s\tremaining: 7.32s\n",
      "151:\tlearn: 0.8744021\ttotal: 7.46s\tremaining: 7.27s\n",
      "152:\tlearn: 0.8747166\ttotal: 7.51s\tremaining: 7.22s\n",
      "153:\tlearn: 0.8748583\ttotal: 7.57s\tremaining: 7.17s\n",
      "154:\tlearn: 0.8750863\ttotal: 7.63s\tremaining: 7.13s\n",
      "155:\tlearn: 0.8759059\ttotal: 7.68s\tremaining: 7.09s\n",
      "156:\tlearn: 0.8763801\ttotal: 7.73s\tremaining: 7.04s\n",
      "157:\tlearn: 0.8767866\ttotal: 7.77s\tremaining: 6.99s\n",
      "158:\tlearn: 0.8774766\ttotal: 7.82s\tremaining: 6.94s\n",
      "159:\tlearn: 0.8783277\ttotal: 7.87s\tremaining: 6.89s\n",
      "160:\tlearn: 0.8789238\ttotal: 7.92s\tremaining: 6.84s\n",
      "161:\tlearn: 0.8792075\ttotal: 7.97s\tremaining: 6.79s\n",
      "162:\tlearn: 0.8790029\ttotal: 8.02s\tremaining: 6.74s\n",
      "163:\tlearn: 0.8793774\ttotal: 8.08s\tremaining: 6.7s\n",
      "164:\tlearn: 0.8804691\ttotal: 8.13s\tremaining: 6.65s\n",
      "165:\tlearn: 0.8815796\ttotal: 8.18s\tremaining: 6.6s\n",
      "166:\tlearn: 0.8822458\ttotal: 8.23s\tremaining: 6.56s\n",
      "167:\tlearn: 0.8833637\ttotal: 8.29s\tremaining: 6.51s\n",
      "168:\tlearn: 0.8837118\ttotal: 8.35s\tremaining: 6.47s\n",
      "169:\tlearn: 0.8841286\ttotal: 8.4s\tremaining: 6.42s\n",
      "170:\tlearn: 0.8849105\ttotal: 8.45s\tremaining: 6.37s\n",
      "171:\tlearn: 0.8857297\ttotal: 8.5s\tremaining: 6.33s\n",
      "172:\tlearn: 0.8858506\ttotal: 8.55s\tremaining: 6.27s\n",
      "173:\tlearn: 0.8868658\ttotal: 8.59s\tremaining: 6.22s\n",
      "174:\tlearn: 0.8875117\ttotal: 8.64s\tremaining: 6.17s\n",
      "175:\tlearn: 0.8882440\ttotal: 8.7s\tremaining: 6.13s\n",
      "176:\tlearn: 0.8885719\ttotal: 8.75s\tremaining: 6.08s\n",
      "177:\tlearn: 0.8879705\ttotal: 8.81s\tremaining: 6.04s\n",
      "178:\tlearn: 0.8887796\ttotal: 8.86s\tremaining: 5.99s\n",
      "179:\tlearn: 0.8892058\ttotal: 8.91s\tremaining: 5.94s\n",
      "180:\tlearn: 0.8905275\ttotal: 8.96s\tremaining: 5.89s\n",
      "181:\tlearn: 0.8912574\ttotal: 9.02s\tremaining: 5.85s\n",
      "182:\tlearn: 0.8907125\ttotal: 9.07s\tremaining: 5.8s\n",
      "183:\tlearn: 0.8908555\ttotal: 9.12s\tremaining: 5.75s\n",
      "184:\tlearn: 0.8914123\ttotal: 9.17s\tremaining: 5.7s\n",
      "185:\tlearn: 0.8918162\ttotal: 9.22s\tremaining: 5.65s\n",
      "186:\tlearn: 0.8925587\ttotal: 9.28s\tremaining: 5.61s\n",
      "187:\tlearn: 0.8929063\ttotal: 9.33s\tremaining: 5.56s\n",
      "188:\tlearn: 0.8937823\ttotal: 9.38s\tremaining: 5.51s\n",
      "189:\tlearn: 0.8937279\ttotal: 9.44s\tremaining: 5.46s\n",
      "190:\tlearn: 0.8940853\ttotal: 9.49s\tremaining: 5.42s\n",
      "191:\tlearn: 0.8946773\ttotal: 9.55s\tremaining: 5.37s\n",
      "192:\tlearn: 0.8951145\ttotal: 9.6s\tremaining: 5.32s\n",
      "193:\tlearn: 0.8951894\ttotal: 9.65s\tremaining: 5.28s\n",
      "194:\tlearn: 0.8958333\ttotal: 9.71s\tremaining: 5.23s\n",
      "195:\tlearn: 0.8962806\ttotal: 9.76s\tremaining: 5.18s\n",
      "196:\tlearn: 0.8968566\ttotal: 9.81s\tremaining: 5.13s\n",
      "197:\tlearn: 0.8974560\ttotal: 9.86s\tremaining: 5.08s\n",
      "198:\tlearn: 0.8975983\ttotal: 9.9s\tremaining: 5.03s\n",
      "199:\tlearn: 0.8973477\ttotal: 9.95s\tremaining: 4.98s\n",
      "200:\tlearn: 0.8987826\ttotal: 10s\tremaining: 4.93s\n",
      "201:\tlearn: 0.8987671\ttotal: 10.1s\tremaining: 4.88s\n",
      "202:\tlearn: 0.8991898\ttotal: 10.1s\tremaining: 4.83s\n",
      "203:\tlearn: 0.8992438\ttotal: 10.2s\tremaining: 4.78s\n",
      "204:\tlearn: 0.8995680\ttotal: 10.2s\tremaining: 4.73s\n",
      "205:\tlearn: 0.8992294\ttotal: 10.3s\tremaining: 4.69s\n",
      "206:\tlearn: 0.8997891\ttotal: 10.3s\tremaining: 4.64s\n",
      "207:\tlearn: 0.9007207\ttotal: 10.4s\tremaining: 4.59s\n",
      "208:\tlearn: 0.9017454\ttotal: 10.4s\tremaining: 4.54s\n",
      "209:\tlearn: 0.9022704\ttotal: 10.5s\tremaining: 4.49s\n",
      "210:\tlearn: 0.9029221\ttotal: 10.5s\tremaining: 4.43s\n",
      "211:\tlearn: 0.9038330\ttotal: 10.6s\tremaining: 4.38s\n",
      "212:\tlearn: 0.9042089\ttotal: 10.6s\tremaining: 4.33s\n",
      "213:\tlearn: 0.9038358\ttotal: 10.6s\tremaining: 4.28s\n",
      "214:\tlearn: 0.9044074\ttotal: 10.7s\tremaining: 4.23s\n",
      "215:\tlearn: 0.9044611\ttotal: 10.7s\tremaining: 4.18s\n",
      "216:\tlearn: 0.9052797\ttotal: 10.8s\tremaining: 4.13s\n",
      "217:\tlearn: 0.9055384\ttotal: 10.8s\tremaining: 4.08s\n",
      "218:\tlearn: 0.9058749\ttotal: 10.9s\tremaining: 4.03s\n",
      "219:\tlearn: 0.9064551\ttotal: 10.9s\tremaining: 3.97s\n",
      "220:\tlearn: 0.9071054\ttotal: 11s\tremaining: 3.92s\n",
      "221:\tlearn: 0.9073811\ttotal: 11s\tremaining: 3.88s\n",
      "222:\tlearn: 0.9072296\ttotal: 11.1s\tremaining: 3.82s\n",
      "223:\tlearn: 0.9078799\ttotal: 11.1s\tremaining: 3.77s\n",
      "224:\tlearn: 0.9083427\ttotal: 11.2s\tremaining: 3.72s\n",
      "225:\tlearn: 0.9091087\ttotal: 11.2s\tremaining: 3.67s\n",
      "226:\tlearn: 0.9092956\ttotal: 11.3s\tremaining: 3.62s\n",
      "227:\tlearn: 0.9098830\ttotal: 11.3s\tremaining: 3.57s\n",
      "228:\tlearn: 0.9106304\ttotal: 11.4s\tremaining: 3.52s\n",
      "229:\tlearn: 0.9106041\ttotal: 11.4s\tremaining: 3.47s\n",
      "230:\tlearn: 0.9108707\ttotal: 11.5s\tremaining: 3.42s\n",
      "231:\tlearn: 0.9107020\ttotal: 11.5s\tremaining: 3.37s\n",
      "232:\tlearn: 0.9116898\ttotal: 11.6s\tremaining: 3.32s\n",
      "233:\tlearn: 0.9123065\ttotal: 11.6s\tremaining: 3.27s\n",
      "234:\tlearn: 0.9126965\ttotal: 11.6s\tremaining: 3.22s\n",
      "235:\tlearn: 0.9133373\ttotal: 11.7s\tremaining: 3.17s\n",
      "236:\tlearn: 0.9123391\ttotal: 11.7s\tremaining: 3.12s\n",
      "237:\tlearn: 0.9134691\ttotal: 11.8s\tremaining: 3.07s\n",
      "238:\tlearn: 0.9138386\ttotal: 11.8s\tremaining: 3.02s\n",
      "239:\tlearn: 0.9143025\ttotal: 11.9s\tremaining: 2.97s\n",
      "240:\tlearn: 0.9146688\ttotal: 11.9s\tremaining: 2.92s\n",
      "241:\tlearn: 0.9147219\ttotal: 12s\tremaining: 2.87s\n",
      "242:\tlearn: 0.9149009\ttotal: 12s\tremaining: 2.82s\n",
      "243:\tlearn: 0.9153571\ttotal: 12.1s\tremaining: 2.77s\n",
      "244:\tlearn: 0.9158173\ttotal: 12.1s\tremaining: 2.73s\n",
      "245:\tlearn: 0.9158421\ttotal: 12.2s\tremaining: 2.67s\n",
      "246:\tlearn: 0.9162668\ttotal: 12.2s\tremaining: 2.63s\n",
      "247:\tlearn: 0.9162137\ttotal: 12.3s\tremaining: 2.58s\n",
      "248:\tlearn: 0.9161770\ttotal: 12.3s\tremaining: 2.52s\n",
      "249:\tlearn: 0.9166830\ttotal: 12.4s\tremaining: 2.48s\n",
      "250:\tlearn: 0.9171438\ttotal: 12.4s\tremaining: 2.42s\n",
      "251:\tlearn: 0.9168993\ttotal: 12.5s\tremaining: 2.38s\n",
      "252:\tlearn: 0.9175031\ttotal: 12.5s\tremaining: 2.33s\n",
      "253:\tlearn: 0.9178290\ttotal: 12.6s\tremaining: 2.27s\n",
      "254:\tlearn: 0.9177392\ttotal: 12.6s\tremaining: 2.23s\n",
      "255:\tlearn: 0.9178980\ttotal: 12.7s\tremaining: 2.18s\n",
      "256:\tlearn: 0.9183314\ttotal: 12.7s\tremaining: 2.13s\n",
      "257:\tlearn: 0.9191756\ttotal: 12.8s\tremaining: 2.08s\n",
      "258:\tlearn: 0.9193027\ttotal: 12.8s\tremaining: 2.03s\n",
      "259:\tlearn: 0.9193714\ttotal: 12.9s\tremaining: 1.98s\n",
      "260:\tlearn: 0.9197573\ttotal: 12.9s\tremaining: 1.93s\n",
      "261:\tlearn: 0.9200587\ttotal: 13s\tremaining: 1.88s\n",
      "262:\tlearn: 0.9205573\ttotal: 13s\tremaining: 1.83s\n",
      "263:\tlearn: 0.9207746\ttotal: 13.1s\tremaining: 1.78s\n",
      "264:\tlearn: 0.9210526\ttotal: 13.1s\tremaining: 1.73s\n",
      "265:\tlearn: 0.9214055\ttotal: 13.2s\tremaining: 1.68s\n",
      "266:\tlearn: 0.9217894\ttotal: 13.2s\tremaining: 1.63s\n",
      "267:\tlearn: 0.9218276\ttotal: 13.3s\tremaining: 1.58s\n",
      "268:\tlearn: 0.9219705\ttotal: 13.3s\tremaining: 1.53s\n",
      "269:\tlearn: 0.9226103\ttotal: 13.4s\tremaining: 1.48s\n",
      "270:\tlearn: 0.9231672\ttotal: 13.4s\tremaining: 1.43s\n",
      "271:\tlearn: 0.9231823\ttotal: 13.5s\tremaining: 1.38s\n",
      "272:\tlearn: 0.9239577\ttotal: 13.5s\tremaining: 1.33s\n",
      "273:\tlearn: 0.9237392\ttotal: 13.5s\tremaining: 1.28s\n",
      "274:\tlearn: 0.9244997\ttotal: 13.6s\tremaining: 1.24s\n",
      "275:\tlearn: 0.9247859\ttotal: 13.6s\tremaining: 1.19s\n",
      "276:\tlearn: 0.9248617\ttotal: 13.7s\tremaining: 1.14s\n",
      "277:\tlearn: 0.9252446\ttotal: 13.7s\tremaining: 1.09s\n",
      "278:\tlearn: 0.9254418\ttotal: 13.8s\tremaining: 1.04s\n",
      "279:\tlearn: 0.9250416\ttotal: 13.8s\tremaining: 988ms\n",
      "280:\tlearn: 0.9248764\ttotal: 13.9s\tremaining: 939ms\n",
      "281:\tlearn: 0.9258535\ttotal: 13.9s\tremaining: 889ms\n",
      "282:\tlearn: 0.9259893\ttotal: 14s\tremaining: 840ms\n",
      "283:\tlearn: 0.9262303\ttotal: 14s\tremaining: 790ms\n",
      "284:\tlearn: 0.9263879\ttotal: 14.1s\tremaining: 741ms\n",
      "285:\tlearn: 0.9269366\ttotal: 14.1s\tremaining: 691ms\n",
      "286:\tlearn: 0.9263498\ttotal: 14.2s\tremaining: 642ms\n",
      "287:\tlearn: 0.9270512\ttotal: 14.2s\tremaining: 592ms\n",
      "288:\tlearn: 0.9275930\ttotal: 14.3s\tremaining: 543ms\n",
      "289:\tlearn: 0.9279107\ttotal: 14.3s\tremaining: 493ms\n",
      "290:\tlearn: 0.9280611\ttotal: 14.4s\tremaining: 444ms\n",
      "291:\tlearn: 0.9278371\ttotal: 14.4s\tremaining: 395ms\n",
      "292:\tlearn: 0.9282779\ttotal: 14.5s\tremaining: 345ms\n",
      "293:\tlearn: 0.9288650\ttotal: 14.5s\tremaining: 296ms\n",
      "294:\tlearn: 0.9293542\ttotal: 14.6s\tremaining: 247ms\n",
      "295:\tlearn: 0.9295361\ttotal: 14.6s\tremaining: 197ms\n",
      "296:\tlearn: 0.9298366\ttotal: 14.7s\tremaining: 148ms\n",
      "297:\tlearn: 0.9302667\ttotal: 14.7s\tremaining: 98.7ms\n",
      "298:\tlearn: 0.9303646\ttotal: 14.8s\tremaining: 49.4ms\n",
      "299:\tlearn: 0.9302940\ttotal: 14.8s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0.1, border_count=160, depth=5, eval_metric=F1, iterations=300, l2_leaf_reg=9, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=2; total time=  15.3s\n",
      "0:\tlearn: 0.6989445\ttotal: 191ms\tremaining: 2m 32s\n",
      "1:\tlearn: 0.7272027\ttotal: 371ms\tremaining: 2m 28s\n",
      "2:\tlearn: 0.7501090\ttotal: 553ms\tremaining: 2m 26s\n",
      "3:\tlearn: 0.7553763\ttotal: 730ms\tremaining: 2m 25s\n",
      "4:\tlearn: 0.7758320\ttotal: 920ms\tremaining: 2m 26s\n",
      "5:\tlearn: 0.7961316\ttotal: 1.1s\tremaining: 2m 25s\n",
      "6:\tlearn: 0.8075417\ttotal: 1.29s\tremaining: 2m 25s\n",
      "7:\tlearn: 0.8216274\ttotal: 1.47s\tremaining: 2m 25s\n",
      "8:\tlearn: 0.8273427\ttotal: 1.65s\tremaining: 2m 24s\n",
      "9:\tlearn: 0.8289742\ttotal: 1.83s\tremaining: 2m 24s\n",
      "10:\tlearn: 0.8374423\ttotal: 2.01s\tremaining: 2m 24s\n",
      "11:\tlearn: 0.8412861\ttotal: 2.19s\tremaining: 2m 23s\n",
      "12:\tlearn: 0.8466461\ttotal: 2.37s\tremaining: 2m 23s\n",
      "13:\tlearn: 0.8501195\ttotal: 2.54s\tremaining: 2m 22s\n",
      "14:\tlearn: 0.8543831\ttotal: 2.73s\tremaining: 2m 22s\n",
      "15:\tlearn: 0.8579518\ttotal: 2.91s\tremaining: 2m 22s\n",
      "16:\tlearn: 0.8619663\ttotal: 3.09s\tremaining: 2m 22s\n",
      "17:\tlearn: 0.8643265\ttotal: 3.27s\tremaining: 2m 22s\n",
      "18:\tlearn: 0.8644010\ttotal: 3.46s\tremaining: 2m 22s\n",
      "19:\tlearn: 0.8664161\ttotal: 3.65s\tremaining: 2m 22s\n",
      "20:\tlearn: 0.8693870\ttotal: 3.82s\tremaining: 2m 21s\n",
      "21:\tlearn: 0.8701166\ttotal: 4s\tremaining: 2m 21s\n",
      "22:\tlearn: 0.8733467\ttotal: 4.18s\tremaining: 2m 21s\n",
      "23:\tlearn: 0.8753352\ttotal: 4.36s\tremaining: 2m 20s\n",
      "24:\tlearn: 0.8764385\ttotal: 4.54s\tremaining: 2m 20s\n",
      "25:\tlearn: 0.8794264\ttotal: 4.71s\tremaining: 2m 20s\n",
      "26:\tlearn: 0.8830586\ttotal: 4.89s\tremaining: 2m 20s\n",
      "27:\tlearn: 0.8857727\ttotal: 5.07s\tremaining: 2m 19s\n",
      "28:\tlearn: 0.8881746\ttotal: 5.26s\tremaining: 2m 19s\n",
      "29:\tlearn: 0.8890732\ttotal: 5.44s\tremaining: 2m 19s\n",
      "30:\tlearn: 0.8902766\ttotal: 5.62s\tremaining: 2m 19s\n",
      "31:\tlearn: 0.8909888\ttotal: 5.8s\tremaining: 2m 19s\n",
      "32:\tlearn: 0.8930554\ttotal: 5.98s\tremaining: 2m 19s\n",
      "33:\tlearn: 0.8943683\ttotal: 6.16s\tremaining: 2m 18s\n",
      "34:\tlearn: 0.8943785\ttotal: 6.33s\tremaining: 2m 18s\n",
      "35:\tlearn: 0.8959914\ttotal: 6.51s\tremaining: 2m 18s\n",
      "36:\tlearn: 0.8980842\ttotal: 6.69s\tremaining: 2m 17s\n",
      "37:\tlearn: 0.8983224\ttotal: 6.87s\tremaining: 2m 17s\n",
      "38:\tlearn: 0.8996011\ttotal: 7.05s\tremaining: 2m 17s\n",
      "39:\tlearn: 0.9022183\ttotal: 7.23s\tremaining: 2m 17s\n",
      "40:\tlearn: 0.9033011\ttotal: 7.41s\tremaining: 2m 17s\n",
      "41:\tlearn: 0.9038845\ttotal: 7.59s\tremaining: 2m 17s\n",
      "42:\tlearn: 0.9053154\ttotal: 7.77s\tremaining: 2m 16s\n",
      "43:\tlearn: 0.9070118\ttotal: 7.95s\tremaining: 2m 16s\n",
      "44:\tlearn: 0.9079761\ttotal: 8.12s\tremaining: 2m 16s\n",
      "45:\tlearn: 0.9086220\ttotal: 8.3s\tremaining: 2m 16s\n",
      "46:\tlearn: 0.9097635\ttotal: 8.48s\tremaining: 2m 15s\n",
      "47:\tlearn: 0.9126204\ttotal: 8.67s\tremaining: 2m 15s\n",
      "48:\tlearn: 0.9131598\ttotal: 8.86s\tremaining: 2m 15s\n",
      "49:\tlearn: 0.9139633\ttotal: 9.03s\tremaining: 2m 15s\n",
      "50:\tlearn: 0.9155794\ttotal: 9.22s\tremaining: 2m 15s\n",
      "51:\tlearn: 0.9153416\ttotal: 9.4s\tremaining: 2m 15s\n",
      "52:\tlearn: 0.9160751\ttotal: 9.58s\tremaining: 2m 15s\n",
      "53:\tlearn: 0.9160224\ttotal: 9.76s\tremaining: 2m 14s\n",
      "54:\tlearn: 0.9177261\ttotal: 9.94s\tremaining: 2m 14s\n",
      "55:\tlearn: 0.9187951\ttotal: 10.1s\tremaining: 2m 14s\n",
      "56:\tlearn: 0.9207974\ttotal: 10.3s\tremaining: 2m 14s\n",
      "57:\tlearn: 0.9216518\ttotal: 10.5s\tremaining: 2m 14s\n",
      "58:\tlearn: 0.9224772\ttotal: 10.6s\tremaining: 2m 13s\n",
      "59:\tlearn: 0.9238945\ttotal: 10.8s\tremaining: 2m 13s\n",
      "60:\tlearn: 0.9246158\ttotal: 11s\tremaining: 2m 13s\n",
      "61:\tlearn: 0.9259006\ttotal: 11.2s\tremaining: 2m 13s\n",
      "62:\tlearn: 0.9261483\ttotal: 11.4s\tremaining: 2m 13s\n",
      "63:\tlearn: 0.9271006\ttotal: 11.6s\tremaining: 2m 12s\n",
      "64:\tlearn: 0.9277667\ttotal: 11.7s\tremaining: 2m 12s\n",
      "65:\tlearn: 0.9287944\ttotal: 11.9s\tremaining: 2m 12s\n",
      "66:\tlearn: 0.9299693\ttotal: 12.1s\tremaining: 2m 12s\n",
      "67:\tlearn: 0.9315363\ttotal: 12.3s\tremaining: 2m 11s\n",
      "68:\tlearn: 0.9321099\ttotal: 12.4s\tremaining: 2m 11s\n",
      "69:\tlearn: 0.9330274\ttotal: 12.6s\tremaining: 2m 11s\n",
      "70:\tlearn: 0.9340037\ttotal: 12.8s\tremaining: 2m 11s\n",
      "71:\tlearn: 0.9350713\ttotal: 13s\tremaining: 2m 11s\n",
      "72:\tlearn: 0.9358380\ttotal: 13.1s\tremaining: 2m 10s\n",
      "73:\tlearn: 0.9379243\ttotal: 13.3s\tremaining: 2m 10s\n",
      "74:\tlearn: 0.9389570\ttotal: 13.5s\tremaining: 2m 10s\n",
      "75:\tlearn: 0.9402336\ttotal: 13.7s\tremaining: 2m 10s\n",
      "76:\tlearn: 0.9403831\ttotal: 13.9s\tremaining: 2m 10s\n",
      "77:\tlearn: 0.9415216\ttotal: 14s\tremaining: 2m 9s\n",
      "78:\tlearn: 0.9423321\ttotal: 14.2s\tremaining: 2m 9s\n",
      "79:\tlearn: 0.9421536\ttotal: 14.4s\tremaining: 2m 9s\n",
      "80:\tlearn: 0.9429996\ttotal: 14.6s\tremaining: 2m 9s\n",
      "81:\tlearn: 0.9444743\ttotal: 14.8s\tremaining: 2m 9s\n",
      "82:\tlearn: 0.9445368\ttotal: 14.9s\tremaining: 2m 8s\n",
      "83:\tlearn: 0.9461892\ttotal: 15.1s\tremaining: 2m 8s\n",
      "84:\tlearn: 0.9461629\ttotal: 15.3s\tremaining: 2m 8s\n",
      "85:\tlearn: 0.9467299\ttotal: 15.5s\tremaining: 2m 8s\n",
      "86:\tlearn: 0.9476929\ttotal: 15.6s\tremaining: 2m 8s\n",
      "87:\tlearn: 0.9484294\ttotal: 15.8s\tremaining: 2m 7s\n",
      "88:\tlearn: 0.9486665\ttotal: 16s\tremaining: 2m 7s\n",
      "89:\tlearn: 0.9501150\ttotal: 16.2s\tremaining: 2m 7s\n",
      "90:\tlearn: 0.9509626\ttotal: 16.3s\tremaining: 2m 7s\n",
      "91:\tlearn: 0.9513355\ttotal: 16.5s\tremaining: 2m 7s\n",
      "92:\tlearn: 0.9516944\ttotal: 16.7s\tremaining: 2m 6s\n",
      "93:\tlearn: 0.9521055\ttotal: 16.9s\tremaining: 2m 6s\n",
      "94:\tlearn: 0.9530254\ttotal: 17.1s\tremaining: 2m 6s\n",
      "95:\tlearn: 0.9536093\ttotal: 17.2s\tremaining: 2m 6s\n",
      "96:\tlearn: 0.9543137\ttotal: 17.4s\tremaining: 2m 6s\n",
      "97:\tlearn: 0.9544541\ttotal: 17.6s\tremaining: 2m 6s\n",
      "98:\tlearn: 0.9546635\ttotal: 17.8s\tremaining: 2m 5s\n",
      "99:\tlearn: 0.9549064\ttotal: 18s\tremaining: 2m 5s\n",
      "100:\tlearn: 0.9553790\ttotal: 18.1s\tremaining: 2m 5s\n",
      "101:\tlearn: 0.9556133\ttotal: 18.3s\tremaining: 2m 5s\n",
      "102:\tlearn: 0.9557886\ttotal: 18.5s\tremaining: 2m 5s\n",
      "103:\tlearn: 0.9562745\ttotal: 18.7s\tremaining: 2m 5s\n",
      "104:\tlearn: 0.9563554\ttotal: 18.9s\tremaining: 2m 4s\n",
      "105:\tlearn: 0.9565431\ttotal: 19s\tremaining: 2m 4s\n",
      "106:\tlearn: 0.9572004\ttotal: 19.2s\tremaining: 2m 4s\n",
      "107:\tlearn: 0.9583538\ttotal: 19.4s\tremaining: 2m 4s\n",
      "108:\tlearn: 0.9588368\ttotal: 19.6s\tremaining: 2m 4s\n",
      "109:\tlearn: 0.9594143\ttotal: 19.8s\tremaining: 2m 3s\n",
      "110:\tlearn: 0.9600196\ttotal: 19.9s\tremaining: 2m 3s\n",
      "111:\tlearn: 0.9608527\ttotal: 20.1s\tremaining: 2m 3s\n",
      "112:\tlearn: 0.9617427\ttotal: 20.3s\tremaining: 2m 3s\n",
      "113:\tlearn: 0.9616841\ttotal: 20.5s\tremaining: 2m 3s\n",
      "114:\tlearn: 0.9617352\ttotal: 20.7s\tremaining: 2m 3s\n",
      "115:\tlearn: 0.9624127\ttotal: 20.9s\tremaining: 2m 3s\n",
      "116:\tlearn: 0.9631416\ttotal: 21s\tremaining: 2m 2s\n",
      "117:\tlearn: 0.9637071\ttotal: 21.2s\tremaining: 2m 2s\n",
      "118:\tlearn: 0.9634771\ttotal: 21.4s\tremaining: 2m 2s\n",
      "119:\tlearn: 0.9646641\ttotal: 21.6s\tremaining: 2m 2s\n",
      "120:\tlearn: 0.9652963\ttotal: 21.8s\tremaining: 2m 2s\n",
      "121:\tlearn: 0.9655410\ttotal: 22s\tremaining: 2m 2s\n",
      "122:\tlearn: 0.9662655\ttotal: 22.1s\tremaining: 2m 1s\n",
      "123:\tlearn: 0.9667358\ttotal: 22.3s\tremaining: 2m 1s\n",
      "124:\tlearn: 0.9667522\ttotal: 22.5s\tremaining: 2m 1s\n",
      "125:\tlearn: 0.9672261\ttotal: 22.7s\tremaining: 2m 1s\n",
      "126:\tlearn: 0.9678534\ttotal: 22.9s\tremaining: 2m 1s\n",
      "127:\tlearn: 0.9680446\ttotal: 23s\tremaining: 2m\n",
      "128:\tlearn: 0.9688164\ttotal: 23.2s\tremaining: 2m\n",
      "129:\tlearn: 0.9691700\ttotal: 23.4s\tremaining: 2m\n",
      "130:\tlearn: 0.9695951\ttotal: 23.6s\tremaining: 2m\n",
      "131:\tlearn: 0.9696970\ttotal: 23.7s\tremaining: 2m\n",
      "132:\tlearn: 0.9698408\ttotal: 23.9s\tremaining: 1m 59s\n",
      "133:\tlearn: 0.9698977\ttotal: 24.1s\tremaining: 1m 59s\n",
      "134:\tlearn: 0.9703744\ttotal: 24.3s\tremaining: 1m 59s\n",
      "135:\tlearn: 0.9709593\ttotal: 24.4s\tremaining: 1m 59s\n",
      "136:\tlearn: 0.9712504\ttotal: 24.6s\tremaining: 1m 59s\n",
      "137:\tlearn: 0.9715445\ttotal: 24.8s\tremaining: 1m 58s\n",
      "138:\tlearn: 0.9718045\ttotal: 25s\tremaining: 1m 58s\n",
      "139:\tlearn: 0.9717028\ttotal: 25.2s\tremaining: 1m 58s\n",
      "140:\tlearn: 0.9727669\ttotal: 25.3s\tremaining: 1m 58s\n",
      "141:\tlearn: 0.9731524\ttotal: 25.5s\tremaining: 1m 58s\n",
      "142:\tlearn: 0.9734443\ttotal: 25.7s\tremaining: 1m 58s\n",
      "143:\tlearn: 0.9737872\ttotal: 25.9s\tremaining: 1m 57s\n",
      "144:\tlearn: 0.9741811\ttotal: 26.1s\tremaining: 1m 57s\n",
      "145:\tlearn: 0.9745141\ttotal: 26.2s\tremaining: 1m 57s\n",
      "146:\tlearn: 0.9750000\ttotal: 26.4s\tremaining: 1m 57s\n",
      "147:\tlearn: 0.9756267\ttotal: 26.6s\tremaining: 1m 57s\n",
      "148:\tlearn: 0.9755299\ttotal: 26.8s\tremaining: 1m 56s\n",
      "149:\tlearn: 0.9760723\ttotal: 26.9s\tremaining: 1m 56s\n",
      "150:\tlearn: 0.9763193\ttotal: 27.1s\tremaining: 1m 56s\n",
      "151:\tlearn: 0.9765062\ttotal: 27.3s\tremaining: 1m 56s\n",
      "152:\tlearn: 0.9770932\ttotal: 27.5s\tremaining: 1m 56s\n",
      "153:\tlearn: 0.9774907\ttotal: 27.7s\tremaining: 1m 56s\n",
      "154:\tlearn: 0.9779744\ttotal: 27.8s\tremaining: 1m 55s\n",
      "155:\tlearn: 0.9779723\ttotal: 28s\tremaining: 1m 55s\n",
      "156:\tlearn: 0.9780717\ttotal: 28.2s\tremaining: 1m 55s\n",
      "157:\tlearn: 0.9783636\ttotal: 28.4s\tremaining: 1m 55s\n",
      "158:\tlearn: 0.9786578\ttotal: 28.5s\tremaining: 1m 55s\n",
      "159:\tlearn: 0.9789563\ttotal: 28.7s\tremaining: 1m 54s\n",
      "160:\tlearn: 0.9797361\ttotal: 28.9s\tremaining: 1m 54s\n",
      "161:\tlearn: 0.9797849\ttotal: 29.1s\tremaining: 1m 54s\n",
      "162:\tlearn: 0.9801364\ttotal: 29.2s\tremaining: 1m 54s\n",
      "163:\tlearn: 0.9804781\ttotal: 29.4s\tremaining: 1m 54s\n",
      "164:\tlearn: 0.9806246\ttotal: 29.6s\tremaining: 1m 53s\n",
      "165:\tlearn: 0.9810644\ttotal: 29.8s\tremaining: 1m 53s\n",
      "166:\tlearn: 0.9807635\ttotal: 30s\tremaining: 1m 53s\n",
      "167:\tlearn: 0.9809590\ttotal: 30.1s\tremaining: 1m 53s\n",
      "168:\tlearn: 0.9811076\ttotal: 30.3s\tremaining: 1m 53s\n",
      "169:\tlearn: 0.9812111\ttotal: 30.5s\tremaining: 1m 53s\n",
      "170:\tlearn: 0.9816079\ttotal: 30.7s\tremaining: 1m 52s\n",
      "171:\tlearn: 0.9815590\ttotal: 30.9s\tremaining: 1m 52s\n",
      "172:\tlearn: 0.9824929\ttotal: 31s\tremaining: 1m 52s\n",
      "173:\tlearn: 0.9825419\ttotal: 31.2s\tremaining: 1m 52s\n",
      "174:\tlearn: 0.9826924\ttotal: 31.4s\tremaining: 1m 52s\n",
      "175:\tlearn: 0.9826417\ttotal: 31.6s\tremaining: 1m 51s\n",
      "176:\tlearn: 0.9830881\ttotal: 31.7s\tremaining: 1m 51s\n",
      "177:\tlearn: 0.9834331\ttotal: 31.9s\tremaining: 1m 51s\n",
      "178:\tlearn: 0.9836344\ttotal: 32.1s\tremaining: 1m 51s\n",
      "179:\tlearn: 0.9837816\ttotal: 32.3s\tremaining: 1m 51s\n",
      "180:\tlearn: 0.9841761\ttotal: 32.4s\tremaining: 1m 50s\n",
      "181:\tlearn: 0.9843282\ttotal: 32.6s\tremaining: 1m 50s\n",
      "182:\tlearn: 0.9846231\ttotal: 32.8s\tremaining: 1m 50s\n",
      "183:\tlearn: 0.9846200\ttotal: 33s\tremaining: 1m 50s\n",
      "184:\tlearn: 0.9850165\ttotal: 33.1s\tremaining: 1m 50s\n",
      "185:\tlearn: 0.9853624\ttotal: 33.3s\tremaining: 1m 50s\n",
      "186:\tlearn: 0.9854102\ttotal: 33.5s\tremaining: 1m 49s\n",
      "187:\tlearn: 0.9854117\ttotal: 33.7s\tremaining: 1m 49s\n",
      "188:\tlearn: 0.9858057\ttotal: 33.9s\tremaining: 1m 49s\n",
      "189:\tlearn: 0.9859549\ttotal: 34s\tremaining: 1m 49s\n",
      "190:\tlearn: 0.9859549\ttotal: 34.2s\tremaining: 1m 49s\n",
      "191:\tlearn: 0.9864973\ttotal: 34.4s\tremaining: 1m 48s\n",
      "192:\tlearn: 0.9868428\ttotal: 34.6s\tremaining: 1m 48s\n",
      "193:\tlearn: 0.9869415\ttotal: 34.8s\tremaining: 1m 48s\n",
      "194:\tlearn: 0.9871404\ttotal: 34.9s\tremaining: 1m 48s\n",
      "195:\tlearn: 0.9872886\ttotal: 35.1s\tremaining: 1m 48s\n",
      "196:\tlearn: 0.9873874\ttotal: 35.3s\tremaining: 1m 48s\n",
      "197:\tlearn: 0.9875357\ttotal: 35.5s\tremaining: 1m 47s\n",
      "198:\tlearn: 0.9874875\ttotal: 35.7s\tremaining: 1m 47s\n",
      "199:\tlearn: 0.9878348\ttotal: 35.8s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.9879349\ttotal: 36s\tremaining: 1m 47s\n",
      "201:\tlearn: 0.9881340\ttotal: 36.2s\tremaining: 1m 47s\n",
      "202:\tlearn: 0.9885288\ttotal: 36.4s\tremaining: 1m 46s\n",
      "203:\tlearn: 0.9884274\ttotal: 36.6s\tremaining: 1m 46s\n",
      "204:\tlearn: 0.9887280\ttotal: 36.7s\tremaining: 1m 46s\n",
      "205:\tlearn: 0.9887291\ttotal: 36.9s\tremaining: 1m 46s\n",
      "206:\tlearn: 0.9889284\ttotal: 37.1s\tremaining: 1m 46s\n",
      "207:\tlearn: 0.9887787\ttotal: 37.3s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.9892743\ttotal: 37.5s\tremaining: 1m 45s\n",
      "209:\tlearn: 0.9894747\ttotal: 37.6s\tremaining: 1m 45s\n",
      "210:\tlearn: 0.9896721\ttotal: 37.8s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.9897228\ttotal: 38s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.9901189\ttotal: 38.2s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.9898210\ttotal: 38.4s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.9901685\ttotal: 38.6s\tremaining: 1m 44s\n",
      "215:\tlearn: 0.9902192\ttotal: 38.8s\tremaining: 1m 44s\n",
      "216:\tlearn: 0.9904169\ttotal: 39s\tremaining: 1m 44s\n",
      "217:\tlearn: 0.9905670\ttotal: 39.1s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.9908644\ttotal: 39.3s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.9911140\ttotal: 39.5s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.9912135\ttotal: 39.7s\tremaining: 1m 43s\n",
      "221:\tlearn: 0.9914126\ttotal: 39.9s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.9915620\ttotal: 40.1s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.9917115\ttotal: 40.2s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.9918601\ttotal: 40.4s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.9920603\ttotal: 40.6s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.9922099\ttotal: 40.8s\tremaining: 1m 43s\n",
      "227:\tlearn: 0.9922107\ttotal: 41s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.9923603\ttotal: 41.2s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.9923104\ttotal: 41.4s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.9926105\ttotal: 41.6s\tremaining: 1m 42s\n",
      "231:\tlearn: 0.9926105\ttotal: 41.7s\tremaining: 1m 42s\n",
      "232:\tlearn: 0.9927103\ttotal: 41.9s\tremaining: 1m 42s\n",
      "233:\tlearn: 0.9927609\ttotal: 42.1s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.9928600\ttotal: 42.3s\tremaining: 1m 41s\n",
      "235:\tlearn: 0.9929599\ttotal: 42.5s\tremaining: 1m 41s\n",
      "236:\tlearn: 0.9931603\ttotal: 42.7s\tremaining: 1m 41s\n",
      "237:\tlearn: 0.9930597\ttotal: 42.8s\tremaining: 1m 41s\n",
      "238:\tlearn: 0.9931090\ttotal: 43s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.9933095\ttotal: 43.2s\tremaining: 1m 40s\n",
      "240:\tlearn: 0.9936601\ttotal: 43.4s\tremaining: 1m 40s\n",
      "241:\tlearn: 0.9937113\ttotal: 43.6s\tremaining: 1m 40s\n",
      "242:\tlearn: 0.9938107\ttotal: 43.7s\tremaining: 1m 40s\n",
      "243:\tlearn: 0.9939614\ttotal: 43.9s\tremaining: 1m 40s\n",
      "244:\tlearn: 0.9939614\ttotal: 44.1s\tremaining: 1m 39s\n",
      "245:\tlearn: 0.9940114\ttotal: 44.3s\tremaining: 1m 39s\n",
      "246:\tlearn: 0.9940620\ttotal: 44.5s\tremaining: 1m 39s\n",
      "247:\tlearn: 0.9941621\ttotal: 44.7s\tremaining: 1m 39s\n",
      "248:\tlearn: 0.9943617\ttotal: 44.8s\tremaining: 1m 39s\n",
      "249:\tlearn: 0.9944612\ttotal: 45s\tremaining: 1m 39s\n",
      "250:\tlearn: 0.9947122\ttotal: 45.2s\tremaining: 1m 38s\n",
      "251:\tlearn: 0.9948625\ttotal: 45.4s\tremaining: 1m 38s\n",
      "252:\tlearn: 0.9949126\ttotal: 45.6s\tremaining: 1m 38s\n",
      "253:\tlearn: 0.9949627\ttotal: 45.8s\tremaining: 1m 38s\n",
      "254:\tlearn: 0.9950630\ttotal: 46s\tremaining: 1m 38s\n",
      "255:\tlearn: 0.9950128\ttotal: 46.1s\tremaining: 1m 38s\n",
      "256:\tlearn: 0.9953137\ttotal: 46.3s\tremaining: 1m 37s\n",
      "257:\tlearn: 0.9954140\ttotal: 46.5s\tremaining: 1m 37s\n",
      "258:\tlearn: 0.9956649\ttotal: 46.7s\tremaining: 1m 37s\n",
      "259:\tlearn: 0.9958155\ttotal: 46.9s\tremaining: 1m 37s\n",
      "260:\tlearn: 0.9957653\ttotal: 47.1s\tremaining: 1m 37s\n",
      "261:\tlearn: 0.9957155\ttotal: 47.3s\tremaining: 1m 37s\n",
      "262:\tlearn: 0.9956147\ttotal: 47.4s\tremaining: 1m 36s\n",
      "263:\tlearn: 0.9957657\ttotal: 47.6s\tremaining: 1m 36s\n",
      "264:\tlearn: 0.9958657\ttotal: 47.8s\tremaining: 1m 36s\n",
      "265:\tlearn: 0.9960163\ttotal: 48s\tremaining: 1m 36s\n",
      "266:\tlearn: 0.9960666\ttotal: 48.2s\tremaining: 1m 36s\n",
      "267:\tlearn: 0.9960163\ttotal: 48.4s\tremaining: 1m 36s\n",
      "268:\tlearn: 0.9961168\ttotal: 48.6s\tremaining: 1m 35s\n",
      "269:\tlearn: 0.9963178\ttotal: 48.8s\tremaining: 1m 35s\n",
      "270:\tlearn: 0.9963178\ttotal: 48.9s\tremaining: 1m 35s\n",
      "271:\tlearn: 0.9965188\ttotal: 49.1s\tremaining: 1m 35s\n",
      "272:\tlearn: 0.9964686\ttotal: 49.3s\tremaining: 1m 35s\n",
      "273:\tlearn: 0.9964686\ttotal: 49.5s\tremaining: 1m 34s\n",
      "274:\tlearn: 0.9964686\ttotal: 49.7s\tremaining: 1m 34s\n",
      "275:\tlearn: 0.9964686\ttotal: 49.8s\tremaining: 1m 34s\n",
      "276:\tlearn: 0.9964686\ttotal: 50s\tremaining: 1m 34s\n",
      "277:\tlearn: 0.9965691\ttotal: 50.2s\tremaining: 1m 34s\n",
      "278:\tlearn: 0.9966700\ttotal: 50.4s\tremaining: 1m 34s\n",
      "279:\tlearn: 0.9969215\ttotal: 50.6s\tremaining: 1m 33s\n",
      "280:\tlearn: 0.9968712\ttotal: 50.7s\tremaining: 1m 33s\n",
      "281:\tlearn: 0.9969718\ttotal: 50.9s\tremaining: 1m 33s\n",
      "282:\tlearn: 0.9971731\ttotal: 51.1s\tremaining: 1m 33s\n",
      "283:\tlearn: 0.9972736\ttotal: 51.3s\tremaining: 1m 33s\n",
      "284:\tlearn: 0.9972235\ttotal: 51.5s\tremaining: 1m 33s\n",
      "285:\tlearn: 0.9972738\ttotal: 51.7s\tremaining: 1m 32s\n",
      "286:\tlearn: 0.9973745\ttotal: 51.8s\tremaining: 1m 32s\n",
      "287:\tlearn: 0.9973745\ttotal: 52s\tremaining: 1m 32s\n",
      "288:\tlearn: 0.9974249\ttotal: 52.2s\tremaining: 1m 32s\n",
      "289:\tlearn: 0.9973242\ttotal: 52.4s\tremaining: 1m 32s\n",
      "290:\tlearn: 0.9974753\ttotal: 52.5s\tremaining: 1m 31s\n",
      "291:\tlearn: 0.9975760\ttotal: 52.7s\tremaining: 1m 31s\n",
      "292:\tlearn: 0.9976768\ttotal: 52.9s\tremaining: 1m 31s\n",
      "293:\tlearn: 0.9977776\ttotal: 53.1s\tremaining: 1m 31s\n",
      "294:\tlearn: 0.9977272\ttotal: 53.3s\tremaining: 1m 31s\n",
      "295:\tlearn: 0.9977272\ttotal: 53.5s\tremaining: 1m 31s\n",
      "296:\tlearn: 0.9977272\ttotal: 53.6s\tremaining: 1m 30s\n",
      "297:\tlearn: 0.9977776\ttotal: 53.8s\tremaining: 1m 30s\n",
      "298:\tlearn: 0.9978784\ttotal: 54s\tremaining: 1m 30s\n",
      "299:\tlearn: 0.9978784\ttotal: 54.2s\tremaining: 1m 30s\n",
      "300:\tlearn: 0.9977776\ttotal: 54.3s\tremaining: 1m 30s\n",
      "301:\tlearn: 0.9978280\ttotal: 54.5s\tremaining: 1m 29s\n",
      "302:\tlearn: 0.9978280\ttotal: 54.7s\tremaining: 1m 29s\n",
      "303:\tlearn: 0.9977272\ttotal: 54.9s\tremaining: 1m 29s\n",
      "304:\tlearn: 0.9978280\ttotal: 55s\tremaining: 1m 29s\n",
      "305:\tlearn: 0.9979288\ttotal: 55.2s\tremaining: 1m 29s\n",
      "306:\tlearn: 0.9979288\ttotal: 55.4s\tremaining: 1m 28s\n",
      "307:\tlearn: 0.9979288\ttotal: 55.6s\tremaining: 1m 28s\n",
      "308:\tlearn: 0.9979792\ttotal: 55.8s\tremaining: 1m 28s\n",
      "309:\tlearn: 0.9980298\ttotal: 55.9s\tremaining: 1m 28s\n",
      "310:\tlearn: 0.9980802\ttotal: 56.1s\tremaining: 1m 28s\n",
      "311:\tlearn: 0.9981811\ttotal: 56.3s\tremaining: 1m 28s\n",
      "312:\tlearn: 0.9981307\ttotal: 56.5s\tremaining: 1m 27s\n",
      "313:\tlearn: 0.9981811\ttotal: 56.6s\tremaining: 1m 27s\n",
      "314:\tlearn: 0.9980802\ttotal: 56.8s\tremaining: 1m 27s\n",
      "315:\tlearn: 0.9980802\ttotal: 57s\tremaining: 1m 27s\n",
      "316:\tlearn: 0.9981307\ttotal: 57.2s\tremaining: 1m 27s\n",
      "317:\tlearn: 0.9981811\ttotal: 57.3s\tremaining: 1m 26s\n",
      "318:\tlearn: 0.9982820\ttotal: 57.5s\tremaining: 1m 26s\n",
      "319:\tlearn: 0.9982820\ttotal: 57.7s\tremaining: 1m 26s\n",
      "320:\tlearn: 0.9984332\ttotal: 57.9s\tremaining: 1m 26s\n",
      "321:\tlearn: 0.9984836\ttotal: 58.1s\tremaining: 1m 26s\n",
      "322:\tlearn: 0.9984333\ttotal: 58.3s\tremaining: 1m 26s\n",
      "323:\tlearn: 0.9985847\ttotal: 58.4s\tremaining: 1m 25s\n",
      "324:\tlearn: 0.9985846\ttotal: 58.6s\tremaining: 1m 25s\n",
      "325:\tlearn: 0.9985847\ttotal: 58.8s\tremaining: 1m 25s\n",
      "326:\tlearn: 0.9985341\ttotal: 59s\tremaining: 1m 25s\n",
      "327:\tlearn: 0.9985341\ttotal: 59.2s\tremaining: 1m 25s\n",
      "328:\tlearn: 0.9985846\ttotal: 59.3s\tremaining: 1m 24s\n",
      "329:\tlearn: 0.9985846\ttotal: 59.5s\tremaining: 1m 24s\n",
      "330:\tlearn: 0.9986351\ttotal: 59.7s\tremaining: 1m 24s\n",
      "331:\tlearn: 0.9986351\ttotal: 59.9s\tremaining: 1m 24s\n",
      "332:\tlearn: 0.9986351\ttotal: 1m\tremaining: 1m 24s\n",
      "333:\tlearn: 0.9986351\ttotal: 1m\tremaining: 1m 24s\n",
      "334:\tlearn: 0.9986351\ttotal: 1m\tremaining: 1m 23s\n",
      "335:\tlearn: 0.9987360\ttotal: 1m\tremaining: 1m 23s\n",
      "336:\tlearn: 0.9987360\ttotal: 1m\tremaining: 1m 23s\n",
      "337:\tlearn: 0.9986855\ttotal: 1m\tremaining: 1m 23s\n",
      "338:\tlearn: 0.9987865\ttotal: 1m 1s\tremaining: 1m 23s\n",
      "339:\tlearn: 0.9988370\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "340:\tlearn: 0.9987865\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "341:\tlearn: 0.9988372\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "342:\tlearn: 0.9988372\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "343:\tlearn: 0.9988372\ttotal: 1m 2s\tremaining: 1m 22s\n",
      "344:\tlearn: 0.9988372\ttotal: 1m 2s\tremaining: 1m 22s\n",
      "345:\tlearn: 0.9987865\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "346:\tlearn: 0.9987867\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "347:\tlearn: 0.9988370\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "348:\tlearn: 0.9988370\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "349:\tlearn: 0.9988370\ttotal: 1m 3s\tremaining: 1m 21s\n",
      "350:\tlearn: 0.9988875\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "351:\tlearn: 0.9989381\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "352:\tlearn: 0.9988875\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "353:\tlearn: 0.9989381\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "354:\tlearn: 0.9989887\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "355:\tlearn: 0.9990392\ttotal: 1m 4s\tremaining: 1m 20s\n",
      "356:\tlearn: 0.9990896\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "357:\tlearn: 0.9990896\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "358:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "359:\tlearn: 0.9991907\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "360:\tlearn: 0.9992412\ttotal: 1m 5s\tremaining: 1m 19s\n",
      "361:\tlearn: 0.9992412\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "362:\tlearn: 0.9992412\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "363:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "364:\tlearn: 0.9991908\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "365:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "366:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 18s\n",
      "367:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "368:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "369:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "370:\tlearn: 0.9992413\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "371:\tlearn: 0.9992413\ttotal: 1m 7s\tremaining: 1m 17s\n",
      "372:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "373:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "374:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "375:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "376:\tlearn: 0.9992919\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "377:\tlearn: 0.9992919\ttotal: 1m 8s\tremaining: 1m 16s\n",
      "378:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "379:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "380:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "381:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "382:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "383:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "384:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "385:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "386:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "387:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "388:\tlearn: 0.9993424\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "389:\tlearn: 0.9994435\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "390:\tlearn: 0.9994435\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "391:\tlearn: 0.9994435\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "392:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "393:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "394:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "395:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "396:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "397:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "398:\tlearn: 0.9994435\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "399:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "400:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "401:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "402:\tlearn: 0.9994435\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "403:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "404:\tlearn: 0.9995446\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "405:\tlearn: 0.9995446\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "406:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "407:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "408:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "409:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "410:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "411:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "412:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "413:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "414:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "415:\tlearn: 0.9994941\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "416:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "417:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "418:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "419:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "420:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "421:\tlearn: 0.9994941\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "422:\tlearn: 0.9994941\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.9994941\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "424:\tlearn: 0.9995446\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "425:\tlearn: 0.9995446\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "426:\tlearn: 0.9995446\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "427:\tlearn: 0.9995446\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "428:\tlearn: 0.9995446\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "429:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "430:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "431:\tlearn: 0.9995446\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "432:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "433:\tlearn: 0.9995446\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "434:\tlearn: 0.9995446\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "435:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "436:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "437:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "438:\tlearn: 0.9996964\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "439:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "440:\tlearn: 0.9997470\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "441:\tlearn: 0.9997470\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "442:\tlearn: 0.9997470\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "443:\tlearn: 0.9996964\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "444:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "445:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "446:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "447:\tlearn: 0.9996964\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "448:\tlearn: 0.9997470\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "449:\tlearn: 0.9997470\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "450:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "451:\tlearn: 0.9997470\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "452:\tlearn: 0.9997470\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "453:\tlearn: 0.9997470\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "454:\tlearn: 0.9997470\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "455:\tlearn: 0.9997470\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "456:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "457:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "458:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "459:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "460:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m\n",
      "461:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 1m\n",
      "462:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 1m\n",
      "463:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 1m\n",
      "464:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 1m\n",
      "465:\tlearn: 0.9998482\ttotal: 1m 23s\tremaining: 1m\n",
      "466:\tlearn: 0.9998482\ttotal: 1m 23s\tremaining: 59.9s\n",
      "467:\tlearn: 0.9998482\ttotal: 1m 24s\tremaining: 59.7s\n",
      "468:\tlearn: 0.9998482\ttotal: 1m 24s\tremaining: 59.5s\n",
      "469:\tlearn: 0.9998482\ttotal: 1m 24s\tremaining: 59.3s\n",
      "470:\tlearn: 0.9998482\ttotal: 1m 24s\tremaining: 59.1s\n",
      "471:\tlearn: 0.9998482\ttotal: 1m 24s\tremaining: 59s\n",
      "472:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 58.8s\n",
      "473:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 58.6s\n",
      "474:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 58.4s\n",
      "475:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 58.2s\n",
      "476:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 58.1s\n",
      "477:\tlearn: 0.9998482\ttotal: 1m 25s\tremaining: 57.9s\n",
      "478:\tlearn: 0.9998482\ttotal: 1m 26s\tremaining: 57.7s\n",
      "479:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57.5s\n",
      "480:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57.4s\n",
      "481:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57.2s\n",
      "482:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57s\n",
      "483:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.8s\n",
      "484:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.6s\n",
      "485:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.5s\n",
      "486:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.3s\n",
      "487:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.1s\n",
      "488:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 55.9s\n",
      "489:\tlearn: 0.9998482\ttotal: 1m 28s\tremaining: 55.7s\n",
      "490:\tlearn: 0.9998482\ttotal: 1m 28s\tremaining: 55.6s\n",
      "491:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.4s\n",
      "492:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.2s\n",
      "493:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55s\n",
      "494:\tlearn: 0.9997976\ttotal: 1m 29s\tremaining: 54.8s\n",
      "495:\tlearn: 0.9997976\ttotal: 1m 29s\tremaining: 54.7s\n",
      "496:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 54.5s\n",
      "497:\tlearn: 0.9998988\ttotal: 1m 29s\tremaining: 54.3s\n",
      "498:\tlearn: 0.9998988\ttotal: 1m 29s\tremaining: 54.1s\n",
      "499:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 53.9s\n",
      "500:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.8s\n",
      "501:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.6s\n",
      "502:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.4s\n",
      "503:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.2s\n",
      "504:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53s\n",
      "505:\tlearn: 0.9998988\ttotal: 1m 30s\tremaining: 52.9s\n",
      "506:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52.7s\n",
      "507:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52.5s\n",
      "508:\tlearn: 0.9998988\ttotal: 1m 31s\tremaining: 52.3s\n",
      "509:\tlearn: 0.9998988\ttotal: 1m 31s\tremaining: 52.1s\n",
      "510:\tlearn: 0.9998988\ttotal: 1m 31s\tremaining: 51.9s\n",
      "511:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 51.8s\n",
      "512:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 51.6s\n",
      "513:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 51.4s\n",
      "514:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 51.2s\n",
      "515:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 51s\n",
      "516:\tlearn: 0.9998988\ttotal: 1m 32s\tremaining: 50.8s\n",
      "517:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 50.7s\n",
      "518:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 50.5s\n",
      "519:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 50.3s\n",
      "520:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 50.1s\n",
      "521:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 49.9s\n",
      "522:\tlearn: 0.9998988\ttotal: 1m 33s\tremaining: 49.7s\n",
      "523:\tlearn: 0.9998988\ttotal: 1m 34s\tremaining: 49.6s\n",
      "524:\tlearn: 0.9998988\ttotal: 1m 34s\tremaining: 49.4s\n",
      "525:\tlearn: 0.9998988\ttotal: 1m 34s\tremaining: 49.2s\n",
      "526:\tlearn: 0.9998988\ttotal: 1m 34s\tremaining: 49s\n",
      "527:\tlearn: 0.9998988\ttotal: 1m 34s\tremaining: 48.9s\n",
      "528:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 48.7s\n",
      "529:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 48.5s\n",
      "530:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 48.3s\n",
      "531:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 48.1s\n",
      "532:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 48s\n",
      "533:\tlearn: 0.9998988\ttotal: 1m 35s\tremaining: 47.8s\n",
      "534:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 47.6s\n",
      "535:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 47.4s\n",
      "536:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47.2s\n",
      "537:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47s\n",
      "538:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.9s\n",
      "539:\tlearn: 0.9998988\ttotal: 1m 36s\tremaining: 46.7s\n",
      "540:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 46.5s\n",
      "541:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 46.3s\n",
      "542:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 46.1s\n",
      "543:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 46s\n",
      "544:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 45.8s\n",
      "545:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45.6s\n",
      "546:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45.4s\n",
      "547:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45.2s\n",
      "548:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45s\n",
      "549:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 44.9s\n",
      "550:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 44.7s\n",
      "551:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 44.5s\n",
      "552:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 44.3s\n",
      "553:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 44.1s\n",
      "554:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 44s\n",
      "555:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 43.8s\n",
      "556:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 43.6s\n",
      "557:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 43.4s\n",
      "558:\tlearn: 0.9999494\ttotal: 1m 40s\tremaining: 43.2s\n",
      "559:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 43.1s\n",
      "560:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 42.9s\n",
      "561:\tlearn: 1.0000000\ttotal: 1m 40s\tremaining: 42.7s\n",
      "562:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 42.5s\n",
      "563:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 42.4s\n",
      "564:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 42.2s\n",
      "565:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 42s\n",
      "566:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 41.8s\n",
      "567:\tlearn: 1.0000000\ttotal: 1m 41s\tremaining: 41.6s\n",
      "568:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 41.4s\n",
      "569:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 41.3s\n",
      "570:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 41.1s\n",
      "571:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 40.9s\n",
      "572:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 40.7s\n",
      "573:\tlearn: 1.0000000\ttotal: 1m 42s\tremaining: 40.5s\n",
      "574:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 40.4s\n",
      "575:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 40.2s\n",
      "576:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 40s\n",
      "577:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 39.8s\n",
      "578:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 39.7s\n",
      "579:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 39.5s\n",
      "580:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 39.3s\n",
      "581:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 39.1s\n",
      "582:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.9s\n",
      "583:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.8s\n",
      "584:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.6s\n",
      "585:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 38.4s\n",
      "586:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 38.2s\n",
      "587:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 38s\n",
      "588:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.9s\n",
      "589:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.7s\n",
      "590:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 37.5s\n",
      "591:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 37.3s\n",
      "592:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 37.1s\n",
      "593:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 37s\n",
      "594:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 36.8s\n",
      "595:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 36.6s\n",
      "596:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 36.4s\n",
      "597:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 36.2s\n",
      "598:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 36.1s\n",
      "599:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.9s\n",
      "600:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.7s\n",
      "601:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.5s\n",
      "602:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 35.3s\n",
      "603:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 35.2s\n",
      "604:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 35s\n",
      "605:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 34.8s\n",
      "606:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 34.6s\n",
      "607:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 34.4s\n",
      "608:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 34.3s\n",
      "609:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 34.1s\n",
      "610:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 33.9s\n",
      "611:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 33.7s\n",
      "612:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 33.5s\n",
      "613:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 33.4s\n",
      "614:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 33.2s\n",
      "615:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 33s\n",
      "616:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 32.8s\n",
      "617:\tlearn: 1.0000000\ttotal: 1m 50s\tremaining: 32.7s\n",
      "618:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 32.5s\n",
      "619:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 32.3s\n",
      "620:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 32.1s\n",
      "621:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 31.9s\n",
      "622:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 31.8s\n",
      "623:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 31.6s\n",
      "624:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 31.4s\n",
      "625:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 31.2s\n",
      "626:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 31s\n",
      "627:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.9s\n",
      "628:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.7s\n",
      "629:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.5s\n",
      "630:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 30.3s\n",
      "631:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 30.1s\n",
      "632:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 30s\n",
      "633:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 29.8s\n",
      "634:\tlearn: 1.0000000\ttotal: 1m 53s\tremaining: 29.6s\n",
      "635:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 29.4s\n",
      "636:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 29.2s\n",
      "637:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 29.1s\n",
      "638:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 28.9s\n",
      "639:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 28.7s\n",
      "640:\tlearn: 1.0000000\ttotal: 1m 54s\tremaining: 28.5s\n",
      "641:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 28.3s\n",
      "642:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 28.2s\n",
      "643:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 28s\n",
      "644:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 27.8s\n",
      "645:\tlearn: 1.0000000\ttotal: 1m 55s\tremaining: 27.6s\n",
      "646:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 27.4s\n",
      "647:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 27.3s\n",
      "648:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 27.1s\n",
      "649:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.9s\n",
      "650:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.7s\n",
      "651:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.5s\n",
      "652:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 26.4s\n",
      "653:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 26.2s\n",
      "654:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 26s\n",
      "655:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 25.8s\n",
      "656:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 25.6s\n",
      "657:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 25.5s\n",
      "658:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 25.3s\n",
      "659:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 25.1s\n",
      "660:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 24.9s\n",
      "661:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 24.8s\n",
      "662:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 24.6s\n",
      "663:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 24.4s\n",
      "664:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 24.2s\n",
      "665:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 24s\n",
      "666:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 23.9s\n",
      "667:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 23.7s\n",
      "668:\tlearn: 1.0000000\ttotal: 1m 59s\tremaining: 23.5s\n",
      "669:\tlearn: 1.0000000\ttotal: 2m\tremaining: 23.3s\n",
      "670:\tlearn: 1.0000000\ttotal: 2m\tremaining: 23.1s\n",
      "671:\tlearn: 1.0000000\ttotal: 2m\tremaining: 23s\n",
      "672:\tlearn: 1.0000000\ttotal: 2m\tremaining: 22.8s\n",
      "673:\tlearn: 1.0000000\ttotal: 2m\tremaining: 22.6s\n",
      "674:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 22.4s\n",
      "675:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 22.2s\n",
      "676:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 22.1s\n",
      "677:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 21.9s\n",
      "678:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 21.7s\n",
      "679:\tlearn: 1.0000000\ttotal: 2m 1s\tremaining: 21.5s\n",
      "680:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 21.3s\n",
      "681:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 21.2s\n",
      "682:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 21s\n",
      "683:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.8s\n",
      "684:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.6s\n",
      "685:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.4s\n",
      "686:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 20.3s\n",
      "687:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 20.1s\n",
      "688:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.9s\n",
      "689:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.7s\n",
      "690:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.5s\n",
      "691:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 19.4s\n",
      "692:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 19.2s\n",
      "693:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 19s\n",
      "694:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.8s\n",
      "695:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.6s\n",
      "696:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.5s\n",
      "697:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 18.3s\n",
      "698:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 18.1s\n",
      "699:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.9s\n",
      "700:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.7s\n",
      "701:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.6s\n",
      "702:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.4s\n",
      "703:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 17.2s\n",
      "704:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 17s\n",
      "705:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.8s\n",
      "706:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.7s\n",
      "707:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.5s\n",
      "708:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 16.3s\n",
      "709:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 16.1s\n",
      "710:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.9s\n",
      "711:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.8s\n",
      "712:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.6s\n",
      "713:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.4s\n",
      "714:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 15.2s\n",
      "715:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 15s\n",
      "716:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.9s\n",
      "717:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.7s\n",
      "718:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.5s\n",
      "719:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.3s\n",
      "720:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 14.2s\n",
      "721:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 14s\n",
      "722:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.8s\n",
      "723:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.6s\n",
      "724:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.4s\n",
      "725:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 13.3s\n",
      "726:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 13.1s\n",
      "727:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.9s\n",
      "728:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.7s\n",
      "729:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.5s\n",
      "730:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.4s\n",
      "731:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 12.2s\n",
      "732:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 12s\n",
      "733:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.8s\n",
      "734:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.6s\n",
      "735:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.5s\n",
      "736:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.3s\n",
      "737:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 11.1s\n",
      "738:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.9s\n",
      "739:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.7s\n",
      "740:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.6s\n",
      "741:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.4s\n",
      "742:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 10.2s\n",
      "743:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 10s\n",
      "744:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.85s\n",
      "745:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.67s\n",
      "746:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.49s\n",
      "747:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.31s\n",
      "748:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 9.13s\n",
      "749:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.95s\n",
      "750:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.77s\n",
      "751:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.59s\n",
      "752:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.41s\n",
      "753:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.23s\n",
      "754:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 8.05s\n",
      "755:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.88s\n",
      "756:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.7s\n",
      "757:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.52s\n",
      "758:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.34s\n",
      "759:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 7.16s\n",
      "760:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.98s\n",
      "761:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.8s\n",
      "762:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.62s\n",
      "763:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.44s\n",
      "764:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.26s\n",
      "765:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 6.09s\n",
      "766:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.91s\n",
      "767:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.73s\n",
      "768:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.55s\n",
      "769:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.37s\n",
      "770:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 5.19s\n",
      "771:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 5.01s\n",
      "772:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.83s\n",
      "773:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.65s\n",
      "774:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.47s\n",
      "775:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.29s\n",
      "776:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 4.12s\n",
      "777:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.94s\n",
      "778:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.76s\n",
      "779:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.58s\n",
      "780:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.4s\n",
      "781:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.22s\n",
      "782:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 3.04s\n",
      "783:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.86s\n",
      "784:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.68s\n",
      "785:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.5s\n",
      "786:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.33s\n",
      "787:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 2.15s\n",
      "788:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.97s\n",
      "789:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.79s\n",
      "790:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.61s\n",
      "791:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.43s\n",
      "792:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.25s\n",
      "793:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 1.07s\n",
      "794:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 895ms\n",
      "795:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 716ms\n",
      "796:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 537ms\n",
      "797:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 358ms\n",
      "798:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 179ms\n",
      "799:\tlearn: 1.0000000\ttotal: 2m 23s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=8, eval_metric=F1, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=0; total time= 2.4min\n",
      "0:\tlearn: 0.6947418\ttotal: 191ms\tremaining: 2m 32s\n",
      "1:\tlearn: 0.7254286\ttotal: 377ms\tremaining: 2m 30s\n",
      "2:\tlearn: 0.7596698\ttotal: 559ms\tremaining: 2m 28s\n",
      "3:\tlearn: 0.7834526\ttotal: 736ms\tremaining: 2m 26s\n",
      "4:\tlearn: 0.7967306\ttotal: 916ms\tremaining: 2m 25s\n",
      "5:\tlearn: 0.8038545\ttotal: 1.09s\tremaining: 2m 24s\n",
      "6:\tlearn: 0.8079375\ttotal: 1.27s\tremaining: 2m 23s\n",
      "7:\tlearn: 0.8177606\ttotal: 1.45s\tremaining: 2m 23s\n",
      "8:\tlearn: 0.8210415\ttotal: 1.64s\tremaining: 2m 23s\n",
      "9:\tlearn: 0.8293628\ttotal: 1.81s\tremaining: 2m 23s\n",
      "10:\tlearn: 0.8325770\ttotal: 1.99s\tremaining: 2m 22s\n",
      "11:\tlearn: 0.8374189\ttotal: 2.17s\tremaining: 2m 22s\n",
      "12:\tlearn: 0.8434846\ttotal: 2.35s\tremaining: 2m 22s\n",
      "13:\tlearn: 0.8475530\ttotal: 2.52s\tremaining: 2m 21s\n",
      "14:\tlearn: 0.8505025\ttotal: 2.7s\tremaining: 2m 21s\n",
      "15:\tlearn: 0.8565072\ttotal: 2.88s\tremaining: 2m 21s\n",
      "16:\tlearn: 0.8607153\ttotal: 3.06s\tremaining: 2m 21s\n",
      "17:\tlearn: 0.8654563\ttotal: 3.24s\tremaining: 2m 20s\n",
      "18:\tlearn: 0.8662734\ttotal: 3.42s\tremaining: 2m 20s\n",
      "19:\tlearn: 0.8706167\ttotal: 3.6s\tremaining: 2m 20s\n",
      "20:\tlearn: 0.8731264\ttotal: 3.79s\tremaining: 2m 20s\n",
      "21:\tlearn: 0.8746976\ttotal: 3.97s\tremaining: 2m 20s\n",
      "22:\tlearn: 0.8747100\ttotal: 4.14s\tremaining: 2m 20s\n",
      "23:\tlearn: 0.8772472\ttotal: 4.33s\tremaining: 2m 19s\n",
      "24:\tlearn: 0.8787644\ttotal: 4.51s\tremaining: 2m 19s\n",
      "25:\tlearn: 0.8804958\ttotal: 4.69s\tremaining: 2m 19s\n",
      "26:\tlearn: 0.8835633\ttotal: 4.87s\tremaining: 2m 19s\n",
      "27:\tlearn: 0.8852967\ttotal: 5.06s\tremaining: 2m 19s\n",
      "28:\tlearn: 0.8865660\ttotal: 5.24s\tremaining: 2m 19s\n",
      "29:\tlearn: 0.8890716\ttotal: 5.42s\tremaining: 2m 19s\n",
      "30:\tlearn: 0.8905025\ttotal: 5.61s\tremaining: 2m 19s\n",
      "31:\tlearn: 0.8914075\ttotal: 5.79s\tremaining: 2m 19s\n",
      "32:\tlearn: 0.8932791\ttotal: 5.98s\tremaining: 2m 18s\n",
      "33:\tlearn: 0.8957566\ttotal: 6.17s\tremaining: 2m 18s\n",
      "34:\tlearn: 0.8968727\ttotal: 6.35s\tremaining: 2m 18s\n",
      "35:\tlearn: 0.8989865\ttotal: 6.54s\tremaining: 2m 18s\n",
      "36:\tlearn: 0.9008188\ttotal: 6.71s\tremaining: 2m 18s\n",
      "37:\tlearn: 0.9029004\ttotal: 6.9s\tremaining: 2m 18s\n",
      "38:\tlearn: 0.9052979\ttotal: 7.08s\tremaining: 2m 18s\n",
      "39:\tlearn: 0.9061969\ttotal: 7.27s\tremaining: 2m 18s\n",
      "40:\tlearn: 0.9069361\ttotal: 7.46s\tremaining: 2m 18s\n",
      "41:\tlearn: 0.9076266\ttotal: 7.63s\tremaining: 2m 17s\n",
      "42:\tlearn: 0.9084029\ttotal: 7.82s\tremaining: 2m 17s\n",
      "43:\tlearn: 0.9101762\ttotal: 8.01s\tremaining: 2m 17s\n",
      "44:\tlearn: 0.9115633\ttotal: 8.19s\tremaining: 2m 17s\n",
      "45:\tlearn: 0.9125431\ttotal: 8.37s\tremaining: 2m 17s\n",
      "46:\tlearn: 0.9138475\ttotal: 8.56s\tremaining: 2m 17s\n",
      "47:\tlearn: 0.9155094\ttotal: 8.74s\tremaining: 2m 16s\n",
      "48:\tlearn: 0.9160958\ttotal: 8.92s\tremaining: 2m 16s\n",
      "49:\tlearn: 0.9173261\ttotal: 9.1s\tremaining: 2m 16s\n",
      "50:\tlearn: 0.9176619\ttotal: 9.28s\tremaining: 2m 16s\n",
      "51:\tlearn: 0.9193650\ttotal: 9.46s\tremaining: 2m 16s\n",
      "52:\tlearn: 0.9199087\ttotal: 9.64s\tremaining: 2m 15s\n",
      "53:\tlearn: 0.9207844\ttotal: 9.82s\tremaining: 2m 15s\n",
      "54:\tlearn: 0.9212109\ttotal: 10s\tremaining: 2m 15s\n",
      "55:\tlearn: 0.9222481\ttotal: 10.2s\tremaining: 2m 15s\n",
      "56:\tlearn: 0.9229575\ttotal: 10.4s\tremaining: 2m 15s\n",
      "57:\tlearn: 0.9243616\ttotal: 10.5s\tremaining: 2m 14s\n",
      "58:\tlearn: 0.9252414\ttotal: 10.7s\tremaining: 2m 14s\n",
      "59:\tlearn: 0.9258667\ttotal: 10.9s\tremaining: 2m 14s\n",
      "60:\tlearn: 0.9268458\ttotal: 11.1s\tremaining: 2m 14s\n",
      "61:\tlearn: 0.9268103\ttotal: 11.3s\tremaining: 2m 14s\n",
      "62:\tlearn: 0.9278711\ttotal: 11.4s\tremaining: 2m 13s\n",
      "63:\tlearn: 0.9290429\ttotal: 11.6s\tremaining: 2m 13s\n",
      "64:\tlearn: 0.9296526\ttotal: 11.8s\tremaining: 2m 13s\n",
      "65:\tlearn: 0.9306162\ttotal: 12s\tremaining: 2m 13s\n",
      "66:\tlearn: 0.9312370\ttotal: 12.2s\tremaining: 2m 12s\n",
      "67:\tlearn: 0.9315202\ttotal: 12.3s\tremaining: 2m 12s\n",
      "68:\tlearn: 0.9328217\ttotal: 12.5s\tremaining: 2m 12s\n",
      "69:\tlearn: 0.9334370\ttotal: 12.7s\tremaining: 2m 12s\n",
      "70:\tlearn: 0.9344931\ttotal: 12.9s\tremaining: 2m 11s\n",
      "71:\tlearn: 0.9351559\ttotal: 13s\tremaining: 2m 11s\n",
      "72:\tlearn: 0.9364578\ttotal: 13.2s\tremaining: 2m 11s\n",
      "73:\tlearn: 0.9378559\ttotal: 13.4s\tremaining: 2m 11s\n",
      "74:\tlearn: 0.9387695\ttotal: 13.6s\tremaining: 2m 11s\n",
      "75:\tlearn: 0.9390660\ttotal: 13.8s\tremaining: 2m 11s\n",
      "76:\tlearn: 0.9398295\ttotal: 13.9s\tremaining: 2m 10s\n",
      "77:\tlearn: 0.9401793\ttotal: 14.1s\tremaining: 2m 10s\n",
      "78:\tlearn: 0.9409472\ttotal: 14.3s\tremaining: 2m 10s\n",
      "79:\tlearn: 0.9410044\ttotal: 14.5s\tremaining: 2m 10s\n",
      "80:\tlearn: 0.9411822\ttotal: 14.7s\tremaining: 2m 10s\n",
      "81:\tlearn: 0.9420311\ttotal: 14.8s\tremaining: 2m 9s\n",
      "82:\tlearn: 0.9435507\ttotal: 15s\tremaining: 2m 9s\n",
      "83:\tlearn: 0.9439517\ttotal: 15.2s\tremaining: 2m 9s\n",
      "84:\tlearn: 0.9451941\ttotal: 15.4s\tremaining: 2m 9s\n",
      "85:\tlearn: 0.9459104\ttotal: 15.5s\tremaining: 2m 9s\n",
      "86:\tlearn: 0.9463729\ttotal: 15.7s\tremaining: 2m 8s\n",
      "87:\tlearn: 0.9465217\ttotal: 15.9s\tremaining: 2m 8s\n",
      "88:\tlearn: 0.9477532\ttotal: 16.1s\tremaining: 2m 8s\n",
      "89:\tlearn: 0.9484415\ttotal: 16.3s\tremaining: 2m 8s\n",
      "90:\tlearn: 0.9490070\ttotal: 16.4s\tremaining: 2m 8s\n",
      "91:\tlearn: 0.9495778\ttotal: 16.6s\tremaining: 2m 7s\n",
      "92:\tlearn: 0.9500000\ttotal: 16.8s\tremaining: 2m 7s\n",
      "93:\tlearn: 0.9515806\ttotal: 17s\tremaining: 2m 7s\n",
      "94:\tlearn: 0.9518596\ttotal: 17.2s\tremaining: 2m 7s\n",
      "95:\tlearn: 0.9523112\ttotal: 17.3s\tremaining: 2m 7s\n",
      "96:\tlearn: 0.9534565\ttotal: 17.5s\tremaining: 2m 6s\n",
      "97:\tlearn: 0.9533213\ttotal: 17.7s\tremaining: 2m 6s\n",
      "98:\tlearn: 0.9537033\ttotal: 17.9s\tremaining: 2m 6s\n",
      "99:\tlearn: 0.9539078\ttotal: 18.1s\tremaining: 2m 6s\n",
      "100:\tlearn: 0.9542477\ttotal: 18.2s\tremaining: 2m 6s\n",
      "101:\tlearn: 0.9546210\ttotal: 18.4s\tremaining: 2m 5s\n",
      "102:\tlearn: 0.9547945\ttotal: 18.6s\tremaining: 2m 5s\n",
      "103:\tlearn: 0.9548835\ttotal: 18.8s\tremaining: 2m 5s\n",
      "104:\tlearn: 0.9558917\ttotal: 18.9s\tremaining: 2m 5s\n",
      "105:\tlearn: 0.9564238\ttotal: 19.1s\tremaining: 2m 5s\n",
      "106:\tlearn: 0.9567560\ttotal: 19.3s\tremaining: 2m 4s\n",
      "107:\tlearn: 0.9576167\ttotal: 19.5s\tremaining: 2m 4s\n",
      "108:\tlearn: 0.9578555\ttotal: 19.7s\tremaining: 2m 4s\n",
      "109:\tlearn: 0.9583292\ttotal: 19.8s\tremaining: 2m 4s\n",
      "110:\tlearn: 0.9589834\ttotal: 20s\tremaining: 2m 4s\n",
      "111:\tlearn: 0.9592387\ttotal: 20.2s\tremaining: 2m 4s\n",
      "112:\tlearn: 0.9596624\ttotal: 20.4s\tremaining: 2m 3s\n",
      "113:\tlearn: 0.9600471\ttotal: 20.5s\tremaining: 2m 3s\n",
      "114:\tlearn: 0.9608719\ttotal: 20.7s\tremaining: 2m 3s\n",
      "115:\tlearn: 0.9610211\ttotal: 20.9s\tremaining: 2m 3s\n",
      "116:\tlearn: 0.9620713\ttotal: 21.1s\tremaining: 2m 3s\n",
      "117:\tlearn: 0.9624060\ttotal: 21.3s\tremaining: 2m 2s\n",
      "118:\tlearn: 0.9625805\ttotal: 21.4s\tremaining: 2m 2s\n",
      "119:\tlearn: 0.9632252\ttotal: 21.6s\tremaining: 2m 2s\n",
      "120:\tlearn: 0.9634110\ttotal: 21.8s\tremaining: 2m 2s\n",
      "121:\tlearn: 0.9642418\ttotal: 22s\tremaining: 2m 2s\n",
      "122:\tlearn: 0.9645669\ttotal: 22.1s\tremaining: 2m 1s\n",
      "123:\tlearn: 0.9650047\ttotal: 22.3s\tremaining: 2m 1s\n",
      "124:\tlearn: 0.9654494\ttotal: 22.5s\tremaining: 2m 1s\n",
      "125:\tlearn: 0.9662302\ttotal: 22.7s\tremaining: 2m 1s\n",
      "126:\tlearn: 0.9665764\ttotal: 22.9s\tremaining: 2m 1s\n",
      "127:\tlearn: 0.9666174\ttotal: 23.1s\tremaining: 2m 1s\n",
      "128:\tlearn: 0.9670525\ttotal: 23.2s\tremaining: 2m\n",
      "129:\tlearn: 0.9670427\ttotal: 23.4s\tremaining: 2m\n",
      "130:\tlearn: 0.9673286\ttotal: 23.6s\tremaining: 2m\n",
      "131:\tlearn: 0.9683878\ttotal: 23.8s\tremaining: 2m\n",
      "132:\tlearn: 0.9687284\ttotal: 24s\tremaining: 2m\n",
      "133:\tlearn: 0.9690752\ttotal: 24.1s\tremaining: 1m 59s\n",
      "134:\tlearn: 0.9692695\ttotal: 24.3s\tremaining: 1m 59s\n",
      "135:\tlearn: 0.9694638\ttotal: 24.5s\tremaining: 1m 59s\n",
      "136:\tlearn: 0.9696671\ttotal: 24.7s\tremaining: 1m 59s\n",
      "137:\tlearn: 0.9698195\ttotal: 24.8s\tremaining: 1m 59s\n",
      "138:\tlearn: 0.9699719\ttotal: 25s\tremaining: 1m 59s\n",
      "139:\tlearn: 0.9706419\ttotal: 25.2s\tremaining: 1m 58s\n",
      "140:\tlearn: 0.9711268\ttotal: 25.4s\tremaining: 1m 58s\n",
      "141:\tlearn: 0.9716571\ttotal: 25.6s\tremaining: 1m 58s\n",
      "142:\tlearn: 0.9718039\ttotal: 25.7s\tremaining: 1m 58s\n",
      "143:\tlearn: 0.9728795\ttotal: 25.9s\tremaining: 1m 58s\n",
      "144:\tlearn: 0.9728742\ttotal: 26.1s\tremaining: 1m 57s\n",
      "145:\tlearn: 0.9734111\ttotal: 26.3s\tremaining: 1m 57s\n",
      "146:\tlearn: 0.9738039\ttotal: 26.5s\tremaining: 1m 57s\n",
      "147:\tlearn: 0.9739027\ttotal: 26.6s\tremaining: 1m 57s\n",
      "148:\tlearn: 0.9742044\ttotal: 26.8s\tremaining: 1m 57s\n",
      "149:\tlearn: 0.9744426\ttotal: 27s\tremaining: 1m 56s\n",
      "150:\tlearn: 0.9745390\ttotal: 27.2s\tremaining: 1m 56s\n",
      "151:\tlearn: 0.9748232\ttotal: 27.4s\tremaining: 1m 56s\n",
      "152:\tlearn: 0.9753660\ttotal: 27.5s\tremaining: 1m 56s\n",
      "153:\tlearn: 0.9758923\ttotal: 27.7s\tremaining: 1m 56s\n",
      "154:\tlearn: 0.9757933\ttotal: 27.9s\tremaining: 1m 56s\n",
      "155:\tlearn: 0.9761846\ttotal: 28.1s\tremaining: 1m 55s\n",
      "156:\tlearn: 0.9764770\ttotal: 28.2s\tremaining: 1m 55s\n",
      "157:\tlearn: 0.9766705\ttotal: 28.4s\tremaining: 1m 55s\n",
      "158:\tlearn: 0.9770160\ttotal: 28.6s\tremaining: 1m 55s\n",
      "159:\tlearn: 0.9773549\ttotal: 28.8s\tremaining: 1m 55s\n",
      "160:\tlearn: 0.9774034\ttotal: 29s\tremaining: 1m 54s\n",
      "161:\tlearn: 0.9774540\ttotal: 29.1s\tremaining: 1m 54s\n",
      "162:\tlearn: 0.9776478\ttotal: 29.3s\tremaining: 1m 54s\n",
      "163:\tlearn: 0.9784280\ttotal: 29.5s\tremaining: 1m 54s\n",
      "164:\tlearn: 0.9784237\ttotal: 29.7s\tremaining: 1m 54s\n",
      "165:\tlearn: 0.9790571\ttotal: 29.8s\tremaining: 1m 53s\n",
      "166:\tlearn: 0.9791057\ttotal: 30s\tremaining: 1m 53s\n",
      "167:\tlearn: 0.9797418\ttotal: 30.2s\tremaining: 1m 53s\n",
      "168:\tlearn: 0.9804253\ttotal: 30.4s\tremaining: 1m 53s\n",
      "169:\tlearn: 0.9804740\ttotal: 30.6s\tremaining: 1m 53s\n",
      "170:\tlearn: 0.9807176\ttotal: 30.7s\tremaining: 1m 53s\n",
      "171:\tlearn: 0.9808639\ttotal: 30.9s\tremaining: 1m 52s\n",
      "172:\tlearn: 0.9809633\ttotal: 31.1s\tremaining: 1m 52s\n",
      "173:\tlearn: 0.9809164\ttotal: 31.3s\tremaining: 1m 52s\n",
      "174:\tlearn: 0.9811602\ttotal: 31.5s\tremaining: 1m 52s\n",
      "175:\tlearn: 0.9811583\ttotal: 31.6s\tremaining: 1m 52s\n",
      "176:\tlearn: 0.9813047\ttotal: 31.8s\tremaining: 1m 52s\n",
      "177:\tlearn: 0.9813535\ttotal: 32s\tremaining: 1m 51s\n",
      "178:\tlearn: 0.9816952\ttotal: 32.2s\tremaining: 1m 51s\n",
      "179:\tlearn: 0.9818399\ttotal: 32.4s\tremaining: 1m 51s\n",
      "180:\tlearn: 0.9819865\ttotal: 32.6s\tremaining: 1m 51s\n",
      "181:\tlearn: 0.9826256\ttotal: 32.7s\tremaining: 1m 51s\n",
      "182:\tlearn: 0.9829209\ttotal: 32.9s\tremaining: 1m 50s\n",
      "183:\tlearn: 0.9829681\ttotal: 33.1s\tremaining: 1m 50s\n",
      "184:\tlearn: 0.9833616\ttotal: 33.3s\tremaining: 1m 50s\n",
      "185:\tlearn: 0.9834089\ttotal: 33.5s\tremaining: 1m 50s\n",
      "186:\tlearn: 0.9836049\ttotal: 33.6s\tremaining: 1m 50s\n",
      "187:\tlearn: 0.9837520\ttotal: 33.8s\tremaining: 1m 50s\n",
      "188:\tlearn: 0.9841935\ttotal: 34s\tremaining: 1m 50s\n",
      "189:\tlearn: 0.9841444\ttotal: 34.2s\tremaining: 1m 49s\n",
      "190:\tlearn: 0.9842441\ttotal: 34.4s\tremaining: 1m 49s\n",
      "191:\tlearn: 0.9848825\ttotal: 34.6s\tremaining: 1m 49s\n",
      "192:\tlearn: 0.9849793\ttotal: 34.8s\tremaining: 1m 49s\n",
      "193:\tlearn: 0.9854725\ttotal: 34.9s\tremaining: 1m 49s\n",
      "194:\tlearn: 0.9855709\ttotal: 35.1s\tremaining: 1m 48s\n",
      "195:\tlearn: 0.9856173\ttotal: 35.3s\tremaining: 1m 48s\n",
      "196:\tlearn: 0.9857664\ttotal: 35.5s\tremaining: 1m 48s\n",
      "197:\tlearn: 0.9860112\ttotal: 35.6s\tremaining: 1m 48s\n",
      "198:\tlearn: 0.9860632\ttotal: 35.8s\tremaining: 1m 48s\n",
      "199:\tlearn: 0.9860632\ttotal: 36s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.9862617\ttotal: 36.2s\tremaining: 1m 47s\n",
      "201:\tlearn: 0.9867560\ttotal: 36.4s\tremaining: 1m 47s\n",
      "202:\tlearn: 0.9872013\ttotal: 36.5s\tremaining: 1m 47s\n",
      "203:\tlearn: 0.9872000\ttotal: 36.7s\tremaining: 1m 47s\n",
      "204:\tlearn: 0.9871000\ttotal: 36.9s\tremaining: 1m 47s\n",
      "205:\tlearn: 0.9873975\ttotal: 37.1s\tremaining: 1m 46s\n",
      "206:\tlearn: 0.9875469\ttotal: 37.2s\tremaining: 1m 46s\n",
      "207:\tlearn: 0.9877951\ttotal: 37.4s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.9878939\ttotal: 37.6s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.9878927\ttotal: 37.8s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.9878433\ttotal: 38s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.9882883\ttotal: 38.1s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.9886853\ttotal: 38.3s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.9886335\ttotal: 38.5s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.9889317\ttotal: 38.7s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.9889802\ttotal: 38.9s\tremaining: 1m 45s\n",
      "216:\tlearn: 0.9895771\ttotal: 39s\tremaining: 1m 44s\n",
      "217:\tlearn: 0.9897259\ttotal: 39.2s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.9897259\ttotal: 39.4s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.9900246\ttotal: 39.6s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.9903224\ttotal: 39.7s\tremaining: 1m 44s\n",
      "221:\tlearn: 0.9905201\ttotal: 39.9s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.9908192\ttotal: 40.1s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.9910181\ttotal: 40.3s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.9910181\ttotal: 40.5s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.9913672\ttotal: 40.7s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.9914667\ttotal: 40.8s\tremaining: 1m 43s\n",
      "227:\tlearn: 0.9915671\ttotal: 41s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.9916667\ttotal: 41.2s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.9917165\ttotal: 41.4s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.9917165\ttotal: 41.6s\tremaining: 1m 42s\n",
      "231:\tlearn: 0.9917165\ttotal: 41.8s\tremaining: 1m 42s\n",
      "232:\tlearn: 0.9917165\ttotal: 41.9s\tremaining: 1m 42s\n",
      "233:\tlearn: 0.9919156\ttotal: 42.1s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.9921149\ttotal: 42.3s\tremaining: 1m 41s\n",
      "235:\tlearn: 0.9923143\ttotal: 42.5s\tremaining: 1m 41s\n",
      "236:\tlearn: 0.9925636\ttotal: 42.6s\tremaining: 1m 41s\n",
      "237:\tlearn: 0.9926134\ttotal: 42.8s\tremaining: 1m 41s\n",
      "238:\tlearn: 0.9928130\ttotal: 43s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.9929128\ttotal: 43.2s\tremaining: 1m 40s\n",
      "240:\tlearn: 0.9931125\ttotal: 43.3s\tremaining: 1m 40s\n",
      "241:\tlearn: 0.9934121\ttotal: 43.5s\tremaining: 1m 40s\n",
      "242:\tlearn: 0.9933129\ttotal: 43.7s\tremaining: 1m 40s\n",
      "243:\tlearn: 0.9936126\ttotal: 43.9s\tremaining: 1m 39s\n",
      "244:\tlearn: 0.9936126\ttotal: 44.1s\tremaining: 1m 39s\n",
      "245:\tlearn: 0.9937626\ttotal: 44.2s\tremaining: 1m 39s\n",
      "246:\tlearn: 0.9938626\ttotal: 44.4s\tremaining: 1m 39s\n",
      "247:\tlearn: 0.9939126\ttotal: 44.6s\tremaining: 1m 39s\n",
      "248:\tlearn: 0.9939626\ttotal: 44.8s\tremaining: 1m 39s\n",
      "249:\tlearn: 0.9939126\ttotal: 45s\tremaining: 1m 38s\n",
      "250:\tlearn: 0.9939626\ttotal: 45.1s\tremaining: 1m 38s\n",
      "251:\tlearn: 0.9940626\ttotal: 45.3s\tremaining: 1m 38s\n",
      "252:\tlearn: 0.9943127\ttotal: 45.5s\tremaining: 1m 38s\n",
      "253:\tlearn: 0.9942627\ttotal: 45.7s\tremaining: 1m 38s\n",
      "254:\tlearn: 0.9941621\ttotal: 45.9s\tremaining: 1m 38s\n",
      "255:\tlearn: 0.9943122\ttotal: 46s\tremaining: 1m 37s\n",
      "256:\tlearn: 0.9945130\ttotal: 46.2s\tremaining: 1m 37s\n",
      "257:\tlearn: 0.9944629\ttotal: 46.4s\tremaining: 1m 37s\n",
      "258:\tlearn: 0.9945130\ttotal: 46.6s\tremaining: 1m 37s\n",
      "259:\tlearn: 0.9947133\ttotal: 46.7s\tremaining: 1m 37s\n",
      "260:\tlearn: 0.9947133\ttotal: 46.9s\tremaining: 1m 36s\n",
      "261:\tlearn: 0.9950139\ttotal: 47.1s\tremaining: 1m 36s\n",
      "262:\tlearn: 0.9951141\ttotal: 47.3s\tremaining: 1m 36s\n",
      "263:\tlearn: 0.9952143\ttotal: 47.5s\tremaining: 1m 36s\n",
      "264:\tlearn: 0.9951642\ttotal: 47.7s\tremaining: 1m 36s\n",
      "265:\tlearn: 0.9954149\ttotal: 47.8s\tremaining: 1m 36s\n",
      "266:\tlearn: 0.9952645\ttotal: 48s\tremaining: 1m 35s\n",
      "267:\tlearn: 0.9953648\ttotal: 48.2s\tremaining: 1m 35s\n",
      "268:\tlearn: 0.9953146\ttotal: 48.4s\tremaining: 1m 35s\n",
      "269:\tlearn: 0.9953146\ttotal: 48.5s\tremaining: 1m 35s\n",
      "270:\tlearn: 0.9955152\ttotal: 48.7s\tremaining: 1m 35s\n",
      "271:\tlearn: 0.9955654\ttotal: 48.9s\tremaining: 1m 34s\n",
      "272:\tlearn: 0.9956658\ttotal: 49.1s\tremaining: 1m 34s\n",
      "273:\tlearn: 0.9956658\ttotal: 49.2s\tremaining: 1m 34s\n",
      "274:\tlearn: 0.9957159\ttotal: 49.4s\tremaining: 1m 34s\n",
      "275:\tlearn: 0.9958665\ttotal: 49.6s\tremaining: 1m 34s\n",
      "276:\tlearn: 0.9956658\ttotal: 49.8s\tremaining: 1m 33s\n",
      "277:\tlearn: 0.9959167\ttotal: 50s\tremaining: 1m 33s\n",
      "278:\tlearn: 0.9960674\ttotal: 50.1s\tremaining: 1m 33s\n",
      "279:\tlearn: 0.9960171\ttotal: 50.3s\tremaining: 1m 33s\n",
      "280:\tlearn: 0.9960674\ttotal: 50.5s\tremaining: 1m 33s\n",
      "281:\tlearn: 0.9961176\ttotal: 50.7s\tremaining: 1m 33s\n",
      "282:\tlearn: 0.9963185\ttotal: 50.8s\tremaining: 1m 32s\n",
      "283:\tlearn: 0.9963185\ttotal: 51s\tremaining: 1m 32s\n",
      "284:\tlearn: 0.9965195\ttotal: 51.2s\tremaining: 1m 32s\n",
      "285:\tlearn: 0.9967206\ttotal: 51.4s\tremaining: 1m 32s\n",
      "286:\tlearn: 0.9967709\ttotal: 51.6s\tremaining: 1m 32s\n",
      "287:\tlearn: 0.9968212\ttotal: 51.7s\tremaining: 1m 31s\n",
      "288:\tlearn: 0.9968715\ttotal: 51.9s\tremaining: 1m 31s\n",
      "289:\tlearn: 0.9971231\ttotal: 52.1s\tremaining: 1m 31s\n",
      "290:\tlearn: 0.9972741\ttotal: 52.3s\tremaining: 1m 31s\n",
      "291:\tlearn: 0.9972741\ttotal: 52.5s\tremaining: 1m 31s\n",
      "292:\tlearn: 0.9972741\ttotal: 52.6s\tremaining: 1m 31s\n",
      "293:\tlearn: 0.9973748\ttotal: 52.8s\tremaining: 1m 30s\n",
      "294:\tlearn: 0.9974755\ttotal: 53s\tremaining: 1m 30s\n",
      "295:\tlearn: 0.9974755\ttotal: 53.2s\tremaining: 1m 30s\n",
      "296:\tlearn: 0.9976266\ttotal: 53.3s\tremaining: 1m 30s\n",
      "297:\tlearn: 0.9976770\ttotal: 53.5s\tremaining: 1m 30s\n",
      "298:\tlearn: 0.9977274\ttotal: 53.7s\tremaining: 1m 29s\n",
      "299:\tlearn: 0.9978786\ttotal: 53.9s\tremaining: 1m 29s\n",
      "300:\tlearn: 0.9978786\ttotal: 54s\tremaining: 1m 29s\n",
      "301:\tlearn: 0.9980802\ttotal: 54.2s\tremaining: 1m 29s\n",
      "302:\tlearn: 0.9979290\ttotal: 54.4s\tremaining: 1m 29s\n",
      "303:\tlearn: 0.9981307\ttotal: 54.6s\tremaining: 1m 29s\n",
      "304:\tlearn: 0.9980802\ttotal: 54.8s\tremaining: 1m 28s\n",
      "305:\tlearn: 0.9981811\ttotal: 54.9s\tremaining: 1m 28s\n",
      "306:\tlearn: 0.9981811\ttotal: 55.1s\tremaining: 1m 28s\n",
      "307:\tlearn: 0.9981811\ttotal: 55.3s\tremaining: 1m 28s\n",
      "308:\tlearn: 0.9981811\ttotal: 55.5s\tremaining: 1m 28s\n",
      "309:\tlearn: 0.9982820\ttotal: 55.7s\tremaining: 1m 27s\n",
      "310:\tlearn: 0.9982820\ttotal: 55.8s\tremaining: 1m 27s\n",
      "311:\tlearn: 0.9983829\ttotal: 56s\tremaining: 1m 27s\n",
      "312:\tlearn: 0.9983324\ttotal: 56.2s\tremaining: 1m 27s\n",
      "313:\tlearn: 0.9983324\ttotal: 56.4s\tremaining: 1m 27s\n",
      "314:\tlearn: 0.9982820\ttotal: 56.5s\tremaining: 1m 27s\n",
      "315:\tlearn: 0.9983324\ttotal: 56.7s\tremaining: 1m 26s\n",
      "316:\tlearn: 0.9983324\ttotal: 56.9s\tremaining: 1m 26s\n",
      "317:\tlearn: 0.9983324\ttotal: 57.1s\tremaining: 1m 26s\n",
      "318:\tlearn: 0.9983829\ttotal: 57.2s\tremaining: 1m 26s\n",
      "319:\tlearn: 0.9983324\ttotal: 57.4s\tremaining: 1m 26s\n",
      "320:\tlearn: 0.9983829\ttotal: 57.6s\tremaining: 1m 25s\n",
      "321:\tlearn: 0.9983829\ttotal: 57.8s\tremaining: 1m 25s\n",
      "322:\tlearn: 0.9983829\ttotal: 57.9s\tremaining: 1m 25s\n",
      "323:\tlearn: 0.9984838\ttotal: 58.1s\tremaining: 1m 25s\n",
      "324:\tlearn: 0.9984838\ttotal: 58.3s\tremaining: 1m 25s\n",
      "325:\tlearn: 0.9986352\ttotal: 58.5s\tremaining: 1m 25s\n",
      "326:\tlearn: 0.9986352\ttotal: 58.7s\tremaining: 1m 24s\n",
      "327:\tlearn: 0.9986352\ttotal: 58.9s\tremaining: 1m 24s\n",
      "328:\tlearn: 0.9986352\ttotal: 59s\tremaining: 1m 24s\n",
      "329:\tlearn: 0.9986857\ttotal: 59.2s\tremaining: 1m 24s\n",
      "330:\tlearn: 0.9987362\ttotal: 59.4s\tremaining: 1m 24s\n",
      "331:\tlearn: 0.9986352\ttotal: 59.6s\tremaining: 1m 23s\n",
      "332:\tlearn: 0.9986857\ttotal: 59.8s\tremaining: 1m 23s\n",
      "333:\tlearn: 0.9985847\ttotal: 59.9s\tremaining: 1m 23s\n",
      "334:\tlearn: 0.9986352\ttotal: 1m\tremaining: 1m 23s\n",
      "335:\tlearn: 0.9986352\ttotal: 1m\tremaining: 1m 23s\n",
      "336:\tlearn: 0.9986351\ttotal: 1m\tremaining: 1m 23s\n",
      "337:\tlearn: 0.9986857\ttotal: 1m\tremaining: 1m 22s\n",
      "338:\tlearn: 0.9986857\ttotal: 1m\tremaining: 1m 22s\n",
      "339:\tlearn: 0.9986855\ttotal: 1m\tremaining: 1m 22s\n",
      "340:\tlearn: 0.9987362\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "341:\tlearn: 0.9988370\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "342:\tlearn: 0.9988370\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "343:\tlearn: 0.9988875\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "344:\tlearn: 0.9989886\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "345:\tlearn: 0.9989382\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "346:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "347:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "348:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "349:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "350:\tlearn: 0.9989887\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "351:\tlearn: 0.9990897\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "352:\tlearn: 0.9990897\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "353:\tlearn: 0.9990897\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "354:\tlearn: 0.9990897\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "355:\tlearn: 0.9990392\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "356:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "357:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "358:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "359:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "360:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "361:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "362:\tlearn: 0.9991402\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "363:\tlearn: 0.9991402\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "364:\tlearn: 0.9991402\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "365:\tlearn: 0.9991402\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "366:\tlearn: 0.9991402\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "367:\tlearn: 0.9991402\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "368:\tlearn: 0.9990896\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "369:\tlearn: 0.9990896\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "370:\tlearn: 0.9990896\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "371:\tlearn: 0.9990896\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "372:\tlearn: 0.9990896\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "373:\tlearn: 0.9990896\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "374:\tlearn: 0.9990896\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "375:\tlearn: 0.9991402\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "376:\tlearn: 0.9991907\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "377:\tlearn: 0.9991907\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "378:\tlearn: 0.9992412\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "379:\tlearn: 0.9992412\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "380:\tlearn: 0.9991907\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "381:\tlearn: 0.9992412\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "382:\tlearn: 0.9992412\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "383:\tlearn: 0.9992412\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "384:\tlearn: 0.9993423\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "385:\tlearn: 0.9992919\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "386:\tlearn: 0.9992918\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "387:\tlearn: 0.9993423\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "388:\tlearn: 0.9993423\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "389:\tlearn: 0.9994435\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "390:\tlearn: 0.9994435\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "391:\tlearn: 0.9995446\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "392:\tlearn: 0.9994940\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "393:\tlearn: 0.9994940\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "394:\tlearn: 0.9994940\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "395:\tlearn: 0.9994435\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "396:\tlearn: 0.9994435\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "397:\tlearn: 0.9994435\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "398:\tlearn: 0.9995446\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "399:\tlearn: 0.9995446\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "400:\tlearn: 0.9995446\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "401:\tlearn: 0.9994941\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "402:\tlearn: 0.9995446\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "403:\tlearn: 0.9995446\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "404:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "405:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "406:\tlearn: 0.9995952\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "407:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "408:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "409:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "410:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "411:\tlearn: 0.9996458\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "412:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "413:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "414:\tlearn: 0.9996458\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "415:\tlearn: 0.9996964\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "416:\tlearn: 0.9996458\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "417:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "418:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "419:\tlearn: 0.9996458\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "420:\tlearn: 0.9996458\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "421:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "422:\tlearn: 0.9996964\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.9997470\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "424:\tlearn: 0.9997470\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "425:\tlearn: 0.9997470\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "426:\tlearn: 0.9997470\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "427:\tlearn: 0.9997470\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "428:\tlearn: 0.9997976\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "429:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "430:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "431:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "432:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "433:\tlearn: 0.9997976\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "434:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "435:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "436:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "437:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "438:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "439:\tlearn: 0.9997976\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "440:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "441:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "442:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "443:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "444:\tlearn: 0.9997976\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "445:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "446:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "447:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "448:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "449:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "450:\tlearn: 0.9997976\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "451:\tlearn: 0.9997976\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "452:\tlearn: 0.9997976\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "453:\tlearn: 0.9997976\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "454:\tlearn: 0.9997976\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "455:\tlearn: 0.9997976\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "456:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "457:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "458:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "459:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "460:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m\n",
      "461:\tlearn: 0.9997976\ttotal: 1m 22s\tremaining: 1m\n",
      "462:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 1m\n",
      "463:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 1m\n",
      "464:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 1m\n",
      "465:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 59.9s\n",
      "466:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 59.7s\n",
      "467:\tlearn: 0.9997976\ttotal: 1m 23s\tremaining: 59.6s\n",
      "468:\tlearn: 0.9997976\ttotal: 1m 24s\tremaining: 59.4s\n",
      "469:\tlearn: 0.9997976\ttotal: 1m 24s\tremaining: 59.2s\n",
      "470:\tlearn: 0.9997976\ttotal: 1m 24s\tremaining: 59s\n",
      "471:\tlearn: 0.9997976\ttotal: 1m 24s\tremaining: 58.8s\n",
      "472:\tlearn: 0.9997976\ttotal: 1m 24s\tremaining: 58.7s\n",
      "473:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 58.5s\n",
      "474:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 58.3s\n",
      "475:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 58.1s\n",
      "476:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 57.9s\n",
      "477:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 57.8s\n",
      "478:\tlearn: 0.9997976\ttotal: 1m 25s\tremaining: 57.6s\n",
      "479:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57.4s\n",
      "480:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57.2s\n",
      "481:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 57s\n",
      "482:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 56.8s\n",
      "483:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 56.7s\n",
      "484:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 56.5s\n",
      "485:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.3s\n",
      "486:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56.1s\n",
      "487:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 56s\n",
      "488:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 55.8s\n",
      "489:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 55.6s\n",
      "490:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.4s\n",
      "491:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.2s\n",
      "492:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.1s\n",
      "493:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 54.9s\n",
      "494:\tlearn: 0.9998482\ttotal: 1m 28s\tremaining: 54.7s\n",
      "495:\tlearn: 0.9998482\ttotal: 1m 28s\tremaining: 54.5s\n",
      "496:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 54.3s\n",
      "497:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 54.1s\n",
      "498:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 54s\n",
      "499:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 53.8s\n",
      "500:\tlearn: 0.9998482\ttotal: 1m 29s\tremaining: 53.6s\n",
      "501:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.4s\n",
      "502:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.2s\n",
      "503:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 53.1s\n",
      "504:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 52.9s\n",
      "505:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 52.7s\n",
      "506:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 52.5s\n",
      "507:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52.3s\n",
      "508:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52.2s\n",
      "509:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52s\n",
      "510:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.8s\n",
      "511:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.6s\n",
      "512:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.4s\n",
      "513:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 51.3s\n",
      "514:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 51.1s\n",
      "515:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.9s\n",
      "516:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.7s\n",
      "517:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.6s\n",
      "518:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 50.4s\n",
      "519:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 50.2s\n",
      "520:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 50s\n",
      "521:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.8s\n",
      "522:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.7s\n",
      "523:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.5s\n",
      "524:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 49.3s\n",
      "525:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 49.1s\n",
      "526:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.9s\n",
      "527:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.8s\n",
      "528:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.6s\n",
      "529:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 48.4s\n",
      "530:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 48.2s\n",
      "531:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 48.1s\n",
      "532:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.9s\n",
      "533:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.7s\n",
      "534:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.5s\n",
      "535:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47.3s\n",
      "536:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47.1s\n",
      "537:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47s\n",
      "538:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.8s\n",
      "539:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.6s\n",
      "540:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.4s\n",
      "541:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 46.2s\n",
      "542:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 46.1s\n",
      "543:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 45.9s\n",
      "544:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 45.7s\n",
      "545:\tlearn: 0.9998988\ttotal: 1m 37s\tremaining: 45.5s\n",
      "546:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45.3s\n",
      "547:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45.2s\n",
      "548:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 45s\n",
      "549:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 44.8s\n",
      "550:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 44.6s\n",
      "551:\tlearn: 0.9998988\ttotal: 1m 38s\tremaining: 44.4s\n",
      "552:\tlearn: 0.9999494\ttotal: 1m 39s\tremaining: 44.3s\n",
      "553:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 44.1s\n",
      "554:\tlearn: 0.9998988\ttotal: 1m 39s\tremaining: 43.9s\n",
      "555:\tlearn: 0.9999494\ttotal: 1m 39s\tremaining: 43.7s\n",
      "556:\tlearn: 0.9999494\ttotal: 1m 39s\tremaining: 43.5s\n",
      "557:\tlearn: 0.9999494\ttotal: 1m 39s\tremaining: 43.4s\n",
      "558:\tlearn: 0.9999494\ttotal: 1m 40s\tremaining: 43.2s\n",
      "559:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 43s\n",
      "560:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 42.8s\n",
      "561:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 42.6s\n",
      "562:\tlearn: 0.9998988\ttotal: 1m 40s\tremaining: 42.5s\n",
      "563:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 42.3s\n",
      "564:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 42.1s\n",
      "565:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 41.9s\n",
      "566:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 41.7s\n",
      "567:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 41.6s\n",
      "568:\tlearn: 0.9998988\ttotal: 1m 41s\tremaining: 41.4s\n",
      "569:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 41.2s\n",
      "570:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 41s\n",
      "571:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 40.8s\n",
      "572:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 40.7s\n",
      "573:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 40.5s\n",
      "574:\tlearn: 0.9998988\ttotal: 1m 42s\tremaining: 40.3s\n",
      "575:\tlearn: 0.9998988\ttotal: 1m 43s\tremaining: 40.1s\n",
      "576:\tlearn: 0.9998988\ttotal: 1m 43s\tremaining: 39.9s\n",
      "577:\tlearn: 0.9999494\ttotal: 1m 43s\tremaining: 39.8s\n",
      "578:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 39.6s\n",
      "579:\tlearn: 1.0000000\ttotal: 1m 43s\tremaining: 39.4s\n",
      "580:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 39.2s\n",
      "581:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 39s\n",
      "582:\tlearn: 0.9999494\ttotal: 1m 44s\tremaining: 38.9s\n",
      "583:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.7s\n",
      "584:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.5s\n",
      "585:\tlearn: 1.0000000\ttotal: 1m 44s\tremaining: 38.3s\n",
      "586:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 38.1s\n",
      "587:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 38s\n",
      "588:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.8s\n",
      "589:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.6s\n",
      "590:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.4s\n",
      "591:\tlearn: 1.0000000\ttotal: 1m 45s\tremaining: 37.2s\n",
      "592:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 37.1s\n",
      "593:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 36.9s\n",
      "594:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 36.7s\n",
      "595:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 36.5s\n",
      "596:\tlearn: 0.9999494\ttotal: 1m 46s\tremaining: 36.3s\n",
      "597:\tlearn: 0.9999494\ttotal: 1m 47s\tremaining: 36.2s\n",
      "598:\tlearn: 0.9999494\ttotal: 1m 47s\tremaining: 36s\n",
      "599:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.8s\n",
      "600:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.6s\n",
      "601:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.4s\n",
      "602:\tlearn: 1.0000000\ttotal: 1m 47s\tremaining: 35.3s\n",
      "603:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 35.1s\n",
      "604:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 34.9s\n",
      "605:\tlearn: 0.9999494\ttotal: 1m 48s\tremaining: 34.7s\n",
      "606:\tlearn: 0.9999494\ttotal: 1m 48s\tremaining: 34.5s\n",
      "607:\tlearn: 1.0000000\ttotal: 1m 48s\tremaining: 34.4s\n",
      "608:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 34.2s\n",
      "609:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 34s\n",
      "610:\tlearn: 1.0000000\ttotal: 1m 49s\tremaining: 33.8s\n",
      "611:\tlearn: 0.9999494\ttotal: 1m 49s\tremaining: 33.6s\n",
      "612:\tlearn: 0.9999494\ttotal: 1m 49s\tremaining: 33.5s\n",
      "613:\tlearn: 0.9999494\ttotal: 1m 49s\tremaining: 33.3s\n",
      "614:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 33.1s\n",
      "615:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 32.9s\n",
      "616:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 32.8s\n",
      "617:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 32.6s\n",
      "618:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 32.4s\n",
      "619:\tlearn: 0.9999494\ttotal: 1m 50s\tremaining: 32.2s\n",
      "620:\tlearn: 0.9999494\ttotal: 1m 51s\tremaining: 32s\n",
      "621:\tlearn: 0.9999494\ttotal: 1m 51s\tremaining: 31.9s\n",
      "622:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 31.7s\n",
      "623:\tlearn: 1.0000000\ttotal: 1m 51s\tremaining: 31.5s\n",
      "624:\tlearn: 0.9999494\ttotal: 1m 51s\tremaining: 31.3s\n",
      "625:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 31.1s\n",
      "626:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 31s\n",
      "627:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.8s\n",
      "628:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.6s\n",
      "629:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.4s\n",
      "630:\tlearn: 1.0000000\ttotal: 1m 52s\tremaining: 30.2s\n",
      "631:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 30.1s\n",
      "632:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 29.9s\n",
      "633:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 29.7s\n",
      "634:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 29.5s\n",
      "635:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 29.3s\n",
      "636:\tlearn: 0.9999494\ttotal: 1m 53s\tremaining: 29.2s\n",
      "637:\tlearn: 0.9999494\ttotal: 1m 54s\tremaining: 29s\n",
      "638:\tlearn: 0.9999494\ttotal: 1m 54s\tremaining: 28.8s\n",
      "639:\tlearn: 0.9999494\ttotal: 1m 54s\tremaining: 28.6s\n",
      "640:\tlearn: 0.9999494\ttotal: 1m 54s\tremaining: 28.4s\n",
      "641:\tlearn: 0.9999494\ttotal: 1m 54s\tremaining: 28.3s\n",
      "642:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 28.1s\n",
      "643:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 27.9s\n",
      "644:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 27.7s\n",
      "645:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 27.5s\n",
      "646:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 27.4s\n",
      "647:\tlearn: 0.9999494\ttotal: 1m 55s\tremaining: 27.2s\n",
      "648:\tlearn: 0.9999494\ttotal: 1m 56s\tremaining: 27s\n",
      "649:\tlearn: 0.9999494\ttotal: 1m 56s\tremaining: 26.8s\n",
      "650:\tlearn: 0.9999494\ttotal: 1m 56s\tremaining: 26.6s\n",
      "651:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.5s\n",
      "652:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.3s\n",
      "653:\tlearn: 1.0000000\ttotal: 1m 56s\tremaining: 26.1s\n",
      "654:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 25.9s\n",
      "655:\tlearn: 0.9999494\ttotal: 1m 57s\tremaining: 25.8s\n",
      "656:\tlearn: 0.9999494\ttotal: 1m 57s\tremaining: 25.6s\n",
      "657:\tlearn: 0.9999494\ttotal: 1m 57s\tremaining: 25.4s\n",
      "658:\tlearn: 1.0000000\ttotal: 1m 57s\tremaining: 25.2s\n",
      "659:\tlearn: 0.9999494\ttotal: 1m 58s\tremaining: 25s\n",
      "660:\tlearn: 0.9999494\ttotal: 1m 58s\tremaining: 24.9s\n",
      "661:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 24.7s\n",
      "662:\tlearn: 0.9999494\ttotal: 1m 58s\tremaining: 24.5s\n",
      "663:\tlearn: 0.9998988\ttotal: 1m 58s\tremaining: 24.3s\n",
      "664:\tlearn: 0.9998988\ttotal: 1m 58s\tremaining: 24.1s\n",
      "665:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 24s\n",
      "666:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 23.8s\n",
      "667:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 23.6s\n",
      "668:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 23.4s\n",
      "669:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 23.2s\n",
      "670:\tlearn: 0.9998988\ttotal: 1m 59s\tremaining: 23.1s\n",
      "671:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.9s\n",
      "672:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.7s\n",
      "673:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.5s\n",
      "674:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.3s\n",
      "675:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.2s\n",
      "676:\tlearn: 0.9998988\ttotal: 2m 1s\tremaining: 22s\n",
      "677:\tlearn: 0.9999494\ttotal: 2m 1s\tremaining: 21.8s\n",
      "678:\tlearn: 0.9998988\ttotal: 2m 1s\tremaining: 21.6s\n",
      "679:\tlearn: 0.9998988\ttotal: 2m 1s\tremaining: 21.5s\n",
      "680:\tlearn: 0.9998988\ttotal: 2m 1s\tremaining: 21.3s\n",
      "681:\tlearn: 0.9998988\ttotal: 2m 1s\tremaining: 21.1s\n",
      "682:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.9s\n",
      "683:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.7s\n",
      "684:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.6s\n",
      "685:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.4s\n",
      "686:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20.2s\n",
      "687:\tlearn: 1.0000000\ttotal: 2m 2s\tremaining: 20s\n",
      "688:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.8s\n",
      "689:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.7s\n",
      "690:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.5s\n",
      "691:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.3s\n",
      "692:\tlearn: 1.0000000\ttotal: 2m 3s\tremaining: 19.1s\n",
      "693:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.9s\n",
      "694:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.8s\n",
      "695:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.6s\n",
      "696:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.4s\n",
      "697:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.2s\n",
      "698:\tlearn: 1.0000000\ttotal: 2m 4s\tremaining: 18.1s\n",
      "699:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.9s\n",
      "700:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.7s\n",
      "701:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.5s\n",
      "702:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.3s\n",
      "703:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17.2s\n",
      "704:\tlearn: 1.0000000\ttotal: 2m 5s\tremaining: 17s\n",
      "705:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.8s\n",
      "706:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.6s\n",
      "707:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.4s\n",
      "708:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.3s\n",
      "709:\tlearn: 1.0000000\ttotal: 2m 6s\tremaining: 16.1s\n",
      "710:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.9s\n",
      "711:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.7s\n",
      "712:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.5s\n",
      "713:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.4s\n",
      "714:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15.2s\n",
      "715:\tlearn: 1.0000000\ttotal: 2m 7s\tremaining: 15s\n",
      "716:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.8s\n",
      "717:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.7s\n",
      "718:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.5s\n",
      "719:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.3s\n",
      "720:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 14.1s\n",
      "721:\tlearn: 1.0000000\ttotal: 2m 8s\tremaining: 13.9s\n",
      "722:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.8s\n",
      "723:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.6s\n",
      "724:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.4s\n",
      "725:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13.2s\n",
      "726:\tlearn: 1.0000000\ttotal: 2m 9s\tremaining: 13s\n",
      "727:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.9s\n",
      "728:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.7s\n",
      "729:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.5s\n",
      "730:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.3s\n",
      "731:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12.1s\n",
      "732:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 12s\n",
      "733:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.8s\n",
      "734:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.6s\n",
      "735:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.4s\n",
      "736:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.3s\n",
      "737:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 11.1s\n",
      "738:\tlearn: 1.0000000\ttotal: 2m 11s\tremaining: 10.9s\n",
      "739:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.7s\n",
      "740:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.5s\n",
      "741:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.4s\n",
      "742:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10.2s\n",
      "743:\tlearn: 1.0000000\ttotal: 2m 12s\tremaining: 10s\n",
      "744:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.82s\n",
      "745:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.64s\n",
      "746:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.46s\n",
      "747:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.29s\n",
      "748:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 9.11s\n",
      "749:\tlearn: 1.0000000\ttotal: 2m 13s\tremaining: 8.93s\n",
      "750:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.75s\n",
      "751:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.57s\n",
      "752:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.39s\n",
      "753:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.21s\n",
      "754:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 8.03s\n",
      "755:\tlearn: 1.0000000\ttotal: 2m 14s\tremaining: 7.86s\n",
      "756:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.68s\n",
      "757:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.5s\n",
      "758:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.32s\n",
      "759:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 7.14s\n",
      "760:\tlearn: 1.0000000\ttotal: 2m 15s\tremaining: 6.96s\n",
      "761:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.78s\n",
      "762:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.6s\n",
      "763:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.43s\n",
      "764:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.25s\n",
      "765:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 6.07s\n",
      "766:\tlearn: 1.0000000\ttotal: 2m 16s\tremaining: 5.89s\n",
      "767:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.71s\n",
      "768:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.53s\n",
      "769:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.36s\n",
      "770:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.18s\n",
      "771:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5s\n",
      "772:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 4.82s\n",
      "773:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.64s\n",
      "774:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.46s\n",
      "775:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.28s\n",
      "776:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.11s\n",
      "777:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 3.93s\n",
      "778:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.75s\n",
      "779:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.57s\n",
      "780:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.39s\n",
      "781:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.21s\n",
      "782:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.03s\n",
      "783:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 2.86s\n",
      "784:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.68s\n",
      "785:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.5s\n",
      "786:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.32s\n",
      "787:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.14s\n",
      "788:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 1.96s\n",
      "789:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.78s\n",
      "790:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.61s\n",
      "791:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.43s\n",
      "792:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.25s\n",
      "793:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.07s\n",
      "794:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 893ms\n",
      "795:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 714ms\n",
      "796:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 536ms\n",
      "797:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 357ms\n",
      "798:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 179ms\n",
      "799:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=8, eval_metric=F1, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=0; total time= 2.4min\n",
      "0:\tlearn: 0.6985932\ttotal: 187ms\tremaining: 2m 29s\n",
      "1:\tlearn: 0.7288062\ttotal: 370ms\tremaining: 2m 27s\n",
      "2:\tlearn: 0.7518504\ttotal: 553ms\tremaining: 2m 26s\n",
      "3:\tlearn: 0.7634716\ttotal: 735ms\tremaining: 2m 26s\n",
      "4:\tlearn: 0.7926974\ttotal: 926ms\tremaining: 2m 27s\n",
      "5:\tlearn: 0.8030846\ttotal: 1.1s\tremaining: 2m 26s\n",
      "6:\tlearn: 0.8095285\ttotal: 1.29s\tremaining: 2m 26s\n",
      "7:\tlearn: 0.8182840\ttotal: 1.47s\tremaining: 2m 25s\n",
      "8:\tlearn: 0.8222830\ttotal: 1.65s\tremaining: 2m 25s\n",
      "9:\tlearn: 0.8262687\ttotal: 1.84s\tremaining: 2m 25s\n",
      "10:\tlearn: 0.8323677\ttotal: 2.02s\tremaining: 2m 24s\n",
      "11:\tlearn: 0.8360823\ttotal: 2.2s\tremaining: 2m 24s\n",
      "12:\tlearn: 0.8422388\ttotal: 2.38s\tremaining: 2m 24s\n",
      "13:\tlearn: 0.8439447\ttotal: 2.56s\tremaining: 2m 23s\n",
      "14:\tlearn: 0.8470990\ttotal: 2.74s\tremaining: 2m 23s\n",
      "15:\tlearn: 0.8518789\ttotal: 2.92s\tremaining: 2m 23s\n",
      "16:\tlearn: 0.8594840\ttotal: 3.1s\tremaining: 2m 22s\n",
      "17:\tlearn: 0.8611666\ttotal: 3.28s\tremaining: 2m 22s\n",
      "18:\tlearn: 0.8641987\ttotal: 3.46s\tremaining: 2m 22s\n",
      "19:\tlearn: 0.8670797\ttotal: 3.63s\tremaining: 2m 21s\n",
      "20:\tlearn: 0.8684339\ttotal: 3.81s\tremaining: 2m 21s\n",
      "21:\tlearn: 0.8682571\ttotal: 3.99s\tremaining: 2m 21s\n",
      "22:\tlearn: 0.8751279\ttotal: 4.17s\tremaining: 2m 20s\n",
      "23:\tlearn: 0.8778801\ttotal: 4.35s\tremaining: 2m 20s\n",
      "24:\tlearn: 0.8788779\ttotal: 4.52s\tremaining: 2m 20s\n",
      "25:\tlearn: 0.8799610\ttotal: 4.7s\tremaining: 2m 19s\n",
      "26:\tlearn: 0.8828715\ttotal: 4.87s\tremaining: 2m 19s\n",
      "27:\tlearn: 0.8870615\ttotal: 5.05s\tremaining: 2m 19s\n",
      "28:\tlearn: 0.8891161\ttotal: 5.24s\tremaining: 2m 19s\n",
      "29:\tlearn: 0.8899056\ttotal: 5.41s\tremaining: 2m 18s\n",
      "30:\tlearn: 0.8922703\ttotal: 5.59s\tremaining: 2m 18s\n",
      "31:\tlearn: 0.8930463\ttotal: 5.77s\tremaining: 2m 18s\n",
      "32:\tlearn: 0.8954992\ttotal: 5.96s\tremaining: 2m 18s\n",
      "33:\tlearn: 0.8956036\ttotal: 6.14s\tremaining: 2m 18s\n",
      "34:\tlearn: 0.8983635\ttotal: 6.32s\tremaining: 2m 18s\n",
      "35:\tlearn: 0.8997037\ttotal: 6.49s\tremaining: 2m 17s\n",
      "36:\tlearn: 0.9008554\ttotal: 6.67s\tremaining: 2m 17s\n",
      "37:\tlearn: 0.9028399\ttotal: 6.86s\tremaining: 2m 17s\n",
      "38:\tlearn: 0.9044840\ttotal: 7.04s\tremaining: 2m 17s\n",
      "39:\tlearn: 0.9051208\ttotal: 7.22s\tremaining: 2m 17s\n",
      "40:\tlearn: 0.9072787\ttotal: 7.39s\tremaining: 2m 16s\n",
      "41:\tlearn: 0.9088344\ttotal: 7.58s\tremaining: 2m 16s\n",
      "42:\tlearn: 0.9089759\ttotal: 7.76s\tremaining: 2m 16s\n",
      "43:\tlearn: 0.9103462\ttotal: 7.94s\tremaining: 2m 16s\n",
      "44:\tlearn: 0.9108054\ttotal: 8.12s\tremaining: 2m 16s\n",
      "45:\tlearn: 0.9121066\ttotal: 8.3s\tremaining: 2m 16s\n",
      "46:\tlearn: 0.9138661\ttotal: 8.48s\tremaining: 2m 15s\n",
      "47:\tlearn: 0.9145831\ttotal: 8.65s\tremaining: 2m 15s\n",
      "48:\tlearn: 0.9154026\ttotal: 8.83s\tremaining: 2m 15s\n",
      "49:\tlearn: 0.9173473\ttotal: 9.01s\tremaining: 2m 15s\n",
      "50:\tlearn: 0.9181235\ttotal: 9.19s\tremaining: 2m 14s\n",
      "51:\tlearn: 0.9195838\ttotal: 9.37s\tremaining: 2m 14s\n",
      "52:\tlearn: 0.9213571\ttotal: 9.55s\tremaining: 2m 14s\n",
      "53:\tlearn: 0.9224109\ttotal: 9.73s\tremaining: 2m 14s\n",
      "54:\tlearn: 0.9236084\ttotal: 9.91s\tremaining: 2m 14s\n",
      "55:\tlearn: 0.9241621\ttotal: 10.1s\tremaining: 2m 14s\n",
      "56:\tlearn: 0.9244622\ttotal: 10.3s\tremaining: 2m 13s\n",
      "57:\tlearn: 0.9260935\ttotal: 10.4s\tremaining: 2m 13s\n",
      "58:\tlearn: 0.9267487\ttotal: 10.6s\tremaining: 2m 13s\n",
      "59:\tlearn: 0.9283250\ttotal: 10.8s\tremaining: 2m 13s\n",
      "60:\tlearn: 0.9290021\ttotal: 11s\tremaining: 2m 13s\n",
      "61:\tlearn: 0.9298254\ttotal: 11.2s\tremaining: 2m 12s\n",
      "62:\tlearn: 0.9314522\ttotal: 11.4s\tremaining: 2m 12s\n",
      "63:\tlearn: 0.9315628\ttotal: 11.5s\tremaining: 2m 12s\n",
      "64:\tlearn: 0.9325482\ttotal: 11.7s\tremaining: 2m 12s\n",
      "65:\tlearn: 0.9329633\ttotal: 11.9s\tremaining: 2m 12s\n",
      "66:\tlearn: 0.9343265\ttotal: 12.1s\tremaining: 2m 12s\n",
      "67:\tlearn: 0.9348017\ttotal: 12.3s\tremaining: 2m 12s\n",
      "68:\tlearn: 0.9355295\ttotal: 12.5s\tremaining: 2m 12s\n",
      "69:\tlearn: 0.9368693\ttotal: 12.7s\tremaining: 2m 12s\n",
      "70:\tlearn: 0.9371924\ttotal: 12.9s\tremaining: 2m 12s\n",
      "71:\tlearn: 0.9374848\ttotal: 13s\tremaining: 2m 11s\n",
      "72:\tlearn: 0.9378140\ttotal: 13.2s\tremaining: 2m 11s\n",
      "73:\tlearn: 0.9389525\ttotal: 13.4s\tremaining: 2m 11s\n",
      "74:\tlearn: 0.9386602\ttotal: 13.6s\tremaining: 2m 11s\n",
      "75:\tlearn: 0.9395947\ttotal: 13.8s\tremaining: 2m 11s\n",
      "76:\tlearn: 0.9404257\ttotal: 14s\tremaining: 2m 11s\n",
      "77:\tlearn: 0.9411364\ttotal: 14.2s\tremaining: 2m 11s\n",
      "78:\tlearn: 0.9423742\ttotal: 14.4s\tremaining: 2m 11s\n",
      "79:\tlearn: 0.9425231\ttotal: 14.5s\tremaining: 2m 10s\n",
      "80:\tlearn: 0.9434514\ttotal: 14.7s\tremaining: 2m 10s\n",
      "81:\tlearn: 0.9442415\ttotal: 14.9s\tremaining: 2m 10s\n",
      "82:\tlearn: 0.9453357\ttotal: 15.1s\tremaining: 2m 10s\n",
      "83:\tlearn: 0.9452382\ttotal: 15.3s\tremaining: 2m 10s\n",
      "84:\tlearn: 0.9465880\ttotal: 15.4s\tremaining: 2m 9s\n",
      "85:\tlearn: 0.9476049\ttotal: 15.6s\tremaining: 2m 9s\n",
      "86:\tlearn: 0.9484486\ttotal: 15.8s\tremaining: 2m 9s\n",
      "87:\tlearn: 0.9483096\ttotal: 16s\tremaining: 2m 9s\n",
      "88:\tlearn: 0.9492056\ttotal: 16.2s\tremaining: 2m 9s\n",
      "89:\tlearn: 0.9495206\ttotal: 16.4s\tremaining: 2m 9s\n",
      "90:\tlearn: 0.9502373\ttotal: 16.5s\tremaining: 2m 8s\n",
      "91:\tlearn: 0.9508902\ttotal: 16.7s\tremaining: 2m 8s\n",
      "92:\tlearn: 0.9512625\ttotal: 16.9s\tremaining: 2m 8s\n",
      "93:\tlearn: 0.9513186\ttotal: 17.1s\tremaining: 2m 8s\n",
      "94:\tlearn: 0.9517282\ttotal: 17.2s\tremaining: 2m 7s\n",
      "95:\tlearn: 0.9521526\ttotal: 17.4s\tremaining: 2m 7s\n",
      "96:\tlearn: 0.9523670\ttotal: 17.6s\tremaining: 2m 7s\n",
      "97:\tlearn: 0.9537753\ttotal: 17.8s\tremaining: 2m 7s\n",
      "98:\tlearn: 0.9545455\ttotal: 18s\tremaining: 2m 7s\n",
      "99:\tlearn: 0.9553965\ttotal: 18.1s\tremaining: 2m 7s\n",
      "100:\tlearn: 0.9559588\ttotal: 18.3s\tremaining: 2m 6s\n",
      "101:\tlearn: 0.9559588\ttotal: 18.5s\tremaining: 2m 6s\n",
      "102:\tlearn: 0.9568458\ttotal: 18.7s\tremaining: 2m 6s\n",
      "103:\tlearn: 0.9571443\ttotal: 18.9s\tremaining: 2m 6s\n",
      "104:\tlearn: 0.9577285\ttotal: 19s\tremaining: 2m 6s\n",
      "105:\tlearn: 0.9583476\ttotal: 19.2s\tremaining: 2m 5s\n",
      "106:\tlearn: 0.9586420\ttotal: 19.4s\tremaining: 2m 5s\n",
      "107:\tlearn: 0.9594502\ttotal: 19.6s\tremaining: 2m 5s\n",
      "108:\tlearn: 0.9601846\ttotal: 19.7s\tremaining: 2m 5s\n",
      "109:\tlearn: 0.9608527\ttotal: 19.9s\tremaining: 2m 4s\n",
      "110:\tlearn: 0.9615800\ttotal: 20.1s\tremaining: 2m 4s\n",
      "111:\tlearn: 0.9614553\ttotal: 20.3s\tremaining: 2m 4s\n",
      "112:\tlearn: 0.9616519\ttotal: 20.5s\tremaining: 2m 4s\n",
      "113:\tlearn: 0.9619693\ttotal: 20.6s\tremaining: 2m 4s\n",
      "114:\tlearn: 0.9627445\ttotal: 20.8s\tremaining: 2m 4s\n",
      "115:\tlearn: 0.9633673\ttotal: 21s\tremaining: 2m 3s\n",
      "116:\tlearn: 0.9635166\ttotal: 21.2s\tremaining: 2m 3s\n",
      "117:\tlearn: 0.9638009\ttotal: 21.4s\tremaining: 2m 3s\n",
      "118:\tlearn: 0.9651506\ttotal: 21.5s\tremaining: 2m 3s\n",
      "119:\tlearn: 0.9660232\ttotal: 21.7s\tremaining: 2m 3s\n",
      "120:\tlearn: 0.9659790\ttotal: 21.9s\tremaining: 2m 2s\n",
      "121:\tlearn: 0.9666929\ttotal: 22.1s\tremaining: 2m 2s\n",
      "122:\tlearn: 0.9673506\ttotal: 22.2s\tremaining: 2m 2s\n",
      "123:\tlearn: 0.9680856\ttotal: 22.4s\tremaining: 2m 2s\n",
      "124:\tlearn: 0.9683722\ttotal: 22.6s\tremaining: 2m 2s\n",
      "125:\tlearn: 0.9684200\ttotal: 22.8s\tremaining: 2m 1s\n",
      "126:\tlearn: 0.9689551\ttotal: 23s\tremaining: 2m 1s\n",
      "127:\tlearn: 0.9692065\ttotal: 23.1s\tremaining: 2m 1s\n",
      "128:\tlearn: 0.9698376\ttotal: 23.3s\tremaining: 2m 1s\n",
      "129:\tlearn: 0.9701817\ttotal: 23.5s\tremaining: 2m 1s\n",
      "130:\tlearn: 0.9705650\ttotal: 23.7s\tremaining: 2m\n",
      "131:\tlearn: 0.9715755\ttotal: 23.8s\tremaining: 2m\n",
      "132:\tlearn: 0.9715783\ttotal: 24s\tremaining: 2m\n",
      "133:\tlearn: 0.9720670\ttotal: 24.2s\tremaining: 2m\n",
      "134:\tlearn: 0.9726041\ttotal: 24.4s\tremaining: 2m\n",
      "135:\tlearn: 0.9727057\ttotal: 24.5s\tremaining: 1m 59s\n",
      "136:\tlearn: 0.9732377\ttotal: 24.7s\tremaining: 1m 59s\n",
      "137:\tlearn: 0.9732832\ttotal: 24.9s\tremaining: 1m 59s\n",
      "138:\tlearn: 0.9739656\ttotal: 25.1s\tremaining: 1m 59s\n",
      "139:\tlearn: 0.9738640\ttotal: 25.2s\tremaining: 1m 59s\n",
      "140:\tlearn: 0.9743945\ttotal: 25.4s\tremaining: 1m 58s\n",
      "141:\tlearn: 0.9745926\ttotal: 25.6s\tremaining: 1m 58s\n",
      "142:\tlearn: 0.9749306\ttotal: 25.8s\tremaining: 1m 58s\n",
      "143:\tlearn: 0.9749306\ttotal: 26s\tremaining: 1m 58s\n",
      "144:\tlearn: 0.9754647\ttotal: 26.1s\tremaining: 1m 58s\n",
      "145:\tlearn: 0.9756581\ttotal: 26.3s\tremaining: 1m 57s\n",
      "146:\tlearn: 0.9759048\ttotal: 26.5s\tremaining: 1m 57s\n",
      "147:\tlearn: 0.9761999\ttotal: 26.7s\tremaining: 1m 57s\n",
      "148:\tlearn: 0.9767857\ttotal: 26.9s\tremaining: 1m 57s\n",
      "149:\tlearn: 0.9767373\ttotal: 27.1s\tremaining: 1m 57s\n",
      "150:\tlearn: 0.9771227\ttotal: 27.2s\tremaining: 1m 57s\n",
      "151:\tlearn: 0.9776123\ttotal: 27.4s\tremaining: 1m 56s\n",
      "152:\tlearn: 0.9778065\ttotal: 27.6s\tremaining: 1m 56s\n",
      "153:\tlearn: 0.9782943\ttotal: 27.8s\tremaining: 1m 56s\n",
      "154:\tlearn: 0.9783472\ttotal: 27.9s\tremaining: 1m 56s\n",
      "155:\tlearn: 0.9786875\ttotal: 28.1s\tremaining: 1m 56s\n",
      "156:\tlearn: 0.9788841\ttotal: 28.3s\tremaining: 1m 55s\n",
      "157:\tlearn: 0.9791252\ttotal: 28.5s\tremaining: 1m 55s\n",
      "158:\tlearn: 0.9792713\ttotal: 28.7s\tremaining: 1m 55s\n",
      "159:\tlearn: 0.9796629\ttotal: 28.8s\tremaining: 1m 55s\n",
      "160:\tlearn: 0.9798578\ttotal: 29s\tremaining: 1m 55s\n",
      "161:\tlearn: 0.9802010\ttotal: 29.2s\tremaining: 1m 54s\n",
      "162:\tlearn: 0.9804448\ttotal: 29.4s\tremaining: 1m 54s\n",
      "163:\tlearn: 0.9810363\ttotal: 29.5s\tremaining: 1m 54s\n",
      "164:\tlearn: 0.9813801\ttotal: 29.7s\tremaining: 1m 54s\n",
      "165:\tlearn: 0.9818182\ttotal: 29.9s\tremaining: 1m 54s\n",
      "166:\tlearn: 0.9823565\ttotal: 30.1s\tremaining: 1m 54s\n",
      "167:\tlearn: 0.9827010\ttotal: 30.3s\tremaining: 1m 53s\n",
      "168:\tlearn: 0.9829934\ttotal: 30.4s\tremaining: 1m 53s\n",
      "169:\tlearn: 0.9830931\ttotal: 30.6s\tremaining: 1m 53s\n",
      "170:\tlearn: 0.9834397\ttotal: 30.8s\tremaining: 1m 53s\n",
      "171:\tlearn: 0.9837374\ttotal: 31s\tremaining: 1m 53s\n",
      "172:\tlearn: 0.9842284\ttotal: 31.2s\tremaining: 1m 52s\n",
      "173:\tlearn: 0.9844725\ttotal: 31.3s\tremaining: 1m 52s\n",
      "174:\tlearn: 0.9845217\ttotal: 31.5s\tremaining: 1m 52s\n",
      "175:\tlearn: 0.9847229\ttotal: 31.7s\tremaining: 1m 52s\n",
      "176:\tlearn: 0.9849673\ttotal: 31.9s\tremaining: 1m 52s\n",
      "177:\tlearn: 0.9853132\ttotal: 32.1s\tremaining: 1m 52s\n",
      "178:\tlearn: 0.9853639\ttotal: 32.2s\tremaining: 1m 51s\n",
      "179:\tlearn: 0.9856101\ttotal: 32.4s\tremaining: 1m 51s\n",
      "180:\tlearn: 0.9857100\ttotal: 32.6s\tremaining: 1m 51s\n",
      "181:\tlearn: 0.9861535\ttotal: 32.8s\tremaining: 1m 51s\n",
      "182:\tlearn: 0.9864986\ttotal: 32.9s\tremaining: 1m 51s\n",
      "183:\tlearn: 0.9869935\ttotal: 33.1s\tremaining: 1m 50s\n",
      "184:\tlearn: 0.9872392\ttotal: 33.3s\tremaining: 1m 50s\n",
      "185:\tlearn: 0.9875357\ttotal: 33.5s\tremaining: 1m 50s\n",
      "186:\tlearn: 0.9876840\ttotal: 33.6s\tremaining: 1m 50s\n",
      "187:\tlearn: 0.9879820\ttotal: 33.8s\tremaining: 1m 50s\n",
      "188:\tlearn: 0.9883296\ttotal: 34s\tremaining: 1m 49s\n",
      "189:\tlearn: 0.9884274\ttotal: 34.2s\tremaining: 1m 49s\n",
      "190:\tlearn: 0.9886290\ttotal: 34.4s\tremaining: 1m 49s\n",
      "191:\tlearn: 0.9885772\ttotal: 34.5s\tremaining: 1m 49s\n",
      "192:\tlearn: 0.9888260\ttotal: 34.7s\tremaining: 1m 49s\n",
      "193:\tlearn: 0.9887776\ttotal: 34.9s\tremaining: 1m 48s\n",
      "194:\tlearn: 0.9889251\ttotal: 35.1s\tremaining: 1m 48s\n",
      "195:\tlearn: 0.9888237\ttotal: 35.2s\tremaining: 1m 48s\n",
      "196:\tlearn: 0.9890231\ttotal: 35.4s\tremaining: 1m 48s\n",
      "197:\tlearn: 0.9891223\ttotal: 35.6s\tremaining: 1m 48s\n",
      "198:\tlearn: 0.9894188\ttotal: 35.8s\tremaining: 1m 48s\n",
      "199:\tlearn: 0.9895191\ttotal: 36s\tremaining: 1m 47s\n",
      "200:\tlearn: 0.9896194\ttotal: 36.1s\tremaining: 1m 47s\n",
      "201:\tlearn: 0.9894209\ttotal: 36.3s\tremaining: 1m 47s\n",
      "202:\tlearn: 0.9897683\ttotal: 36.5s\tremaining: 1m 47s\n",
      "203:\tlearn: 0.9900662\ttotal: 36.7s\tremaining: 1m 47s\n",
      "204:\tlearn: 0.9901656\ttotal: 36.9s\tremaining: 1m 46s\n",
      "205:\tlearn: 0.9902153\ttotal: 37s\tremaining: 1m 46s\n",
      "206:\tlearn: 0.9904160\ttotal: 37.2s\tremaining: 1m 46s\n",
      "207:\tlearn: 0.9905651\ttotal: 37.4s\tremaining: 1m 46s\n",
      "208:\tlearn: 0.9907142\ttotal: 37.6s\tremaining: 1m 46s\n",
      "209:\tlearn: 0.9905154\ttotal: 37.8s\tremaining: 1m 46s\n",
      "210:\tlearn: 0.9908137\ttotal: 37.9s\tremaining: 1m 45s\n",
      "211:\tlearn: 0.9907640\ttotal: 38.1s\tremaining: 1m 45s\n",
      "212:\tlearn: 0.9909629\ttotal: 38.3s\tremaining: 1m 45s\n",
      "213:\tlearn: 0.9913122\ttotal: 38.5s\tremaining: 1m 45s\n",
      "214:\tlearn: 0.9913629\ttotal: 38.6s\tremaining: 1m 45s\n",
      "215:\tlearn: 0.9915131\ttotal: 38.8s\tremaining: 1m 44s\n",
      "216:\tlearn: 0.9918119\ttotal: 39s\tremaining: 1m 44s\n",
      "217:\tlearn: 0.9918618\ttotal: 39.2s\tremaining: 1m 44s\n",
      "218:\tlearn: 0.9920105\ttotal: 39.3s\tremaining: 1m 44s\n",
      "219:\tlearn: 0.9921600\ttotal: 39.5s\tremaining: 1m 44s\n",
      "220:\tlearn: 0.9922598\ttotal: 39.7s\tremaining: 1m 43s\n",
      "221:\tlearn: 0.9927088\ttotal: 39.9s\tremaining: 1m 43s\n",
      "222:\tlearn: 0.9927595\ttotal: 40s\tremaining: 1m 43s\n",
      "223:\tlearn: 0.9926596\ttotal: 40.2s\tremaining: 1m 43s\n",
      "224:\tlearn: 0.9925591\ttotal: 40.4s\tremaining: 1m 43s\n",
      "225:\tlearn: 0.9928586\ttotal: 40.6s\tremaining: 1m 43s\n",
      "226:\tlearn: 0.9931083\ttotal: 40.8s\tremaining: 1m 42s\n",
      "227:\tlearn: 0.9931083\ttotal: 40.9s\tremaining: 1m 42s\n",
      "228:\tlearn: 0.9932582\ttotal: 41.1s\tremaining: 1m 42s\n",
      "229:\tlearn: 0.9932582\ttotal: 41.3s\tremaining: 1m 42s\n",
      "230:\tlearn: 0.9934088\ttotal: 41.5s\tremaining: 1m 42s\n",
      "231:\tlearn: 0.9935094\ttotal: 41.6s\tremaining: 1m 41s\n",
      "232:\tlearn: 0.9934088\ttotal: 41.8s\tremaining: 1m 41s\n",
      "233:\tlearn: 0.9933088\ttotal: 42s\tremaining: 1m 41s\n",
      "234:\tlearn: 0.9936594\ttotal: 42.2s\tremaining: 1m 41s\n",
      "235:\tlearn: 0.9939101\ttotal: 42.4s\tremaining: 1m 41s\n",
      "236:\tlearn: 0.9939601\ttotal: 42.6s\tremaining: 1m 41s\n",
      "237:\tlearn: 0.9941102\ttotal: 42.8s\tremaining: 1m 40s\n",
      "238:\tlearn: 0.9942604\ttotal: 42.9s\tremaining: 1m 40s\n",
      "239:\tlearn: 0.9944607\ttotal: 43.1s\tremaining: 1m 40s\n",
      "240:\tlearn: 0.9947111\ttotal: 43.3s\tremaining: 1m 40s\n",
      "241:\tlearn: 0.9948113\ttotal: 43.5s\tremaining: 1m 40s\n",
      "242:\tlearn: 0.9949121\ttotal: 43.7s\tremaining: 1m 40s\n",
      "243:\tlearn: 0.9950630\ttotal: 43.9s\tremaining: 1m 39s\n",
      "244:\tlearn: 0.9949627\ttotal: 44.1s\tremaining: 1m 39s\n",
      "245:\tlearn: 0.9950128\ttotal: 44.3s\tremaining: 1m 39s\n",
      "246:\tlearn: 0.9952631\ttotal: 44.4s\tremaining: 1m 39s\n",
      "247:\tlearn: 0.9954642\ttotal: 44.6s\tremaining: 1m 39s\n",
      "248:\tlearn: 0.9956147\ttotal: 44.8s\tremaining: 1m 39s\n",
      "249:\tlearn: 0.9957155\ttotal: 45s\tremaining: 1m 38s\n",
      "250:\tlearn: 0.9955645\ttotal: 45.1s\tremaining: 1m 38s\n",
      "251:\tlearn: 0.9956151\ttotal: 45.3s\tremaining: 1m 38s\n",
      "252:\tlearn: 0.9956653\ttotal: 45.5s\tremaining: 1m 38s\n",
      "253:\tlearn: 0.9955645\ttotal: 45.7s\tremaining: 1m 38s\n",
      "254:\tlearn: 0.9955650\ttotal: 45.9s\tremaining: 1m 38s\n",
      "255:\tlearn: 0.9957657\ttotal: 46s\tremaining: 1m 37s\n",
      "256:\tlearn: 0.9958159\ttotal: 46.2s\tremaining: 1m 37s\n",
      "257:\tlearn: 0.9960167\ttotal: 46.4s\tremaining: 1m 37s\n",
      "258:\tlearn: 0.9960167\ttotal: 46.6s\tremaining: 1m 37s\n",
      "259:\tlearn: 0.9960167\ttotal: 46.7s\tremaining: 1m 37s\n",
      "260:\tlearn: 0.9960167\ttotal: 46.9s\tremaining: 1m 36s\n",
      "261:\tlearn: 0.9960167\ttotal: 47.1s\tremaining: 1m 36s\n",
      "262:\tlearn: 0.9960167\ttotal: 47.3s\tremaining: 1m 36s\n",
      "263:\tlearn: 0.9959665\ttotal: 47.4s\tremaining: 1m 36s\n",
      "264:\tlearn: 0.9960167\ttotal: 47.6s\tremaining: 1m 36s\n",
      "265:\tlearn: 0.9962177\ttotal: 47.8s\tremaining: 1m 35s\n",
      "266:\tlearn: 0.9963684\ttotal: 48s\tremaining: 1m 35s\n",
      "267:\tlearn: 0.9964689\ttotal: 48.2s\tremaining: 1m 35s\n",
      "268:\tlearn: 0.9966201\ttotal: 48.3s\tremaining: 1m 35s\n",
      "269:\tlearn: 0.9966704\ttotal: 48.5s\tremaining: 1m 35s\n",
      "270:\tlearn: 0.9967203\ttotal: 48.7s\tremaining: 1m 35s\n",
      "271:\tlearn: 0.9967203\ttotal: 48.9s\tremaining: 1m 34s\n",
      "272:\tlearn: 0.9966197\ttotal: 49.1s\tremaining: 1m 34s\n",
      "273:\tlearn: 0.9966700\ttotal: 49.2s\tremaining: 1m 34s\n",
      "274:\tlearn: 0.9966700\ttotal: 49.4s\tremaining: 1m 34s\n",
      "275:\tlearn: 0.9968209\ttotal: 49.6s\tremaining: 1m 34s\n",
      "276:\tlearn: 0.9968209\ttotal: 49.8s\tremaining: 1m 33s\n",
      "277:\tlearn: 0.9969218\ttotal: 49.9s\tremaining: 1m 33s\n",
      "278:\tlearn: 0.9968712\ttotal: 50.1s\tremaining: 1m 33s\n",
      "279:\tlearn: 0.9969218\ttotal: 50.3s\tremaining: 1m 33s\n",
      "280:\tlearn: 0.9969218\ttotal: 50.5s\tremaining: 1m 33s\n",
      "281:\tlearn: 0.9969218\ttotal: 50.7s\tremaining: 1m 33s\n",
      "282:\tlearn: 0.9969721\ttotal: 50.8s\tremaining: 1m 32s\n",
      "283:\tlearn: 0.9969721\ttotal: 51s\tremaining: 1m 32s\n",
      "284:\tlearn: 0.9972238\ttotal: 51.2s\tremaining: 1m 32s\n",
      "285:\tlearn: 0.9972238\ttotal: 51.4s\tremaining: 1m 32s\n",
      "286:\tlearn: 0.9972238\ttotal: 51.6s\tremaining: 1m 32s\n",
      "287:\tlearn: 0.9972741\ttotal: 51.7s\tremaining: 1m 31s\n",
      "288:\tlearn: 0.9973244\ttotal: 51.9s\tremaining: 1m 31s\n",
      "289:\tlearn: 0.9973244\ttotal: 52.1s\tremaining: 1m 31s\n",
      "290:\tlearn: 0.9974755\ttotal: 52.3s\tremaining: 1m 31s\n",
      "291:\tlearn: 0.9973748\ttotal: 52.4s\tremaining: 1m 31s\n",
      "292:\tlearn: 0.9973748\ttotal: 52.6s\tremaining: 1m 31s\n",
      "293:\tlearn: 0.9973748\ttotal: 52.8s\tremaining: 1m 30s\n",
      "294:\tlearn: 0.9974755\ttotal: 53s\tremaining: 1m 30s\n",
      "295:\tlearn: 0.9976266\ttotal: 53.1s\tremaining: 1m 30s\n",
      "296:\tlearn: 0.9976266\ttotal: 53.3s\tremaining: 1m 30s\n",
      "297:\tlearn: 0.9976266\ttotal: 53.5s\tremaining: 1m 30s\n",
      "298:\tlearn: 0.9975762\ttotal: 53.7s\tremaining: 1m 29s\n",
      "299:\tlearn: 0.9975762\ttotal: 53.8s\tremaining: 1m 29s\n",
      "300:\tlearn: 0.9975762\ttotal: 54s\tremaining: 1m 29s\n",
      "301:\tlearn: 0.9976770\ttotal: 54.2s\tremaining: 1m 29s\n",
      "302:\tlearn: 0.9977274\ttotal: 54.4s\tremaining: 1m 29s\n",
      "303:\tlearn: 0.9977274\ttotal: 54.6s\tremaining: 1m 29s\n",
      "304:\tlearn: 0.9977274\ttotal: 54.7s\tremaining: 1m 28s\n",
      "305:\tlearn: 0.9977778\ttotal: 54.9s\tremaining: 1m 28s\n",
      "306:\tlearn: 0.9978282\ttotal: 55.1s\tremaining: 1m 28s\n",
      "307:\tlearn: 0.9979794\ttotal: 55.3s\tremaining: 1m 28s\n",
      "308:\tlearn: 0.9980298\ttotal: 55.4s\tremaining: 1m 28s\n",
      "309:\tlearn: 0.9980802\ttotal: 55.6s\tremaining: 1m 27s\n",
      "310:\tlearn: 0.9980802\ttotal: 55.8s\tremaining: 1m 27s\n",
      "311:\tlearn: 0.9982820\ttotal: 56s\tremaining: 1m 27s\n",
      "312:\tlearn: 0.9982820\ttotal: 56.2s\tremaining: 1m 27s\n",
      "313:\tlearn: 0.9982820\ttotal: 56.3s\tremaining: 1m 27s\n",
      "314:\tlearn: 0.9983324\ttotal: 56.5s\tremaining: 1m 27s\n",
      "315:\tlearn: 0.9983829\ttotal: 56.7s\tremaining: 1m 26s\n",
      "316:\tlearn: 0.9983829\ttotal: 56.9s\tremaining: 1m 26s\n",
      "317:\tlearn: 0.9984333\ttotal: 57.1s\tremaining: 1m 26s\n",
      "318:\tlearn: 0.9984333\ttotal: 57.2s\tremaining: 1m 26s\n",
      "319:\tlearn: 0.9984838\ttotal: 57.4s\tremaining: 1m 26s\n",
      "320:\tlearn: 0.9984838\ttotal: 57.6s\tremaining: 1m 25s\n",
      "321:\tlearn: 0.9985847\ttotal: 57.8s\tremaining: 1m 25s\n",
      "322:\tlearn: 0.9986857\ttotal: 57.9s\tremaining: 1m 25s\n",
      "323:\tlearn: 0.9987362\ttotal: 58.1s\tremaining: 1m 25s\n",
      "324:\tlearn: 0.9986857\ttotal: 58.3s\tremaining: 1m 25s\n",
      "325:\tlearn: 0.9986857\ttotal: 58.5s\tremaining: 1m 25s\n",
      "326:\tlearn: 0.9987362\ttotal: 58.6s\tremaining: 1m 24s\n",
      "327:\tlearn: 0.9987867\ttotal: 58.8s\tremaining: 1m 24s\n",
      "328:\tlearn: 0.9988372\ttotal: 59s\tremaining: 1m 24s\n",
      "329:\tlearn: 0.9988372\ttotal: 59.2s\tremaining: 1m 24s\n",
      "330:\tlearn: 0.9988372\ttotal: 59.4s\tremaining: 1m 24s\n",
      "331:\tlearn: 0.9988877\ttotal: 59.5s\tremaining: 1m 23s\n",
      "332:\tlearn: 0.9988877\ttotal: 59.7s\tremaining: 1m 23s\n",
      "333:\tlearn: 0.9988877\ttotal: 59.9s\tremaining: 1m 23s\n",
      "334:\tlearn: 0.9988877\ttotal: 1m\tremaining: 1m 23s\n",
      "335:\tlearn: 0.9989382\ttotal: 1m\tremaining: 1m 23s\n",
      "336:\tlearn: 0.9989382\ttotal: 1m\tremaining: 1m 23s\n",
      "337:\tlearn: 0.9989887\ttotal: 1m\tremaining: 1m 22s\n",
      "338:\tlearn: 0.9989887\ttotal: 1m\tremaining: 1m 22s\n",
      "339:\tlearn: 0.9989887\ttotal: 1m\tremaining: 1m 22s\n",
      "340:\tlearn: 0.9989887\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "341:\tlearn: 0.9990392\ttotal: 1m 1s\tremaining: 1m 22s\n",
      "342:\tlearn: 0.9990897\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "343:\tlearn: 0.9990897\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "344:\tlearn: 0.9990897\ttotal: 1m 1s\tremaining: 1m 21s\n",
      "345:\tlearn: 0.9990897\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "346:\tlearn: 0.9990897\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "347:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 21s\n",
      "348:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "349:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "350:\tlearn: 0.9991908\ttotal: 1m 2s\tremaining: 1m 20s\n",
      "351:\tlearn: 0.9991402\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "352:\tlearn: 0.9991402\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "353:\tlearn: 0.9991402\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "354:\tlearn: 0.9991402\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "355:\tlearn: 0.9991402\ttotal: 1m 3s\tremaining: 1m 19s\n",
      "356:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "357:\tlearn: 0.9991402\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "358:\tlearn: 0.9992413\ttotal: 1m 4s\tremaining: 1m 19s\n",
      "359:\tlearn: 0.9992413\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "360:\tlearn: 0.9992413\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "361:\tlearn: 0.9992413\ttotal: 1m 4s\tremaining: 1m 18s\n",
      "362:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "363:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "364:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 18s\n",
      "365:\tlearn: 0.9992413\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "366:\tlearn: 0.9992919\ttotal: 1m 5s\tremaining: 1m 17s\n",
      "367:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "368:\tlearn: 0.9992919\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "369:\tlearn: 0.9992413\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "370:\tlearn: 0.9993424\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "371:\tlearn: 0.9993424\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "372:\tlearn: 0.9993424\ttotal: 1m 6s\tremaining: 1m 16s\n",
      "373:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "374:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "375:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 16s\n",
      "376:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "377:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "378:\tlearn: 0.9993424\ttotal: 1m 7s\tremaining: 1m 15s\n",
      "379:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "380:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 15s\n",
      "381:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "382:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "383:\tlearn: 0.9993424\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "384:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "385:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "386:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "387:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "388:\tlearn: 0.9993424\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "389:\tlearn: 0.9993930\ttotal: 1m 9s\tremaining: 1m 13s\n",
      "390:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "391:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 13s\n",
      "392:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "393:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "394:\tlearn: 0.9993930\ttotal: 1m 10s\tremaining: 1m 12s\n",
      "395:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "396:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "397:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 12s\n",
      "398:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "399:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "400:\tlearn: 0.9993930\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "401:\tlearn: 0.9993424\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "402:\tlearn: 0.9993424\ttotal: 1m 12s\tremaining: 1m 11s\n",
      "403:\tlearn: 0.9993930\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "404:\tlearn: 0.9994435\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "405:\tlearn: 0.9993930\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "406:\tlearn: 0.9994435\ttotal: 1m 12s\tremaining: 1m 10s\n",
      "407:\tlearn: 0.9994941\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "408:\tlearn: 0.9995446\ttotal: 1m 13s\tremaining: 1m 10s\n",
      "409:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "410:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "411:\tlearn: 0.9995952\ttotal: 1m 13s\tremaining: 1m 9s\n",
      "412:\tlearn: 0.9995446\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "413:\tlearn: 0.9995446\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "414:\tlearn: 0.9995446\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "415:\tlearn: 0.9995446\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "416:\tlearn: 0.9995952\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "417:\tlearn: 0.9995446\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "418:\tlearn: 0.9995446\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "419:\tlearn: 0.9995952\ttotal: 1m 15s\tremaining: 1m 8s\n",
      "420:\tlearn: 0.9995446\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "421:\tlearn: 0.9995446\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "422:\tlearn: 0.9995446\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "423:\tlearn: 0.9995952\ttotal: 1m 15s\tremaining: 1m 7s\n",
      "424:\tlearn: 0.9995952\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "425:\tlearn: 0.9995952\ttotal: 1m 16s\tremaining: 1m 7s\n",
      "426:\tlearn: 0.9995952\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "427:\tlearn: 0.9995952\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "428:\tlearn: 0.9995952\ttotal: 1m 16s\tremaining: 1m 6s\n",
      "429:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "430:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "431:\tlearn: 0.9995446\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "432:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "433:\tlearn: 0.9995952\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "434:\tlearn: 0.9996458\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "435:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "436:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 5s\n",
      "437:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "438:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "439:\tlearn: 0.9996458\ttotal: 1m 18s\tremaining: 1m 4s\n",
      "440:\tlearn: 0.9996458\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "441:\tlearn: 0.9995446\ttotal: 1m 19s\tremaining: 1m 4s\n",
      "442:\tlearn: 0.9995952\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "443:\tlearn: 0.9996458\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "444:\tlearn: 0.9995952\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "445:\tlearn: 0.9995952\ttotal: 1m 19s\tremaining: 1m 3s\n",
      "446:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "447:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "448:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "449:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "450:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "451:\tlearn: 0.9996458\ttotal: 1m 20s\tremaining: 1m 2s\n",
      "452:\tlearn: 0.9996458\ttotal: 1m 21s\tremaining: 1m 2s\n",
      "453:\tlearn: 0.9996458\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "454:\tlearn: 0.9996964\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "455:\tlearn: 0.9996458\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "456:\tlearn: 0.9996458\ttotal: 1m 21s\tremaining: 1m 1s\n",
      "457:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "458:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m 1s\n",
      "459:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m\n",
      "460:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m\n",
      "461:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m\n",
      "462:\tlearn: 0.9997470\ttotal: 1m 22s\tremaining: 1m\n",
      "463:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 1m\n",
      "464:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 1m\n",
      "465:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 59.8s\n",
      "466:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 59.6s\n",
      "467:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 59.5s\n",
      "468:\tlearn: 0.9997470\ttotal: 1m 23s\tremaining: 59.3s\n",
      "469:\tlearn: 0.9997470\ttotal: 1m 24s\tremaining: 59.1s\n",
      "470:\tlearn: 0.9997470\ttotal: 1m 24s\tremaining: 58.9s\n",
      "471:\tlearn: 0.9997470\ttotal: 1m 24s\tremaining: 58.7s\n",
      "472:\tlearn: 0.9997470\ttotal: 1m 24s\tremaining: 58.6s\n",
      "473:\tlearn: 0.9997470\ttotal: 1m 24s\tremaining: 58.4s\n",
      "474:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 58.2s\n",
      "475:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 58s\n",
      "476:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 57.8s\n",
      "477:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 57.7s\n",
      "478:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 57.5s\n",
      "479:\tlearn: 0.9997470\ttotal: 1m 25s\tremaining: 57.3s\n",
      "480:\tlearn: 0.9997470\ttotal: 1m 26s\tremaining: 57.1s\n",
      "481:\tlearn: 0.9997470\ttotal: 1m 26s\tremaining: 56.9s\n",
      "482:\tlearn: 0.9997470\ttotal: 1m 26s\tremaining: 56.8s\n",
      "483:\tlearn: 0.9997976\ttotal: 1m 26s\tremaining: 56.6s\n",
      "484:\tlearn: 0.9997470\ttotal: 1m 26s\tremaining: 56.4s\n",
      "485:\tlearn: 0.9997470\ttotal: 1m 27s\tremaining: 56.2s\n",
      "486:\tlearn: 0.9997470\ttotal: 1m 27s\tremaining: 56.1s\n",
      "487:\tlearn: 0.9997470\ttotal: 1m 27s\tremaining: 55.9s\n",
      "488:\tlearn: 0.9997470\ttotal: 1m 27s\tremaining: 55.7s\n",
      "489:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 55.5s\n",
      "490:\tlearn: 0.9997976\ttotal: 1m 27s\tremaining: 55.3s\n",
      "491:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55.1s\n",
      "492:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 55s\n",
      "493:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 54.8s\n",
      "494:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 54.6s\n",
      "495:\tlearn: 0.9997976\ttotal: 1m 28s\tremaining: 54.4s\n",
      "496:\tlearn: 0.9997470\ttotal: 1m 28s\tremaining: 54.2s\n",
      "497:\tlearn: 0.9997470\ttotal: 1m 29s\tremaining: 54.1s\n",
      "498:\tlearn: 0.9997470\ttotal: 1m 29s\tremaining: 53.9s\n",
      "499:\tlearn: 0.9997976\ttotal: 1m 29s\tremaining: 53.7s\n",
      "500:\tlearn: 0.9997976\ttotal: 1m 29s\tremaining: 53.5s\n",
      "501:\tlearn: 0.9997976\ttotal: 1m 29s\tremaining: 53.4s\n",
      "502:\tlearn: 0.9997976\ttotal: 1m 30s\tremaining: 53.2s\n",
      "503:\tlearn: 0.9997976\ttotal: 1m 30s\tremaining: 53s\n",
      "504:\tlearn: 0.9997976\ttotal: 1m 30s\tremaining: 52.8s\n",
      "505:\tlearn: 0.9997976\ttotal: 1m 30s\tremaining: 52.6s\n",
      "506:\tlearn: 0.9997976\ttotal: 1m 30s\tremaining: 52.5s\n",
      "507:\tlearn: 0.9998482\ttotal: 1m 30s\tremaining: 52.3s\n",
      "508:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 52.1s\n",
      "509:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.9s\n",
      "510:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.7s\n",
      "511:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.6s\n",
      "512:\tlearn: 0.9998482\ttotal: 1m 31s\tremaining: 51.4s\n",
      "513:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 51.2s\n",
      "514:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 51s\n",
      "515:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.8s\n",
      "516:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.7s\n",
      "517:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.5s\n",
      "518:\tlearn: 0.9998482\ttotal: 1m 32s\tremaining: 50.3s\n",
      "519:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 50.1s\n",
      "520:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 50s\n",
      "521:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.8s\n",
      "522:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.6s\n",
      "523:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.4s\n",
      "524:\tlearn: 0.9998482\ttotal: 1m 33s\tremaining: 49.2s\n",
      "525:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 49s\n",
      "526:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.9s\n",
      "527:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.7s\n",
      "528:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.5s\n",
      "529:\tlearn: 0.9998482\ttotal: 1m 34s\tremaining: 48.3s\n",
      "530:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 48.2s\n",
      "531:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 48s\n",
      "532:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.8s\n",
      "533:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.6s\n",
      "534:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.4s\n",
      "535:\tlearn: 0.9998482\ttotal: 1m 35s\tremaining: 47.3s\n",
      "536:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 47.1s\n",
      "537:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.9s\n",
      "538:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.7s\n",
      "539:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.5s\n",
      "540:\tlearn: 0.9998482\ttotal: 1m 36s\tremaining: 46.4s\n",
      "541:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 46.2s\n",
      "542:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 46s\n",
      "543:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 45.8s\n",
      "544:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 45.6s\n",
      "545:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 45.5s\n",
      "546:\tlearn: 0.9998482\ttotal: 1m 37s\tremaining: 45.3s\n",
      "547:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 45.1s\n",
      "548:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 44.9s\n",
      "549:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 44.7s\n",
      "550:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 44.6s\n",
      "551:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 44.4s\n",
      "552:\tlearn: 0.9998482\ttotal: 1m 38s\tremaining: 44.2s\n",
      "553:\tlearn: 0.9998482\ttotal: 1m 39s\tremaining: 44s\n",
      "554:\tlearn: 0.9998482\ttotal: 1m 39s\tremaining: 43.8s\n",
      "555:\tlearn: 0.9998482\ttotal: 1m 39s\tremaining: 43.7s\n",
      "556:\tlearn: 0.9998482\ttotal: 1m 39s\tremaining: 43.5s\n",
      "557:\tlearn: 0.9998482\ttotal: 1m 39s\tremaining: 43.3s\n",
      "558:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 43.1s\n",
      "559:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 42.9s\n",
      "560:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 42.8s\n",
      "561:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 42.6s\n",
      "562:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 42.4s\n",
      "563:\tlearn: 0.9998482\ttotal: 1m 40s\tremaining: 42.2s\n",
      "564:\tlearn: 0.9998482\ttotal: 1m 41s\tremaining: 42.1s\n",
      "565:\tlearn: 0.9998482\ttotal: 1m 41s\tremaining: 41.9s\n",
      "566:\tlearn: 0.9998482\ttotal: 1m 41s\tremaining: 41.7s\n",
      "567:\tlearn: 0.9998482\ttotal: 1m 41s\tremaining: 41.5s\n",
      "568:\tlearn: 0.9998482\ttotal: 1m 41s\tremaining: 41.4s\n",
      "569:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 41.2s\n",
      "570:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 41s\n",
      "571:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 40.8s\n",
      "572:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 40.6s\n",
      "573:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 40.5s\n",
      "574:\tlearn: 0.9998482\ttotal: 1m 42s\tremaining: 40.3s\n",
      "575:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 40.1s\n",
      "576:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 39.9s\n",
      "577:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 39.7s\n",
      "578:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 39.6s\n",
      "579:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 39.4s\n",
      "580:\tlearn: 0.9998482\ttotal: 1m 43s\tremaining: 39.2s\n",
      "581:\tlearn: 0.9998482\ttotal: 1m 44s\tremaining: 39s\n",
      "582:\tlearn: 0.9998482\ttotal: 1m 44s\tremaining: 38.8s\n",
      "583:\tlearn: 0.9998482\ttotal: 1m 44s\tremaining: 38.7s\n",
      "584:\tlearn: 0.9998482\ttotal: 1m 44s\tremaining: 38.5s\n",
      "585:\tlearn: 0.9998482\ttotal: 1m 44s\tremaining: 38.3s\n",
      "586:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 38.1s\n",
      "587:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 37.9s\n",
      "588:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 37.8s\n",
      "589:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 37.6s\n",
      "590:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 37.4s\n",
      "591:\tlearn: 0.9998482\ttotal: 1m 45s\tremaining: 37.2s\n",
      "592:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 37s\n",
      "593:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 36.9s\n",
      "594:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 36.7s\n",
      "595:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 36.5s\n",
      "596:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 36.3s\n",
      "597:\tlearn: 0.9998482\ttotal: 1m 46s\tremaining: 36.1s\n",
      "598:\tlearn: 0.9998988\ttotal: 1m 47s\tremaining: 36s\n",
      "599:\tlearn: 0.9998988\ttotal: 1m 47s\tremaining: 35.8s\n",
      "600:\tlearn: 0.9998988\ttotal: 1m 47s\tremaining: 35.6s\n",
      "601:\tlearn: 0.9998988\ttotal: 1m 47s\tremaining: 35.4s\n",
      "602:\tlearn: 0.9998988\ttotal: 1m 47s\tremaining: 35.2s\n",
      "603:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 35.1s\n",
      "604:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 34.9s\n",
      "605:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 34.7s\n",
      "606:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 34.5s\n",
      "607:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 34.3s\n",
      "608:\tlearn: 0.9998988\ttotal: 1m 48s\tremaining: 34.2s\n",
      "609:\tlearn: 0.9998988\ttotal: 1m 49s\tremaining: 34s\n",
      "610:\tlearn: 0.9998988\ttotal: 1m 49s\tremaining: 33.8s\n",
      "611:\tlearn: 0.9998988\ttotal: 1m 49s\tremaining: 33.6s\n",
      "612:\tlearn: 0.9998988\ttotal: 1m 49s\tremaining: 33.5s\n",
      "613:\tlearn: 0.9998988\ttotal: 1m 49s\tremaining: 33.3s\n",
      "614:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 33.1s\n",
      "615:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 32.9s\n",
      "616:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 32.7s\n",
      "617:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 32.6s\n",
      "618:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 32.4s\n",
      "619:\tlearn: 0.9998988\ttotal: 1m 50s\tremaining: 32.2s\n",
      "620:\tlearn: 0.9998988\ttotal: 1m 51s\tremaining: 32s\n",
      "621:\tlearn: 0.9998988\ttotal: 1m 51s\tremaining: 31.8s\n",
      "622:\tlearn: 0.9998988\ttotal: 1m 51s\tremaining: 31.7s\n",
      "623:\tlearn: 0.9998482\ttotal: 1m 51s\tremaining: 31.5s\n",
      "624:\tlearn: 0.9998482\ttotal: 1m 51s\tremaining: 31.3s\n",
      "625:\tlearn: 0.9998482\ttotal: 1m 51s\tremaining: 31.1s\n",
      "626:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30.9s\n",
      "627:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30.8s\n",
      "628:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30.6s\n",
      "629:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30.4s\n",
      "630:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30.2s\n",
      "631:\tlearn: 0.9998482\ttotal: 1m 52s\tremaining: 30s\n",
      "632:\tlearn: 0.9998482\ttotal: 1m 53s\tremaining: 29.9s\n",
      "633:\tlearn: 0.9998988\ttotal: 1m 53s\tremaining: 29.7s\n",
      "634:\tlearn: 0.9998482\ttotal: 1m 53s\tremaining: 29.5s\n",
      "635:\tlearn: 0.9998988\ttotal: 1m 53s\tremaining: 29.3s\n",
      "636:\tlearn: 0.9998988\ttotal: 1m 53s\tremaining: 29.1s\n",
      "637:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 29s\n",
      "638:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 28.8s\n",
      "639:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 28.6s\n",
      "640:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 28.4s\n",
      "641:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 28.2s\n",
      "642:\tlearn: 0.9998482\ttotal: 1m 54s\tremaining: 28.1s\n",
      "643:\tlearn: 0.9998482\ttotal: 1m 55s\tremaining: 27.9s\n",
      "644:\tlearn: 0.9998482\ttotal: 1m 55s\tremaining: 27.7s\n",
      "645:\tlearn: 0.9998482\ttotal: 1m 55s\tremaining: 27.5s\n",
      "646:\tlearn: 0.9998482\ttotal: 1m 55s\tremaining: 27.4s\n",
      "647:\tlearn: 0.9998482\ttotal: 1m 55s\tremaining: 27.2s\n",
      "648:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 27s\n",
      "649:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 26.8s\n",
      "650:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 26.6s\n",
      "651:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 26.5s\n",
      "652:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 26.3s\n",
      "653:\tlearn: 0.9998482\ttotal: 1m 56s\tremaining: 26.1s\n",
      "654:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25.9s\n",
      "655:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25.7s\n",
      "656:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25.6s\n",
      "657:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25.4s\n",
      "658:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25.2s\n",
      "659:\tlearn: 0.9998482\ttotal: 1m 57s\tremaining: 25s\n",
      "660:\tlearn: 0.9998482\ttotal: 1m 58s\tremaining: 24.9s\n",
      "661:\tlearn: 0.9998482\ttotal: 1m 58s\tremaining: 24.7s\n",
      "662:\tlearn: 0.9998482\ttotal: 1m 58s\tremaining: 24.5s\n",
      "663:\tlearn: 0.9998482\ttotal: 1m 58s\tremaining: 24.3s\n",
      "664:\tlearn: 0.9998988\ttotal: 1m 58s\tremaining: 24.1s\n",
      "665:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 24s\n",
      "666:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 23.8s\n",
      "667:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 23.6s\n",
      "668:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 23.4s\n",
      "669:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 23.2s\n",
      "670:\tlearn: 0.9998482\ttotal: 1m 59s\tremaining: 23.1s\n",
      "671:\tlearn: 0.9998482\ttotal: 2m\tremaining: 22.9s\n",
      "672:\tlearn: 0.9998482\ttotal: 2m\tremaining: 22.7s\n",
      "673:\tlearn: 0.9998482\ttotal: 2m\tremaining: 22.5s\n",
      "674:\tlearn: 0.9998482\ttotal: 2m\tremaining: 22.3s\n",
      "675:\tlearn: 0.9998988\ttotal: 2m\tremaining: 22.2s\n",
      "676:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 22s\n",
      "677:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 21.8s\n",
      "678:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 21.6s\n",
      "679:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 21.5s\n",
      "680:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 21.3s\n",
      "681:\tlearn: 0.9998482\ttotal: 2m 1s\tremaining: 21.1s\n",
      "682:\tlearn: 0.9998482\ttotal: 2m 2s\tremaining: 20.9s\n",
      "683:\tlearn: 0.9998988\ttotal: 2m 2s\tremaining: 20.7s\n",
      "684:\tlearn: 0.9998482\ttotal: 2m 2s\tremaining: 20.6s\n",
      "685:\tlearn: 0.9998482\ttotal: 2m 2s\tremaining: 20.4s\n",
      "686:\tlearn: 0.9998482\ttotal: 2m 2s\tremaining: 20.2s\n",
      "687:\tlearn: 0.9998482\ttotal: 2m 3s\tremaining: 20s\n",
      "688:\tlearn: 0.9998482\ttotal: 2m 3s\tremaining: 19.9s\n",
      "689:\tlearn: 0.9998482\ttotal: 2m 3s\tremaining: 19.7s\n",
      "690:\tlearn: 0.9998482\ttotal: 2m 3s\tremaining: 19.5s\n",
      "691:\tlearn: 0.9998988\ttotal: 2m 3s\tremaining: 19.3s\n",
      "692:\tlearn: 0.9998988\ttotal: 2m 3s\tremaining: 19.1s\n",
      "693:\tlearn: 0.9998988\ttotal: 2m 4s\tremaining: 19s\n",
      "694:\tlearn: 0.9998988\ttotal: 2m 4s\tremaining: 18.8s\n",
      "695:\tlearn: 0.9998988\ttotal: 2m 4s\tremaining: 18.6s\n",
      "696:\tlearn: 0.9998988\ttotal: 2m 4s\tremaining: 18.4s\n",
      "697:\tlearn: 0.9998988\ttotal: 2m 4s\tremaining: 18.2s\n",
      "698:\tlearn: 0.9998988\ttotal: 2m 5s\tremaining: 18.1s\n",
      "699:\tlearn: 0.9998988\ttotal: 2m 5s\tremaining: 17.9s\n",
      "700:\tlearn: 0.9998988\ttotal: 2m 5s\tremaining: 17.7s\n",
      "701:\tlearn: 0.9998988\ttotal: 2m 5s\tremaining: 17.5s\n",
      "702:\tlearn: 0.9998988\ttotal: 2m 5s\tremaining: 17.4s\n",
      "703:\tlearn: 0.9998482\ttotal: 2m 5s\tremaining: 17.2s\n",
      "704:\tlearn: 0.9998482\ttotal: 2m 6s\tremaining: 17s\n",
      "705:\tlearn: 0.9998482\ttotal: 2m 6s\tremaining: 16.8s\n",
      "706:\tlearn: 0.9998482\ttotal: 2m 6s\tremaining: 16.6s\n",
      "707:\tlearn: 0.9998482\ttotal: 2m 6s\tremaining: 16.5s\n",
      "708:\tlearn: 0.9998482\ttotal: 2m 6s\tremaining: 16.3s\n",
      "709:\tlearn: 0.9998482\ttotal: 2m 7s\tremaining: 16.1s\n",
      "710:\tlearn: 0.9998482\ttotal: 2m 7s\tremaining: 15.9s\n",
      "711:\tlearn: 0.9998482\ttotal: 2m 7s\tremaining: 15.8s\n",
      "712:\tlearn: 0.9998988\ttotal: 2m 7s\tremaining: 15.6s\n",
      "713:\tlearn: 0.9998988\ttotal: 2m 7s\tremaining: 15.4s\n",
      "714:\tlearn: 0.9998988\ttotal: 2m 7s\tremaining: 15.2s\n",
      "715:\tlearn: 0.9998482\ttotal: 2m 8s\tremaining: 15s\n",
      "716:\tlearn: 0.9998482\ttotal: 2m 8s\tremaining: 14.9s\n",
      "717:\tlearn: 0.9998988\ttotal: 2m 8s\tremaining: 14.7s\n",
      "718:\tlearn: 0.9998988\ttotal: 2m 8s\tremaining: 14.5s\n",
      "719:\tlearn: 0.9998988\ttotal: 2m 8s\tremaining: 14.3s\n",
      "720:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 14.1s\n",
      "721:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 14s\n",
      "722:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 13.8s\n",
      "723:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 13.6s\n",
      "724:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 13.4s\n",
      "725:\tlearn: 0.9998988\ttotal: 2m 9s\tremaining: 13.2s\n",
      "726:\tlearn: 0.9998988\ttotal: 2m 10s\tremaining: 13.1s\n",
      "727:\tlearn: 0.9998988\ttotal: 2m 10s\tremaining: 12.9s\n",
      "728:\tlearn: 0.9998988\ttotal: 2m 10s\tremaining: 12.7s\n",
      "729:\tlearn: 0.9998988\ttotal: 2m 10s\tremaining: 12.5s\n",
      "730:\tlearn: 0.9998988\ttotal: 2m 10s\tremaining: 12.4s\n",
      "731:\tlearn: 0.9998988\ttotal: 2m 11s\tremaining: 12.2s\n",
      "732:\tlearn: 0.9998988\ttotal: 2m 11s\tremaining: 12s\n",
      "733:\tlearn: 0.9998482\ttotal: 2m 11s\tremaining: 11.8s\n",
      "734:\tlearn: 0.9998482\ttotal: 2m 11s\tremaining: 11.6s\n",
      "735:\tlearn: 0.9998482\ttotal: 2m 11s\tremaining: 11.5s\n",
      "736:\tlearn: 0.9998988\ttotal: 2m 11s\tremaining: 11.3s\n",
      "737:\tlearn: 0.9998988\ttotal: 2m 12s\tremaining: 11.1s\n",
      "738:\tlearn: 0.9998988\ttotal: 2m 12s\tremaining: 10.9s\n",
      "739:\tlearn: 0.9998988\ttotal: 2m 12s\tremaining: 10.7s\n",
      "740:\tlearn: 0.9998988\ttotal: 2m 12s\tremaining: 10.6s\n",
      "741:\tlearn: 0.9998988\ttotal: 2m 12s\tremaining: 10.4s\n",
      "742:\tlearn: 0.9999494\ttotal: 2m 13s\tremaining: 10.2s\n",
      "743:\tlearn: 0.9998988\ttotal: 2m 13s\tremaining: 10s\n",
      "744:\tlearn: 0.9999494\ttotal: 2m 13s\tremaining: 9.85s\n",
      "745:\tlearn: 0.9998988\ttotal: 2m 13s\tremaining: 9.67s\n",
      "746:\tlearn: 0.9998988\ttotal: 2m 13s\tremaining: 9.49s\n",
      "747:\tlearn: 0.9998988\ttotal: 2m 13s\tremaining: 9.31s\n",
      "748:\tlearn: 0.9998988\ttotal: 2m 14s\tremaining: 9.13s\n",
      "749:\tlearn: 0.9998988\ttotal: 2m 14s\tremaining: 8.95s\n",
      "750:\tlearn: 0.9998988\ttotal: 2m 14s\tremaining: 8.77s\n",
      "751:\tlearn: 0.9998988\ttotal: 2m 14s\tremaining: 8.59s\n",
      "752:\tlearn: 0.9998988\ttotal: 2m 14s\tremaining: 8.41s\n",
      "753:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 8.24s\n",
      "754:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 8.06s\n",
      "755:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 7.88s\n",
      "756:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 7.7s\n",
      "757:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 7.52s\n",
      "758:\tlearn: 0.9998988\ttotal: 2m 15s\tremaining: 7.34s\n",
      "759:\tlearn: 0.9998988\ttotal: 2m 16s\tremaining: 7.16s\n",
      "760:\tlearn: 0.9998988\ttotal: 2m 16s\tremaining: 6.98s\n",
      "761:\tlearn: 0.9998988\ttotal: 2m 16s\tremaining: 6.8s\n",
      "762:\tlearn: 0.9999494\ttotal: 2m 16s\tremaining: 6.62s\n",
      "763:\tlearn: 0.9999494\ttotal: 2m 16s\tremaining: 6.45s\n",
      "764:\tlearn: 0.9999494\ttotal: 2m 16s\tremaining: 6.27s\n",
      "765:\tlearn: 0.9999494\ttotal: 2m 17s\tremaining: 6.09s\n",
      "766:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.91s\n",
      "767:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.73s\n",
      "768:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.55s\n",
      "769:\tlearn: 1.0000000\ttotal: 2m 17s\tremaining: 5.37s\n",
      "770:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 5.19s\n",
      "771:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 5.01s\n",
      "772:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.83s\n",
      "773:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.66s\n",
      "774:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.47s\n",
      "775:\tlearn: 1.0000000\ttotal: 2m 18s\tremaining: 4.3s\n",
      "776:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 4.12s\n",
      "777:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.94s\n",
      "778:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.76s\n",
      "779:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.58s\n",
      "780:\tlearn: 1.0000000\ttotal: 2m 19s\tremaining: 3.4s\n",
      "781:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 3.22s\n",
      "782:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 3.04s\n",
      "783:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.86s\n",
      "784:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.69s\n",
      "785:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.51s\n",
      "786:\tlearn: 1.0000000\ttotal: 2m 20s\tremaining: 2.33s\n",
      "787:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 2.15s\n",
      "788:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.97s\n",
      "789:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.79s\n",
      "790:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.61s\n",
      "791:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.43s\n",
      "792:\tlearn: 1.0000000\ttotal: 2m 21s\tremaining: 1.25s\n",
      "793:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 1.07s\n",
      "794:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 895ms\n",
      "795:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 716ms\n",
      "796:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 537ms\n",
      "797:\tlearn: 1.0000000\ttotal: 2m 22s\tremaining: 358ms\n",
      "798:\tlearn: 1.0000000\ttotal: 2m 23s\tremaining: 179ms\n",
      "799:\tlearn: 1.0000000\ttotal: 2m 23s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=8, eval_metric=F1, iterations=800, l2_leaf_reg=7, leaf_estimation_method=Newton, learning_rate=0.1, random_strength=0; total time= 2.4min\n",
      "0:\tlearn: 0.6816643\ttotal: 86.4ms\tremaining: 1m\n",
      "1:\tlearn: 0.6786537\ttotal: 163ms\tremaining: 56.9s\n",
      "2:\tlearn: 0.6821404\ttotal: 243ms\tremaining: 56.5s\n",
      "3:\tlearn: 0.7006168\ttotal: 319ms\tremaining: 55.5s\n",
      "4:\tlearn: 0.7102510\ttotal: 403ms\tremaining: 56s\n",
      "5:\tlearn: 0.7179046\ttotal: 477ms\tremaining: 55.2s\n",
      "6:\tlearn: 0.7186919\ttotal: 552ms\tremaining: 54.6s\n",
      "7:\tlearn: 0.7336295\ttotal: 631ms\tremaining: 54.6s\n",
      "8:\tlearn: 0.7457975\ttotal: 714ms\tremaining: 54.8s\n",
      "9:\tlearn: 0.7484452\ttotal: 798ms\tremaining: 55s\n",
      "10:\tlearn: 0.7495629\ttotal: 872ms\tremaining: 54.6s\n",
      "11:\tlearn: 0.7574063\ttotal: 954ms\tremaining: 54.7s\n",
      "12:\tlearn: 0.7627898\ttotal: 1.04s\tremaining: 54.8s\n",
      "13:\tlearn: 0.7644297\ttotal: 1.12s\tremaining: 54.8s\n",
      "14:\tlearn: 0.7653861\ttotal: 1.2s\tremaining: 54.7s\n",
      "15:\tlearn: 0.7704452\ttotal: 1.27s\tremaining: 54.5s\n",
      "16:\tlearn: 0.7780841\ttotal: 1.35s\tremaining: 54.2s\n",
      "17:\tlearn: 0.7825360\ttotal: 1.42s\tremaining: 53.9s\n",
      "18:\tlearn: 0.7877565\ttotal: 1.5s\tremaining: 53.9s\n",
      "19:\tlearn: 0.7923304\ttotal: 1.58s\tremaining: 53.9s\n",
      "20:\tlearn: 0.7973226\ttotal: 1.66s\tremaining: 53.8s\n",
      "21:\tlearn: 0.7986248\ttotal: 1.74s\tremaining: 53.5s\n",
      "22:\tlearn: 0.8005888\ttotal: 1.81s\tremaining: 53.4s\n",
      "23:\tlearn: 0.8055951\ttotal: 1.9s\tremaining: 53.5s\n",
      "24:\tlearn: 0.8089181\ttotal: 1.98s\tremaining: 53.4s\n",
      "25:\tlearn: 0.8103313\ttotal: 2.06s\tremaining: 53.3s\n",
      "26:\tlearn: 0.8112237\ttotal: 2.14s\tremaining: 53.3s\n",
      "27:\tlearn: 0.8121997\ttotal: 2.21s\tremaining: 53s\n",
      "28:\tlearn: 0.8155349\ttotal: 2.29s\tremaining: 53s\n",
      "29:\tlearn: 0.8174194\ttotal: 2.36s\tremaining: 52.8s\n",
      "30:\tlearn: 0.8173836\ttotal: 2.44s\tremaining: 52.7s\n",
      "31:\tlearn: 0.8192606\ttotal: 2.51s\tremaining: 52.5s\n",
      "32:\tlearn: 0.8223878\ttotal: 2.59s\tremaining: 52.4s\n",
      "33:\tlearn: 0.8230622\ttotal: 2.67s\tremaining: 52.2s\n",
      "34:\tlearn: 0.8260273\ttotal: 2.75s\tremaining: 52.2s\n",
      "35:\tlearn: 0.8265216\ttotal: 2.83s\tremaining: 52.2s\n",
      "36:\tlearn: 0.8285966\ttotal: 2.9s\tremaining: 52s\n",
      "37:\tlearn: 0.8298352\ttotal: 2.98s\tremaining: 51.8s\n",
      "38:\tlearn: 0.8304088\ttotal: 3.05s\tremaining: 51.7s\n",
      "39:\tlearn: 0.8319027\ttotal: 3.13s\tremaining: 51.6s\n",
      "40:\tlearn: 0.8320989\ttotal: 3.2s\tremaining: 51.5s\n",
      "41:\tlearn: 0.8332270\ttotal: 3.29s\tremaining: 51.6s\n",
      "42:\tlearn: 0.8342425\ttotal: 3.37s\tremaining: 51.5s\n",
      "43:\tlearn: 0.8361243\ttotal: 3.45s\tremaining: 51.4s\n",
      "44:\tlearn: 0.8371292\ttotal: 3.53s\tremaining: 51.4s\n",
      "45:\tlearn: 0.8395911\ttotal: 3.61s\tremaining: 51.4s\n",
      "46:\tlearn: 0.8400177\ttotal: 3.69s\tremaining: 51.3s\n",
      "47:\tlearn: 0.8404616\ttotal: 3.77s\tremaining: 51.2s\n",
      "48:\tlearn: 0.8408532\ttotal: 3.85s\tremaining: 51.2s\n",
      "49:\tlearn: 0.8435013\ttotal: 3.94s\tremaining: 51.2s\n",
      "50:\tlearn: 0.8438421\ttotal: 4.02s\tremaining: 51.1s\n",
      "51:\tlearn: 0.8454287\ttotal: 4.09s\tremaining: 50.9s\n",
      "52:\tlearn: 0.8481367\ttotal: 4.16s\tremaining: 50.8s\n",
      "53:\tlearn: 0.8487733\ttotal: 4.25s\tremaining: 50.8s\n",
      "54:\tlearn: 0.8504462\ttotal: 4.33s\tremaining: 50.8s\n",
      "55:\tlearn: 0.8506006\ttotal: 4.41s\tremaining: 50.7s\n",
      "56:\tlearn: 0.8513871\ttotal: 4.48s\tremaining: 50.6s\n",
      "57:\tlearn: 0.8524381\ttotal: 4.56s\tremaining: 50.5s\n",
      "58:\tlearn: 0.8529570\ttotal: 4.64s\tremaining: 50.4s\n",
      "59:\tlearn: 0.8537267\ttotal: 4.72s\tremaining: 50.4s\n",
      "60:\tlearn: 0.8543128\ttotal: 4.81s\tremaining: 50.4s\n",
      "61:\tlearn: 0.8551514\ttotal: 4.89s\tremaining: 50.3s\n",
      "62:\tlearn: 0.8553336\ttotal: 4.97s\tremaining: 50.2s\n",
      "63:\tlearn: 0.8561617\ttotal: 5.04s\tremaining: 50.1s\n",
      "64:\tlearn: 0.8566101\ttotal: 5.12s\tremaining: 50s\n",
      "65:\tlearn: 0.8574795\ttotal: 5.2s\tremaining: 50s\n",
      "66:\tlearn: 0.8569747\ttotal: 5.28s\tremaining: 49.9s\n",
      "67:\tlearn: 0.8571429\ttotal: 5.36s\tremaining: 49.8s\n",
      "68:\tlearn: 0.8578573\ttotal: 5.44s\tremaining: 49.8s\n",
      "69:\tlearn: 0.8591197\ttotal: 5.52s\tremaining: 49.7s\n",
      "70:\tlearn: 0.8599432\ttotal: 5.6s\tremaining: 49.6s\n",
      "71:\tlearn: 0.8608389\ttotal: 5.68s\tremaining: 49.6s\n",
      "72:\tlearn: 0.8613604\ttotal: 5.76s\tremaining: 49.5s\n",
      "73:\tlearn: 0.8613468\ttotal: 5.83s\tremaining: 49.3s\n",
      "74:\tlearn: 0.8633714\ttotal: 5.91s\tremaining: 49.3s\n",
      "75:\tlearn: 0.8644965\ttotal: 5.99s\tremaining: 49.2s\n",
      "76:\tlearn: 0.8655648\ttotal: 6.07s\tremaining: 49.1s\n",
      "77:\tlearn: 0.8650848\ttotal: 6.14s\tremaining: 49s\n",
      "78:\tlearn: 0.8667026\ttotal: 6.22s\tremaining: 48.9s\n",
      "79:\tlearn: 0.8676968\ttotal: 6.3s\tremaining: 48.8s\n",
      "80:\tlearn: 0.8683333\ttotal: 6.37s\tremaining: 48.7s\n",
      "81:\tlearn: 0.8702552\ttotal: 6.45s\tremaining: 48.6s\n",
      "82:\tlearn: 0.8702170\ttotal: 6.53s\tremaining: 48.5s\n",
      "83:\tlearn: 0.8712997\ttotal: 6.61s\tremaining: 48.5s\n",
      "84:\tlearn: 0.8720788\ttotal: 6.68s\tremaining: 48.3s\n",
      "85:\tlearn: 0.8728930\ttotal: 6.76s\tremaining: 48.2s\n",
      "86:\tlearn: 0.8738112\ttotal: 6.83s\tremaining: 48.1s\n",
      "87:\tlearn: 0.8747612\ttotal: 6.91s\tremaining: 48s\n",
      "88:\tlearn: 0.8743995\ttotal: 6.98s\tremaining: 47.9s\n",
      "89:\tlearn: 0.8757542\ttotal: 7.06s\tremaining: 47.8s\n",
      "90:\tlearn: 0.8771758\ttotal: 7.14s\tremaining: 47.8s\n",
      "91:\tlearn: 0.8770279\ttotal: 7.22s\tremaining: 47.7s\n",
      "92:\tlearn: 0.8782664\ttotal: 7.29s\tremaining: 47.6s\n",
      "93:\tlearn: 0.8780464\ttotal: 7.38s\tremaining: 47.6s\n",
      "94:\tlearn: 0.8788087\ttotal: 7.46s\tremaining: 47.5s\n",
      "95:\tlearn: 0.8798275\ttotal: 7.53s\tremaining: 47.4s\n",
      "96:\tlearn: 0.8807133\ttotal: 7.61s\tremaining: 47.3s\n",
      "97:\tlearn: 0.8809046\ttotal: 7.69s\tremaining: 47.2s\n",
      "98:\tlearn: 0.8829667\ttotal: 7.76s\tremaining: 47.1s\n",
      "99:\tlearn: 0.8828573\ttotal: 7.85s\tremaining: 47.1s\n",
      "100:\tlearn: 0.8842157\ttotal: 7.93s\tremaining: 47s\n",
      "101:\tlearn: 0.8854999\ttotal: 8s\tremaining: 46.9s\n",
      "102:\tlearn: 0.8860561\ttotal: 8.08s\tremaining: 46.8s\n",
      "103:\tlearn: 0.8870580\ttotal: 8.15s\tremaining: 46.7s\n",
      "104:\tlearn: 0.8875711\ttotal: 8.23s\tremaining: 46.7s\n",
      "105:\tlearn: 0.8873867\ttotal: 8.31s\tremaining: 46.5s\n",
      "106:\tlearn: 0.8894873\ttotal: 8.38s\tremaining: 46.5s\n",
      "107:\tlearn: 0.8901513\ttotal: 8.46s\tremaining: 46.4s\n",
      "108:\tlearn: 0.8904995\ttotal: 8.54s\tremaining: 46.3s\n",
      "109:\tlearn: 0.8910115\ttotal: 8.61s\tremaining: 46.2s\n",
      "110:\tlearn: 0.8908147\ttotal: 8.68s\tremaining: 46.1s\n",
      "111:\tlearn: 0.8918046\ttotal: 8.75s\tremaining: 46s\n",
      "112:\tlearn: 0.8927732\ttotal: 8.83s\tremaining: 45.9s\n",
      "113:\tlearn: 0.8939253\ttotal: 8.91s\tremaining: 45.8s\n",
      "114:\tlearn: 0.8953471\ttotal: 8.99s\tremaining: 45.7s\n",
      "115:\tlearn: 0.8958935\ttotal: 9.08s\tremaining: 45.7s\n",
      "116:\tlearn: 0.8967578\ttotal: 9.15s\tremaining: 45.6s\n",
      "117:\tlearn: 0.8975915\ttotal: 9.23s\tremaining: 45.5s\n",
      "118:\tlearn: 0.8976894\ttotal: 9.3s\tremaining: 45.4s\n",
      "119:\tlearn: 0.8983748\ttotal: 9.38s\tremaining: 45.3s\n",
      "120:\tlearn: 0.8991490\ttotal: 9.46s\tremaining: 45.3s\n",
      "121:\tlearn: 0.8988797\ttotal: 9.53s\tremaining: 45.2s\n",
      "122:\tlearn: 0.8992756\ttotal: 9.61s\tremaining: 45.1s\n",
      "123:\tlearn: 0.9009697\ttotal: 9.69s\tremaining: 45s\n",
      "124:\tlearn: 0.9012581\ttotal: 9.77s\tremaining: 44.9s\n",
      "125:\tlearn: 0.9017052\ttotal: 9.85s\tremaining: 44.9s\n",
      "126:\tlearn: 0.9021798\ttotal: 9.92s\tremaining: 44.8s\n",
      "127:\tlearn: 0.9028213\ttotal: 10s\tremaining: 44.7s\n",
      "128:\tlearn: 0.9036776\ttotal: 10.1s\tremaining: 44.6s\n",
      "129:\tlearn: 0.9040666\ttotal: 10.2s\tremaining: 44.5s\n",
      "130:\tlearn: 0.9043819\ttotal: 10.2s\tremaining: 44.5s\n",
      "131:\tlearn: 0.9049322\ttotal: 10.3s\tremaining: 44.4s\n",
      "132:\tlearn: 0.9052374\ttotal: 10.4s\tremaining: 44.3s\n",
      "133:\tlearn: 0.9057804\ttotal: 10.5s\tremaining: 44.2s\n",
      "134:\tlearn: 0.9069733\ttotal: 10.5s\tremaining: 44.1s\n",
      "135:\tlearn: 0.9074273\ttotal: 10.6s\tremaining: 44s\n",
      "136:\tlearn: 0.9083884\ttotal: 10.7s\tremaining: 44s\n",
      "137:\tlearn: 0.9092154\ttotal: 10.8s\tremaining: 43.9s\n",
      "138:\tlearn: 0.9099002\ttotal: 10.8s\tremaining: 43.8s\n",
      "139:\tlearn: 0.9101937\ttotal: 10.9s\tremaining: 43.7s\n",
      "140:\tlearn: 0.9110209\ttotal: 11s\tremaining: 43.6s\n",
      "141:\tlearn: 0.9123631\ttotal: 11.1s\tremaining: 43.5s\n",
      "142:\tlearn: 0.9124370\ttotal: 11.2s\tremaining: 43.4s\n",
      "143:\tlearn: 0.9128200\ttotal: 11.2s\tremaining: 43.4s\n",
      "144:\tlearn: 0.9133033\ttotal: 11.3s\tremaining: 43.3s\n",
      "145:\tlearn: 0.9141822\ttotal: 11.4s\tremaining: 43.2s\n",
      "146:\tlearn: 0.9149738\ttotal: 11.5s\tremaining: 43.1s\n",
      "147:\tlearn: 0.9151663\ttotal: 11.5s\tremaining: 43s\n",
      "148:\tlearn: 0.9162875\ttotal: 11.6s\tremaining: 42.9s\n",
      "149:\tlearn: 0.9170990\ttotal: 11.7s\tremaining: 42.9s\n",
      "150:\tlearn: 0.9178243\ttotal: 11.8s\tremaining: 42.8s\n",
      "151:\tlearn: 0.9187656\ttotal: 11.8s\tremaining: 42.7s\n",
      "152:\tlearn: 0.9185910\ttotal: 11.9s\tremaining: 42.6s\n",
      "153:\tlearn: 0.9199530\ttotal: 12s\tremaining: 42.5s\n",
      "154:\tlearn: 0.9209689\ttotal: 12.1s\tremaining: 42.5s\n",
      "155:\tlearn: 0.9206520\ttotal: 12.2s\tremaining: 42.4s\n",
      "156:\tlearn: 0.9212252\ttotal: 12.2s\tremaining: 42.3s\n",
      "157:\tlearn: 0.9219629\ttotal: 12.3s\tremaining: 42.2s\n",
      "158:\tlearn: 0.9220379\ttotal: 12.4s\tremaining: 42.1s\n",
      "159:\tlearn: 0.9220150\ttotal: 12.5s\tremaining: 42.1s\n",
      "160:\tlearn: 0.9227911\ttotal: 12.5s\tremaining: 42s\n",
      "161:\tlearn: 0.9234380\ttotal: 12.6s\tremaining: 41.9s\n",
      "162:\tlearn: 0.9237914\ttotal: 12.7s\tremaining: 41.8s\n",
      "163:\tlearn: 0.9246344\ttotal: 12.8s\tremaining: 41.7s\n",
      "164:\tlearn: 0.9249878\ttotal: 12.8s\tremaining: 41.6s\n",
      "165:\tlearn: 0.9255907\ttotal: 12.9s\tremaining: 41.5s\n",
      "166:\tlearn: 0.9258462\ttotal: 13s\tremaining: 41.5s\n",
      "167:\tlearn: 0.9260274\ttotal: 13.1s\tremaining: 41.4s\n",
      "168:\tlearn: 0.9260419\ttotal: 13.2s\tremaining: 41.4s\n",
      "169:\tlearn: 0.9260582\ttotal: 13.2s\tremaining: 41.3s\n",
      "170:\tlearn: 0.9268030\ttotal: 13.3s\tremaining: 41.2s\n",
      "171:\tlearn: 0.9274639\ttotal: 13.4s\tremaining: 41.1s\n",
      "172:\tlearn: 0.9280892\ttotal: 13.5s\tremaining: 41s\n",
      "173:\tlearn: 0.9284666\ttotal: 13.5s\tremaining: 40.9s\n",
      "174:\tlearn: 0.9287847\ttotal: 13.6s\tremaining: 40.9s\n",
      "175:\tlearn: 0.9291516\ttotal: 13.7s\tremaining: 40.8s\n",
      "176:\tlearn: 0.9296409\ttotal: 13.8s\tremaining: 40.7s\n",
      "177:\tlearn: 0.9305719\ttotal: 13.8s\tremaining: 40.6s\n",
      "178:\tlearn: 0.9306194\ttotal: 13.9s\tremaining: 40.5s\n",
      "179:\tlearn: 0.9307425\ttotal: 14s\tremaining: 40.4s\n",
      "180:\tlearn: 0.9315645\ttotal: 14.1s\tremaining: 40.4s\n",
      "181:\tlearn: 0.9317214\ttotal: 14.2s\tremaining: 40.3s\n",
      "182:\tlearn: 0.9318071\ttotal: 14.2s\tremaining: 40.2s\n",
      "183:\tlearn: 0.9323220\ttotal: 14.3s\tremaining: 40.1s\n",
      "184:\tlearn: 0.9326810\ttotal: 14.4s\tremaining: 40.1s\n",
      "185:\tlearn: 0.9334377\ttotal: 14.5s\tremaining: 40s\n",
      "186:\tlearn: 0.9339207\ttotal: 14.5s\tremaining: 39.9s\n",
      "187:\tlearn: 0.9342344\ttotal: 14.6s\tremaining: 39.8s\n",
      "188:\tlearn: 0.9347315\ttotal: 14.7s\tremaining: 39.7s\n",
      "189:\tlearn: 0.9352088\ttotal: 14.8s\tremaining: 39.7s\n",
      "190:\tlearn: 0.9349593\ttotal: 14.8s\tremaining: 39.6s\n",
      "191:\tlearn: 0.9358328\ttotal: 14.9s\tremaining: 39.5s\n",
      "192:\tlearn: 0.9357744\ttotal: 15s\tremaining: 39.4s\n",
      "193:\tlearn: 0.9360807\ttotal: 15.1s\tremaining: 39.3s\n",
      "194:\tlearn: 0.9366432\ttotal: 15.2s\tremaining: 39.2s\n",
      "195:\tlearn: 0.9372491\ttotal: 15.2s\tremaining: 39.2s\n",
      "196:\tlearn: 0.9375612\ttotal: 15.3s\tremaining: 39.1s\n",
      "197:\tlearn: 0.9375795\ttotal: 15.4s\tremaining: 39s\n",
      "198:\tlearn: 0.9383960\ttotal: 15.5s\tremaining: 38.9s\n",
      "199:\tlearn: 0.9384939\ttotal: 15.5s\tremaining: 38.8s\n",
      "200:\tlearn: 0.9390351\ttotal: 15.6s\tremaining: 38.8s\n",
      "201:\tlearn: 0.9389492\ttotal: 15.7s\tremaining: 38.7s\n",
      "202:\tlearn: 0.9392146\ttotal: 15.8s\tremaining: 38.6s\n",
      "203:\tlearn: 0.9389791\ttotal: 15.8s\tremaining: 38.5s\n",
      "204:\tlearn: 0.9396564\ttotal: 15.9s\tremaining: 38.4s\n",
      "205:\tlearn: 0.9399667\ttotal: 16s\tremaining: 38.3s\n",
      "206:\tlearn: 0.9403818\ttotal: 16.1s\tremaining: 38.2s\n",
      "207:\tlearn: 0.9404855\ttotal: 16.1s\tremaining: 38.2s\n",
      "208:\tlearn: 0.9407850\ttotal: 16.2s\tremaining: 38.1s\n",
      "209:\tlearn: 0.9414758\ttotal: 16.3s\tremaining: 38s\n",
      "210:\tlearn: 0.9421035\ttotal: 16.4s\tremaining: 37.9s\n",
      "211:\tlearn: 0.9427481\ttotal: 16.4s\tremaining: 37.9s\n",
      "212:\tlearn: 0.9431451\ttotal: 16.5s\tremaining: 37.8s\n",
      "213:\tlearn: 0.9427718\ttotal: 16.6s\tremaining: 37.7s\n",
      "214:\tlearn: 0.9436530\ttotal: 16.7s\tremaining: 37.6s\n",
      "215:\tlearn: 0.9439170\ttotal: 16.7s\tremaining: 37.5s\n",
      "216:\tlearn: 0.9445559\ttotal: 16.8s\tremaining: 37.4s\n",
      "217:\tlearn: 0.9444526\ttotal: 16.9s\tremaining: 37.4s\n",
      "218:\tlearn: 0.9447354\ttotal: 17s\tremaining: 37.3s\n",
      "219:\tlearn: 0.9448033\ttotal: 17s\tremaining: 37.2s\n",
      "220:\tlearn: 0.9451023\ttotal: 17.1s\tremaining: 37.1s\n",
      "221:\tlearn: 0.9453905\ttotal: 17.2s\tremaining: 37s\n",
      "222:\tlearn: 0.9457463\ttotal: 17.3s\tremaining: 36.9s\n",
      "223:\tlearn: 0.9462660\ttotal: 17.3s\tremaining: 36.8s\n",
      "224:\tlearn: 0.9464565\ttotal: 17.4s\tremaining: 36.8s\n",
      "225:\tlearn: 0.9468429\ttotal: 17.5s\tremaining: 36.7s\n",
      "226:\tlearn: 0.9472345\ttotal: 17.6s\tremaining: 36.6s\n",
      "227:\tlearn: 0.9470798\ttotal: 17.6s\tremaining: 36.5s\n",
      "228:\tlearn: 0.9473633\ttotal: 17.7s\tremaining: 36.4s\n",
      "229:\tlearn: 0.9479457\ttotal: 17.8s\tremaining: 36.3s\n",
      "230:\tlearn: 0.9484152\ttotal: 17.9s\tremaining: 36.3s\n",
      "231:\tlearn: 0.9484566\ttotal: 17.9s\tremaining: 36.2s\n",
      "232:\tlearn: 0.9485810\ttotal: 18s\tremaining: 36.1s\n",
      "233:\tlearn: 0.9487205\ttotal: 18.1s\tremaining: 36s\n",
      "234:\tlearn: 0.9491642\ttotal: 18.2s\tremaining: 35.9s\n",
      "235:\tlearn: 0.9496297\ttotal: 18.2s\tremaining: 35.9s\n",
      "236:\tlearn: 0.9498138\ttotal: 18.3s\tremaining: 35.8s\n",
      "237:\tlearn: 0.9500736\ttotal: 18.4s\tremaining: 35.7s\n",
      "238:\tlearn: 0.9500270\ttotal: 18.5s\tremaining: 35.6s\n",
      "239:\tlearn: 0.9507039\ttotal: 18.6s\tremaining: 35.6s\n",
      "240:\tlearn: 0.9513667\ttotal: 18.6s\tremaining: 35.5s\n",
      "241:\tlearn: 0.9517499\ttotal: 18.7s\tremaining: 35.4s\n",
      "242:\tlearn: 0.9515163\ttotal: 18.8s\tremaining: 35.3s\n",
      "243:\tlearn: 0.9519509\ttotal: 18.9s\tremaining: 35.2s\n",
      "244:\tlearn: 0.9526241\ttotal: 18.9s\tremaining: 35.2s\n",
      "245:\tlearn: 0.9536118\ttotal: 19s\tremaining: 35.1s\n",
      "246:\tlearn: 0.9537902\ttotal: 19.1s\tremaining: 35s\n",
      "247:\tlearn: 0.9544829\ttotal: 19.2s\tremaining: 34.9s\n",
      "248:\tlearn: 0.9543422\ttotal: 19.3s\tremaining: 34.9s\n",
      "249:\tlearn: 0.9543691\ttotal: 19.3s\tremaining: 34.8s\n",
      "250:\tlearn: 0.9541257\ttotal: 19.4s\tremaining: 34.7s\n",
      "251:\tlearn: 0.9546929\ttotal: 19.5s\tremaining: 34.6s\n",
      "252:\tlearn: 0.9548336\ttotal: 19.5s\tremaining: 34.5s\n",
      "253:\tlearn: 0.9549319\ttotal: 19.6s\tremaining: 34.4s\n",
      "254:\tlearn: 0.9556156\ttotal: 19.7s\tremaining: 34.4s\n",
      "255:\tlearn: 0.9557052\ttotal: 19.8s\tremaining: 34.3s\n",
      "256:\tlearn: 0.9554747\ttotal: 19.8s\tremaining: 34.2s\n",
      "257:\tlearn: 0.9557052\ttotal: 19.9s\tremaining: 34.1s\n",
      "258:\tlearn: 0.9561028\ttotal: 20s\tremaining: 34.1s\n",
      "259:\tlearn: 0.9563465\ttotal: 20.1s\tremaining: 34s\n",
      "260:\tlearn: 0.9565901\ttotal: 20.2s\tremaining: 33.9s\n",
      "261:\tlearn: 0.9569152\ttotal: 20.2s\tremaining: 33.8s\n",
      "262:\tlearn: 0.9569110\ttotal: 20.3s\tremaining: 33.7s\n",
      "263:\tlearn: 0.9574029\ttotal: 20.4s\tremaining: 33.7s\n",
      "264:\tlearn: 0.9575871\ttotal: 20.5s\tremaining: 33.6s\n",
      "265:\tlearn: 0.9576938\ttotal: 20.5s\tremaining: 33.5s\n",
      "266:\tlearn: 0.9582554\ttotal: 20.6s\tremaining: 33.4s\n",
      "267:\tlearn: 0.9584051\ttotal: 20.7s\tremaining: 33.3s\n",
      "268:\tlearn: 0.9582206\ttotal: 20.8s\tremaining: 33.3s\n",
      "269:\tlearn: 0.9587086\ttotal: 20.8s\tremaining: 33.2s\n",
      "270:\tlearn: 0.9586061\ttotal: 20.9s\tremaining: 33.1s\n",
      "271:\tlearn: 0.9586533\ttotal: 21s\tremaining: 33s\n",
      "272:\tlearn: 0.9594761\ttotal: 21.1s\tremaining: 32.9s\n",
      "273:\tlearn: 0.9595233\ttotal: 21.1s\tremaining: 32.9s\n",
      "274:\tlearn: 0.9594289\ttotal: 21.2s\tremaining: 32.8s\n",
      "275:\tlearn: 0.9595233\ttotal: 21.3s\tremaining: 32.7s\n",
      "276:\tlearn: 0.9597557\ttotal: 21.4s\tremaining: 32.6s\n",
      "277:\tlearn: 0.9602956\ttotal: 21.5s\tremaining: 32.6s\n",
      "278:\tlearn: 0.9610172\ttotal: 21.5s\tremaining: 32.5s\n",
      "279:\tlearn: 0.9607882\ttotal: 21.6s\tremaining: 32.4s\n",
      "280:\tlearn: 0.9607920\ttotal: 21.7s\tremaining: 32.3s\n",
      "281:\tlearn: 0.9608906\ttotal: 21.8s\tremaining: 32.3s\n",
      "282:\tlearn: 0.9615100\ttotal: 21.8s\tremaining: 32.2s\n",
      "283:\tlearn: 0.9620465\ttotal: 21.9s\tremaining: 32.1s\n",
      "284:\tlearn: 0.9624735\ttotal: 22s\tremaining: 32s\n",
      "285:\tlearn: 0.9629082\ttotal: 22.1s\tremaining: 31.9s\n",
      "286:\tlearn: 0.9631932\ttotal: 22.1s\tremaining: 31.9s\n",
      "287:\tlearn: 0.9632552\ttotal: 22.2s\tremaining: 31.8s\n",
      "288:\tlearn: 0.9635036\ttotal: 22.3s\tremaining: 31.7s\n",
      "289:\tlearn: 0.9635584\ttotal: 22.4s\tremaining: 31.6s\n",
      "290:\tlearn: 0.9639493\ttotal: 22.4s\tremaining: 31.5s\n",
      "291:\tlearn: 0.9638946\ttotal: 22.5s\tremaining: 31.5s\n",
      "292:\tlearn: 0.9643879\ttotal: 22.6s\tremaining: 31.4s\n",
      "293:\tlearn: 0.9645642\ttotal: 22.7s\tremaining: 31.3s\n",
      "294:\tlearn: 0.9646594\ttotal: 22.7s\tremaining: 31.2s\n",
      "295:\tlearn: 0.9649080\ttotal: 22.8s\tremaining: 31.1s\n",
      "296:\tlearn: 0.9649963\ttotal: 22.9s\tremaining: 31.1s\n",
      "297:\tlearn: 0.9655377\ttotal: 23s\tremaining: 31s\n",
      "298:\tlearn: 0.9656807\ttotal: 23s\tremaining: 30.9s\n",
      "299:\tlearn: 0.9660180\ttotal: 23.1s\tremaining: 30.8s\n",
      "300:\tlearn: 0.9661645\ttotal: 23.2s\tremaining: 30.7s\n",
      "301:\tlearn: 0.9659158\ttotal: 23.3s\tremaining: 30.7s\n",
      "302:\tlearn: 0.9660590\ttotal: 23.3s\tremaining: 30.6s\n",
      "303:\tlearn: 0.9661578\ttotal: 23.4s\tremaining: 30.5s\n",
      "304:\tlearn: 0.9664443\ttotal: 23.5s\tremaining: 30.4s\n",
      "305:\tlearn: 0.9668940\ttotal: 23.6s\tremaining: 30.3s\n",
      "306:\tlearn: 0.9669352\ttotal: 23.6s\tremaining: 30.3s\n",
      "307:\tlearn: 0.9670884\ttotal: 23.7s\tremaining: 30.2s\n",
      "308:\tlearn: 0.9672796\ttotal: 23.8s\tremaining: 30.1s\n",
      "309:\tlearn: 0.9677196\ttotal: 23.9s\tremaining: 30s\n",
      "310:\tlearn: 0.9681119\ttotal: 24s\tremaining: 30s\n",
      "311:\tlearn: 0.9680162\ttotal: 24s\tremaining: 29.9s\n",
      "312:\tlearn: 0.9681566\ttotal: 24.1s\tremaining: 29.8s\n",
      "313:\tlearn: 0.9686418\ttotal: 24.2s\tremaining: 29.7s\n",
      "314:\tlearn: 0.9684950\ttotal: 24.2s\tremaining: 29.6s\n",
      "315:\tlearn: 0.9691273\ttotal: 24.3s\tremaining: 29.6s\n",
      "316:\tlearn: 0.9694181\ttotal: 24.4s\tremaining: 29.5s\n",
      "317:\tlearn: 0.9694690\ttotal: 24.5s\tremaining: 29.4s\n",
      "318:\tlearn: 0.9694150\ttotal: 24.6s\tremaining: 29.3s\n",
      "319:\tlearn: 0.9694211\ttotal: 24.6s\tremaining: 29.2s\n",
      "320:\tlearn: 0.9694660\ttotal: 24.7s\tremaining: 29.2s\n",
      "321:\tlearn: 0.9699941\ttotal: 24.8s\tremaining: 29.1s\n",
      "322:\tlearn: 0.9698530\ttotal: 24.8s\tremaining: 29s\n",
      "323:\tlearn: 0.9703843\ttotal: 24.9s\tremaining: 28.9s\n",
      "324:\tlearn: 0.9703363\ttotal: 25s\tremaining: 28.8s\n",
      "325:\tlearn: 0.9705227\ttotal: 25.1s\tremaining: 28.8s\n",
      "326:\tlearn: 0.9709613\ttotal: 25.1s\tremaining: 28.7s\n",
      "327:\tlearn: 0.9711143\ttotal: 25.2s\tremaining: 28.6s\n",
      "328:\tlearn: 0.9712672\ttotal: 25.3s\tremaining: 28.5s\n",
      "329:\tlearn: 0.9710181\ttotal: 25.4s\tremaining: 28.4s\n",
      "330:\tlearn: 0.9710267\ttotal: 25.5s\tremaining: 28.4s\n",
      "331:\tlearn: 0.9712191\ttotal: 25.5s\tremaining: 28.3s\n",
      "332:\tlearn: 0.9714625\ttotal: 25.6s\tremaining: 28.2s\n",
      "333:\tlearn: 0.9717542\ttotal: 25.7s\tremaining: 28.1s\n",
      "334:\tlearn: 0.9720006\ttotal: 25.8s\tremaining: 28.1s\n",
      "335:\tlearn: 0.9721396\ttotal: 25.8s\tremaining: 28s\n",
      "336:\tlearn: 0.9719950\ttotal: 25.9s\tremaining: 27.9s\n",
      "337:\tlearn: 0.9722842\ttotal: 26s\tremaining: 27.8s\n",
      "338:\tlearn: 0.9721933\ttotal: 26.1s\tremaining: 27.7s\n",
      "339:\tlearn: 0.9723352\ttotal: 26.1s\tremaining: 27.7s\n",
      "340:\tlearn: 0.9726727\ttotal: 26.2s\tremaining: 27.6s\n",
      "341:\tlearn: 0.9730588\ttotal: 26.3s\tremaining: 27.5s\n",
      "342:\tlearn: 0.9732116\ttotal: 26.4s\tremaining: 27.4s\n",
      "343:\tlearn: 0.9734610\ttotal: 26.4s\tremaining: 27.4s\n",
      "344:\tlearn: 0.9736568\ttotal: 26.5s\tremaining: 27.3s\n",
      "345:\tlearn: 0.9734127\ttotal: 26.6s\tremaining: 27.2s\n",
      "346:\tlearn: 0.9733618\ttotal: 26.7s\tremaining: 27.1s\n",
      "347:\tlearn: 0.9735093\ttotal: 26.7s\tremaining: 27.1s\n",
      "348:\tlearn: 0.9736059\ttotal: 26.8s\tremaining: 27s\n",
      "349:\tlearn: 0.9738578\ttotal: 26.9s\tremaining: 26.9s\n",
      "350:\tlearn: 0.9740028\ttotal: 27s\tremaining: 26.8s\n",
      "351:\tlearn: 0.9745372\ttotal: 27.1s\tremaining: 26.8s\n",
      "352:\tlearn: 0.9748350\ttotal: 27.1s\tremaining: 26.7s\n",
      "353:\tlearn: 0.9747357\ttotal: 27.2s\tremaining: 26.6s\n",
      "354:\tlearn: 0.9747866\ttotal: 27.3s\tremaining: 26.5s\n",
      "355:\tlearn: 0.9750794\ttotal: 27.4s\tremaining: 26.4s\n",
      "356:\tlearn: 0.9752271\ttotal: 27.4s\tremaining: 26.4s\n",
      "357:\tlearn: 0.9751787\ttotal: 27.5s\tremaining: 26.3s\n",
      "358:\tlearn: 0.9753724\ttotal: 27.6s\tremaining: 26.2s\n",
      "359:\tlearn: 0.9753748\ttotal: 27.7s\tremaining: 26.1s\n",
      "360:\tlearn: 0.9754741\ttotal: 27.7s\tremaining: 26s\n",
      "361:\tlearn: 0.9755759\ttotal: 27.8s\tremaining: 26s\n",
      "362:\tlearn: 0.9755783\ttotal: 27.9s\tremaining: 25.9s\n",
      "363:\tlearn: 0.9758713\ttotal: 28s\tremaining: 25.8s\n",
      "364:\tlearn: 0.9760604\ttotal: 28s\tremaining: 25.7s\n",
      "365:\tlearn: 0.9761621\ttotal: 28.1s\tremaining: 25.7s\n",
      "366:\tlearn: 0.9762614\ttotal: 28.2s\tremaining: 25.6s\n",
      "367:\tlearn: 0.9765547\ttotal: 28.3s\tremaining: 25.5s\n",
      "368:\tlearn: 0.9770423\ttotal: 28.3s\tremaining: 25.4s\n",
      "369:\tlearn: 0.9770401\ttotal: 28.4s\tremaining: 25.3s\n",
      "370:\tlearn: 0.9774331\ttotal: 28.5s\tremaining: 25.3s\n",
      "371:\tlearn: 0.9776297\ttotal: 28.6s\tremaining: 25.2s\n",
      "372:\tlearn: 0.9778264\ttotal: 28.6s\tremaining: 25.1s\n",
      "373:\tlearn: 0.9778264\ttotal: 28.7s\tremaining: 25s\n",
      "374:\tlearn: 0.9781668\ttotal: 28.8s\tremaining: 25s\n",
      "375:\tlearn: 0.9780695\ttotal: 28.9s\tremaining: 24.9s\n",
      "376:\tlearn: 0.9778220\ttotal: 28.9s\tremaining: 24.8s\n",
      "377:\tlearn: 0.9778750\ttotal: 29s\tremaining: 24.7s\n",
      "378:\tlearn: 0.9781182\ttotal: 29.1s\tremaining: 24.6s\n",
      "379:\tlearn: 0.9783636\ttotal: 29.2s\tremaining: 24.6s\n",
      "380:\tlearn: 0.9783171\ttotal: 29.3s\tremaining: 24.5s\n",
      "381:\tlearn: 0.9785583\ttotal: 29.3s\tremaining: 24.4s\n",
      "382:\tlearn: 0.9786070\ttotal: 29.4s\tremaining: 24.4s\n",
      "383:\tlearn: 0.9787552\ttotal: 29.5s\tremaining: 24.3s\n",
      "384:\tlearn: 0.9788060\ttotal: 29.6s\tremaining: 24.2s\n",
      "385:\tlearn: 0.9788102\ttotal: 29.7s\tremaining: 24.1s\n",
      "386:\tlearn: 0.9790537\ttotal: 29.7s\tremaining: 24s\n",
      "387:\tlearn: 0.9791024\ttotal: 29.8s\tremaining: 24s\n",
      "388:\tlearn: 0.9791998\ttotal: 29.9s\tremaining: 23.9s\n",
      "389:\tlearn: 0.9794497\ttotal: 30s\tremaining: 23.8s\n",
      "390:\tlearn: 0.9795451\ttotal: 30s\tremaining: 23.7s\n",
      "391:\tlearn: 0.9796426\ttotal: 30.1s\tremaining: 23.7s\n",
      "392:\tlearn: 0.9796914\ttotal: 30.2s\tremaining: 23.6s\n",
      "393:\tlearn: 0.9798865\ttotal: 30.3s\tremaining: 23.5s\n",
      "394:\tlearn: 0.9801813\ttotal: 30.3s\tremaining: 23.4s\n",
      "395:\tlearn: 0.9802808\ttotal: 30.4s\tremaining: 23.3s\n",
      "396:\tlearn: 0.9805269\ttotal: 30.5s\tremaining: 23.3s\n",
      "397:\tlearn: 0.9806715\ttotal: 30.6s\tremaining: 23.2s\n",
      "398:\tlearn: 0.9805738\ttotal: 30.6s\tremaining: 23.1s\n",
      "399:\tlearn: 0.9806715\ttotal: 30.7s\tremaining: 23s\n",
      "400:\tlearn: 0.9812092\ttotal: 30.8s\tremaining: 22.9s\n",
      "401:\tlearn: 0.9812600\ttotal: 30.9s\tremaining: 22.9s\n",
      "402:\tlearn: 0.9813089\ttotal: 30.9s\tremaining: 22.8s\n",
      "403:\tlearn: 0.9812111\ttotal: 31s\tremaining: 22.7s\n",
      "404:\tlearn: 0.9813089\ttotal: 31.1s\tremaining: 22.6s\n",
      "405:\tlearn: 0.9816061\ttotal: 31.2s\tremaining: 22.6s\n",
      "406:\tlearn: 0.9817040\ttotal: 31.2s\tremaining: 22.5s\n",
      "407:\tlearn: 0.9816043\ttotal: 31.3s\tremaining: 22.4s\n",
      "408:\tlearn: 0.9817511\ttotal: 31.4s\tremaining: 22.3s\n",
      "409:\tlearn: 0.9819977\ttotal: 31.5s\tremaining: 22.3s\n",
      "410:\tlearn: 0.9820449\ttotal: 31.5s\tremaining: 22.2s\n",
      "411:\tlearn: 0.9819941\ttotal: 31.6s\tremaining: 22.1s\n",
      "412:\tlearn: 0.9821918\ttotal: 31.7s\tremaining: 22s\n",
      "413:\tlearn: 0.9822408\ttotal: 31.8s\tremaining: 21.9s\n",
      "414:\tlearn: 0.9825402\ttotal: 31.8s\tremaining: 21.9s\n",
      "415:\tlearn: 0.9826382\ttotal: 31.9s\tremaining: 21.8s\n",
      "416:\tlearn: 0.9829341\ttotal: 32s\tremaining: 21.7s\n",
      "417:\tlearn: 0.9829307\ttotal: 32.1s\tremaining: 21.6s\n",
      "418:\tlearn: 0.9829815\ttotal: 32.2s\tremaining: 21.6s\n",
      "419:\tlearn: 0.9831270\ttotal: 32.2s\tremaining: 21.5s\n",
      "420:\tlearn: 0.9832709\ttotal: 32.3s\tremaining: 21.4s\n",
      "421:\tlearn: 0.9833691\ttotal: 32.4s\tremaining: 21.3s\n",
      "422:\tlearn: 0.9834166\ttotal: 32.5s\tremaining: 21.3s\n",
      "423:\tlearn: 0.9836655\ttotal: 32.5s\tremaining: 21.2s\n",
      "424:\tlearn: 0.9838129\ttotal: 32.6s\tremaining: 21.1s\n",
      "425:\tlearn: 0.9840144\ttotal: 32.7s\tremaining: 21s\n",
      "426:\tlearn: 0.9840144\ttotal: 32.8s\tremaining: 20.9s\n",
      "427:\tlearn: 0.9842142\ttotal: 32.8s\tremaining: 20.9s\n",
      "428:\tlearn: 0.9844125\ttotal: 32.9s\tremaining: 20.8s\n",
      "429:\tlearn: 0.9846092\ttotal: 33s\tremaining: 20.7s\n",
      "430:\tlearn: 0.9847553\ttotal: 33.1s\tremaining: 20.6s\n",
      "431:\tlearn: 0.9850060\ttotal: 33.1s\tremaining: 20.6s\n",
      "432:\tlearn: 0.9850075\ttotal: 33.2s\tremaining: 20.5s\n",
      "433:\tlearn: 0.9852030\ttotal: 33.3s\tremaining: 20.4s\n",
      "434:\tlearn: 0.9851537\ttotal: 33.4s\tremaining: 20.3s\n",
      "435:\tlearn: 0.9854000\ttotal: 33.4s\tremaining: 20.2s\n",
      "436:\tlearn: 0.9853507\ttotal: 33.5s\tremaining: 20.2s\n",
      "437:\tlearn: 0.9855971\ttotal: 33.6s\tremaining: 20.1s\n",
      "438:\tlearn: 0.9856464\ttotal: 33.7s\tremaining: 20s\n",
      "439:\tlearn: 0.9856450\ttotal: 33.7s\tremaining: 19.9s\n",
      "440:\tlearn: 0.9855957\ttotal: 33.8s\tremaining: 19.9s\n",
      "441:\tlearn: 0.9854971\ttotal: 33.9s\tremaining: 19.8s\n",
      "442:\tlearn: 0.9854478\ttotal: 34s\tremaining: 19.7s\n",
      "443:\tlearn: 0.9855464\ttotal: 34s\tremaining: 19.6s\n",
      "444:\tlearn: 0.9855464\ttotal: 34.1s\tremaining: 19.6s\n",
      "445:\tlearn: 0.9858929\ttotal: 34.2s\tremaining: 19.5s\n",
      "446:\tlearn: 0.9858436\ttotal: 34.3s\tremaining: 19.4s\n",
      "447:\tlearn: 0.9857436\ttotal: 34.3s\tremaining: 19.3s\n",
      "448:\tlearn: 0.9859916\ttotal: 34.4s\tremaining: 19.2s\n",
      "449:\tlearn: 0.9860917\ttotal: 34.5s\tremaining: 19.2s\n",
      "450:\tlearn: 0.9860889\ttotal: 34.6s\tremaining: 19.1s\n",
      "451:\tlearn: 0.9863384\ttotal: 34.6s\tremaining: 19s\n",
      "452:\tlearn: 0.9864398\ttotal: 34.7s\tremaining: 18.9s\n",
      "453:\tlearn: 0.9865879\ttotal: 34.8s\tremaining: 18.9s\n",
      "454:\tlearn: 0.9867374\ttotal: 34.9s\tremaining: 18.8s\n",
      "455:\tlearn: 0.9867894\ttotal: 35s\tremaining: 18.7s\n",
      "456:\tlearn: 0.9868869\ttotal: 35.1s\tremaining: 18.6s\n",
      "457:\tlearn: 0.9875307\ttotal: 35.1s\tremaining: 18.6s\n",
      "458:\tlearn: 0.9877285\ttotal: 35.2s\tremaining: 18.5s\n",
      "459:\tlearn: 0.9876283\ttotal: 35.3s\tremaining: 18.4s\n",
      "460:\tlearn: 0.9876296\ttotal: 35.4s\tremaining: 18.3s\n",
      "461:\tlearn: 0.9876803\ttotal: 35.4s\tremaining: 18.3s\n",
      "462:\tlearn: 0.9878287\ttotal: 35.5s\tremaining: 18.2s\n",
      "463:\tlearn: 0.9879277\ttotal: 35.6s\tremaining: 18.1s\n",
      "464:\tlearn: 0.9877285\ttotal: 35.7s\tremaining: 18s\n",
      "465:\tlearn: 0.9879760\ttotal: 35.8s\tremaining: 18s\n",
      "466:\tlearn: 0.9882223\ttotal: 35.8s\tremaining: 17.9s\n",
      "467:\tlearn: 0.9881740\ttotal: 35.9s\tremaining: 17.8s\n",
      "468:\tlearn: 0.9883721\ttotal: 36s\tremaining: 17.7s\n",
      "469:\tlearn: 0.9883226\ttotal: 36.1s\tremaining: 17.6s\n",
      "470:\tlearn: 0.9884712\ttotal: 36.1s\tremaining: 17.6s\n",
      "471:\tlearn: 0.9883721\ttotal: 36.2s\tremaining: 17.5s\n",
      "472:\tlearn: 0.9884712\ttotal: 36.3s\tremaining: 17.4s\n",
      "473:\tlearn: 0.9883721\ttotal: 36.4s\tremaining: 17.3s\n",
      "474:\tlearn: 0.9883709\ttotal: 36.4s\tremaining: 17.3s\n",
      "475:\tlearn: 0.9885691\ttotal: 36.5s\tremaining: 17.2s\n",
      "476:\tlearn: 0.9885691\ttotal: 36.6s\tremaining: 17.1s\n",
      "477:\tlearn: 0.9887190\ttotal: 36.7s\tremaining: 17s\n",
      "478:\tlearn: 0.9887697\ttotal: 36.7s\tremaining: 17s\n",
      "479:\tlearn: 0.9888688\ttotal: 36.8s\tremaining: 16.9s\n",
      "480:\tlearn: 0.9889680\ttotal: 36.9s\tremaining: 16.8s\n",
      "481:\tlearn: 0.9892171\ttotal: 37s\tremaining: 16.7s\n",
      "482:\tlearn: 0.9890165\ttotal: 37s\tremaining: 16.6s\n",
      "483:\tlearn: 0.9891157\ttotal: 37.1s\tremaining: 16.6s\n",
      "484:\tlearn: 0.9888677\ttotal: 37.2s\tremaining: 16.5s\n",
      "485:\tlearn: 0.9893153\ttotal: 37.3s\tremaining: 16.4s\n",
      "486:\tlearn: 0.9895138\ttotal: 37.3s\tremaining: 16.3s\n",
      "487:\tlearn: 0.9893153\ttotal: 37.4s\tremaining: 16.3s\n",
      "488:\tlearn: 0.9894642\ttotal: 37.5s\tremaining: 16.2s\n",
      "489:\tlearn: 0.9895138\ttotal: 37.6s\tremaining: 16.1s\n",
      "490:\tlearn: 0.9894135\ttotal: 37.6s\tremaining: 16s\n",
      "491:\tlearn: 0.9897114\ttotal: 37.7s\tremaining: 15.9s\n",
      "492:\tlearn: 0.9897611\ttotal: 37.8s\tremaining: 15.9s\n",
      "493:\tlearn: 0.9898108\ttotal: 37.9s\tremaining: 15.8s\n",
      "494:\tlearn: 0.9900095\ttotal: 37.9s\tremaining: 15.7s\n",
      "495:\tlearn: 0.9901587\ttotal: 38s\tremaining: 15.6s\n",
      "496:\tlearn: 0.9903078\ttotal: 38.1s\tremaining: 15.6s\n",
      "497:\tlearn: 0.9903585\ttotal: 38.2s\tremaining: 15.5s\n",
      "498:\tlearn: 0.9903098\ttotal: 38.3s\tremaining: 15.4s\n",
      "499:\tlearn: 0.9904092\ttotal: 38.3s\tremaining: 15.3s\n",
      "500:\tlearn: 0.9904599\ttotal: 38.4s\tremaining: 15.3s\n",
      "501:\tlearn: 0.9905604\ttotal: 38.5s\tremaining: 15.2s\n",
      "502:\tlearn: 0.9907593\ttotal: 38.5s\tremaining: 15.1s\n",
      "503:\tlearn: 0.9908100\ttotal: 38.6s\tremaining: 15s\n",
      "504:\tlearn: 0.9910091\ttotal: 38.7s\tremaining: 14.9s\n",
      "505:\tlearn: 0.9912082\ttotal: 38.8s\tremaining: 14.9s\n",
      "506:\tlearn: 0.9912082\ttotal: 38.9s\tremaining: 14.8s\n",
      "507:\tlearn: 0.9913087\ttotal: 38.9s\tremaining: 14.7s\n",
      "508:\tlearn: 0.9915080\ttotal: 39s\tremaining: 14.6s\n",
      "509:\tlearn: 0.9916076\ttotal: 39.1s\tremaining: 14.6s\n",
      "510:\tlearn: 0.9913585\ttotal: 39.2s\tremaining: 14.5s\n",
      "511:\tlearn: 0.9915088\ttotal: 39.2s\tremaining: 14.4s\n",
      "512:\tlearn: 0.9917081\ttotal: 39.3s\tremaining: 14.3s\n",
      "513:\tlearn: 0.9918585\ttotal: 39.4s\tremaining: 14.3s\n",
      "514:\tlearn: 0.9919083\ttotal: 39.5s\tremaining: 14.2s\n",
      "515:\tlearn: 0.9920579\ttotal: 39.5s\tremaining: 14.1s\n",
      "516:\tlearn: 0.9921577\ttotal: 39.6s\tremaining: 14s\n",
      "517:\tlearn: 0.9921070\ttotal: 39.7s\tremaining: 13.9s\n",
      "518:\tlearn: 0.9921569\ttotal: 39.8s\tremaining: 13.9s\n",
      "519:\tlearn: 0.9921569\ttotal: 39.8s\tremaining: 13.8s\n",
      "520:\tlearn: 0.9922574\ttotal: 39.9s\tremaining: 13.7s\n",
      "521:\tlearn: 0.9923564\ttotal: 40s\tremaining: 13.6s\n",
      "522:\tlearn: 0.9925069\ttotal: 40s\tremaining: 13.6s\n",
      "523:\tlearn: 0.9924570\ttotal: 40.1s\tremaining: 13.5s\n",
      "524:\tlearn: 0.9926067\ttotal: 40.2s\tremaining: 13.4s\n",
      "525:\tlearn: 0.9925568\ttotal: 40.3s\tremaining: 13.3s\n",
      "526:\tlearn: 0.9927073\ttotal: 40.3s\tremaining: 13.2s\n",
      "527:\tlearn: 0.9928571\ttotal: 40.4s\tremaining: 13.2s\n",
      "528:\tlearn: 0.9928571\ttotal: 40.5s\tremaining: 13.1s\n",
      "529:\tlearn: 0.9929570\ttotal: 40.6s\tremaining: 13s\n",
      "530:\tlearn: 0.9930070\ttotal: 40.6s\tremaining: 12.9s\n",
      "531:\tlearn: 0.9929570\ttotal: 40.7s\tremaining: 12.9s\n",
      "532:\tlearn: 0.9931069\ttotal: 40.8s\tremaining: 12.8s\n",
      "533:\tlearn: 0.9930570\ttotal: 40.9s\tremaining: 12.7s\n",
      "534:\tlearn: 0.9931069\ttotal: 41s\tremaining: 12.6s\n",
      "535:\tlearn: 0.9930570\ttotal: 41s\tremaining: 12.6s\n",
      "536:\tlearn: 0.9930570\ttotal: 41.1s\tremaining: 12.5s\n",
      "537:\tlearn: 0.9930570\ttotal: 41.2s\tremaining: 12.4s\n",
      "538:\tlearn: 0.9933068\ttotal: 41.3s\tremaining: 12.3s\n",
      "539:\tlearn: 0.9933075\ttotal: 41.3s\tremaining: 12.2s\n",
      "540:\tlearn: 0.9934075\ttotal: 41.4s\tremaining: 12.2s\n",
      "541:\tlearn: 0.9933075\ttotal: 41.5s\tremaining: 12.1s\n",
      "542:\tlearn: 0.9933568\ttotal: 41.6s\tremaining: 12s\n",
      "543:\tlearn: 0.9934581\ttotal: 41.6s\tremaining: 11.9s\n",
      "544:\tlearn: 0.9934575\ttotal: 41.7s\tremaining: 11.9s\n",
      "545:\tlearn: 0.9935075\ttotal: 41.8s\tremaining: 11.8s\n",
      "546:\tlearn: 0.9936581\ttotal: 41.9s\tremaining: 11.7s\n",
      "547:\tlearn: 0.9936581\ttotal: 41.9s\tremaining: 11.6s\n",
      "548:\tlearn: 0.9937582\ttotal: 42s\tremaining: 11.6s\n",
      "549:\tlearn: 0.9935581\ttotal: 42.1s\tremaining: 11.5s\n",
      "550:\tlearn: 0.9937082\ttotal: 42.2s\tremaining: 11.4s\n",
      "551:\tlearn: 0.9937588\ttotal: 42.2s\tremaining: 11.3s\n",
      "552:\tlearn: 0.9936088\ttotal: 42.3s\tremaining: 11.2s\n",
      "553:\tlearn: 0.9938088\ttotal: 42.4s\tremaining: 11.2s\n",
      "554:\tlearn: 0.9941097\ttotal: 42.5s\tremaining: 11.1s\n",
      "555:\tlearn: 0.9941102\ttotal: 42.5s\tremaining: 11s\n",
      "556:\tlearn: 0.9941102\ttotal: 42.6s\tremaining: 10.9s\n",
      "557:\tlearn: 0.9941102\ttotal: 42.7s\tremaining: 10.9s\n",
      "558:\tlearn: 0.9941097\ttotal: 42.8s\tremaining: 10.8s\n",
      "559:\tlearn: 0.9942598\ttotal: 42.8s\tremaining: 10.7s\n",
      "560:\tlearn: 0.9942604\ttotal: 42.9s\tremaining: 10.6s\n",
      "561:\tlearn: 0.9943105\ttotal: 43s\tremaining: 10.6s\n",
      "562:\tlearn: 0.9943105\ttotal: 43.1s\tremaining: 10.5s\n",
      "563:\tlearn: 0.9942598\ttotal: 43.1s\tremaining: 10.4s\n",
      "564:\tlearn: 0.9942604\ttotal: 43.2s\tremaining: 10.3s\n",
      "565:\tlearn: 0.9942604\ttotal: 43.3s\tremaining: 10.2s\n",
      "566:\tlearn: 0.9942604\ttotal: 43.3s\tremaining: 10.2s\n",
      "567:\tlearn: 0.9944106\ttotal: 43.4s\tremaining: 10.1s\n",
      "568:\tlearn: 0.9944106\ttotal: 43.5s\tremaining: 10s\n",
      "569:\tlearn: 0.9945108\ttotal: 43.6s\tremaining: 9.94s\n",
      "570:\tlearn: 0.9944601\ttotal: 43.7s\tremaining: 9.86s\n",
      "571:\tlearn: 0.9943600\ttotal: 43.7s\tremaining: 9.79s\n",
      "572:\tlearn: 0.9943605\ttotal: 43.8s\tremaining: 9.71s\n",
      "573:\tlearn: 0.9944112\ttotal: 43.9s\tremaining: 9.63s\n",
      "574:\tlearn: 0.9944112\ttotal: 44s\tremaining: 9.56s\n",
      "575:\tlearn: 0.9945113\ttotal: 44s\tremaining: 9.48s\n",
      "576:\tlearn: 0.9944112\ttotal: 44.1s\tremaining: 9.4s\n",
      "577:\tlearn: 0.9945113\ttotal: 44.2s\tremaining: 9.33s\n",
      "578:\tlearn: 0.9945614\ttotal: 44.3s\tremaining: 9.25s\n",
      "579:\tlearn: 0.9947117\ttotal: 44.3s\tremaining: 9.17s\n",
      "580:\tlearn: 0.9947618\ttotal: 44.4s\tremaining: 9.09s\n",
      "581:\tlearn: 0.9947618\ttotal: 44.5s\tremaining: 9.02s\n",
      "582:\tlearn: 0.9947111\ttotal: 44.5s\tremaining: 8.94s\n",
      "583:\tlearn: 0.9949121\ttotal: 44.6s\tremaining: 8.86s\n",
      "584:\tlearn: 0.9949116\ttotal: 44.7s\tremaining: 8.79s\n",
      "585:\tlearn: 0.9950118\ttotal: 44.8s\tremaining: 8.71s\n",
      "586:\tlearn: 0.9951121\ttotal: 44.8s\tremaining: 8.63s\n",
      "587:\tlearn: 0.9951121\ttotal: 44.9s\tremaining: 8.56s\n",
      "588:\tlearn: 0.9951623\ttotal: 45s\tremaining: 8.48s\n",
      "589:\tlearn: 0.9952129\ttotal: 45.1s\tremaining: 8.4s\n",
      "590:\tlearn: 0.9952129\ttotal: 45.1s\tremaining: 8.33s\n",
      "591:\tlearn: 0.9952124\ttotal: 45.2s\tremaining: 8.25s\n",
      "592:\tlearn: 0.9952631\ttotal: 45.3s\tremaining: 8.17s\n",
      "593:\tlearn: 0.9953132\ttotal: 45.4s\tremaining: 8.1s\n",
      "594:\tlearn: 0.9952631\ttotal: 45.4s\tremaining: 8.02s\n",
      "595:\tlearn: 0.9953634\ttotal: 45.5s\tremaining: 7.94s\n",
      "596:\tlearn: 0.9953634\ttotal: 45.6s\tremaining: 7.87s\n",
      "597:\tlearn: 0.9953132\ttotal: 45.7s\tremaining: 7.79s\n",
      "598:\tlearn: 0.9953634\ttotal: 45.8s\tremaining: 7.71s\n",
      "599:\tlearn: 0.9953634\ttotal: 45.8s\tremaining: 7.64s\n",
      "600:\tlearn: 0.9953634\ttotal: 45.9s\tremaining: 7.57s\n",
      "601:\tlearn: 0.9954135\ttotal: 46s\tremaining: 7.49s\n",
      "602:\tlearn: 0.9954637\ttotal: 46.1s\tremaining: 7.41s\n",
      "603:\tlearn: 0.9955139\ttotal: 46.2s\tremaining: 7.34s\n",
      "604:\tlearn: 0.9957648\ttotal: 46.2s\tremaining: 7.26s\n",
      "605:\tlearn: 0.9956143\ttotal: 46.3s\tremaining: 7.19s\n",
      "606:\tlearn: 0.9956644\ttotal: 46.4s\tremaining: 7.11s\n",
      "607:\tlearn: 0.9958155\ttotal: 46.5s\tremaining: 7.04s\n",
      "608:\tlearn: 0.9958155\ttotal: 46.6s\tremaining: 6.96s\n",
      "609:\tlearn: 0.9957653\ttotal: 46.7s\tremaining: 6.88s\n",
      "610:\tlearn: 0.9957653\ttotal: 46.7s\tremaining: 6.81s\n",
      "611:\tlearn: 0.9957653\ttotal: 46.8s\tremaining: 6.73s\n",
      "612:\tlearn: 0.9957653\ttotal: 46.9s\tremaining: 6.66s\n",
      "613:\tlearn: 0.9958657\ttotal: 47s\tremaining: 6.58s\n",
      "614:\tlearn: 0.9958657\ttotal: 47.1s\tremaining: 6.5s\n",
      "615:\tlearn: 0.9957151\ttotal: 47.1s\tremaining: 6.43s\n",
      "616:\tlearn: 0.9957151\ttotal: 47.2s\tremaining: 6.35s\n",
      "617:\tlearn: 0.9957657\ttotal: 47.3s\tremaining: 6.28s\n",
      "618:\tlearn: 0.9958159\ttotal: 47.4s\tremaining: 6.2s\n",
      "619:\tlearn: 0.9958661\ttotal: 47.5s\tremaining: 6.12s\n",
      "620:\tlearn: 0.9959163\ttotal: 47.5s\tremaining: 6.05s\n",
      "621:\tlearn: 0.9959163\ttotal: 47.6s\tremaining: 5.97s\n",
      "622:\tlearn: 0.9959163\ttotal: 47.7s\tremaining: 5.89s\n",
      "623:\tlearn: 0.9959665\ttotal: 47.8s\tremaining: 5.82s\n",
      "624:\tlearn: 0.9961172\ttotal: 47.8s\tremaining: 5.74s\n",
      "625:\tlearn: 0.9962683\ttotal: 47.9s\tremaining: 5.66s\n",
      "626:\tlearn: 0.9962177\ttotal: 48s\tremaining: 5.59s\n",
      "627:\tlearn: 0.9961674\ttotal: 48.1s\tremaining: 5.51s\n",
      "628:\tlearn: 0.9962177\ttotal: 48.1s\tremaining: 5.43s\n",
      "629:\tlearn: 0.9962679\ttotal: 48.2s\tremaining: 5.36s\n",
      "630:\tlearn: 0.9962177\ttotal: 48.3s\tremaining: 5.28s\n",
      "631:\tlearn: 0.9962177\ttotal: 48.4s\tremaining: 5.2s\n",
      "632:\tlearn: 0.9963182\ttotal: 48.4s\tremaining: 5.13s\n",
      "633:\tlearn: 0.9964693\ttotal: 48.5s\tremaining: 5.05s\n",
      "634:\tlearn: 0.9965195\ttotal: 48.6s\tremaining: 4.97s\n",
      "635:\tlearn: 0.9965195\ttotal: 48.7s\tremaining: 4.9s\n",
      "636:\tlearn: 0.9964190\ttotal: 48.8s\tremaining: 4.82s\n",
      "637:\tlearn: 0.9964693\ttotal: 48.8s\tremaining: 4.75s\n",
      "638:\tlearn: 0.9965195\ttotal: 48.9s\tremaining: 4.67s\n",
      "639:\tlearn: 0.9965698\ttotal: 49s\tremaining: 4.59s\n",
      "640:\tlearn: 0.9965698\ttotal: 49.1s\tremaining: 4.52s\n",
      "641:\tlearn: 0.9966704\ttotal: 49.2s\tremaining: 4.44s\n",
      "642:\tlearn: 0.9967206\ttotal: 49.2s\tremaining: 4.36s\n",
      "643:\tlearn: 0.9966704\ttotal: 49.3s\tremaining: 4.29s\n",
      "644:\tlearn: 0.9967206\ttotal: 49.4s\tremaining: 4.21s\n",
      "645:\tlearn: 0.9967709\ttotal: 49.5s\tremaining: 4.13s\n",
      "646:\tlearn: 0.9967709\ttotal: 49.5s\tremaining: 4.06s\n",
      "647:\tlearn: 0.9969218\ttotal: 49.6s\tremaining: 3.98s\n",
      "648:\tlearn: 0.9969721\ttotal: 49.7s\tremaining: 3.9s\n",
      "649:\tlearn: 0.9969218\ttotal: 49.8s\tremaining: 3.83s\n",
      "650:\tlearn: 0.9970225\ttotal: 49.8s\tremaining: 3.75s\n",
      "651:\tlearn: 0.9970225\ttotal: 49.9s\tremaining: 3.67s\n",
      "652:\tlearn: 0.9970728\ttotal: 50s\tremaining: 3.6s\n",
      "653:\tlearn: 0.9970728\ttotal: 50.1s\tremaining: 3.52s\n",
      "654:\tlearn: 0.9972238\ttotal: 50.1s\tremaining: 3.44s\n",
      "655:\tlearn: 0.9972741\ttotal: 50.2s\tremaining: 3.37s\n",
      "656:\tlearn: 0.9972741\ttotal: 50.3s\tremaining: 3.29s\n",
      "657:\tlearn: 0.9972238\ttotal: 50.4s\tremaining: 3.21s\n",
      "658:\tlearn: 0.9972238\ttotal: 50.5s\tremaining: 3.14s\n",
      "659:\tlearn: 0.9972238\ttotal: 50.5s\tremaining: 3.06s\n",
      "660:\tlearn: 0.9972238\ttotal: 50.6s\tremaining: 2.98s\n",
      "661:\tlearn: 0.9972741\ttotal: 50.7s\tremaining: 2.91s\n",
      "662:\tlearn: 0.9972238\ttotal: 50.8s\tremaining: 2.83s\n",
      "663:\tlearn: 0.9972238\ttotal: 50.8s\tremaining: 2.76s\n",
      "664:\tlearn: 0.9973244\ttotal: 50.9s\tremaining: 2.68s\n",
      "665:\tlearn: 0.9973748\ttotal: 51s\tremaining: 2.6s\n",
      "666:\tlearn: 0.9973748\ttotal: 51.1s\tremaining: 2.53s\n",
      "667:\tlearn: 0.9974252\ttotal: 51.1s\tremaining: 2.45s\n",
      "668:\tlearn: 0.9973748\ttotal: 51.2s\tremaining: 2.37s\n",
      "669:\tlearn: 0.9973244\ttotal: 51.3s\tremaining: 2.3s\n",
      "670:\tlearn: 0.9973748\ttotal: 51.4s\tremaining: 2.22s\n",
      "671:\tlearn: 0.9974252\ttotal: 51.5s\tremaining: 2.14s\n",
      "672:\tlearn: 0.9974252\ttotal: 51.5s\tremaining: 2.07s\n",
      "673:\tlearn: 0.9973748\ttotal: 51.6s\tremaining: 1.99s\n",
      "674:\tlearn: 0.9974252\ttotal: 51.7s\tremaining: 1.91s\n",
      "675:\tlearn: 0.9974252\ttotal: 51.8s\tremaining: 1.84s\n",
      "676:\tlearn: 0.9974755\ttotal: 51.8s\tremaining: 1.76s\n",
      "677:\tlearn: 0.9974755\ttotal: 51.9s\tremaining: 1.68s\n",
      "678:\tlearn: 0.9974755\ttotal: 52s\tremaining: 1.61s\n",
      "679:\tlearn: 0.9975259\ttotal: 52.1s\tremaining: 1.53s\n",
      "680:\tlearn: 0.9975259\ttotal: 52.1s\tremaining: 1.45s\n",
      "681:\tlearn: 0.9975762\ttotal: 52.2s\tremaining: 1.38s\n",
      "682:\tlearn: 0.9975762\ttotal: 52.3s\tremaining: 1.3s\n",
      "683:\tlearn: 0.9976266\ttotal: 52.4s\tremaining: 1.23s\n",
      "684:\tlearn: 0.9977274\ttotal: 52.4s\tremaining: 1.15s\n",
      "685:\tlearn: 0.9977778\ttotal: 52.5s\tremaining: 1.07s\n",
      "686:\tlearn: 0.9978282\ttotal: 52.6s\tremaining: 995ms\n",
      "687:\tlearn: 0.9977778\ttotal: 52.7s\tremaining: 919ms\n",
      "688:\tlearn: 0.9978282\ttotal: 52.8s\tremaining: 842ms\n",
      "689:\tlearn: 0.9978282\ttotal: 52.8s\tremaining: 766ms\n",
      "690:\tlearn: 0.9978282\ttotal: 52.9s\tremaining: 689ms\n",
      "691:\tlearn: 0.9978786\ttotal: 53s\tremaining: 612ms\n",
      "692:\tlearn: 0.9978282\ttotal: 53.1s\tremaining: 536ms\n",
      "693:\tlearn: 0.9978282\ttotal: 53.1s\tremaining: 459ms\n",
      "694:\tlearn: 0.9978786\ttotal: 53.2s\tremaining: 383ms\n",
      "695:\tlearn: 0.9978786\ttotal: 53.3s\tremaining: 306ms\n",
      "696:\tlearn: 0.9978786\ttotal: 53.4s\tremaining: 230ms\n",
      "697:\tlearn: 0.9978282\ttotal: 53.5s\tremaining: 153ms\n",
      "698:\tlearn: 0.9978786\ttotal: 53.5s\tremaining: 76.6ms\n",
      "699:\tlearn: 0.9978786\ttotal: 53.6s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=6, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Gradient, learning_rate=0.1, random_strength=1; total time=  54.2s\n",
      "0:\tlearn: 0.6294200\ttotal: 85.8ms\tremaining: 60s\n",
      "1:\tlearn: 0.6520994\ttotal: 168ms\tremaining: 58.6s\n",
      "2:\tlearn: 0.6721494\ttotal: 243ms\tremaining: 56.4s\n",
      "3:\tlearn: 0.6898858\ttotal: 321ms\tremaining: 55.9s\n",
      "4:\tlearn: 0.7096432\ttotal: 398ms\tremaining: 55.3s\n",
      "5:\tlearn: 0.7140053\ttotal: 478ms\tremaining: 55.3s\n",
      "6:\tlearn: 0.7160790\ttotal: 551ms\tremaining: 54.6s\n",
      "7:\tlearn: 0.7321759\ttotal: 632ms\tremaining: 54.7s\n",
      "8:\tlearn: 0.7380571\ttotal: 708ms\tremaining: 54.3s\n",
      "9:\tlearn: 0.7438953\ttotal: 786ms\tremaining: 54.3s\n",
      "10:\tlearn: 0.7497451\ttotal: 863ms\tremaining: 54.1s\n",
      "11:\tlearn: 0.7487666\ttotal: 943ms\tremaining: 54s\n",
      "12:\tlearn: 0.7563810\ttotal: 1.02s\tremaining: 54s\n",
      "13:\tlearn: 0.7656637\ttotal: 1.1s\tremaining: 53.9s\n",
      "14:\tlearn: 0.7706782\ttotal: 1.18s\tremaining: 53.7s\n",
      "15:\tlearn: 0.7771126\ttotal: 1.26s\tremaining: 53.7s\n",
      "16:\tlearn: 0.7794842\ttotal: 1.33s\tremaining: 53.6s\n",
      "17:\tlearn: 0.7832898\ttotal: 1.41s\tremaining: 53.5s\n",
      "18:\tlearn: 0.7887352\ttotal: 1.49s\tremaining: 53.4s\n",
      "19:\tlearn: 0.7934404\ttotal: 1.57s\tremaining: 53.3s\n",
      "20:\tlearn: 0.7942242\ttotal: 1.65s\tremaining: 53.3s\n",
      "21:\tlearn: 0.7973978\ttotal: 1.73s\tremaining: 53.3s\n",
      "22:\tlearn: 0.8001755\ttotal: 1.8s\tremaining: 53.1s\n",
      "23:\tlearn: 0.8037356\ttotal: 1.88s\tremaining: 53s\n",
      "24:\tlearn: 0.8059410\ttotal: 1.98s\tremaining: 53.4s\n",
      "25:\tlearn: 0.8079121\ttotal: 2.06s\tremaining: 53.4s\n",
      "26:\tlearn: 0.8102850\ttotal: 2.13s\tremaining: 53.2s\n",
      "27:\tlearn: 0.8101773\ttotal: 2.21s\tremaining: 53s\n",
      "28:\tlearn: 0.8125336\ttotal: 2.29s\tremaining: 52.9s\n",
      "29:\tlearn: 0.8138955\ttotal: 2.36s\tremaining: 52.7s\n",
      "30:\tlearn: 0.8161628\ttotal: 2.44s\tremaining: 52.6s\n",
      "31:\tlearn: 0.8180615\ttotal: 2.52s\tremaining: 52.5s\n",
      "32:\tlearn: 0.8195275\ttotal: 2.6s\tremaining: 52.5s\n",
      "33:\tlearn: 0.8207265\ttotal: 2.67s\tremaining: 52.4s\n",
      "34:\tlearn: 0.8249951\ttotal: 2.75s\tremaining: 52.2s\n",
      "35:\tlearn: 0.8244830\ttotal: 2.82s\tremaining: 52.1s\n",
      "36:\tlearn: 0.8261873\ttotal: 2.9s\tremaining: 51.9s\n",
      "37:\tlearn: 0.8277996\ttotal: 2.98s\tremaining: 51.8s\n",
      "38:\tlearn: 0.8286500\ttotal: 3.05s\tremaining: 51.8s\n",
      "39:\tlearn: 0.8298698\ttotal: 3.13s\tremaining: 51.6s\n",
      "40:\tlearn: 0.8314993\ttotal: 3.21s\tremaining: 51.6s\n",
      "41:\tlearn: 0.8317872\ttotal: 3.28s\tremaining: 51.4s\n",
      "42:\tlearn: 0.8343649\ttotal: 3.36s\tremaining: 51.3s\n",
      "43:\tlearn: 0.8364851\ttotal: 3.43s\tremaining: 51.2s\n",
      "44:\tlearn: 0.8372893\ttotal: 3.51s\tremaining: 51s\n",
      "45:\tlearn: 0.8378245\ttotal: 3.58s\tremaining: 51s\n",
      "46:\tlearn: 0.8393401\ttotal: 3.65s\tremaining: 50.8s\n",
      "47:\tlearn: 0.8395874\ttotal: 3.73s\tremaining: 50.7s\n",
      "48:\tlearn: 0.8414233\ttotal: 3.81s\tremaining: 50.6s\n",
      "49:\tlearn: 0.8415934\ttotal: 3.88s\tremaining: 50.5s\n",
      "50:\tlearn: 0.8416818\ttotal: 3.96s\tremaining: 50.4s\n",
      "51:\tlearn: 0.8436841\ttotal: 4.04s\tremaining: 50.3s\n",
      "52:\tlearn: 0.8446949\ttotal: 4.11s\tremaining: 50.2s\n",
      "53:\tlearn: 0.8455619\ttotal: 4.19s\tremaining: 50.1s\n",
      "54:\tlearn: 0.8457468\ttotal: 4.26s\tremaining: 50s\n",
      "55:\tlearn: 0.8450787\ttotal: 4.34s\tremaining: 49.9s\n",
      "56:\tlearn: 0.8472249\ttotal: 4.42s\tremaining: 49.9s\n",
      "57:\tlearn: 0.8471766\ttotal: 4.5s\tremaining: 49.8s\n",
      "58:\tlearn: 0.8485234\ttotal: 4.58s\tremaining: 49.7s\n",
      "59:\tlearn: 0.8501664\ttotal: 4.65s\tremaining: 49.6s\n",
      "60:\tlearn: 0.8505117\ttotal: 4.72s\tremaining: 49.5s\n",
      "61:\tlearn: 0.8503621\ttotal: 4.81s\tremaining: 49.5s\n",
      "62:\tlearn: 0.8511992\ttotal: 4.89s\tremaining: 49.4s\n",
      "63:\tlearn: 0.8535917\ttotal: 4.96s\tremaining: 49.3s\n",
      "64:\tlearn: 0.8549902\ttotal: 5.04s\tremaining: 49.3s\n",
      "65:\tlearn: 0.8548363\ttotal: 5.12s\tremaining: 49.2s\n",
      "66:\tlearn: 0.8550313\ttotal: 5.2s\tremaining: 49.1s\n",
      "67:\tlearn: 0.8561785\ttotal: 5.27s\tremaining: 49s\n",
      "68:\tlearn: 0.8578139\ttotal: 5.35s\tremaining: 48.9s\n",
      "69:\tlearn: 0.8593375\ttotal: 5.42s\tremaining: 48.8s\n",
      "70:\tlearn: 0.8607038\ttotal: 5.5s\tremaining: 48.7s\n",
      "71:\tlearn: 0.8610785\ttotal: 5.58s\tremaining: 48.7s\n",
      "72:\tlearn: 0.8621784\ttotal: 5.65s\tremaining: 48.5s\n",
      "73:\tlearn: 0.8640914\ttotal: 5.72s\tremaining: 48.4s\n",
      "74:\tlearn: 0.8646459\ttotal: 5.8s\tremaining: 48.3s\n",
      "75:\tlearn: 0.8655725\ttotal: 5.87s\tremaining: 48.2s\n",
      "76:\tlearn: 0.8665007\ttotal: 5.95s\tremaining: 48.1s\n",
      "77:\tlearn: 0.8670960\ttotal: 6.03s\tremaining: 48.1s\n",
      "78:\tlearn: 0.8692045\ttotal: 6.1s\tremaining: 48s\n",
      "79:\tlearn: 0.8689709\ttotal: 6.18s\tremaining: 47.9s\n",
      "80:\tlearn: 0.8696884\ttotal: 6.25s\tremaining: 47.8s\n",
      "81:\tlearn: 0.8703297\ttotal: 6.33s\tremaining: 47.7s\n",
      "82:\tlearn: 0.8703939\ttotal: 6.4s\tremaining: 47.6s\n",
      "83:\tlearn: 0.8704537\ttotal: 6.47s\tremaining: 47.5s\n",
      "84:\tlearn: 0.8708368\ttotal: 6.55s\tremaining: 47.4s\n",
      "85:\tlearn: 0.8718576\ttotal: 6.62s\tremaining: 47.3s\n",
      "86:\tlearn: 0.8720106\ttotal: 6.7s\tremaining: 47.2s\n",
      "87:\tlearn: 0.8725903\ttotal: 6.77s\tremaining: 47.1s\n",
      "88:\tlearn: 0.8736374\ttotal: 6.85s\tremaining: 47s\n",
      "89:\tlearn: 0.8747799\ttotal: 6.93s\tremaining: 47s\n",
      "90:\tlearn: 0.8761300\ttotal: 7.01s\tremaining: 46.9s\n",
      "91:\tlearn: 0.8767030\ttotal: 7.09s\tremaining: 46.8s\n",
      "92:\tlearn: 0.8763979\ttotal: 7.16s\tremaining: 46.8s\n",
      "93:\tlearn: 0.8773009\ttotal: 7.24s\tremaining: 46.7s\n",
      "94:\tlearn: 0.8779178\ttotal: 7.32s\tremaining: 46.6s\n",
      "95:\tlearn: 0.8791488\ttotal: 7.4s\tremaining: 46.5s\n",
      "96:\tlearn: 0.8797150\ttotal: 7.47s\tremaining: 46.5s\n",
      "97:\tlearn: 0.8809129\ttotal: 7.55s\tremaining: 46.4s\n",
      "98:\tlearn: 0.8803902\ttotal: 7.63s\tremaining: 46.3s\n",
      "99:\tlearn: 0.8820318\ttotal: 7.71s\tremaining: 46.3s\n",
      "100:\tlearn: 0.8822669\ttotal: 7.79s\tremaining: 46.2s\n",
      "101:\tlearn: 0.8824734\ttotal: 7.86s\tremaining: 46.1s\n",
      "102:\tlearn: 0.8831701\ttotal: 7.94s\tremaining: 46s\n",
      "103:\tlearn: 0.8841838\ttotal: 8.01s\tremaining: 45.9s\n",
      "104:\tlearn: 0.8847634\ttotal: 8.09s\tremaining: 45.8s\n",
      "105:\tlearn: 0.8863958\ttotal: 8.16s\tremaining: 45.7s\n",
      "106:\tlearn: 0.8875341\ttotal: 8.23s\tremaining: 45.6s\n",
      "107:\tlearn: 0.8881303\ttotal: 8.31s\tremaining: 45.6s\n",
      "108:\tlearn: 0.8886723\ttotal: 8.39s\tremaining: 45.5s\n",
      "109:\tlearn: 0.8901126\ttotal: 8.46s\tremaining: 45.4s\n",
      "110:\tlearn: 0.8902742\ttotal: 8.54s\tremaining: 45.3s\n",
      "111:\tlearn: 0.8902528\ttotal: 8.61s\tremaining: 45.2s\n",
      "112:\tlearn: 0.8900473\ttotal: 8.68s\tremaining: 45.1s\n",
      "113:\tlearn: 0.8907506\ttotal: 8.76s\tremaining: 45s\n",
      "114:\tlearn: 0.8913340\ttotal: 8.83s\tremaining: 44.9s\n",
      "115:\tlearn: 0.8932228\ttotal: 8.91s\tremaining: 44.8s\n",
      "116:\tlearn: 0.8939549\ttotal: 8.98s\tremaining: 44.8s\n",
      "117:\tlearn: 0.8951935\ttotal: 9.05s\tremaining: 44.7s\n",
      "118:\tlearn: 0.8967534\ttotal: 9.13s\tremaining: 44.6s\n",
      "119:\tlearn: 0.8976985\ttotal: 9.2s\tremaining: 44.5s\n",
      "120:\tlearn: 0.8978180\ttotal: 9.28s\tremaining: 44.4s\n",
      "121:\tlearn: 0.8986891\ttotal: 9.35s\tremaining: 44.3s\n",
      "122:\tlearn: 0.8986608\ttotal: 9.43s\tremaining: 44.2s\n",
      "123:\tlearn: 0.8998441\ttotal: 9.5s\tremaining: 44.1s\n",
      "124:\tlearn: 0.8998782\ttotal: 9.58s\tremaining: 44.1s\n",
      "125:\tlearn: 0.9009114\ttotal: 9.65s\tremaining: 44s\n",
      "126:\tlearn: 0.9011118\ttotal: 9.72s\tremaining: 43.9s\n",
      "127:\tlearn: 0.9027981\ttotal: 9.8s\tremaining: 43.8s\n",
      "128:\tlearn: 0.9033296\ttotal: 9.88s\tremaining: 43.7s\n",
      "129:\tlearn: 0.9044741\ttotal: 9.95s\tremaining: 43.6s\n",
      "130:\tlearn: 0.9049430\ttotal: 10s\tremaining: 43.5s\n",
      "131:\tlearn: 0.9055114\ttotal: 10.1s\tremaining: 43.5s\n",
      "132:\tlearn: 0.9055648\ttotal: 10.2s\tremaining: 43.4s\n",
      "133:\tlearn: 0.9058296\ttotal: 10.3s\tremaining: 43.3s\n",
      "134:\tlearn: 0.9063689\ttotal: 10.3s\tremaining: 43.2s\n",
      "135:\tlearn: 0.9078941\ttotal: 10.4s\tremaining: 43.2s\n",
      "136:\tlearn: 0.9090998\ttotal: 10.5s\tremaining: 43.1s\n",
      "137:\tlearn: 0.9091530\ttotal: 10.6s\tremaining: 43s\n",
      "138:\tlearn: 0.9097466\ttotal: 10.6s\tremaining: 43s\n",
      "139:\tlearn: 0.9102695\ttotal: 10.7s\tremaining: 42.9s\n",
      "140:\tlearn: 0.9112899\ttotal: 10.8s\tremaining: 42.8s\n",
      "141:\tlearn: 0.9116959\ttotal: 10.9s\tremaining: 42.7s\n",
      "142:\tlearn: 0.9114479\ttotal: 10.9s\tremaining: 42.6s\n",
      "143:\tlearn: 0.9116515\ttotal: 11s\tremaining: 42.5s\n",
      "144:\tlearn: 0.9126706\ttotal: 11.1s\tremaining: 42.4s\n",
      "145:\tlearn: 0.9130732\ttotal: 11.2s\tremaining: 42.4s\n",
      "146:\tlearn: 0.9132683\ttotal: 11.2s\tremaining: 42.3s\n",
      "147:\tlearn: 0.9134381\ttotal: 11.3s\tremaining: 42.2s\n",
      "148:\tlearn: 0.9142411\ttotal: 11.4s\tremaining: 42.1s\n",
      "149:\tlearn: 0.9152791\ttotal: 11.5s\tremaining: 42.1s\n",
      "150:\tlearn: 0.9155438\ttotal: 11.6s\tremaining: 42s\n",
      "151:\tlearn: 0.9161662\ttotal: 11.6s\tremaining: 41.9s\n",
      "152:\tlearn: 0.9166545\ttotal: 11.7s\tremaining: 41.9s\n",
      "153:\tlearn: 0.9176068\ttotal: 11.8s\tremaining: 41.8s\n",
      "154:\tlearn: 0.9177367\ttotal: 11.9s\tremaining: 41.7s\n",
      "155:\tlearn: 0.9185178\ttotal: 11.9s\tremaining: 41.6s\n",
      "156:\tlearn: 0.9191460\ttotal: 12s\tremaining: 41.6s\n",
      "157:\tlearn: 0.9192674\ttotal: 12.1s\tremaining: 41.5s\n",
      "158:\tlearn: 0.9198143\ttotal: 12.2s\tremaining: 41.4s\n",
      "159:\tlearn: 0.9203635\ttotal: 12.2s\tremaining: 41.3s\n",
      "160:\tlearn: 0.9204673\ttotal: 12.3s\tremaining: 41.2s\n",
      "161:\tlearn: 0.9209252\ttotal: 12.4s\tremaining: 41.1s\n",
      "162:\tlearn: 0.9215571\ttotal: 12.5s\tremaining: 41.1s\n",
      "163:\tlearn: 0.9216089\ttotal: 12.5s\tremaining: 41s\n",
      "164:\tlearn: 0.9220233\ttotal: 12.6s\tremaining: 40.9s\n",
      "165:\tlearn: 0.9232727\ttotal: 12.7s\tremaining: 40.8s\n",
      "166:\tlearn: 0.9228887\ttotal: 12.8s\tremaining: 40.8s\n",
      "167:\tlearn: 0.9229264\ttotal: 12.9s\tremaining: 40.7s\n",
      "168:\tlearn: 0.9235283\ttotal: 12.9s\tremaining: 40.6s\n",
      "169:\tlearn: 0.9247617\ttotal: 13s\tremaining: 40.6s\n",
      "170:\tlearn: 0.9253177\ttotal: 13.1s\tremaining: 40.5s\n",
      "171:\tlearn: 0.9252812\ttotal: 13.2s\tremaining: 40.4s\n",
      "172:\tlearn: 0.9260689\ttotal: 13.2s\tremaining: 40.4s\n",
      "173:\tlearn: 0.9266768\ttotal: 13.3s\tremaining: 40.3s\n",
      "174:\tlearn: 0.9276113\ttotal: 13.4s\tremaining: 40.2s\n",
      "175:\tlearn: 0.9277615\ttotal: 13.5s\tremaining: 40.2s\n",
      "176:\tlearn: 0.9280446\ttotal: 13.6s\tremaining: 40.1s\n",
      "177:\tlearn: 0.9284004\ttotal: 13.7s\tremaining: 40s\n",
      "178:\tlearn: 0.9282956\ttotal: 13.7s\tremaining: 40s\n",
      "179:\tlearn: 0.9289730\ttotal: 13.8s\tremaining: 39.9s\n",
      "180:\tlearn: 0.9293847\ttotal: 13.9s\tremaining: 39.8s\n",
      "181:\tlearn: 0.9300235\ttotal: 14s\tremaining: 39.7s\n",
      "182:\tlearn: 0.9300235\ttotal: 14s\tremaining: 39.6s\n",
      "183:\tlearn: 0.9308440\ttotal: 14.1s\tremaining: 39.6s\n",
      "184:\tlearn: 0.9314492\ttotal: 14.2s\tremaining: 39.5s\n",
      "185:\tlearn: 0.9320360\ttotal: 14.3s\tremaining: 39.4s\n",
      "186:\tlearn: 0.9321271\ttotal: 14.3s\tremaining: 39.3s\n",
      "187:\tlearn: 0.9326030\ttotal: 14.4s\tremaining: 39.3s\n",
      "188:\tlearn: 0.9333790\ttotal: 14.5s\tremaining: 39.2s\n",
      "189:\tlearn: 0.9332681\ttotal: 14.6s\tremaining: 39.1s\n",
      "190:\tlearn: 0.9329286\ttotal: 14.7s\tremaining: 39.1s\n",
      "191:\tlearn: 0.9329809\ttotal: 14.7s\tremaining: 39s\n",
      "192:\tlearn: 0.9334508\ttotal: 14.8s\tremaining: 38.9s\n",
      "193:\tlearn: 0.9335160\ttotal: 14.9s\tremaining: 38.9s\n",
      "194:\tlearn: 0.9342015\ttotal: 15s\tremaining: 38.8s\n",
      "195:\tlearn: 0.9345932\ttotal: 15.1s\tremaining: 38.7s\n",
      "196:\tlearn: 0.9356307\ttotal: 15.1s\tremaining: 38.6s\n",
      "197:\tlearn: 0.9363160\ttotal: 15.2s\tremaining: 38.6s\n",
      "198:\tlearn: 0.9363805\ttotal: 15.3s\tremaining: 38.5s\n",
      "199:\tlearn: 0.9360744\ttotal: 15.4s\tremaining: 38.4s\n",
      "200:\tlearn: 0.9366742\ttotal: 15.4s\tremaining: 38.3s\n",
      "201:\tlearn: 0.9370013\ttotal: 15.5s\tremaining: 38.3s\n",
      "202:\tlearn: 0.9373745\ttotal: 15.6s\tremaining: 38.2s\n",
      "203:\tlearn: 0.9375306\ttotal: 15.7s\tremaining: 38.1s\n",
      "204:\tlearn: 0.9376529\ttotal: 15.8s\tremaining: 38.1s\n",
      "205:\tlearn: 0.9376468\ttotal: 15.8s\tremaining: 38s\n",
      "206:\tlearn: 0.9382801\ttotal: 15.9s\tremaining: 37.9s\n",
      "207:\tlearn: 0.9391151\ttotal: 16s\tremaining: 37.9s\n",
      "208:\tlearn: 0.9389653\ttotal: 16.1s\tremaining: 37.8s\n",
      "209:\tlearn: 0.9391670\ttotal: 16.2s\tremaining: 37.7s\n",
      "210:\tlearn: 0.9397602\ttotal: 16.2s\tremaining: 37.6s\n",
      "211:\tlearn: 0.9403650\ttotal: 16.3s\tremaining: 37.5s\n",
      "212:\tlearn: 0.9404110\ttotal: 16.4s\tremaining: 37.4s\n",
      "213:\tlearn: 0.9402379\ttotal: 16.5s\tremaining: 37.4s\n",
      "214:\tlearn: 0.9407904\ttotal: 16.5s\tremaining: 37.3s\n",
      "215:\tlearn: 0.9408768\ttotal: 16.6s\tremaining: 37.3s\n",
      "216:\tlearn: 0.9411592\ttotal: 16.7s\tremaining: 37.2s\n",
      "217:\tlearn: 0.9419254\ttotal: 16.8s\tremaining: 37.1s\n",
      "218:\tlearn: 0.9425017\ttotal: 16.9s\tremaining: 37s\n",
      "219:\tlearn: 0.9431818\ttotal: 16.9s\tremaining: 36.9s\n",
      "220:\tlearn: 0.9430656\ttotal: 17s\tremaining: 36.9s\n",
      "221:\tlearn: 0.9431523\ttotal: 17.1s\tremaining: 36.8s\n",
      "222:\tlearn: 0.9435737\ttotal: 17.2s\tremaining: 36.7s\n",
      "223:\tlearn: 0.9434812\ttotal: 17.2s\tremaining: 36.6s\n",
      "224:\tlearn: 0.9438158\ttotal: 17.3s\tremaining: 36.6s\n",
      "225:\tlearn: 0.9442947\ttotal: 17.4s\tremaining: 36.5s\n",
      "226:\tlearn: 0.9444853\ttotal: 17.5s\tremaining: 36.4s\n",
      "227:\tlearn: 0.9448418\ttotal: 17.5s\tremaining: 36.3s\n",
      "228:\tlearn: 0.9457858\ttotal: 17.6s\tremaining: 36.3s\n",
      "229:\tlearn: 0.9459248\ttotal: 17.7s\tremaining: 36.2s\n",
      "230:\tlearn: 0.9459817\ttotal: 17.8s\tremaining: 36.1s\n",
      "231:\tlearn: 0.9460691\ttotal: 17.9s\tremaining: 36s\n",
      "232:\tlearn: 0.9461154\ttotal: 17.9s\tremaining: 35.9s\n",
      "233:\tlearn: 0.9462081\ttotal: 18s\tremaining: 35.9s\n",
      "234:\tlearn: 0.9469816\ttotal: 18.1s\tremaining: 35.8s\n",
      "235:\tlearn: 0.9473323\ttotal: 18.2s\tremaining: 35.7s\n",
      "236:\tlearn: 0.9475129\ttotal: 18.2s\tremaining: 35.6s\n",
      "237:\tlearn: 0.9473478\ttotal: 18.3s\tremaining: 35.5s\n",
      "238:\tlearn: 0.9480551\ttotal: 18.4s\tremaining: 35.5s\n",
      "239:\tlearn: 0.9480602\ttotal: 18.5s\tremaining: 35.4s\n",
      "240:\tlearn: 0.9485821\ttotal: 18.5s\tremaining: 35.3s\n",
      "241:\tlearn: 0.9491509\ttotal: 18.6s\tremaining: 35.2s\n",
      "242:\tlearn: 0.9501743\ttotal: 18.7s\tremaining: 35.1s\n",
      "243:\tlearn: 0.9504737\ttotal: 18.8s\tremaining: 35.1s\n",
      "244:\tlearn: 0.9506652\ttotal: 18.8s\tremaining: 35s\n",
      "245:\tlearn: 0.9510950\ttotal: 18.9s\tremaining: 34.9s\n",
      "246:\tlearn: 0.9513476\ttotal: 19s\tremaining: 34.8s\n",
      "247:\tlearn: 0.9519882\ttotal: 19.1s\tremaining: 34.7s\n",
      "248:\tlearn: 0.9523716\ttotal: 19.1s\tremaining: 34.7s\n",
      "249:\tlearn: 0.9527223\ttotal: 19.2s\tremaining: 34.6s\n",
      "250:\tlearn: 0.9532178\ttotal: 19.3s\tremaining: 34.5s\n",
      "251:\tlearn: 0.9534050\ttotal: 19.4s\tremaining: 34.4s\n",
      "252:\tlearn: 0.9538915\ttotal: 19.4s\tremaining: 34.3s\n",
      "253:\tlearn: 0.9543780\ttotal: 19.5s\tremaining: 34.3s\n",
      "254:\tlearn: 0.9544428\ttotal: 19.6s\tremaining: 34.2s\n",
      "255:\tlearn: 0.9546169\ttotal: 19.7s\tremaining: 34.1s\n",
      "256:\tlearn: 0.9547151\ttotal: 19.8s\tremaining: 34s\n",
      "257:\tlearn: 0.9547576\ttotal: 19.8s\tremaining: 34s\n",
      "258:\tlearn: 0.9544763\ttotal: 19.9s\tremaining: 33.9s\n",
      "259:\tlearn: 0.9545365\ttotal: 20s\tremaining: 33.8s\n",
      "260:\tlearn: 0.9546727\ttotal: 20.1s\tremaining: 33.7s\n",
      "261:\tlearn: 0.9553133\ttotal: 20.1s\tremaining: 33.7s\n",
      "262:\tlearn: 0.9552151\ttotal: 20.2s\tremaining: 33.6s\n",
      "263:\tlearn: 0.9557957\ttotal: 20.3s\tremaining: 33.5s\n",
      "264:\tlearn: 0.9559965\ttotal: 20.4s\tremaining: 33.4s\n",
      "265:\tlearn: 0.9564833\ttotal: 20.4s\tremaining: 33.4s\n",
      "266:\tlearn: 0.9564833\ttotal: 20.5s\tremaining: 33.3s\n",
      "267:\tlearn: 0.9569148\ttotal: 20.6s\tremaining: 33.2s\n",
      "268:\tlearn: 0.9571541\ttotal: 20.7s\tremaining: 33.1s\n",
      "269:\tlearn: 0.9573935\ttotal: 20.7s\tremaining: 33s\n",
      "270:\tlearn: 0.9577866\ttotal: 20.8s\tremaining: 32.9s\n",
      "271:\tlearn: 0.9582186\ttotal: 20.9s\tremaining: 32.9s\n",
      "272:\tlearn: 0.9583681\ttotal: 21s\tremaining: 32.8s\n",
      "273:\tlearn: 0.9587573\ttotal: 21.1s\tremaining: 32.7s\n",
      "274:\tlearn: 0.9582862\ttotal: 21.1s\tremaining: 32.6s\n",
      "275:\tlearn: 0.9589701\ttotal: 21.2s\tremaining: 32.6s\n",
      "276:\tlearn: 0.9590051\ttotal: 21.3s\tremaining: 32.5s\n",
      "277:\tlearn: 0.9593864\ttotal: 21.3s\tremaining: 32.4s\n",
      "278:\tlearn: 0.9595319\ttotal: 21.4s\tremaining: 32.3s\n",
      "279:\tlearn: 0.9600197\ttotal: 21.5s\tremaining: 32.2s\n",
      "280:\tlearn: 0.9604998\ttotal: 21.6s\tremaining: 32.2s\n",
      "281:\tlearn: 0.9612319\ttotal: 21.6s\tremaining: 32.1s\n",
      "282:\tlearn: 0.9614173\ttotal: 21.7s\tremaining: 32s\n",
      "283:\tlearn: 0.9615669\ttotal: 21.8s\tremaining: 31.9s\n",
      "284:\tlearn: 0.9618073\ttotal: 21.9s\tremaining: 31.9s\n",
      "285:\tlearn: 0.9627332\ttotal: 22s\tremaining: 31.8s\n",
      "286:\tlearn: 0.9629338\ttotal: 22s\tremaining: 31.7s\n",
      "287:\tlearn: 0.9634188\ttotal: 22.1s\tremaining: 31.6s\n",
      "288:\tlearn: 0.9633642\ttotal: 22.2s\tremaining: 31.5s\n",
      "289:\tlearn: 0.9633131\ttotal: 22.3s\tremaining: 31.5s\n",
      "290:\tlearn: 0.9636417\ttotal: 22.3s\tremaining: 31.4s\n",
      "291:\tlearn: 0.9641784\ttotal: 22.4s\tremaining: 31.3s\n",
      "292:\tlearn: 0.9641273\ttotal: 22.5s\tremaining: 31.3s\n",
      "293:\tlearn: 0.9639409\ttotal: 22.6s\tremaining: 31.2s\n",
      "294:\tlearn: 0.9639480\ttotal: 22.6s\tremaining: 31.1s\n",
      "295:\tlearn: 0.9638495\ttotal: 22.7s\tremaining: 31s\n",
      "296:\tlearn: 0.9641379\ttotal: 22.8s\tremaining: 30.9s\n",
      "297:\tlearn: 0.9645145\ttotal: 22.9s\tremaining: 30.9s\n",
      "298:\tlearn: 0.9645621\ttotal: 23s\tremaining: 30.8s\n",
      "299:\tlearn: 0.9646537\ttotal: 23s\tremaining: 30.7s\n",
      "300:\tlearn: 0.9650888\ttotal: 23.1s\tremaining: 30.6s\n",
      "301:\tlearn: 0.9650853\ttotal: 23.2s\tremaining: 30.5s\n",
      "302:\tlearn: 0.9654560\ttotal: 23.3s\tremaining: 30.5s\n",
      "303:\tlearn: 0.9662799\ttotal: 23.3s\tremaining: 30.4s\n",
      "304:\tlearn: 0.9666206\ttotal: 23.4s\tremaining: 30.3s\n",
      "305:\tlearn: 0.9665350\ttotal: 23.5s\tremaining: 30.2s\n",
      "306:\tlearn: 0.9670189\ttotal: 23.6s\tremaining: 30.2s\n",
      "307:\tlearn: 0.9674138\ttotal: 23.6s\tremaining: 30.1s\n",
      "308:\tlearn: 0.9676399\ttotal: 23.7s\tremaining: 30s\n",
      "309:\tlearn: 0.9677866\ttotal: 23.8s\tremaining: 29.9s\n",
      "310:\tlearn: 0.9678949\ttotal: 23.9s\tremaining: 29.8s\n",
      "311:\tlearn: 0.9679810\ttotal: 23.9s\tremaining: 29.8s\n",
      "312:\tlearn: 0.9682744\ttotal: 24s\tremaining: 29.7s\n",
      "313:\tlearn: 0.9683253\ttotal: 24.1s\tremaining: 29.6s\n",
      "314:\tlearn: 0.9687654\ttotal: 24.1s\tremaining: 29.5s\n",
      "315:\tlearn: 0.9684627\ttotal: 24.2s\tremaining: 29.4s\n",
      "316:\tlearn: 0.9685043\ttotal: 24.3s\tremaining: 29.4s\n",
      "317:\tlearn: 0.9687531\ttotal: 24.4s\tremaining: 29.3s\n",
      "318:\tlearn: 0.9694302\ttotal: 24.4s\tremaining: 29.2s\n",
      "319:\tlearn: 0.9697719\ttotal: 24.5s\tremaining: 29.1s\n",
      "320:\tlearn: 0.9700148\ttotal: 24.6s\tremaining: 29s\n",
      "321:\tlearn: 0.9702187\ttotal: 24.7s\tremaining: 29s\n",
      "322:\tlearn: 0.9701766\ttotal: 24.7s\tremaining: 28.9s\n",
      "323:\tlearn: 0.9703205\ttotal: 24.8s\tremaining: 28.8s\n",
      "324:\tlearn: 0.9708123\ttotal: 24.9s\tremaining: 28.7s\n",
      "325:\tlearn: 0.9704675\ttotal: 25s\tremaining: 28.7s\n",
      "326:\tlearn: 0.9707556\ttotal: 25.1s\tremaining: 28.6s\n",
      "327:\tlearn: 0.9708911\ttotal: 25.1s\tremaining: 28.5s\n",
      "328:\tlearn: 0.9705970\ttotal: 25.2s\tremaining: 28.4s\n",
      "329:\tlearn: 0.9705489\ttotal: 25.3s\tremaining: 28.3s\n",
      "330:\tlearn: 0.9705941\ttotal: 25.4s\tremaining: 28.3s\n",
      "331:\tlearn: 0.9708853\ttotal: 25.4s\tremaining: 28.2s\n",
      "332:\tlearn: 0.9712248\ttotal: 25.5s\tremaining: 28.1s\n",
      "333:\tlearn: 0.9716098\ttotal: 25.6s\tremaining: 28s\n",
      "334:\tlearn: 0.9717089\ttotal: 25.7s\tremaining: 28s\n",
      "335:\tlearn: 0.9719126\ttotal: 25.7s\tremaining: 27.9s\n",
      "336:\tlearn: 0.9720145\ttotal: 25.8s\tremaining: 27.8s\n",
      "337:\tlearn: 0.9723598\ttotal: 25.9s\tremaining: 27.7s\n",
      "338:\tlearn: 0.9727480\ttotal: 26s\tremaining: 27.7s\n",
      "339:\tlearn: 0.9728471\ttotal: 26.1s\tremaining: 27.6s\n",
      "340:\tlearn: 0.9730426\ttotal: 26.1s\tremaining: 27.5s\n",
      "341:\tlearn: 0.9734417\ttotal: 26.2s\tremaining: 27.4s\n",
      "342:\tlearn: 0.9735785\ttotal: 26.3s\tremaining: 27.3s\n",
      "343:\tlearn: 0.9736751\ttotal: 26.4s\tremaining: 27.3s\n",
      "344:\tlearn: 0.9740717\ttotal: 26.4s\tremaining: 27.2s\n",
      "345:\tlearn: 0.9741200\ttotal: 26.5s\tremaining: 27.1s\n",
      "346:\tlearn: 0.9739243\ttotal: 26.6s\tremaining: 27s\n",
      "347:\tlearn: 0.9739217\ttotal: 26.6s\tremaining: 27s\n",
      "348:\tlearn: 0.9743107\ttotal: 26.7s\tremaining: 26.9s\n",
      "349:\tlearn: 0.9745523\ttotal: 26.8s\tremaining: 26.8s\n",
      "350:\tlearn: 0.9743564\ttotal: 26.9s\tremaining: 26.8s\n",
      "351:\tlearn: 0.9744556\ttotal: 27s\tremaining: 26.7s\n",
      "352:\tlearn: 0.9743513\ttotal: 27.1s\tremaining: 26.6s\n",
      "353:\tlearn: 0.9748375\ttotal: 27.1s\tremaining: 26.5s\n",
      "354:\tlearn: 0.9750794\ttotal: 27.2s\tremaining: 26.5s\n",
      "355:\tlearn: 0.9753264\ttotal: 27.3s\tremaining: 26.4s\n",
      "356:\tlearn: 0.9753748\ttotal: 27.4s\tremaining: 26.3s\n",
      "357:\tlearn: 0.9756170\ttotal: 27.5s\tremaining: 26.2s\n",
      "358:\tlearn: 0.9759563\ttotal: 27.5s\tremaining: 26.2s\n",
      "359:\tlearn: 0.9759563\ttotal: 27.6s\tremaining: 26.1s\n",
      "360:\tlearn: 0.9760556\ttotal: 27.7s\tremaining: 26s\n",
      "361:\tlearn: 0.9762106\ttotal: 27.8s\tremaining: 25.9s\n",
      "362:\tlearn: 0.9763146\ttotal: 27.9s\tremaining: 25.9s\n",
      "363:\tlearn: 0.9759611\ttotal: 27.9s\tremaining: 25.8s\n",
      "364:\tlearn: 0.9763561\ttotal: 28s\tremaining: 25.7s\n",
      "365:\tlearn: 0.9765062\ttotal: 28.1s\tremaining: 25.6s\n",
      "366:\tlearn: 0.9766518\ttotal: 28.2s\tremaining: 25.6s\n",
      "367:\tlearn: 0.9765062\ttotal: 28.3s\tremaining: 25.5s\n",
      "368:\tlearn: 0.9766056\ttotal: 28.3s\tremaining: 25.4s\n",
      "369:\tlearn: 0.9767534\ttotal: 28.4s\tremaining: 25.3s\n",
      "370:\tlearn: 0.9768019\ttotal: 28.5s\tremaining: 25.3s\n",
      "371:\tlearn: 0.9766610\ttotal: 28.6s\tremaining: 25.2s\n",
      "372:\tlearn: 0.9767557\ttotal: 28.6s\tremaining: 25.1s\n",
      "373:\tlearn: 0.9771971\ttotal: 28.7s\tremaining: 25s\n",
      "374:\tlearn: 0.9773450\ttotal: 28.8s\tremaining: 25s\n",
      "375:\tlearn: 0.9774884\ttotal: 28.9s\tremaining: 24.9s\n",
      "376:\tlearn: 0.9776828\ttotal: 29s\tremaining: 24.8s\n",
      "377:\tlearn: 0.9779280\ttotal: 29s\tremaining: 24.7s\n",
      "378:\tlearn: 0.9779788\ttotal: 29.1s\tremaining: 24.7s\n",
      "379:\tlearn: 0.9781733\ttotal: 29.2s\tremaining: 24.6s\n",
      "380:\tlearn: 0.9783722\ttotal: 29.3s\tremaining: 24.5s\n",
      "381:\tlearn: 0.9783679\ttotal: 29.4s\tremaining: 24.4s\n",
      "382:\tlearn: 0.9786663\ttotal: 29.4s\tremaining: 24.4s\n",
      "383:\tlearn: 0.9786641\ttotal: 29.5s\tremaining: 24.3s\n",
      "384:\tlearn: 0.9787615\ttotal: 29.6s\tremaining: 24.2s\n",
      "385:\tlearn: 0.9787678\ttotal: 29.7s\tremaining: 24.1s\n",
      "386:\tlearn: 0.9791615\ttotal: 29.7s\tremaining: 24.1s\n",
      "387:\tlearn: 0.9791128\ttotal: 29.8s\tremaining: 24s\n",
      "388:\tlearn: 0.9790154\ttotal: 29.9s\tremaining: 23.9s\n",
      "389:\tlearn: 0.9793097\ttotal: 30s\tremaining: 23.8s\n",
      "390:\tlearn: 0.9795533\ttotal: 30.1s\tremaining: 23.8s\n",
      "391:\tlearn: 0.9799453\ttotal: 30.1s\tremaining: 23.7s\n",
      "392:\tlearn: 0.9798397\ttotal: 30.2s\tremaining: 23.6s\n",
      "393:\tlearn: 0.9803297\ttotal: 30.3s\tremaining: 23.5s\n",
      "394:\tlearn: 0.9803336\ttotal: 30.4s\tremaining: 23.4s\n",
      "395:\tlearn: 0.9804820\ttotal: 30.4s\tremaining: 23.4s\n",
      "396:\tlearn: 0.9804839\ttotal: 30.5s\tremaining: 23.3s\n",
      "397:\tlearn: 0.9806304\ttotal: 30.6s\tremaining: 23.2s\n",
      "398:\tlearn: 0.9808238\ttotal: 30.7s\tremaining: 23.1s\n",
      "399:\tlearn: 0.9810212\ttotal: 30.7s\tremaining: 23s\n",
      "400:\tlearn: 0.9812167\ttotal: 30.8s\tremaining: 23s\n",
      "401:\tlearn: 0.9813163\ttotal: 30.9s\tremaining: 22.9s\n",
      "402:\tlearn: 0.9813182\ttotal: 31s\tremaining: 22.8s\n",
      "403:\tlearn: 0.9814667\ttotal: 31s\tremaining: 22.7s\n",
      "404:\tlearn: 0.9813219\ttotal: 31.2s\tremaining: 22.7s\n",
      "405:\tlearn: 0.9816697\ttotal: 31.2s\tremaining: 22.6s\n",
      "406:\tlearn: 0.9817167\ttotal: 31.3s\tremaining: 22.5s\n",
      "407:\tlearn: 0.9817675\ttotal: 31.4s\tremaining: 22.5s\n",
      "408:\tlearn: 0.9817656\ttotal: 31.5s\tremaining: 22.4s\n",
      "409:\tlearn: 0.9818146\ttotal: 31.6s\tremaining: 22.3s\n",
      "410:\tlearn: 0.9819631\ttotal: 31.7s\tremaining: 22.3s\n",
      "411:\tlearn: 0.9821081\ttotal: 31.8s\tremaining: 22.2s\n",
      "412:\tlearn: 0.9825034\ttotal: 31.8s\tremaining: 22.1s\n",
      "413:\tlearn: 0.9823057\ttotal: 31.9s\tremaining: 22.1s\n",
      "414:\tlearn: 0.9826013\ttotal: 32s\tremaining: 22s\n",
      "415:\tlearn: 0.9828007\ttotal: 32.1s\tremaining: 21.9s\n",
      "416:\tlearn: 0.9828987\ttotal: 32.2s\tremaining: 21.9s\n",
      "417:\tlearn: 0.9831929\ttotal: 32.3s\tremaining: 21.8s\n",
      "418:\tlearn: 0.9833890\ttotal: 32.4s\tremaining: 21.7s\n",
      "419:\tlearn: 0.9832419\ttotal: 32.5s\tremaining: 21.7s\n",
      "420:\tlearn: 0.9835362\ttotal: 32.6s\tremaining: 21.6s\n",
      "421:\tlearn: 0.9834872\ttotal: 32.7s\tremaining: 21.5s\n",
      "422:\tlearn: 0.9834888\ttotal: 32.7s\tremaining: 21.4s\n",
      "423:\tlearn: 0.9838846\ttotal: 32.8s\tremaining: 21.4s\n",
      "424:\tlearn: 0.9841793\ttotal: 32.9s\tremaining: 21.3s\n",
      "425:\tlearn: 0.9840303\ttotal: 33s\tremaining: 21.2s\n",
      "426:\tlearn: 0.9841793\ttotal: 33.1s\tremaining: 21.1s\n",
      "427:\tlearn: 0.9841793\ttotal: 33.2s\tremaining: 21.1s\n",
      "428:\tlearn: 0.9842759\ttotal: 33.3s\tremaining: 21s\n",
      "429:\tlearn: 0.9843251\ttotal: 33.4s\tremaining: 20.9s\n",
      "430:\tlearn: 0.9844249\ttotal: 33.4s\tremaining: 20.9s\n",
      "431:\tlearn: 0.9845217\ttotal: 33.5s\tremaining: 20.8s\n",
      "432:\tlearn: 0.9845232\ttotal: 33.6s\tremaining: 20.7s\n",
      "433:\tlearn: 0.9844725\ttotal: 33.7s\tremaining: 20.6s\n",
      "434:\tlearn: 0.9845232\ttotal: 33.8s\tremaining: 20.6s\n",
      "435:\tlearn: 0.9846215\ttotal: 33.9s\tremaining: 20.5s\n",
      "436:\tlearn: 0.9846707\ttotal: 33.9s\tremaining: 20.4s\n",
      "437:\tlearn: 0.9850180\ttotal: 34s\tremaining: 20.4s\n",
      "438:\tlearn: 0.9849166\ttotal: 34.1s\tremaining: 20.3s\n",
      "439:\tlearn: 0.9848182\ttotal: 34.2s\tremaining: 20.2s\n",
      "440:\tlearn: 0.9850642\ttotal: 34.3s\tremaining: 20.1s\n",
      "441:\tlearn: 0.9853132\ttotal: 34.3s\tremaining: 20s\n",
      "442:\tlearn: 0.9853132\ttotal: 34.4s\tremaining: 20s\n",
      "443:\tlearn: 0.9853624\ttotal: 34.5s\tremaining: 19.9s\n",
      "444:\tlearn: 0.9859056\ttotal: 34.6s\tremaining: 19.8s\n",
      "445:\tlearn: 0.9858521\ttotal: 34.7s\tremaining: 19.7s\n",
      "446:\tlearn: 0.9858986\ttotal: 34.7s\tremaining: 19.7s\n",
      "447:\tlearn: 0.9858507\ttotal: 34.8s\tremaining: 19.6s\n",
      "448:\tlearn: 0.9859493\ttotal: 34.9s\tremaining: 19.5s\n",
      "449:\tlearn: 0.9862452\ttotal: 35s\tremaining: 19.4s\n",
      "450:\tlearn: 0.9860958\ttotal: 35s\tremaining: 19.4s\n",
      "451:\tlearn: 0.9862945\ttotal: 35.1s\tremaining: 19.3s\n",
      "452:\tlearn: 0.9863959\ttotal: 35.2s\tremaining: 19.2s\n",
      "453:\tlearn: 0.9864453\ttotal: 35.3s\tremaining: 19.1s\n",
      "454:\tlearn: 0.9865960\ttotal: 35.3s\tremaining: 19s\n",
      "455:\tlearn: 0.9868428\ttotal: 35.4s\tremaining: 19s\n",
      "456:\tlearn: 0.9867440\ttotal: 35.5s\tremaining: 18.9s\n",
      "457:\tlearn: 0.9868401\ttotal: 35.6s\tremaining: 18.8s\n",
      "458:\tlearn: 0.9868428\ttotal: 35.7s\tremaining: 18.7s\n",
      "459:\tlearn: 0.9868934\ttotal: 35.7s\tremaining: 18.6s\n",
      "460:\tlearn: 0.9870416\ttotal: 35.8s\tremaining: 18.6s\n",
      "461:\tlearn: 0.9869428\ttotal: 35.9s\tremaining: 18.5s\n",
      "462:\tlearn: 0.9870429\ttotal: 36s\tremaining: 18.4s\n",
      "463:\tlearn: 0.9871416\ttotal: 36s\tremaining: 18.3s\n",
      "464:\tlearn: 0.9872404\ttotal: 36.1s\tremaining: 18.3s\n",
      "465:\tlearn: 0.9873392\ttotal: 36.2s\tremaining: 18.2s\n",
      "466:\tlearn: 0.9874862\ttotal: 36.3s\tremaining: 18.1s\n",
      "467:\tlearn: 0.9876852\ttotal: 36.4s\tremaining: 18s\n",
      "468:\tlearn: 0.9879349\ttotal: 36.4s\tremaining: 17.9s\n",
      "469:\tlearn: 0.9879832\ttotal: 36.5s\tremaining: 17.9s\n",
      "470:\tlearn: 0.9882306\ttotal: 36.6s\tremaining: 17.8s\n",
      "471:\tlearn: 0.9880809\ttotal: 36.7s\tremaining: 17.7s\n",
      "472:\tlearn: 0.9882306\ttotal: 36.7s\tremaining: 17.6s\n",
      "473:\tlearn: 0.9881316\ttotal: 36.8s\tremaining: 17.6s\n",
      "474:\tlearn: 0.9882318\ttotal: 36.9s\tremaining: 17.5s\n",
      "475:\tlearn: 0.9883284\ttotal: 37s\tremaining: 17.4s\n",
      "476:\tlearn: 0.9882789\ttotal: 37.1s\tremaining: 17.3s\n",
      "477:\tlearn: 0.9883284\ttotal: 37.1s\tremaining: 17.2s\n",
      "478:\tlearn: 0.9884286\ttotal: 37.2s\tremaining: 17.2s\n",
      "479:\tlearn: 0.9886267\ttotal: 37.3s\tremaining: 17.1s\n",
      "480:\tlearn: 0.9888744\ttotal: 37.4s\tremaining: 17s\n",
      "481:\tlearn: 0.9891234\ttotal: 37.4s\tremaining: 16.9s\n",
      "482:\tlearn: 0.9889240\ttotal: 37.5s\tremaining: 16.9s\n",
      "483:\tlearn: 0.9889240\ttotal: 37.6s\tremaining: 16.8s\n",
      "484:\tlearn: 0.9888744\ttotal: 37.7s\tremaining: 16.7s\n",
      "485:\tlearn: 0.9892225\ttotal: 37.7s\tremaining: 16.6s\n",
      "486:\tlearn: 0.9891740\ttotal: 37.8s\tremaining: 16.5s\n",
      "487:\tlearn: 0.9892732\ttotal: 37.9s\tremaining: 16.5s\n",
      "488:\tlearn: 0.9892236\ttotal: 38s\tremaining: 16.4s\n",
      "489:\tlearn: 0.9892732\ttotal: 38.1s\tremaining: 16.3s\n",
      "490:\tlearn: 0.9893228\ttotal: 38.1s\tremaining: 16.2s\n",
      "491:\tlearn: 0.9892732\ttotal: 38.2s\tremaining: 16.2s\n",
      "492:\tlearn: 0.9893228\ttotal: 38.3s\tremaining: 16.1s\n",
      "493:\tlearn: 0.9894716\ttotal: 38.4s\tremaining: 16s\n",
      "494:\tlearn: 0.9895212\ttotal: 38.4s\tremaining: 15.9s\n",
      "495:\tlearn: 0.9895212\ttotal: 38.5s\tremaining: 15.8s\n",
      "496:\tlearn: 0.9897693\ttotal: 38.6s\tremaining: 15.8s\n",
      "497:\tlearn: 0.9896711\ttotal: 38.7s\tremaining: 15.7s\n",
      "498:\tlearn: 0.9897197\ttotal: 38.7s\tremaining: 15.6s\n",
      "499:\tlearn: 0.9897693\ttotal: 38.8s\tremaining: 15.5s\n",
      "500:\tlearn: 0.9898696\ttotal: 38.9s\tremaining: 15.5s\n",
      "501:\tlearn: 0.9899699\ttotal: 39s\tremaining: 15.4s\n",
      "502:\tlearn: 0.9901676\ttotal: 39.1s\tremaining: 15.3s\n",
      "503:\tlearn: 0.9903185\ttotal: 39.2s\tremaining: 15.2s\n",
      "504:\tlearn: 0.9904676\ttotal: 39.3s\tremaining: 15.2s\n",
      "505:\tlearn: 0.9905670\ttotal: 39.4s\tremaining: 15.1s\n",
      "506:\tlearn: 0.9906167\ttotal: 39.4s\tremaining: 15s\n",
      "507:\tlearn: 0.9910643\ttotal: 39.5s\tremaining: 14.9s\n",
      "508:\tlearn: 0.9909150\ttotal: 39.6s\tremaining: 14.9s\n",
      "509:\tlearn: 0.9908653\ttotal: 39.7s\tremaining: 14.8s\n",
      "510:\tlearn: 0.9910145\ttotal: 39.7s\tremaining: 14.7s\n",
      "511:\tlearn: 0.9910163\ttotal: 39.8s\tremaining: 14.6s\n",
      "512:\tlearn: 0.9910661\ttotal: 39.9s\tremaining: 14.5s\n",
      "513:\tlearn: 0.9912153\ttotal: 40s\tremaining: 14.5s\n",
      "514:\tlearn: 0.9913646\ttotal: 40s\tremaining: 14.4s\n",
      "515:\tlearn: 0.9914144\ttotal: 40.1s\tremaining: 14.3s\n",
      "516:\tlearn: 0.9914126\ttotal: 40.2s\tremaining: 14.2s\n",
      "517:\tlearn: 0.9914126\ttotal: 40.3s\tremaining: 14.2s\n",
      "518:\tlearn: 0.9914126\ttotal: 40.4s\tremaining: 14.1s\n",
      "519:\tlearn: 0.9913629\ttotal: 40.4s\tremaining: 14s\n",
      "520:\tlearn: 0.9914126\ttotal: 40.5s\tremaining: 13.9s\n",
      "521:\tlearn: 0.9914126\ttotal: 40.6s\tremaining: 13.8s\n",
      "522:\tlearn: 0.9915131\ttotal: 40.7s\tremaining: 13.8s\n",
      "523:\tlearn: 0.9913637\ttotal: 40.8s\tremaining: 13.7s\n",
      "524:\tlearn: 0.9914135\ttotal: 40.8s\tremaining: 13.6s\n",
      "525:\tlearn: 0.9914624\ttotal: 40.9s\tremaining: 13.5s\n",
      "526:\tlearn: 0.9913629\ttotal: 41s\tremaining: 13.5s\n",
      "527:\tlearn: 0.9915122\ttotal: 41.1s\tremaining: 13.4s\n",
      "528:\tlearn: 0.9916135\ttotal: 41.1s\tremaining: 13.3s\n",
      "529:\tlearn: 0.9917131\ttotal: 41.2s\tremaining: 13.2s\n",
      "530:\tlearn: 0.9918127\ttotal: 41.3s\tremaining: 13.1s\n",
      "531:\tlearn: 0.9918626\ttotal: 41.4s\tremaining: 13.1s\n",
      "532:\tlearn: 0.9920619\ttotal: 41.4s\tremaining: 13s\n",
      "533:\tlearn: 0.9921117\ttotal: 41.5s\tremaining: 12.9s\n",
      "534:\tlearn: 0.9922613\ttotal: 41.6s\tremaining: 12.8s\n",
      "535:\tlearn: 0.9922613\ttotal: 41.7s\tremaining: 12.8s\n",
      "536:\tlearn: 0.9925107\ttotal: 41.7s\tremaining: 12.7s\n",
      "537:\tlearn: 0.9925606\ttotal: 41.8s\tremaining: 12.6s\n",
      "538:\tlearn: 0.9925107\ttotal: 41.9s\tremaining: 12.5s\n",
      "539:\tlearn: 0.9926105\ttotal: 42s\tremaining: 12.4s\n",
      "540:\tlearn: 0.9926105\ttotal: 42.1s\tremaining: 12.4s\n",
      "541:\tlearn: 0.9927110\ttotal: 42.2s\tremaining: 12.3s\n",
      "542:\tlearn: 0.9927609\ttotal: 42.2s\tremaining: 12.2s\n",
      "543:\tlearn: 0.9928108\ttotal: 42.3s\tremaining: 12.1s\n",
      "544:\tlearn: 0.9928108\ttotal: 42.4s\tremaining: 12.1s\n",
      "545:\tlearn: 0.9930112\ttotal: 42.5s\tremaining: 12s\n",
      "546:\tlearn: 0.9930112\ttotal: 42.5s\tremaining: 11.9s\n",
      "547:\tlearn: 0.9931111\ttotal: 42.6s\tremaining: 11.8s\n",
      "548:\tlearn: 0.9930611\ttotal: 42.7s\tremaining: 11.7s\n",
      "549:\tlearn: 0.9932110\ttotal: 42.8s\tremaining: 11.7s\n",
      "550:\tlearn: 0.9932110\ttotal: 42.9s\tremaining: 11.6s\n",
      "551:\tlearn: 0.9933109\ttotal: 42.9s\tremaining: 11.5s\n",
      "552:\tlearn: 0.9932609\ttotal: 43s\tremaining: 11.4s\n",
      "553:\tlearn: 0.9934108\ttotal: 43.1s\tremaining: 11.4s\n",
      "554:\tlearn: 0.9934608\ttotal: 43.2s\tremaining: 11.3s\n",
      "555:\tlearn: 0.9934608\ttotal: 43.2s\tremaining: 11.2s\n",
      "556:\tlearn: 0.9934608\ttotal: 43.3s\tremaining: 11.1s\n",
      "557:\tlearn: 0.9934108\ttotal: 43.4s\tremaining: 11s\n",
      "558:\tlearn: 0.9936107\ttotal: 43.5s\tremaining: 11s\n",
      "559:\tlearn: 0.9937107\ttotal: 43.5s\tremaining: 10.9s\n",
      "560:\tlearn: 0.9939614\ttotal: 43.6s\tremaining: 10.8s\n",
      "561:\tlearn: 0.9939113\ttotal: 43.7s\tremaining: 10.7s\n",
      "562:\tlearn: 0.9939614\ttotal: 43.8s\tremaining: 10.6s\n",
      "563:\tlearn: 0.9940614\ttotal: 43.8s\tremaining: 10.6s\n",
      "564:\tlearn: 0.9940114\ttotal: 43.9s\tremaining: 10.5s\n",
      "565:\tlearn: 0.9940614\ttotal: 44s\tremaining: 10.4s\n",
      "566:\tlearn: 0.9940114\ttotal: 44.1s\tremaining: 10.3s\n",
      "567:\tlearn: 0.9940114\ttotal: 44.1s\tremaining: 10.3s\n",
      "568:\tlearn: 0.9940114\ttotal: 44.2s\tremaining: 10.2s\n",
      "569:\tlearn: 0.9942616\ttotal: 44.3s\tremaining: 10.1s\n",
      "570:\tlearn: 0.9942616\ttotal: 44.4s\tremaining: 10s\n",
      "571:\tlearn: 0.9942115\ttotal: 44.4s\tremaining: 9.94s\n",
      "572:\tlearn: 0.9941615\ttotal: 44.5s\tremaining: 9.86s\n",
      "573:\tlearn: 0.9943116\ttotal: 44.6s\tremaining: 9.79s\n",
      "574:\tlearn: 0.9943116\ttotal: 44.7s\tremaining: 9.71s\n",
      "575:\tlearn: 0.9944117\ttotal: 44.7s\tremaining: 9.63s\n",
      "576:\tlearn: 0.9943617\ttotal: 44.8s\tremaining: 9.55s\n",
      "577:\tlearn: 0.9944117\ttotal: 44.9s\tremaining: 9.47s\n",
      "578:\tlearn: 0.9944618\ttotal: 45s\tremaining: 9.39s\n",
      "579:\tlearn: 0.9944117\ttotal: 45s\tremaining: 9.32s\n",
      "580:\tlearn: 0.9944618\ttotal: 45.1s\tremaining: 9.24s\n",
      "581:\tlearn: 0.9944618\ttotal: 45.2s\tremaining: 9.16s\n",
      "582:\tlearn: 0.9947623\ttotal: 45.3s\tremaining: 9.08s\n",
      "583:\tlearn: 0.9948124\ttotal: 45.3s\tremaining: 9.01s\n",
      "584:\tlearn: 0.9949126\ttotal: 45.4s\tremaining: 8.93s\n",
      "585:\tlearn: 0.9949627\ttotal: 45.5s\tremaining: 8.85s\n",
      "586:\tlearn: 0.9950635\ttotal: 45.6s\tremaining: 8.77s\n",
      "587:\tlearn: 0.9951136\ttotal: 45.6s\tremaining: 8.69s\n",
      "588:\tlearn: 0.9951637\ttotal: 45.7s\tremaining: 8.62s\n",
      "589:\tlearn: 0.9951637\ttotal: 45.8s\tremaining: 8.54s\n",
      "590:\tlearn: 0.9951136\ttotal: 45.9s\tremaining: 8.46s\n",
      "591:\tlearn: 0.9952640\ttotal: 46s\tremaining: 8.38s\n",
      "592:\tlearn: 0.9955148\ttotal: 46s\tremaining: 8.31s\n",
      "593:\tlearn: 0.9955148\ttotal: 46.1s\tremaining: 8.23s\n",
      "594:\tlearn: 0.9954145\ttotal: 46.2s\tremaining: 8.15s\n",
      "595:\tlearn: 0.9955148\ttotal: 46.3s\tremaining: 8.07s\n",
      "596:\tlearn: 0.9956151\ttotal: 46.3s\tremaining: 7.99s\n",
      "597:\tlearn: 0.9956653\ttotal: 46.4s\tremaining: 7.92s\n",
      "598:\tlearn: 0.9956151\ttotal: 46.5s\tremaining: 7.84s\n",
      "599:\tlearn: 0.9957155\ttotal: 46.6s\tremaining: 7.76s\n",
      "600:\tlearn: 0.9956653\ttotal: 46.6s\tremaining: 7.68s\n",
      "601:\tlearn: 0.9958159\ttotal: 46.7s\tremaining: 7.61s\n",
      "602:\tlearn: 0.9958159\ttotal: 46.8s\tremaining: 7.53s\n",
      "603:\tlearn: 0.9957155\ttotal: 46.9s\tremaining: 7.45s\n",
      "604:\tlearn: 0.9957657\ttotal: 46.9s\tremaining: 7.37s\n",
      "605:\tlearn: 0.9957657\ttotal: 47s\tremaining: 7.29s\n",
      "606:\tlearn: 0.9957657\ttotal: 47.1s\tremaining: 7.21s\n",
      "607:\tlearn: 0.9957657\ttotal: 47.2s\tremaining: 7.14s\n",
      "608:\tlearn: 0.9960167\ttotal: 47.2s\tremaining: 7.06s\n",
      "609:\tlearn: 0.9961674\ttotal: 47.3s\tremaining: 6.98s\n",
      "610:\tlearn: 0.9960670\ttotal: 47.4s\tremaining: 6.9s\n",
      "611:\tlearn: 0.9962177\ttotal: 47.5s\tremaining: 6.83s\n",
      "612:\tlearn: 0.9961674\ttotal: 47.5s\tremaining: 6.75s\n",
      "613:\tlearn: 0.9961674\ttotal: 47.6s\tremaining: 6.67s\n",
      "614:\tlearn: 0.9961674\ttotal: 47.7s\tremaining: 6.59s\n",
      "615:\tlearn: 0.9962177\ttotal: 47.8s\tremaining: 6.51s\n",
      "616:\tlearn: 0.9963684\ttotal: 47.8s\tremaining: 6.44s\n",
      "617:\tlearn: 0.9964187\ttotal: 47.9s\tremaining: 6.36s\n",
      "618:\tlearn: 0.9963182\ttotal: 48s\tremaining: 6.28s\n",
      "619:\tlearn: 0.9963684\ttotal: 48.1s\tremaining: 6.2s\n",
      "620:\tlearn: 0.9964187\ttotal: 48.1s\tremaining: 6.12s\n",
      "621:\tlearn: 0.9964187\ttotal: 48.2s\tremaining: 6.05s\n",
      "622:\tlearn: 0.9964689\ttotal: 48.3s\tremaining: 5.97s\n",
      "623:\tlearn: 0.9964187\ttotal: 48.4s\tremaining: 5.89s\n",
      "624:\tlearn: 0.9964689\ttotal: 48.4s\tremaining: 5.81s\n",
      "625:\tlearn: 0.9964187\ttotal: 48.5s\tremaining: 5.74s\n",
      "626:\tlearn: 0.9965192\ttotal: 48.6s\tremaining: 5.66s\n",
      "627:\tlearn: 0.9966197\ttotal: 48.7s\tremaining: 5.58s\n",
      "628:\tlearn: 0.9965695\ttotal: 48.8s\tremaining: 5.5s\n",
      "629:\tlearn: 0.9966197\ttotal: 48.8s\tremaining: 5.42s\n",
      "630:\tlearn: 0.9967203\ttotal: 48.9s\tremaining: 5.35s\n",
      "631:\tlearn: 0.9967203\ttotal: 49s\tremaining: 5.27s\n",
      "632:\tlearn: 0.9967203\ttotal: 49.1s\tremaining: 5.19s\n",
      "633:\tlearn: 0.9967203\ttotal: 49.1s\tremaining: 5.11s\n",
      "634:\tlearn: 0.9967203\ttotal: 49.2s\tremaining: 5.04s\n",
      "635:\tlearn: 0.9966197\ttotal: 49.3s\tremaining: 4.96s\n",
      "636:\tlearn: 0.9967203\ttotal: 49.3s\tremaining: 4.88s\n",
      "637:\tlearn: 0.9968209\ttotal: 49.4s\tremaining: 4.8s\n",
      "638:\tlearn: 0.9967706\ttotal: 49.5s\tremaining: 4.72s\n",
      "639:\tlearn: 0.9967706\ttotal: 49.6s\tremaining: 4.65s\n",
      "640:\tlearn: 0.9968209\ttotal: 49.6s\tremaining: 4.57s\n",
      "641:\tlearn: 0.9967706\ttotal: 49.7s\tremaining: 4.49s\n",
      "642:\tlearn: 0.9967706\ttotal: 49.8s\tremaining: 4.41s\n",
      "643:\tlearn: 0.9968209\ttotal: 49.9s\tremaining: 4.34s\n",
      "644:\tlearn: 0.9968712\ttotal: 49.9s\tremaining: 4.26s\n",
      "645:\tlearn: 0.9968209\ttotal: 50s\tremaining: 4.18s\n",
      "646:\tlearn: 0.9967706\ttotal: 50.1s\tremaining: 4.1s\n",
      "647:\tlearn: 0.9967706\ttotal: 50.2s\tremaining: 4.03s\n",
      "648:\tlearn: 0.9968209\ttotal: 50.2s\tremaining: 3.95s\n",
      "649:\tlearn: 0.9967706\ttotal: 50.3s\tremaining: 3.87s\n",
      "650:\tlearn: 0.9968209\ttotal: 50.4s\tremaining: 3.79s\n",
      "651:\tlearn: 0.9969215\ttotal: 50.5s\tremaining: 3.71s\n",
      "652:\tlearn: 0.9969215\ttotal: 50.5s\tremaining: 3.64s\n",
      "653:\tlearn: 0.9969215\ttotal: 50.6s\tremaining: 3.56s\n",
      "654:\tlearn: 0.9969718\ttotal: 50.7s\tremaining: 3.48s\n",
      "655:\tlearn: 0.9969718\ttotal: 50.8s\tremaining: 3.4s\n",
      "656:\tlearn: 0.9970222\ttotal: 50.8s\tremaining: 3.33s\n",
      "657:\tlearn: 0.9970725\ttotal: 50.9s\tremaining: 3.25s\n",
      "658:\tlearn: 0.9970725\ttotal: 51s\tremaining: 3.17s\n",
      "659:\tlearn: 0.9971228\ttotal: 51.1s\tremaining: 3.1s\n",
      "660:\tlearn: 0.9971731\ttotal: 51.2s\tremaining: 3.02s\n",
      "661:\tlearn: 0.9971731\ttotal: 51.2s\tremaining: 2.94s\n",
      "662:\tlearn: 0.9970222\ttotal: 51.3s\tremaining: 2.86s\n",
      "663:\tlearn: 0.9971228\ttotal: 51.4s\tremaining: 2.79s\n",
      "664:\tlearn: 0.9971731\ttotal: 51.5s\tremaining: 2.71s\n",
      "665:\tlearn: 0.9972235\ttotal: 51.5s\tremaining: 2.63s\n",
      "666:\tlearn: 0.9972738\ttotal: 51.6s\tremaining: 2.55s\n",
      "667:\tlearn: 0.9972235\ttotal: 51.7s\tremaining: 2.48s\n",
      "668:\tlearn: 0.9972738\ttotal: 51.8s\tremaining: 2.4s\n",
      "669:\tlearn: 0.9972235\ttotal: 51.8s\tremaining: 2.32s\n",
      "670:\tlearn: 0.9972235\ttotal: 51.9s\tremaining: 2.24s\n",
      "671:\tlearn: 0.9974249\ttotal: 52s\tremaining: 2.17s\n",
      "672:\tlearn: 0.9975256\ttotal: 52.1s\tremaining: 2.09s\n",
      "673:\tlearn: 0.9974753\ttotal: 52.1s\tremaining: 2.01s\n",
      "674:\tlearn: 0.9974753\ttotal: 52.2s\tremaining: 1.93s\n",
      "675:\tlearn: 0.9974249\ttotal: 52.3s\tremaining: 1.86s\n",
      "676:\tlearn: 0.9975760\ttotal: 52.4s\tremaining: 1.78s\n",
      "677:\tlearn: 0.9977272\ttotal: 52.4s\tremaining: 1.7s\n",
      "678:\tlearn: 0.9977272\ttotal: 52.5s\tremaining: 1.62s\n",
      "679:\tlearn: 0.9976768\ttotal: 52.6s\tremaining: 1.55s\n",
      "680:\tlearn: 0.9977776\ttotal: 52.7s\tremaining: 1.47s\n",
      "681:\tlearn: 0.9978280\ttotal: 52.7s\tremaining: 1.39s\n",
      "682:\tlearn: 0.9978784\ttotal: 52.8s\tremaining: 1.31s\n",
      "683:\tlearn: 0.9978280\ttotal: 52.9s\tremaining: 1.24s\n",
      "684:\tlearn: 0.9978280\ttotal: 53s\tremaining: 1.16s\n",
      "685:\tlearn: 0.9978280\ttotal: 53s\tremaining: 1.08s\n",
      "686:\tlearn: 0.9978784\ttotal: 53.1s\tremaining: 1s\n",
      "687:\tlearn: 0.9978280\ttotal: 53.2s\tremaining: 928ms\n",
      "688:\tlearn: 0.9978784\ttotal: 53.3s\tremaining: 850ms\n",
      "689:\tlearn: 0.9979288\ttotal: 53.3s\tremaining: 773ms\n",
      "690:\tlearn: 0.9979792\ttotal: 53.4s\tremaining: 696ms\n",
      "691:\tlearn: 0.9979792\ttotal: 53.5s\tremaining: 618ms\n",
      "692:\tlearn: 0.9980296\ttotal: 53.6s\tremaining: 541ms\n",
      "693:\tlearn: 0.9980296\ttotal: 53.6s\tremaining: 464ms\n",
      "694:\tlearn: 0.9981809\ttotal: 53.7s\tremaining: 386ms\n",
      "695:\tlearn: 0.9982313\ttotal: 53.8s\tremaining: 309ms\n",
      "696:\tlearn: 0.9982313\ttotal: 53.9s\tremaining: 232ms\n",
      "697:\tlearn: 0.9982313\ttotal: 53.9s\tremaining: 155ms\n",
      "698:\tlearn: 0.9982313\ttotal: 54s\tremaining: 77.3ms\n",
      "699:\tlearn: 0.9982313\ttotal: 54.1s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=6, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Gradient, learning_rate=0.1, random_strength=1; total time=  54.9s\n",
      "0:\tlearn: 0.6732001\ttotal: 82.1ms\tremaining: 57.4s\n",
      "1:\tlearn: 0.6840973\ttotal: 164ms\tremaining: 57.2s\n",
      "2:\tlearn: 0.7008308\ttotal: 243ms\tremaining: 56.4s\n",
      "3:\tlearn: 0.7047628\ttotal: 327ms\tremaining: 56.9s\n",
      "4:\tlearn: 0.7195835\ttotal: 412ms\tremaining: 57.2s\n",
      "5:\tlearn: 0.7250842\ttotal: 491ms\tremaining: 56.7s\n",
      "6:\tlearn: 0.7353832\ttotal: 571ms\tremaining: 56.6s\n",
      "7:\tlearn: 0.7421084\ttotal: 651ms\tremaining: 56.3s\n",
      "8:\tlearn: 0.7489336\ttotal: 732ms\tremaining: 56.2s\n",
      "9:\tlearn: 0.7505466\ttotal: 812ms\tremaining: 56s\n",
      "10:\tlearn: 0.7542637\ttotal: 890ms\tremaining: 55.7s\n",
      "11:\tlearn: 0.7595376\ttotal: 969ms\tremaining: 55.6s\n",
      "12:\tlearn: 0.7621030\ttotal: 1.04s\tremaining: 55.2s\n",
      "13:\tlearn: 0.7682250\ttotal: 1.12s\tremaining: 55.1s\n",
      "14:\tlearn: 0.7708313\ttotal: 1.2s\tremaining: 54.9s\n",
      "15:\tlearn: 0.7755909\ttotal: 1.29s\tremaining: 55.3s\n",
      "16:\tlearn: 0.7771553\ttotal: 1.37s\tremaining: 55.2s\n",
      "17:\tlearn: 0.7810411\ttotal: 1.45s\tremaining: 55s\n",
      "18:\tlearn: 0.7845774\ttotal: 1.53s\tremaining: 54.8s\n",
      "19:\tlearn: 0.7863881\ttotal: 1.6s\tremaining: 54.5s\n",
      "20:\tlearn: 0.7862464\ttotal: 1.68s\tremaining: 54.2s\n",
      "21:\tlearn: 0.7894063\ttotal: 1.75s\tremaining: 54s\n",
      "22:\tlearn: 0.7953717\ttotal: 1.82s\tremaining: 53.7s\n",
      "23:\tlearn: 0.7959606\ttotal: 1.9s\tremaining: 53.5s\n",
      "24:\tlearn: 0.7983640\ttotal: 1.98s\tremaining: 53.4s\n",
      "25:\tlearn: 0.8015158\ttotal: 2.05s\tremaining: 53.2s\n",
      "26:\tlearn: 0.8027559\ttotal: 2.13s\tremaining: 53.1s\n",
      "27:\tlearn: 0.8075182\ttotal: 2.21s\tremaining: 53s\n",
      "28:\tlearn: 0.8092446\ttotal: 2.29s\tremaining: 53.1s\n",
      "29:\tlearn: 0.8125739\ttotal: 2.37s\tremaining: 53s\n",
      "30:\tlearn: 0.8157662\ttotal: 2.45s\tremaining: 52.9s\n",
      "31:\tlearn: 0.8177743\ttotal: 2.53s\tremaining: 52.8s\n",
      "32:\tlearn: 0.8198287\ttotal: 2.61s\tremaining: 52.7s\n",
      "33:\tlearn: 0.8209087\ttotal: 2.69s\tremaining: 52.6s\n",
      "34:\tlearn: 0.8213514\ttotal: 2.76s\tremaining: 52.4s\n",
      "35:\tlearn: 0.8239575\ttotal: 2.83s\tremaining: 52.2s\n",
      "36:\tlearn: 0.8256357\ttotal: 2.9s\tremaining: 52.1s\n",
      "37:\tlearn: 0.8280681\ttotal: 2.99s\tremaining: 52s\n",
      "38:\tlearn: 0.8300069\ttotal: 3.06s\tremaining: 51.9s\n",
      "39:\tlearn: 0.8309326\ttotal: 3.15s\tremaining: 51.9s\n",
      "40:\tlearn: 0.8318262\ttotal: 3.22s\tremaining: 51.8s\n",
      "41:\tlearn: 0.8325712\ttotal: 3.3s\tremaining: 51.7s\n",
      "42:\tlearn: 0.8340049\ttotal: 3.37s\tremaining: 51.6s\n",
      "43:\tlearn: 0.8364548\ttotal: 3.45s\tremaining: 51.5s\n",
      "44:\tlearn: 0.8400767\ttotal: 3.53s\tremaining: 51.4s\n",
      "45:\tlearn: 0.8402064\ttotal: 3.61s\tremaining: 51.3s\n",
      "46:\tlearn: 0.8416654\ttotal: 3.69s\tremaining: 51.2s\n",
      "47:\tlearn: 0.8432337\ttotal: 3.76s\tremaining: 51.1s\n",
      "48:\tlearn: 0.8448877\ttotal: 3.84s\tremaining: 51s\n",
      "49:\tlearn: 0.8452767\ttotal: 3.92s\tremaining: 51s\n",
      "50:\tlearn: 0.8452504\ttotal: 4s\tremaining: 50.9s\n",
      "51:\tlearn: 0.8462068\ttotal: 4.08s\tremaining: 50.9s\n",
      "52:\tlearn: 0.8467096\ttotal: 4.16s\tremaining: 50.8s\n",
      "53:\tlearn: 0.8476125\ttotal: 4.23s\tremaining: 50.6s\n",
      "54:\tlearn: 0.8485682\ttotal: 4.31s\tremaining: 50.6s\n",
      "55:\tlearn: 0.8499558\ttotal: 4.39s\tremaining: 50.5s\n",
      "56:\tlearn: 0.8519172\ttotal: 4.47s\tremaining: 50.4s\n",
      "57:\tlearn: 0.8526904\ttotal: 4.55s\tremaining: 50.3s\n",
      "58:\tlearn: 0.8534876\ttotal: 4.64s\tremaining: 50.4s\n",
      "59:\tlearn: 0.8546916\ttotal: 4.72s\tremaining: 50.3s\n",
      "60:\tlearn: 0.8555741\ttotal: 4.79s\tremaining: 50.2s\n",
      "61:\tlearn: 0.8568769\ttotal: 4.87s\tremaining: 50.1s\n",
      "62:\tlearn: 0.8573108\ttotal: 4.95s\tremaining: 50.1s\n",
      "63:\tlearn: 0.8577730\ttotal: 5.03s\tremaining: 50s\n",
      "64:\tlearn: 0.8585844\ttotal: 5.12s\tremaining: 50s\n",
      "65:\tlearn: 0.8590334\ttotal: 5.19s\tremaining: 49.9s\n",
      "66:\tlearn: 0.8606951\ttotal: 5.27s\tremaining: 49.8s\n",
      "67:\tlearn: 0.8605995\ttotal: 5.36s\tremaining: 49.8s\n",
      "68:\tlearn: 0.8620132\ttotal: 5.44s\tremaining: 49.8s\n",
      "69:\tlearn: 0.8627374\ttotal: 5.53s\tremaining: 49.7s\n",
      "70:\tlearn: 0.8623422\ttotal: 5.6s\tremaining: 49.6s\n",
      "71:\tlearn: 0.8632228\ttotal: 5.68s\tremaining: 49.5s\n",
      "72:\tlearn: 0.8648913\ttotal: 5.76s\tremaining: 49.4s\n",
      "73:\tlearn: 0.8666830\ttotal: 5.83s\tremaining: 49.4s\n",
      "74:\tlearn: 0.8676866\ttotal: 5.91s\tremaining: 49.3s\n",
      "75:\tlearn: 0.8679411\ttotal: 5.99s\tremaining: 49.2s\n",
      "76:\tlearn: 0.8693526\ttotal: 6.07s\tremaining: 49.1s\n",
      "77:\tlearn: 0.8697950\ttotal: 6.15s\tremaining: 49s\n",
      "78:\tlearn: 0.8702454\ttotal: 6.22s\tremaining: 48.9s\n",
      "79:\tlearn: 0.8708494\ttotal: 6.3s\tremaining: 48.8s\n",
      "80:\tlearn: 0.8717046\ttotal: 6.38s\tremaining: 48.7s\n",
      "81:\tlearn: 0.8720834\ttotal: 6.45s\tremaining: 48.6s\n",
      "82:\tlearn: 0.8726277\ttotal: 6.53s\tremaining: 48.5s\n",
      "83:\tlearn: 0.8741016\ttotal: 6.6s\tremaining: 48.4s\n",
      "84:\tlearn: 0.8746943\ttotal: 6.68s\tremaining: 48.4s\n",
      "85:\tlearn: 0.8743763\ttotal: 6.76s\tremaining: 48.3s\n",
      "86:\tlearn: 0.8750428\ttotal: 6.84s\tremaining: 48.2s\n",
      "87:\tlearn: 0.8755810\ttotal: 6.92s\tremaining: 48.1s\n",
      "88:\tlearn: 0.8754462\ttotal: 6.99s\tremaining: 48s\n",
      "89:\tlearn: 0.8764177\ttotal: 7.07s\tremaining: 47.9s\n",
      "90:\tlearn: 0.8774503\ttotal: 7.15s\tremaining: 47.8s\n",
      "91:\tlearn: 0.8773318\ttotal: 7.22s\tremaining: 47.7s\n",
      "92:\tlearn: 0.8775959\ttotal: 7.3s\tremaining: 47.7s\n",
      "93:\tlearn: 0.8787183\ttotal: 7.38s\tremaining: 47.6s\n",
      "94:\tlearn: 0.8798164\ttotal: 7.46s\tremaining: 47.5s\n",
      "95:\tlearn: 0.8801524\ttotal: 7.53s\tremaining: 47.4s\n",
      "96:\tlearn: 0.8812781\ttotal: 7.61s\tremaining: 47.3s\n",
      "97:\tlearn: 0.8810697\ttotal: 7.68s\tremaining: 47.2s\n",
      "98:\tlearn: 0.8823903\ttotal: 7.76s\tremaining: 47.1s\n",
      "99:\tlearn: 0.8830156\ttotal: 7.84s\tremaining: 47s\n",
      "100:\tlearn: 0.8829304\ttotal: 7.91s\tremaining: 46.9s\n",
      "101:\tlearn: 0.8842455\ttotal: 8s\tremaining: 46.9s\n",
      "102:\tlearn: 0.8847544\ttotal: 8.07s\tremaining: 46.8s\n",
      "103:\tlearn: 0.8850059\ttotal: 8.15s\tremaining: 46.7s\n",
      "104:\tlearn: 0.8852011\ttotal: 8.23s\tremaining: 46.6s\n",
      "105:\tlearn: 0.8855818\ttotal: 8.3s\tremaining: 46.5s\n",
      "106:\tlearn: 0.8869913\ttotal: 8.39s\tremaining: 46.5s\n",
      "107:\tlearn: 0.8872180\ttotal: 8.47s\tremaining: 46.4s\n",
      "108:\tlearn: 0.8884767\ttotal: 8.56s\tremaining: 46.4s\n",
      "109:\tlearn: 0.8891602\ttotal: 8.63s\tremaining: 46.3s\n",
      "110:\tlearn: 0.8899634\ttotal: 8.71s\tremaining: 46.2s\n",
      "111:\tlearn: 0.8902011\ttotal: 8.79s\tremaining: 46.1s\n",
      "112:\tlearn: 0.8900503\ttotal: 8.87s\tremaining: 46.1s\n",
      "113:\tlearn: 0.8912312\ttotal: 8.95s\tremaining: 46s\n",
      "114:\tlearn: 0.8915133\ttotal: 9.04s\tremaining: 46s\n",
      "115:\tlearn: 0.8921306\ttotal: 9.11s\tremaining: 45.9s\n",
      "116:\tlearn: 0.8928240\ttotal: 9.19s\tremaining: 45.8s\n",
      "117:\tlearn: 0.8933242\ttotal: 9.27s\tremaining: 45.7s\n",
      "118:\tlearn: 0.8942233\ttotal: 9.35s\tremaining: 45.6s\n",
      "119:\tlearn: 0.8948293\ttotal: 9.42s\tremaining: 45.6s\n",
      "120:\tlearn: 0.8951554\ttotal: 9.5s\tremaining: 45.4s\n",
      "121:\tlearn: 0.8958008\ttotal: 9.58s\tremaining: 45.4s\n",
      "122:\tlearn: 0.8966022\ttotal: 9.66s\tremaining: 45.3s\n",
      "123:\tlearn: 0.8963230\ttotal: 9.74s\tremaining: 45.2s\n",
      "124:\tlearn: 0.8972519\ttotal: 9.82s\tremaining: 45.2s\n",
      "125:\tlearn: 0.8972994\ttotal: 9.89s\tremaining: 45.1s\n",
      "126:\tlearn: 0.8982562\ttotal: 9.97s\tremaining: 45s\n",
      "127:\tlearn: 0.8981866\ttotal: 10.1s\tremaining: 44.9s\n",
      "128:\tlearn: 0.8990763\ttotal: 10.1s\tremaining: 44.8s\n",
      "129:\tlearn: 0.8994869\ttotal: 10.2s\tremaining: 44.7s\n",
      "130:\tlearn: 0.8998387\ttotal: 10.3s\tremaining: 44.7s\n",
      "131:\tlearn: 0.9001710\ttotal: 10.4s\tremaining: 44.6s\n",
      "132:\tlearn: 0.9006642\ttotal: 10.4s\tremaining: 44.5s\n",
      "133:\tlearn: 0.9013672\ttotal: 10.5s\tremaining: 44.4s\n",
      "134:\tlearn: 0.9024105\ttotal: 10.6s\tremaining: 44.4s\n",
      "135:\tlearn: 0.9026747\ttotal: 10.7s\tremaining: 44.3s\n",
      "136:\tlearn: 0.9039531\ttotal: 10.8s\tremaining: 44.2s\n",
      "137:\tlearn: 0.9047085\ttotal: 10.8s\tremaining: 44.1s\n",
      "138:\tlearn: 0.9058243\ttotal: 10.9s\tremaining: 44s\n",
      "139:\tlearn: 0.9062058\ttotal: 11s\tremaining: 44s\n",
      "140:\tlearn: 0.9076262\ttotal: 11.1s\tremaining: 43.9s\n",
      "141:\tlearn: 0.9075811\ttotal: 11.2s\tremaining: 43.9s\n",
      "142:\tlearn: 0.9079635\ttotal: 11.2s\tremaining: 43.8s\n",
      "143:\tlearn: 0.9092773\ttotal: 11.3s\tremaining: 43.7s\n",
      "144:\tlearn: 0.9091353\ttotal: 11.4s\tremaining: 43.6s\n",
      "145:\tlearn: 0.9100767\ttotal: 11.5s\tremaining: 43.5s\n",
      "146:\tlearn: 0.9114097\ttotal: 11.5s\tremaining: 43.4s\n",
      "147:\tlearn: 0.9121813\ttotal: 11.6s\tremaining: 43.3s\n",
      "148:\tlearn: 0.9114530\ttotal: 11.7s\tremaining: 43.2s\n",
      "149:\tlearn: 0.9122687\ttotal: 11.8s\tremaining: 43.2s\n",
      "150:\tlearn: 0.9125891\ttotal: 11.8s\tremaining: 43s\n",
      "151:\tlearn: 0.9134235\ttotal: 11.9s\tremaining: 43s\n",
      "152:\tlearn: 0.9133897\ttotal: 12s\tremaining: 42.9s\n",
      "153:\tlearn: 0.9142522\ttotal: 12.1s\tremaining: 42.8s\n",
      "154:\tlearn: 0.9150423\ttotal: 12.2s\tremaining: 42.7s\n",
      "155:\tlearn: 0.9158075\ttotal: 12.2s\tremaining: 42.7s\n",
      "156:\tlearn: 0.9166178\ttotal: 12.3s\tremaining: 42.6s\n",
      "157:\tlearn: 0.9171433\ttotal: 12.4s\tremaining: 42.5s\n",
      "158:\tlearn: 0.9175953\ttotal: 12.5s\tremaining: 42.4s\n",
      "159:\tlearn: 0.9177828\ttotal: 12.5s\tremaining: 42.3s\n",
      "160:\tlearn: 0.9183005\ttotal: 12.6s\tremaining: 42.2s\n",
      "161:\tlearn: 0.9188264\ttotal: 12.7s\tremaining: 42.1s\n",
      "162:\tlearn: 0.9189401\ttotal: 12.8s\tremaining: 42s\n",
      "163:\tlearn: 0.9192783\ttotal: 12.8s\tremaining: 42s\n",
      "164:\tlearn: 0.9200372\ttotal: 12.9s\tremaining: 41.9s\n",
      "165:\tlearn: 0.9205557\ttotal: 13s\tremaining: 41.8s\n",
      "166:\tlearn: 0.9211659\ttotal: 13.1s\tremaining: 41.7s\n",
      "167:\tlearn: 0.9218353\ttotal: 13.1s\tremaining: 41.6s\n",
      "168:\tlearn: 0.9224079\ttotal: 13.2s\tremaining: 41.5s\n",
      "169:\tlearn: 0.9225806\ttotal: 13.3s\tremaining: 41.4s\n",
      "170:\tlearn: 0.9227761\ttotal: 13.4s\tremaining: 41.4s\n",
      "171:\tlearn: 0.9229717\ttotal: 13.4s\tremaining: 41.3s\n",
      "172:\tlearn: 0.9236559\ttotal: 13.5s\tremaining: 41.2s\n",
      "173:\tlearn: 0.9242343\ttotal: 13.6s\tremaining: 41.1s\n",
      "174:\tlearn: 0.9252652\ttotal: 13.7s\tremaining: 41.1s\n",
      "175:\tlearn: 0.9255657\ttotal: 13.8s\tremaining: 41s\n",
      "176:\tlearn: 0.9260780\ttotal: 13.8s\tremaining: 40.9s\n",
      "177:\tlearn: 0.9267959\ttotal: 13.9s\tremaining: 40.8s\n",
      "178:\tlearn: 0.9269487\ttotal: 14s\tremaining: 40.7s\n",
      "179:\tlearn: 0.9279037\ttotal: 14.1s\tremaining: 40.6s\n",
      "180:\tlearn: 0.9282255\ttotal: 14.1s\tremaining: 40.6s\n",
      "181:\tlearn: 0.9286308\ttotal: 14.2s\tremaining: 40.5s\n",
      "182:\tlearn: 0.9286902\ttotal: 14.3s\tremaining: 40.4s\n",
      "183:\tlearn: 0.9290954\ttotal: 14.4s\tremaining: 40.3s\n",
      "184:\tlearn: 0.9291339\ttotal: 14.4s\tremaining: 40.2s\n",
      "185:\tlearn: 0.9304965\ttotal: 14.5s\tremaining: 40.1s\n",
      "186:\tlearn: 0.9307376\ttotal: 14.6s\tremaining: 40s\n",
      "187:\tlearn: 0.9318204\ttotal: 14.7s\tremaining: 39.9s\n",
      "188:\tlearn: 0.9325243\ttotal: 14.7s\tremaining: 39.9s\n",
      "189:\tlearn: 0.9323220\ttotal: 14.8s\tremaining: 39.8s\n",
      "190:\tlearn: 0.9330071\ttotal: 14.9s\tremaining: 39.7s\n",
      "191:\tlearn: 0.9336010\ttotal: 15s\tremaining: 39.6s\n",
      "192:\tlearn: 0.9337904\ttotal: 15.1s\tremaining: 39.5s\n",
      "193:\tlearn: 0.9346399\ttotal: 15.1s\tremaining: 39.4s\n",
      "194:\tlearn: 0.9356181\ttotal: 15.2s\tremaining: 39.4s\n",
      "195:\tlearn: 0.9361015\ttotal: 15.3s\tremaining: 39.3s\n",
      "196:\tlearn: 0.9362951\ttotal: 15.4s\tremaining: 39.2s\n",
      "197:\tlearn: 0.9364660\ttotal: 15.4s\tremaining: 39.1s\n",
      "198:\tlearn: 0.9369493\ttotal: 15.5s\tremaining: 39s\n",
      "199:\tlearn: 0.9370013\ttotal: 15.6s\tremaining: 38.9s\n",
      "200:\tlearn: 0.9380262\ttotal: 15.7s\tremaining: 38.9s\n",
      "201:\tlearn: 0.9381458\ttotal: 15.7s\tremaining: 38.8s\n",
      "202:\tlearn: 0.9379682\ttotal: 15.8s\tremaining: 38.7s\n",
      "203:\tlearn: 0.9382402\ttotal: 15.9s\tremaining: 38.6s\n",
      "204:\tlearn: 0.9384819\ttotal: 16s\tremaining: 38.5s\n",
      "205:\tlearn: 0.9390232\ttotal: 16s\tremaining: 38.5s\n",
      "206:\tlearn: 0.9386536\ttotal: 16.1s\tremaining: 38.4s\n",
      "207:\tlearn: 0.9389653\ttotal: 16.2s\tremaining: 38.3s\n",
      "208:\tlearn: 0.9394429\ttotal: 16.3s\tremaining: 38.2s\n",
      "209:\tlearn: 0.9390513\ttotal: 16.3s\tremaining: 38.1s\n",
      "210:\tlearn: 0.9394429\ttotal: 16.4s\tremaining: 38s\n",
      "211:\tlearn: 0.9391253\ttotal: 16.5s\tremaining: 38s\n",
      "212:\tlearn: 0.9401341\ttotal: 16.6s\tremaining: 37.9s\n",
      "213:\tlearn: 0.9401458\ttotal: 16.6s\tremaining: 37.8s\n",
      "214:\tlearn: 0.9407389\ttotal: 16.7s\tremaining: 37.7s\n",
      "215:\tlearn: 0.9412110\ttotal: 16.8s\tremaining: 37.6s\n",
      "216:\tlearn: 0.9415969\ttotal: 16.9s\tremaining: 37.6s\n",
      "217:\tlearn: 0.9417984\ttotal: 17s\tremaining: 37.5s\n",
      "218:\tlearn: 0.9417637\ttotal: 17s\tremaining: 37.4s\n",
      "219:\tlearn: 0.9427145\ttotal: 17.1s\tremaining: 37.3s\n",
      "220:\tlearn: 0.9427662\ttotal: 17.2s\tremaining: 37.2s\n",
      "221:\tlearn: 0.9431746\ttotal: 17.3s\tremaining: 37.1s\n",
      "222:\tlearn: 0.9434276\ttotal: 17.3s\tremaining: 37.1s\n",
      "223:\tlearn: 0.9439170\ttotal: 17.4s\tremaining: 37s\n",
      "224:\tlearn: 0.9442106\ttotal: 17.5s\tremaining: 36.9s\n",
      "225:\tlearn: 0.9440556\ttotal: 17.6s\tremaining: 36.8s\n",
      "226:\tlearn: 0.9443792\ttotal: 17.6s\tremaining: 36.8s\n",
      "227:\tlearn: 0.9449883\ttotal: 17.7s\tremaining: 36.7s\n",
      "228:\tlearn: 0.9452678\ttotal: 17.8s\tremaining: 36.6s\n",
      "229:\tlearn: 0.9460808\ttotal: 17.9s\tremaining: 36.5s\n",
      "230:\tlearn: 0.9460703\ttotal: 17.9s\tremaining: 36.4s\n",
      "231:\tlearn: 0.9469460\ttotal: 18s\tremaining: 36.3s\n",
      "232:\tlearn: 0.9467450\ttotal: 18.1s\tremaining: 36.2s\n",
      "233:\tlearn: 0.9471778\ttotal: 18.2s\tremaining: 36.2s\n",
      "234:\tlearn: 0.9472653\ttotal: 18.2s\tremaining: 36.1s\n",
      "235:\tlearn: 0.9472860\ttotal: 18.3s\tremaining: 36s\n",
      "236:\tlearn: 0.9475076\ttotal: 18.4s\tremaining: 35.9s\n",
      "237:\tlearn: 0.9479616\ttotal: 18.5s\tremaining: 35.8s\n",
      "238:\tlearn: 0.9485294\ttotal: 18.5s\tremaining: 35.8s\n",
      "239:\tlearn: 0.9489681\ttotal: 18.6s\tremaining: 35.7s\n",
      "240:\tlearn: 0.9495564\ttotal: 18.7s\tremaining: 35.6s\n",
      "241:\tlearn: 0.9497842\ttotal: 18.8s\tremaining: 35.5s\n",
      "242:\tlearn: 0.9505543\ttotal: 18.8s\tremaining: 35.4s\n",
      "243:\tlearn: 0.9507457\ttotal: 18.9s\tremaining: 35.3s\n",
      "244:\tlearn: 0.9513344\ttotal: 19s\tremaining: 35.3s\n",
      "245:\tlearn: 0.9511656\ttotal: 19.1s\tremaining: 35.2s\n",
      "246:\tlearn: 0.9509789\ttotal: 19.2s\tremaining: 35.1s\n",
      "247:\tlearn: 0.9515488\ttotal: 19.2s\tremaining: 35.1s\n",
      "248:\tlearn: 0.9516517\ttotal: 19.3s\tremaining: 35s\n",
      "249:\tlearn: 0.9522921\ttotal: 19.4s\tremaining: 34.9s\n",
      "250:\tlearn: 0.9520723\ttotal: 19.5s\tremaining: 34.8s\n",
      "251:\tlearn: 0.9527037\ttotal: 19.5s\tremaining: 34.7s\n",
      "252:\tlearn: 0.9530828\ttotal: 19.6s\tremaining: 34.7s\n",
      "253:\tlearn: 0.9533399\ttotal: 19.7s\tremaining: 34.6s\n",
      "254:\tlearn: 0.9535877\ttotal: 19.8s\tremaining: 34.5s\n",
      "255:\tlearn: 0.9540834\ttotal: 19.8s\tremaining: 34.4s\n",
      "256:\tlearn: 0.9547196\ttotal: 19.9s\tremaining: 34.3s\n",
      "257:\tlearn: 0.9549027\ttotal: 20s\tremaining: 34.2s\n",
      "258:\tlearn: 0.9546549\ttotal: 20.1s\tremaining: 34.2s\n",
      "259:\tlearn: 0.9550435\ttotal: 20.1s\tremaining: 34.1s\n",
      "260:\tlearn: 0.9550948\ttotal: 20.2s\tremaining: 34s\n",
      "261:\tlearn: 0.9551843\ttotal: 20.3s\tremaining: 33.9s\n",
      "262:\tlearn: 0.9560088\ttotal: 20.4s\tremaining: 33.8s\n",
      "263:\tlearn: 0.9560856\ttotal: 20.4s\tremaining: 33.8s\n",
      "264:\tlearn: 0.9560942\ttotal: 20.5s\tremaining: 33.7s\n",
      "265:\tlearn: 0.9562780\ttotal: 20.6s\tremaining: 33.6s\n",
      "266:\tlearn: 0.9564105\ttotal: 20.7s\tremaining: 33.5s\n",
      "267:\tlearn: 0.9567740\ttotal: 20.7s\tremaining: 33.4s\n",
      "268:\tlearn: 0.9569665\ttotal: 20.8s\tremaining: 33.4s\n",
      "269:\tlearn: 0.9572574\ttotal: 20.9s\tremaining: 33.3s\n",
      "270:\tlearn: 0.9570305\ttotal: 21s\tremaining: 33.2s\n",
      "271:\tlearn: 0.9572187\ttotal: 21.1s\tremaining: 33.1s\n",
      "272:\tlearn: 0.9576121\ttotal: 21.1s\tremaining: 33.1s\n",
      "273:\tlearn: 0.9583006\ttotal: 21.2s\tremaining: 33s\n",
      "274:\tlearn: 0.9590873\ttotal: 21.3s\tremaining: 32.9s\n",
      "275:\tlearn: 0.9588825\ttotal: 21.4s\tremaining: 32.8s\n",
      "276:\tlearn: 0.9593272\ttotal: 21.4s\tremaining: 32.7s\n",
      "277:\tlearn: 0.9594728\ttotal: 21.5s\tremaining: 32.7s\n",
      "278:\tlearn: 0.9595120\ttotal: 21.6s\tremaining: 32.6s\n",
      "279:\tlearn: 0.9601811\ttotal: 21.7s\tremaining: 32.5s\n",
      "280:\tlearn: 0.9606695\ttotal: 21.7s\tremaining: 32.4s\n",
      "281:\tlearn: 0.9610083\ttotal: 21.8s\tremaining: 32.3s\n",
      "282:\tlearn: 0.9610518\ttotal: 21.9s\tremaining: 32.3s\n",
      "283:\tlearn: 0.9615877\ttotal: 22s\tremaining: 32.2s\n",
      "284:\tlearn: 0.9614930\ttotal: 22.1s\tremaining: 32.1s\n",
      "285:\tlearn: 0.9616900\ttotal: 22.1s\tremaining: 32s\n",
      "286:\tlearn: 0.9615555\ttotal: 22.2s\tremaining: 32s\n",
      "287:\tlearn: 0.9617524\ttotal: 22.3s\tremaining: 31.9s\n",
      "288:\tlearn: 0.9618396\ttotal: 22.4s\tremaining: 31.8s\n",
      "289:\tlearn: 0.9619967\ttotal: 22.4s\tremaining: 31.7s\n",
      "290:\tlearn: 0.9623357\ttotal: 22.5s\tremaining: 31.6s\n",
      "291:\tlearn: 0.9624741\ttotal: 22.6s\tremaining: 31.6s\n",
      "292:\tlearn: 0.9626200\ttotal: 22.7s\tremaining: 31.5s\n",
      "293:\tlearn: 0.9632951\ttotal: 22.7s\tremaining: 31.4s\n",
      "294:\tlearn: 0.9637224\ttotal: 22.8s\tremaining: 31.3s\n",
      "295:\tlearn: 0.9643474\ttotal: 22.9s\tremaining: 31.2s\n",
      "296:\tlearn: 0.9643579\ttotal: 23s\tremaining: 31.2s\n",
      "297:\tlearn: 0.9647384\ttotal: 23s\tremaining: 31.1s\n",
      "298:\tlearn: 0.9649729\ttotal: 23.1s\tremaining: 31s\n",
      "299:\tlearn: 0.9652178\ttotal: 23.2s\tremaining: 30.9s\n",
      "300:\tlearn: 0.9656023\ttotal: 23.3s\tremaining: 30.8s\n",
      "301:\tlearn: 0.9659837\ttotal: 23.3s\tremaining: 30.8s\n",
      "302:\tlearn: 0.9661779\ttotal: 23.4s\tremaining: 30.7s\n",
      "303:\tlearn: 0.9660824\ttotal: 23.5s\tremaining: 30.6s\n",
      "304:\tlearn: 0.9662222\ttotal: 23.6s\tremaining: 30.5s\n",
      "305:\tlearn: 0.9665185\ttotal: 23.7s\tremaining: 30.5s\n",
      "306:\tlearn: 0.9670123\ttotal: 23.7s\tremaining: 30.4s\n",
      "307:\tlearn: 0.9668148\ttotal: 23.8s\tremaining: 30.3s\n",
      "308:\tlearn: 0.9671556\ttotal: 23.9s\tremaining: 30.2s\n",
      "309:\tlearn: 0.9672576\ttotal: 24s\tremaining: 30.2s\n",
      "310:\tlearn: 0.9674520\ttotal: 24s\tremaining: 30.1s\n",
      "311:\tlearn: 0.9677834\ttotal: 24.1s\tremaining: 30s\n",
      "312:\tlearn: 0.9679237\ttotal: 24.2s\tremaining: 29.9s\n",
      "313:\tlearn: 0.9677738\ttotal: 24.3s\tremaining: 29.9s\n",
      "314:\tlearn: 0.9682171\ttotal: 24.4s\tremaining: 29.8s\n",
      "315:\tlearn: 0.9682587\ttotal: 24.4s\tremaining: 29.7s\n",
      "316:\tlearn: 0.9687376\ttotal: 24.5s\tremaining: 29.6s\n",
      "317:\tlearn: 0.9688845\ttotal: 24.6s\tremaining: 29.5s\n",
      "318:\tlearn: 0.9689324\ttotal: 24.7s\tremaining: 29.5s\n",
      "319:\tlearn: 0.9691273\ttotal: 24.7s\tremaining: 29.4s\n",
      "320:\tlearn: 0.9694690\ttotal: 24.8s\tremaining: 29.3s\n",
      "321:\tlearn: 0.9692772\ttotal: 24.9s\tremaining: 29.2s\n",
      "322:\tlearn: 0.9693282\ttotal: 25s\tremaining: 29.2s\n",
      "323:\tlearn: 0.9694751\ttotal: 25.1s\tremaining: 29.1s\n",
      "324:\tlearn: 0.9696220\ttotal: 25.1s\tremaining: 29s\n",
      "325:\tlearn: 0.9696670\ttotal: 25.2s\tremaining: 28.9s\n",
      "326:\tlearn: 0.9697120\ttotal: 25.3s\tremaining: 28.8s\n",
      "327:\tlearn: 0.9702069\ttotal: 25.4s\tremaining: 28.8s\n",
      "328:\tlearn: 0.9705853\ttotal: 25.4s\tremaining: 28.7s\n",
      "329:\tlearn: 0.9709334\ttotal: 25.5s\tremaining: 28.6s\n",
      "330:\tlearn: 0.9709786\ttotal: 25.6s\tremaining: 28.5s\n",
      "331:\tlearn: 0.9711229\ttotal: 25.7s\tremaining: 28.4s\n",
      "332:\tlearn: 0.9711653\ttotal: 25.7s\tremaining: 28.4s\n",
      "333:\tlearn: 0.9713635\ttotal: 25.8s\tremaining: 28.3s\n",
      "334:\tlearn: 0.9712162\ttotal: 25.9s\tremaining: 28.2s\n",
      "335:\tlearn: 0.9712644\ttotal: 26s\tremaining: 28.1s\n",
      "336:\tlearn: 0.9714625\ttotal: 26.1s\tremaining: 28.1s\n",
      "337:\tlearn: 0.9718052\ttotal: 26.1s\tremaining: 28s\n",
      "338:\tlearn: 0.9721451\ttotal: 26.2s\tremaining: 27.9s\n",
      "339:\tlearn: 0.9722415\ttotal: 26.3s\tremaining: 27.8s\n",
      "340:\tlearn: 0.9725307\ttotal: 26.3s\tremaining: 27.7s\n",
      "341:\tlearn: 0.9728738\ttotal: 26.4s\tremaining: 27.7s\n",
      "342:\tlearn: 0.9730185\ttotal: 26.5s\tremaining: 27.6s\n",
      "343:\tlearn: 0.9730668\ttotal: 26.6s\tremaining: 27.5s\n",
      "344:\tlearn: 0.9731687\ttotal: 26.7s\tremaining: 27.5s\n",
      "345:\tlearn: 0.9731713\ttotal: 26.8s\tremaining: 27.4s\n",
      "346:\tlearn: 0.9734636\ttotal: 26.8s\tremaining: 27.3s\n",
      "347:\tlearn: 0.9736085\ttotal: 26.9s\tremaining: 27.2s\n",
      "348:\tlearn: 0.9735119\ttotal: 27s\tremaining: 27.1s\n",
      "349:\tlearn: 0.9739010\ttotal: 27.1s\tremaining: 27.1s\n",
      "350:\tlearn: 0.9740485\ttotal: 27.1s\tremaining: 27s\n",
      "351:\tlearn: 0.9741987\ttotal: 27.2s\tremaining: 26.9s\n",
      "352:\tlearn: 0.9747841\ttotal: 27.3s\tremaining: 26.8s\n",
      "353:\tlearn: 0.9748325\ttotal: 27.4s\tremaining: 26.8s\n",
      "354:\tlearn: 0.9746898\ttotal: 27.4s\tremaining: 26.7s\n",
      "355:\tlearn: 0.9748834\ttotal: 27.5s\tremaining: 26.6s\n",
      "356:\tlearn: 0.9749367\ttotal: 27.6s\tremaining: 26.5s\n",
      "357:\tlearn: 0.9752247\ttotal: 27.7s\tremaining: 26.4s\n",
      "358:\tlearn: 0.9751278\ttotal: 27.8s\tremaining: 26.4s\n",
      "359:\tlearn: 0.9754184\ttotal: 27.8s\tremaining: 26.3s\n",
      "360:\tlearn: 0.9758157\ttotal: 27.9s\tremaining: 26.2s\n",
      "361:\tlearn: 0.9757212\ttotal: 28s\tremaining: 26.1s\n",
      "362:\tlearn: 0.9758229\ttotal: 28.1s\tremaining: 26.1s\n",
      "363:\tlearn: 0.9758689\ttotal: 28.1s\tremaining: 26s\n",
      "364:\tlearn: 0.9758713\ttotal: 28.2s\tremaining: 25.9s\n",
      "365:\tlearn: 0.9763076\ttotal: 28.3s\tremaining: 25.8s\n",
      "366:\tlearn: 0.9763537\ttotal: 28.4s\tremaining: 25.7s\n",
      "367:\tlearn: 0.9766009\ttotal: 28.5s\tremaining: 25.7s\n",
      "368:\tlearn: 0.9771372\ttotal: 28.5s\tremaining: 25.6s\n",
      "369:\tlearn: 0.9771372\ttotal: 28.6s\tremaining: 25.5s\n",
      "370:\tlearn: 0.9771394\ttotal: 28.7s\tremaining: 25.4s\n",
      "371:\tlearn: 0.9768921\ttotal: 28.8s\tremaining: 25.4s\n",
      "372:\tlearn: 0.9771857\ttotal: 28.8s\tremaining: 25.3s\n",
      "373:\tlearn: 0.9776783\ttotal: 28.9s\tremaining: 25.2s\n",
      "374:\tlearn: 0.9775326\ttotal: 29s\tremaining: 25.1s\n",
      "375:\tlearn: 0.9776806\ttotal: 29.1s\tremaining: 25s\n",
      "376:\tlearn: 0.9778264\ttotal: 29.1s\tremaining: 25s\n",
      "377:\tlearn: 0.9781203\ttotal: 29.2s\tremaining: 24.9s\n",
      "378:\tlearn: 0.9780652\ttotal: 29.3s\tremaining: 24.8s\n",
      "379:\tlearn: 0.9783593\ttotal: 29.4s\tremaining: 24.7s\n",
      "380:\tlearn: 0.9787043\ttotal: 29.4s\tremaining: 24.7s\n",
      "381:\tlearn: 0.9789013\ttotal: 29.5s\tremaining: 24.6s\n",
      "382:\tlearn: 0.9788526\ttotal: 29.6s\tremaining: 24.5s\n",
      "383:\tlearn: 0.9789563\ttotal: 29.7s\tremaining: 24.4s\n",
      "384:\tlearn: 0.9793481\ttotal: 29.7s\tremaining: 24.3s\n",
      "385:\tlearn: 0.9793927\ttotal: 29.8s\tremaining: 24.3s\n",
      "386:\tlearn: 0.9792973\ttotal: 29.9s\tremaining: 24.2s\n",
      "387:\tlearn: 0.9795939\ttotal: 30s\tremaining: 24.1s\n",
      "388:\tlearn: 0.9797909\ttotal: 30s\tremaining: 24s\n",
      "389:\tlearn: 0.9797422\ttotal: 30.1s\tremaining: 23.9s\n",
      "390:\tlearn: 0.9800349\ttotal: 30.2s\tremaining: 23.9s\n",
      "391:\tlearn: 0.9800368\ttotal: 30.3s\tremaining: 23.8s\n",
      "392:\tlearn: 0.9800876\ttotal: 30.3s\tremaining: 23.7s\n",
      "393:\tlearn: 0.9803336\ttotal: 30.4s\tremaining: 23.6s\n",
      "394:\tlearn: 0.9802848\ttotal: 30.5s\tremaining: 23.5s\n",
      "395:\tlearn: 0.9804800\ttotal: 30.6s\tremaining: 23.5s\n",
      "396:\tlearn: 0.9805777\ttotal: 30.6s\tremaining: 23.4s\n",
      "397:\tlearn: 0.9810682\ttotal: 30.7s\tremaining: 23.3s\n",
      "398:\tlearn: 0.9811640\ttotal: 30.8s\tremaining: 23.2s\n",
      "399:\tlearn: 0.9811640\ttotal: 30.9s\tremaining: 23.2s\n",
      "400:\tlearn: 0.9812637\ttotal: 30.9s\tremaining: 23.1s\n",
      "401:\tlearn: 0.9814123\ttotal: 31s\tremaining: 23s\n",
      "402:\tlearn: 0.9815101\ttotal: 31.1s\tremaining: 22.9s\n",
      "403:\tlearn: 0.9816098\ttotal: 31.2s\tremaining: 22.8s\n",
      "404:\tlearn: 0.9815082\ttotal: 31.2s\tremaining: 22.8s\n",
      "405:\tlearn: 0.9814612\ttotal: 31.3s\tremaining: 22.7s\n",
      "406:\tlearn: 0.9816569\ttotal: 31.4s\tremaining: 22.6s\n",
      "407:\tlearn: 0.9817566\ttotal: 31.5s\tremaining: 22.5s\n",
      "408:\tlearn: 0.9818073\ttotal: 31.6s\tremaining: 22.5s\n",
      "409:\tlearn: 0.9819559\ttotal: 31.6s\tremaining: 22.4s\n",
      "410:\tlearn: 0.9821518\ttotal: 31.7s\tremaining: 22.3s\n",
      "411:\tlearn: 0.9822025\ttotal: 31.8s\tremaining: 22.2s\n",
      "412:\tlearn: 0.9823004\ttotal: 31.9s\tremaining: 22.1s\n",
      "413:\tlearn: 0.9825454\ttotal: 31.9s\tremaining: 22.1s\n",
      "414:\tlearn: 0.9825454\ttotal: 32s\tremaining: 22s\n",
      "415:\tlearn: 0.9828868\ttotal: 32.1s\tremaining: 21.9s\n",
      "416:\tlearn: 0.9828902\ttotal: 32.2s\tremaining: 21.8s\n",
      "417:\tlearn: 0.9830881\ttotal: 32.2s\tremaining: 21.8s\n",
      "418:\tlearn: 0.9830390\ttotal: 32.3s\tremaining: 21.7s\n",
      "419:\tlearn: 0.9831861\ttotal: 32.4s\tremaining: 21.6s\n",
      "420:\tlearn: 0.9833333\ttotal: 32.5s\tremaining: 21.5s\n",
      "421:\tlearn: 0.9831371\ttotal: 32.5s\tremaining: 21.4s\n",
      "422:\tlearn: 0.9833841\ttotal: 32.6s\tremaining: 21.4s\n",
      "423:\tlearn: 0.9837309\ttotal: 32.7s\tremaining: 21.3s\n",
      "424:\tlearn: 0.9839257\ttotal: 32.8s\tremaining: 21.2s\n",
      "425:\tlearn: 0.9841714\ttotal: 32.8s\tremaining: 21.1s\n",
      "426:\tlearn: 0.9841238\ttotal: 32.9s\tremaining: 21s\n",
      "427:\tlearn: 0.9841222\ttotal: 33s\tremaining: 21s\n",
      "428:\tlearn: 0.9842712\ttotal: 33.1s\tremaining: 20.9s\n",
      "429:\tlearn: 0.9842189\ttotal: 33.1s\tremaining: 20.8s\n",
      "430:\tlearn: 0.9846138\ttotal: 33.2s\tremaining: 20.7s\n",
      "431:\tlearn: 0.9847122\ttotal: 33.3s\tremaining: 20.6s\n",
      "432:\tlearn: 0.9849583\ttotal: 33.4s\tremaining: 20.6s\n",
      "433:\tlearn: 0.9849583\ttotal: 33.4s\tremaining: 20.5s\n",
      "434:\tlearn: 0.9851060\ttotal: 33.5s\tremaining: 20.4s\n",
      "435:\tlearn: 0.9852030\ttotal: 33.6s\tremaining: 20.3s\n",
      "436:\tlearn: 0.9854507\ttotal: 33.7s\tremaining: 20.3s\n",
      "437:\tlearn: 0.9855493\ttotal: 33.7s\tremaining: 20.2s\n",
      "438:\tlearn: 0.9857972\ttotal: 33.8s\tremaining: 20.1s\n",
      "439:\tlearn: 0.9858958\ttotal: 33.9s\tremaining: 20s\n",
      "440:\tlearn: 0.9857479\ttotal: 34s\tremaining: 19.9s\n",
      "441:\tlearn: 0.9859944\ttotal: 34s\tremaining: 19.9s\n",
      "442:\tlearn: 0.9858958\ttotal: 34.1s\tremaining: 19.8s\n",
      "443:\tlearn: 0.9860437\ttotal: 34.2s\tremaining: 19.7s\n",
      "444:\tlearn: 0.9860930\ttotal: 34.3s\tremaining: 19.6s\n",
      "445:\tlearn: 0.9860451\ttotal: 34.3s\tremaining: 19.6s\n",
      "446:\tlearn: 0.9862424\ttotal: 34.4s\tremaining: 19.5s\n",
      "447:\tlearn: 0.9861438\ttotal: 34.5s\tremaining: 19.4s\n",
      "448:\tlearn: 0.9862411\ttotal: 34.6s\tremaining: 19.3s\n",
      "449:\tlearn: 0.9863411\ttotal: 34.6s\tremaining: 19.2s\n",
      "450:\tlearn: 0.9866907\ttotal: 34.7s\tremaining: 19.2s\n",
      "451:\tlearn: 0.9868388\ttotal: 34.8s\tremaining: 19.1s\n",
      "452:\tlearn: 0.9866400\ttotal: 34.9s\tremaining: 19s\n",
      "453:\tlearn: 0.9868375\ttotal: 34.9s\tremaining: 18.9s\n",
      "454:\tlearn: 0.9867868\ttotal: 35s\tremaining: 18.8s\n",
      "455:\tlearn: 0.9871339\ttotal: 35.1s\tremaining: 18.8s\n",
      "456:\tlearn: 0.9871352\ttotal: 35.2s\tremaining: 18.7s\n",
      "457:\tlearn: 0.9874318\ttotal: 35.2s\tremaining: 18.6s\n",
      "458:\tlearn: 0.9873316\ttotal: 35.3s\tremaining: 18.5s\n",
      "459:\tlearn: 0.9876778\ttotal: 35.4s\tremaining: 18.5s\n",
      "460:\tlearn: 0.9875789\ttotal: 35.5s\tremaining: 18.4s\n",
      "461:\tlearn: 0.9877298\ttotal: 35.5s\tremaining: 18.3s\n",
      "462:\tlearn: 0.9878782\ttotal: 35.6s\tremaining: 18.2s\n",
      "463:\tlearn: 0.9877780\ttotal: 35.7s\tremaining: 18.2s\n",
      "464:\tlearn: 0.9878782\ttotal: 35.8s\tremaining: 18.1s\n",
      "465:\tlearn: 0.9880773\ttotal: 35.8s\tremaining: 18s\n",
      "466:\tlearn: 0.9881752\ttotal: 35.9s\tremaining: 17.9s\n",
      "467:\tlearn: 0.9881268\ttotal: 36s\tremaining: 17.8s\n",
      "468:\tlearn: 0.9883261\ttotal: 36.1s\tremaining: 17.8s\n",
      "469:\tlearn: 0.9882766\ttotal: 36.2s\tremaining: 17.7s\n",
      "470:\tlearn: 0.9881280\ttotal: 36.2s\tremaining: 17.6s\n",
      "471:\tlearn: 0.9883768\ttotal: 36.3s\tremaining: 17.5s\n",
      "472:\tlearn: 0.9887235\ttotal: 36.4s\tremaining: 17.5s\n",
      "473:\tlearn: 0.9888722\ttotal: 36.5s\tremaining: 17.4s\n",
      "474:\tlearn: 0.9888722\ttotal: 36.5s\tremaining: 17.3s\n",
      "475:\tlearn: 0.9886740\ttotal: 36.6s\tremaining: 17.2s\n",
      "476:\tlearn: 0.9890220\ttotal: 36.7s\tremaining: 17.1s\n",
      "477:\tlearn: 0.9890716\ttotal: 36.8s\tremaining: 17.1s\n",
      "478:\tlearn: 0.9892204\ttotal: 36.8s\tremaining: 17s\n",
      "479:\tlearn: 0.9890705\ttotal: 36.9s\tremaining: 16.9s\n",
      "480:\tlearn: 0.9892689\ttotal: 37s\tremaining: 16.8s\n",
      "481:\tlearn: 0.9892193\ttotal: 37.1s\tremaining: 16.8s\n",
      "482:\tlearn: 0.9894673\ttotal: 37.1s\tremaining: 16.7s\n",
      "483:\tlearn: 0.9893185\ttotal: 37.2s\tremaining: 16.6s\n",
      "484:\tlearn: 0.9894673\ttotal: 37.3s\tremaining: 16.5s\n",
      "485:\tlearn: 0.9895180\ttotal: 37.4s\tremaining: 16.4s\n",
      "486:\tlearn: 0.9895180\ttotal: 37.4s\tremaining: 16.4s\n",
      "487:\tlearn: 0.9897176\ttotal: 37.5s\tremaining: 16.3s\n",
      "488:\tlearn: 0.9897673\ttotal: 37.6s\tremaining: 16.2s\n",
      "489:\tlearn: 0.9898666\ttotal: 37.7s\tremaining: 16.1s\n",
      "490:\tlearn: 0.9899659\ttotal: 37.7s\tremaining: 16.1s\n",
      "491:\tlearn: 0.9901159\ttotal: 37.8s\tremaining: 16s\n",
      "492:\tlearn: 0.9901656\ttotal: 37.9s\tremaining: 15.9s\n",
      "493:\tlearn: 0.9901159\ttotal: 38s\tremaining: 15.8s\n",
      "494:\tlearn: 0.9901656\ttotal: 38s\tremaining: 15.8s\n",
      "495:\tlearn: 0.9902153\ttotal: 38.1s\tremaining: 15.7s\n",
      "496:\tlearn: 0.9903643\ttotal: 38.2s\tremaining: 15.6s\n",
      "497:\tlearn: 0.9904638\ttotal: 38.3s\tremaining: 15.5s\n",
      "498:\tlearn: 0.9904141\ttotal: 38.3s\tremaining: 15.4s\n",
      "499:\tlearn: 0.9904141\ttotal: 38.4s\tremaining: 15.4s\n",
      "500:\tlearn: 0.9906627\ttotal: 38.5s\tremaining: 15.3s\n",
      "501:\tlearn: 0.9908128\ttotal: 38.6s\tremaining: 15.2s\n",
      "502:\tlearn: 0.9909620\ttotal: 38.6s\tremaining: 15.1s\n",
      "503:\tlearn: 0.9908625\ttotal: 38.7s\tremaining: 15.1s\n",
      "504:\tlearn: 0.9908137\ttotal: 38.8s\tremaining: 15s\n",
      "505:\tlearn: 0.9909132\ttotal: 38.9s\tremaining: 14.9s\n",
      "506:\tlearn: 0.9909639\ttotal: 38.9s\tremaining: 14.8s\n",
      "507:\tlearn: 0.9912127\ttotal: 39s\tremaining: 14.7s\n",
      "508:\tlearn: 0.9911122\ttotal: 39.1s\tremaining: 14.7s\n",
      "509:\tlearn: 0.9911620\ttotal: 39.2s\tremaining: 14.6s\n",
      "510:\tlearn: 0.9912616\ttotal: 39.2s\tremaining: 14.5s\n",
      "511:\tlearn: 0.9913611\ttotal: 39.3s\tremaining: 14.4s\n",
      "512:\tlearn: 0.9914109\ttotal: 39.4s\tremaining: 14.4s\n",
      "513:\tlearn: 0.9913611\ttotal: 39.5s\tremaining: 14.3s\n",
      "514:\tlearn: 0.9915105\ttotal: 39.6s\tremaining: 14.2s\n",
      "515:\tlearn: 0.9915105\ttotal: 39.6s\tremaining: 14.1s\n",
      "516:\tlearn: 0.9916608\ttotal: 39.7s\tremaining: 14.1s\n",
      "517:\tlearn: 0.9916110\ttotal: 39.8s\tremaining: 14s\n",
      "518:\tlearn: 0.9915603\ttotal: 39.9s\tremaining: 13.9s\n",
      "519:\tlearn: 0.9916101\ttotal: 39.9s\tremaining: 13.8s\n",
      "520:\tlearn: 0.9917098\ttotal: 40s\tremaining: 13.8s\n",
      "521:\tlearn: 0.9918095\ttotal: 40.1s\tremaining: 13.7s\n",
      "522:\tlearn: 0.9918593\ttotal: 40.2s\tremaining: 13.6s\n",
      "523:\tlearn: 0.9921584\ttotal: 40.2s\tremaining: 13.5s\n",
      "524:\tlearn: 0.9922091\ttotal: 40.3s\tremaining: 13.4s\n",
      "525:\tlearn: 0.9922590\ttotal: 40.4s\tremaining: 13.4s\n",
      "526:\tlearn: 0.9924086\ttotal: 40.5s\tremaining: 13.3s\n",
      "527:\tlearn: 0.9926082\ttotal: 40.5s\tremaining: 13.2s\n",
      "528:\tlearn: 0.9926589\ttotal: 40.6s\tremaining: 13.1s\n",
      "529:\tlearn: 0.9926090\ttotal: 40.7s\tremaining: 13.1s\n",
      "530:\tlearn: 0.9927088\ttotal: 40.8s\tremaining: 13s\n",
      "531:\tlearn: 0.9928086\ttotal: 40.8s\tremaining: 12.9s\n",
      "532:\tlearn: 0.9929085\ttotal: 40.9s\tremaining: 12.8s\n",
      "533:\tlearn: 0.9929085\ttotal: 41s\tremaining: 12.7s\n",
      "534:\tlearn: 0.9929585\ttotal: 41.1s\tremaining: 12.7s\n",
      "535:\tlearn: 0.9927587\ttotal: 41.2s\tremaining: 12.6s\n",
      "536:\tlearn: 0.9931083\ttotal: 41.2s\tremaining: 12.5s\n",
      "537:\tlearn: 0.9930590\ttotal: 41.3s\tremaining: 12.4s\n",
      "538:\tlearn: 0.9932089\ttotal: 41.4s\tremaining: 12.4s\n",
      "539:\tlearn: 0.9933088\ttotal: 41.5s\tremaining: 12.3s\n",
      "540:\tlearn: 0.9932089\ttotal: 41.5s\tremaining: 12.2s\n",
      "541:\tlearn: 0.9933088\ttotal: 41.6s\tremaining: 12.1s\n",
      "542:\tlearn: 0.9932589\ttotal: 41.7s\tremaining: 12.1s\n",
      "543:\tlearn: 0.9933588\ttotal: 41.8s\tremaining: 12s\n",
      "544:\tlearn: 0.9934594\ttotal: 41.8s\tremaining: 11.9s\n",
      "545:\tlearn: 0.9936094\ttotal: 41.9s\tremaining: 11.8s\n",
      "546:\tlearn: 0.9937094\ttotal: 42s\tremaining: 11.7s\n",
      "547:\tlearn: 0.9936094\ttotal: 42.1s\tremaining: 11.7s\n",
      "548:\tlearn: 0.9935594\ttotal: 42.1s\tremaining: 11.6s\n",
      "549:\tlearn: 0.9935094\ttotal: 42.2s\tremaining: 11.5s\n",
      "550:\tlearn: 0.9938095\ttotal: 42.3s\tremaining: 11.4s\n",
      "551:\tlearn: 0.9938095\ttotal: 42.4s\tremaining: 11.4s\n",
      "552:\tlearn: 0.9937588\ttotal: 42.4s\tremaining: 11.3s\n",
      "553:\tlearn: 0.9938589\ttotal: 42.5s\tremaining: 11.2s\n",
      "554:\tlearn: 0.9938088\ttotal: 42.6s\tremaining: 11.1s\n",
      "555:\tlearn: 0.9938088\ttotal: 42.7s\tremaining: 11s\n",
      "556:\tlearn: 0.9939595\ttotal: 42.7s\tremaining: 11s\n",
      "557:\tlearn: 0.9940596\ttotal: 42.8s\tremaining: 10.9s\n",
      "558:\tlearn: 0.9941597\ttotal: 42.9s\tremaining: 10.8s\n",
      "559:\tlearn: 0.9942092\ttotal: 43s\tremaining: 10.7s\n",
      "560:\tlearn: 0.9941091\ttotal: 43s\tremaining: 10.7s\n",
      "561:\tlearn: 0.9942098\ttotal: 43.1s\tremaining: 10.6s\n",
      "562:\tlearn: 0.9942598\ttotal: 43.2s\tremaining: 10.5s\n",
      "563:\tlearn: 0.9943105\ttotal: 43.3s\tremaining: 10.4s\n",
      "564:\tlearn: 0.9943110\ttotal: 43.3s\tremaining: 10.4s\n",
      "565:\tlearn: 0.9944112\ttotal: 43.4s\tremaining: 10.3s\n",
      "566:\tlearn: 0.9944612\ttotal: 43.5s\tremaining: 10.2s\n",
      "567:\tlearn: 0.9946115\ttotal: 43.6s\tremaining: 10.1s\n",
      "568:\tlearn: 0.9946616\ttotal: 43.6s\tremaining: 10s\n",
      "569:\tlearn: 0.9947117\ttotal: 43.7s\tremaining: 9.97s\n",
      "570:\tlearn: 0.9947618\ttotal: 43.8s\tremaining: 9.89s\n",
      "571:\tlearn: 0.9949121\ttotal: 43.8s\tremaining: 9.81s\n",
      "572:\tlearn: 0.9949121\ttotal: 43.9s\tremaining: 9.73s\n",
      "573:\tlearn: 0.9949622\ttotal: 44s\tremaining: 9.66s\n",
      "574:\tlearn: 0.9949121\ttotal: 44.1s\tremaining: 9.58s\n",
      "575:\tlearn: 0.9950123\ttotal: 44.2s\tremaining: 9.51s\n",
      "576:\tlearn: 0.9949116\ttotal: 44.2s\tremaining: 9.43s\n",
      "577:\tlearn: 0.9949116\ttotal: 44.3s\tremaining: 9.35s\n",
      "578:\tlearn: 0.9949121\ttotal: 44.4s\tremaining: 9.27s\n",
      "579:\tlearn: 0.9949622\ttotal: 44.5s\tremaining: 9.2s\n",
      "580:\tlearn: 0.9950123\ttotal: 44.5s\tremaining: 9.12s\n",
      "581:\tlearn: 0.9949622\ttotal: 44.6s\tremaining: 9.04s\n",
      "582:\tlearn: 0.9951126\ttotal: 44.7s\tremaining: 8.96s\n",
      "583:\tlearn: 0.9949622\ttotal: 44.8s\tremaining: 8.89s\n",
      "584:\tlearn: 0.9950625\ttotal: 44.8s\tremaining: 8.81s\n",
      "585:\tlearn: 0.9951628\ttotal: 44.9s\tremaining: 8.74s\n",
      "586:\tlearn: 0.9953132\ttotal: 45s\tremaining: 8.66s\n",
      "587:\tlearn: 0.9953132\ttotal: 45.1s\tremaining: 8.58s\n",
      "588:\tlearn: 0.9953634\ttotal: 45.1s\tremaining: 8.51s\n",
      "589:\tlearn: 0.9954637\ttotal: 45.2s\tremaining: 8.43s\n",
      "590:\tlearn: 0.9956143\ttotal: 45.3s\tremaining: 8.35s\n",
      "591:\tlearn: 0.9955139\ttotal: 45.4s\tremaining: 8.27s\n",
      "592:\tlearn: 0.9954135\ttotal: 45.4s\tremaining: 8.2s\n",
      "593:\tlearn: 0.9956644\ttotal: 45.5s\tremaining: 8.12s\n",
      "594:\tlearn: 0.9957146\ttotal: 45.6s\tremaining: 8.04s\n",
      "595:\tlearn: 0.9957648\ttotal: 45.7s\tremaining: 7.97s\n",
      "596:\tlearn: 0.9958151\ttotal: 45.7s\tremaining: 7.89s\n",
      "597:\tlearn: 0.9958151\ttotal: 45.8s\tremaining: 7.81s\n",
      "598:\tlearn: 0.9959155\ttotal: 45.9s\tremaining: 7.74s\n",
      "599:\tlearn: 0.9958151\ttotal: 46s\tremaining: 7.66s\n",
      "600:\tlearn: 0.9957146\ttotal: 46s\tremaining: 7.58s\n",
      "601:\tlearn: 0.9958151\ttotal: 46.1s\tremaining: 7.5s\n",
      "602:\tlearn: 0.9958653\ttotal: 46.2s\tremaining: 7.43s\n",
      "603:\tlearn: 0.9958151\ttotal: 46.3s\tremaining: 7.35s\n",
      "604:\tlearn: 0.9958151\ttotal: 46.3s\tremaining: 7.27s\n",
      "605:\tlearn: 0.9959155\ttotal: 46.4s\tremaining: 7.2s\n",
      "606:\tlearn: 0.9958653\ttotal: 46.5s\tremaining: 7.12s\n",
      "607:\tlearn: 0.9959657\ttotal: 46.6s\tremaining: 7.04s\n",
      "608:\tlearn: 0.9960159\ttotal: 46.6s\tremaining: 6.97s\n",
      "609:\tlearn: 0.9960159\ttotal: 46.7s\tremaining: 6.89s\n",
      "610:\tlearn: 0.9960662\ttotal: 46.8s\tremaining: 6.82s\n",
      "611:\tlearn: 0.9961164\ttotal: 46.9s\tremaining: 6.74s\n",
      "612:\tlearn: 0.9961164\ttotal: 46.9s\tremaining: 6.66s\n",
      "613:\tlearn: 0.9962169\ttotal: 47s\tremaining: 6.59s\n",
      "614:\tlearn: 0.9962672\ttotal: 47.1s\tremaining: 6.51s\n",
      "615:\tlearn: 0.9962672\ttotal: 47.2s\tremaining: 6.43s\n",
      "616:\tlearn: 0.9962169\ttotal: 47.3s\tremaining: 6.36s\n",
      "617:\tlearn: 0.9962169\ttotal: 47.3s\tremaining: 6.28s\n",
      "618:\tlearn: 0.9962672\ttotal: 47.4s\tremaining: 6.2s\n",
      "619:\tlearn: 0.9963174\ttotal: 47.5s\tremaining: 6.13s\n",
      "620:\tlearn: 0.9962672\ttotal: 47.6s\tremaining: 6.05s\n",
      "621:\tlearn: 0.9963174\ttotal: 47.6s\tremaining: 5.97s\n",
      "622:\tlearn: 0.9964179\ttotal: 47.7s\tremaining: 5.89s\n",
      "623:\tlearn: 0.9963677\ttotal: 47.8s\tremaining: 5.82s\n",
      "624:\tlearn: 0.9963677\ttotal: 47.9s\tremaining: 5.74s\n",
      "625:\tlearn: 0.9963680\ttotal: 47.9s\tremaining: 5.67s\n",
      "626:\tlearn: 0.9964183\ttotal: 48s\tremaining: 5.59s\n",
      "627:\tlearn: 0.9965188\ttotal: 48.1s\tremaining: 5.51s\n",
      "628:\tlearn: 0.9966197\ttotal: 48.1s\tremaining: 5.43s\n",
      "629:\tlearn: 0.9966700\ttotal: 48.2s\tremaining: 5.36s\n",
      "630:\tlearn: 0.9966700\ttotal: 48.3s\tremaining: 5.28s\n",
      "631:\tlearn: 0.9967706\ttotal: 48.4s\tremaining: 5.2s\n",
      "632:\tlearn: 0.9967203\ttotal: 48.5s\tremaining: 5.13s\n",
      "633:\tlearn: 0.9967203\ttotal: 48.5s\tremaining: 5.05s\n",
      "634:\tlearn: 0.9967706\ttotal: 48.6s\tremaining: 4.97s\n",
      "635:\tlearn: 0.9967706\ttotal: 48.7s\tremaining: 4.9s\n",
      "636:\tlearn: 0.9967706\ttotal: 48.7s\tremaining: 4.82s\n",
      "637:\tlearn: 0.9967706\ttotal: 48.8s\tremaining: 4.74s\n",
      "638:\tlearn: 0.9968709\ttotal: 48.9s\tremaining: 4.67s\n",
      "639:\tlearn: 0.9968709\ttotal: 49s\tremaining: 4.59s\n",
      "640:\tlearn: 0.9968709\ttotal: 49s\tremaining: 4.51s\n",
      "641:\tlearn: 0.9968709\ttotal: 49.1s\tremaining: 4.44s\n",
      "642:\tlearn: 0.9968712\ttotal: 49.2s\tremaining: 4.36s\n",
      "643:\tlearn: 0.9968209\ttotal: 49.3s\tremaining: 4.28s\n",
      "644:\tlearn: 0.9968209\ttotal: 49.4s\tremaining: 4.21s\n",
      "645:\tlearn: 0.9968712\ttotal: 49.4s\tremaining: 4.13s\n",
      "646:\tlearn: 0.9969215\ttotal: 49.5s\tremaining: 4.05s\n",
      "647:\tlearn: 0.9969718\ttotal: 49.6s\tremaining: 3.98s\n",
      "648:\tlearn: 0.9969215\ttotal: 49.7s\tremaining: 3.9s\n",
      "649:\tlearn: 0.9969718\ttotal: 49.7s\tremaining: 3.83s\n",
      "650:\tlearn: 0.9969215\ttotal: 49.8s\tremaining: 3.75s\n",
      "651:\tlearn: 0.9970725\ttotal: 49.9s\tremaining: 3.67s\n",
      "652:\tlearn: 0.9970725\ttotal: 50s\tremaining: 3.6s\n",
      "653:\tlearn: 0.9970222\ttotal: 50s\tremaining: 3.52s\n",
      "654:\tlearn: 0.9970725\ttotal: 50.1s\tremaining: 3.44s\n",
      "655:\tlearn: 0.9970725\ttotal: 50.2s\tremaining: 3.37s\n",
      "656:\tlearn: 0.9971228\ttotal: 50.3s\tremaining: 3.29s\n",
      "657:\tlearn: 0.9971731\ttotal: 50.3s\tremaining: 3.21s\n",
      "658:\tlearn: 0.9971228\ttotal: 50.4s\tremaining: 3.14s\n",
      "659:\tlearn: 0.9971731\ttotal: 50.5s\tremaining: 3.06s\n",
      "660:\tlearn: 0.9972235\ttotal: 50.6s\tremaining: 2.98s\n",
      "661:\tlearn: 0.9973242\ttotal: 50.6s\tremaining: 2.91s\n",
      "662:\tlearn: 0.9972738\ttotal: 50.7s\tremaining: 2.83s\n",
      "663:\tlearn: 0.9973242\ttotal: 50.8s\tremaining: 2.75s\n",
      "664:\tlearn: 0.9972738\ttotal: 50.9s\tremaining: 2.68s\n",
      "665:\tlearn: 0.9973745\ttotal: 50.9s\tremaining: 2.6s\n",
      "666:\tlearn: 0.9973745\ttotal: 51s\tremaining: 2.52s\n",
      "667:\tlearn: 0.9974249\ttotal: 51.1s\tremaining: 2.45s\n",
      "668:\tlearn: 0.9974753\ttotal: 51.1s\tremaining: 2.37s\n",
      "669:\tlearn: 0.9975760\ttotal: 51.2s\tremaining: 2.29s\n",
      "670:\tlearn: 0.9975760\ttotal: 51.3s\tremaining: 2.22s\n",
      "671:\tlearn: 0.9975760\ttotal: 51.4s\tremaining: 2.14s\n",
      "672:\tlearn: 0.9975760\ttotal: 51.5s\tremaining: 2.06s\n",
      "673:\tlearn: 0.9976264\ttotal: 51.5s\tremaining: 1.99s\n",
      "674:\tlearn: 0.9976264\ttotal: 51.6s\tremaining: 1.91s\n",
      "675:\tlearn: 0.9976768\ttotal: 51.7s\tremaining: 1.83s\n",
      "676:\tlearn: 0.9976768\ttotal: 51.8s\tremaining: 1.76s\n",
      "677:\tlearn: 0.9976768\ttotal: 51.8s\tremaining: 1.68s\n",
      "678:\tlearn: 0.9976768\ttotal: 51.9s\tremaining: 1.6s\n",
      "679:\tlearn: 0.9975256\ttotal: 52s\tremaining: 1.53s\n",
      "680:\tlearn: 0.9975760\ttotal: 52.1s\tremaining: 1.45s\n",
      "681:\tlearn: 0.9975256\ttotal: 52.1s\tremaining: 1.38s\n",
      "682:\tlearn: 0.9975256\ttotal: 52.2s\tremaining: 1.3s\n",
      "683:\tlearn: 0.9976264\ttotal: 52.3s\tremaining: 1.22s\n",
      "684:\tlearn: 0.9977274\ttotal: 52.4s\tremaining: 1.15s\n",
      "685:\tlearn: 0.9978282\ttotal: 52.4s\tremaining: 1.07s\n",
      "686:\tlearn: 0.9977776\ttotal: 52.5s\tremaining: 994ms\n",
      "687:\tlearn: 0.9978282\ttotal: 52.6s\tremaining: 917ms\n",
      "688:\tlearn: 0.9977778\ttotal: 52.7s\tremaining: 841ms\n",
      "689:\tlearn: 0.9979290\ttotal: 52.7s\tremaining: 764ms\n",
      "690:\tlearn: 0.9978786\ttotal: 52.8s\tremaining: 688ms\n",
      "691:\tlearn: 0.9978786\ttotal: 52.9s\tremaining: 611ms\n",
      "692:\tlearn: 0.9979792\ttotal: 53s\tremaining: 535ms\n",
      "693:\tlearn: 0.9979792\ttotal: 53s\tremaining: 459ms\n",
      "694:\tlearn: 0.9978280\ttotal: 53.1s\tremaining: 382ms\n",
      "695:\tlearn: 0.9979290\ttotal: 53.2s\tremaining: 306ms\n",
      "696:\tlearn: 0.9979290\ttotal: 53.3s\tremaining: 229ms\n",
      "697:\tlearn: 0.9979794\ttotal: 53.3s\tremaining: 153ms\n",
      "698:\tlearn: 0.9979290\ttotal: 53.4s\tremaining: 76.4ms\n",
      "699:\tlearn: 0.9980298\ttotal: 53.5s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0, border_count=128, depth=6, eval_metric=F1, iterations=700, l2_leaf_reg=5, leaf_estimation_method=Gradient, learning_rate=0.1, random_strength=1; total time=  54.1s\n",
      "0:\tlearn: 0.6774041\ttotal: 1.29s\tremaining: 17m 14s\n",
      "1:\tlearn: 0.7358239\ttotal: 2.59s\tremaining: 17m 12s\n",
      "2:\tlearn: 0.7961367\ttotal: 3.86s\tremaining: 17m 6s\n",
      "3:\tlearn: 0.8207013\ttotal: 5.16s\tremaining: 17m 6s\n",
      "4:\tlearn: 0.8380716\ttotal: 6.41s\tremaining: 16m 58s\n",
      "5:\tlearn: 0.8478432\ttotal: 7.66s\tremaining: 16m 54s\n",
      "6:\tlearn: 0.8622248\ttotal: 8.97s\tremaining: 16m 56s\n",
      "7:\tlearn: 0.8845279\ttotal: 10.3s\tremaining: 16m 55s\n",
      "8:\tlearn: 0.8950946\ttotal: 11.5s\tremaining: 16m 52s\n",
      "9:\tlearn: 0.9026365\ttotal: 12.8s\tremaining: 16m 50s\n",
      "10:\tlearn: 0.9082931\ttotal: 14.1s\tremaining: 16m 50s\n",
      "11:\tlearn: 0.9122235\ttotal: 15.3s\tremaining: 16m 46s\n",
      "12:\tlearn: 0.9183472\ttotal: 16.6s\tremaining: 16m 45s\n",
      "13:\tlearn: 0.9232749\ttotal: 18s\tremaining: 16m 49s\n",
      "14:\tlearn: 0.9305487\ttotal: 19.3s\tremaining: 16m 50s\n",
      "15:\tlearn: 0.9314472\ttotal: 20.6s\tremaining: 16m 47s\n",
      "16:\tlearn: 0.9355542\ttotal: 21.8s\tremaining: 16m 46s\n",
      "17:\tlearn: 0.9374195\ttotal: 23.1s\tremaining: 16m 45s\n",
      "18:\tlearn: 0.9383277\ttotal: 24.4s\tremaining: 16m 43s\n",
      "19:\tlearn: 0.9465528\ttotal: 25.7s\tremaining: 16m 41s\n",
      "20:\tlearn: 0.9479643\ttotal: 27s\tremaining: 16m 40s\n",
      "21:\tlearn: 0.9451811\ttotal: 28.2s\tremaining: 16m 38s\n",
      "22:\tlearn: 0.9462802\ttotal: 29.5s\tremaining: 16m 36s\n",
      "23:\tlearn: 0.9503370\ttotal: 30.8s\tremaining: 16m 35s\n",
      "24:\tlearn: 0.9512074\ttotal: 32.1s\tremaining: 16m 34s\n",
      "25:\tlearn: 0.9538431\ttotal: 33.3s\tremaining: 16m 32s\n",
      "26:\tlearn: 0.9550584\ttotal: 34.6s\tremaining: 16m 30s\n",
      "27:\tlearn: 0.9551707\ttotal: 35.9s\tremaining: 16m 30s\n",
      "28:\tlearn: 0.9569179\ttotal: 37.2s\tremaining: 16m 29s\n",
      "29:\tlearn: 0.9573835\ttotal: 38.5s\tremaining: 16m 27s\n",
      "30:\tlearn: 0.9576405\ttotal: 39.7s\tremaining: 16m 25s\n",
      "31:\tlearn: 0.9594059\ttotal: 41s\tremaining: 16m 24s\n",
      "32:\tlearn: 0.9600753\ttotal: 42.3s\tremaining: 16m 22s\n",
      "33:\tlearn: 0.9605511\ttotal: 43.5s\tremaining: 16m 20s\n",
      "34:\tlearn: 0.9604430\ttotal: 44.8s\tremaining: 16m 19s\n",
      "35:\tlearn: 0.9611007\ttotal: 46.1s\tremaining: 16m 17s\n",
      "36:\tlearn: 0.9614320\ttotal: 47.3s\tremaining: 16m 16s\n",
      "37:\tlearn: 0.9613598\ttotal: 48.6s\tremaining: 16m 14s\n",
      "38:\tlearn: 0.9602368\ttotal: 49.8s\tremaining: 16m 12s\n",
      "39:\tlearn: 0.9608558\ttotal: 51.1s\tremaining: 16m 11s\n",
      "40:\tlearn: 0.9608674\ttotal: 52.4s\tremaining: 16m 9s\n",
      "41:\tlearn: 0.9614740\ttotal: 53.6s\tremaining: 16m 7s\n",
      "42:\tlearn: 0.9614816\ttotal: 54.9s\tremaining: 16m 7s\n",
      "43:\tlearn: 0.9616862\ttotal: 56.2s\tremaining: 16m 5s\n",
      "44:\tlearn: 0.9617772\ttotal: 57.4s\tremaining: 16m 3s\n",
      "45:\tlearn: 0.9620154\ttotal: 58.7s\tremaining: 16m 2s\n",
      "46:\tlearn: 0.9623905\ttotal: 60s\tremaining: 16m\n",
      "47:\tlearn: 0.9633570\ttotal: 1m 1s\tremaining: 15m 59s\n",
      "48:\tlearn: 0.9635396\ttotal: 1m 2s\tremaining: 15m 57s\n",
      "49:\tlearn: 0.9643209\ttotal: 1m 3s\tremaining: 15m 56s\n",
      "50:\tlearn: 0.9634483\ttotal: 1m 5s\tremaining: 15m 54s\n",
      "51:\tlearn: 0.9637831\ttotal: 1m 6s\tremaining: 15m 53s\n",
      "52:\tlearn: 0.9634986\ttotal: 1m 7s\tremaining: 15m 51s\n",
      "53:\tlearn: 0.9636847\ttotal: 1m 8s\tremaining: 15m 50s\n",
      "54:\tlearn: 0.9622567\ttotal: 1m 10s\tremaining: 15m 49s\n",
      "55:\tlearn: 0.9633307\ttotal: 1m 11s\tremaining: 15m 47s\n",
      "56:\tlearn: 0.9639064\ttotal: 1m 12s\tremaining: 15m 46s\n",
      "57:\tlearn: 0.9643911\ttotal: 1m 13s\tremaining: 15m 44s\n",
      "58:\tlearn: 0.9643103\ttotal: 1m 15s\tremaining: 15m 43s\n",
      "59:\tlearn: 0.9644226\ttotal: 1m 16s\tremaining: 15m 42s\n",
      "60:\tlearn: 0.9640577\ttotal: 1m 17s\tremaining: 15m 40s\n",
      "61:\tlearn: 0.9638755\ttotal: 1m 18s\tremaining: 15m 39s\n",
      "62:\tlearn: 0.9642577\ttotal: 1m 20s\tremaining: 15m 38s\n",
      "63:\tlearn: 0.9638791\ttotal: 1m 21s\tremaining: 15m 36s\n",
      "64:\tlearn: 0.9642506\ttotal: 1m 22s\tremaining: 15m 35s\n",
      "65:\tlearn: 0.9642506\ttotal: 1m 24s\tremaining: 15m 34s\n",
      "66:\tlearn: 0.9639039\ttotal: 1m 25s\tremaining: 15m 33s\n",
      "67:\tlearn: 0.9641981\ttotal: 1m 26s\tremaining: 15m 32s\n",
      "68:\tlearn: 0.9642787\ttotal: 1m 27s\tremaining: 15m 31s\n",
      "69:\tlearn: 0.9655206\ttotal: 1m 29s\tremaining: 15m 30s\n",
      "70:\tlearn: 0.9651277\ttotal: 1m 30s\tremaining: 15m 29s\n",
      "71:\tlearn: 0.9656935\ttotal: 1m 31s\tremaining: 15m 28s\n",
      "72:\tlearn: 0.9655952\ttotal: 1m 33s\tremaining: 15m 26s\n",
      "73:\tlearn: 0.9654292\ttotal: 1m 34s\tremaining: 15m 25s\n",
      "74:\tlearn: 0.9656290\ttotal: 1m 35s\tremaining: 15m 23s\n",
      "75:\tlearn: 0.9653412\ttotal: 1m 36s\tremaining: 15m 22s\n",
      "76:\tlearn: 0.9657238\ttotal: 1m 38s\tremaining: 15m 21s\n",
      "77:\tlearn: 0.9657339\ttotal: 1m 39s\tremaining: 15m 19s\n",
      "78:\tlearn: 0.9658187\ttotal: 1m 40s\tremaining: 15m 18s\n",
      "79:\tlearn: 0.9658254\ttotal: 1m 41s\tremaining: 15m 17s\n",
      "80:\tlearn: 0.9663981\ttotal: 1m 43s\tremaining: 15m 16s\n",
      "81:\tlearn: 0.9664047\ttotal: 1m 44s\tremaining: 15m 14s\n",
      "82:\tlearn: 0.9666045\ttotal: 1m 45s\tremaining: 15m 13s\n",
      "83:\tlearn: 0.9669909\ttotal: 1m 47s\tremaining: 15m 12s\n",
      "84:\tlearn: 0.9668959\ttotal: 1m 48s\tremaining: 15m 11s\n",
      "85:\tlearn: 0.9670956\ttotal: 1m 49s\tremaining: 15m 9s\n",
      "86:\tlearn: 0.9677578\ttotal: 1m 50s\tremaining: 15m 8s\n",
      "87:\tlearn: 0.9682368\ttotal: 1m 52s\tremaining: 15m 6s\n",
      "88:\tlearn: 0.9686055\ttotal: 1m 53s\tremaining: 15m 5s\n",
      "89:\tlearn: 0.9685194\ttotal: 1m 54s\tremaining: 15m 4s\n",
      "90:\tlearn: 0.9682399\ttotal: 1m 55s\tremaining: 15m 2s\n",
      "91:\tlearn: 0.9680464\ttotal: 1m 57s\tremaining: 15m 1s\n",
      "92:\tlearn: 0.9691036\ttotal: 1m 58s\tremaining: 15m\n",
      "93:\tlearn: 0.9695776\ttotal: 1m 59s\tremaining: 14m 59s\n",
      "94:\tlearn: 0.9690113\ttotal: 2m 1s\tremaining: 14m 58s\n",
      "95:\tlearn: 0.9692020\ttotal: 2m 2s\tremaining: 14m 56s\n",
      "96:\tlearn: 0.9695896\ttotal: 2m 3s\tremaining: 14m 55s\n",
      "97:\tlearn: 0.9697775\ttotal: 2m 4s\tremaining: 14m 53s\n",
      "98:\tlearn: 0.9700670\ttotal: 2m 6s\tremaining: 14m 52s\n",
      "99:\tlearn: 0.9707331\ttotal: 2m 7s\tremaining: 14m 50s\n",
      "100:\tlearn: 0.9707331\ttotal: 2m 8s\tremaining: 14m 49s\n",
      "101:\tlearn: 0.9709188\ttotal: 2m 9s\tremaining: 14m 47s\n",
      "102:\tlearn: 0.9707447\ttotal: 2m 11s\tremaining: 14m 46s\n",
      "103:\tlearn: 0.9714145\ttotal: 2m 12s\tremaining: 14m 45s\n",
      "104:\tlearn: 0.9708374\ttotal: 2m 13s\tremaining: 14m 43s\n",
      "105:\tlearn: 0.9714117\ttotal: 2m 14s\tremaining: 14m 42s\n",
      "106:\tlearn: 0.9712173\ttotal: 2m 16s\tremaining: 14m 41s\n",
      "107:\tlearn: 0.9710345\ttotal: 2m 17s\tremaining: 14m 39s\n",
      "108:\tlearn: 0.9711302\ttotal: 2m 18s\tremaining: 14m 38s\n",
      "109:\tlearn: 0.9715131\ttotal: 2m 19s\tremaining: 14m 36s\n",
      "110:\tlearn: 0.9716172\ttotal: 2m 21s\tremaining: 14m 35s\n",
      "111:\tlearn: 0.9718990\ttotal: 2m 22s\tremaining: 14m 34s\n",
      "112:\tlearn: 0.9718060\ttotal: 2m 23s\tremaining: 14m 32s\n",
      "113:\tlearn: 0.9721866\ttotal: 2m 24s\tremaining: 14m 31s\n",
      "114:\tlearn: 0.9720962\ttotal: 2m 26s\tremaining: 14m 30s\n",
      "115:\tlearn: 0.9716228\ttotal: 2m 27s\tremaining: 14m 28s\n",
      "116:\tlearn: 0.9718143\ttotal: 2m 28s\tremaining: 14m 27s\n",
      "117:\tlearn: 0.9719046\ttotal: 2m 29s\tremaining: 14m 26s\n",
      "118:\tlearn: 0.9725784\ttotal: 2m 31s\tremaining: 14m 25s\n",
      "119:\tlearn: 0.9722880\ttotal: 2m 32s\tremaining: 14m 23s\n",
      "120:\tlearn: 0.9725784\ttotal: 2m 33s\tremaining: 14m 22s\n",
      "121:\tlearn: 0.9726771\ttotal: 2m 35s\tremaining: 14m 21s\n",
      "122:\tlearn: 0.9732504\ttotal: 2m 36s\tremaining: 14m 20s\n",
      "123:\tlearn: 0.9726744\ttotal: 2m 37s\tremaining: 14m 18s\n",
      "124:\tlearn: 0.9726744\ttotal: 2m 38s\tremaining: 14m 17s\n",
      "125:\tlearn: 0.9726744\ttotal: 2m 40s\tremaining: 14m 16s\n",
      "126:\tlearn: 0.9727703\ttotal: 2m 41s\tremaining: 14m 14s\n",
      "127:\tlearn: 0.9731517\ttotal: 2m 42s\tremaining: 14m 13s\n",
      "128:\tlearn: 0.9736348\ttotal: 2m 43s\tremaining: 14m 11s\n",
      "129:\tlearn: 0.9733439\ttotal: 2m 45s\tremaining: 14m 10s\n",
      "130:\tlearn: 0.9737284\ttotal: 2m 46s\tremaining: 14m 9s\n",
      "131:\tlearn: 0.9736374\ttotal: 2m 47s\tremaining: 14m 7s\n",
      "132:\tlearn: 0.9734478\ttotal: 2m 48s\tremaining: 14m 6s\n",
      "133:\tlearn: 0.9732610\ttotal: 2m 50s\tremaining: 14m 5s\n",
      "134:\tlearn: 0.9730636\ttotal: 2m 51s\tremaining: 14m 4s\n",
      "135:\tlearn: 0.9730690\ttotal: 2m 52s\tremaining: 14m 2s\n",
      "136:\tlearn: 0.9726905\ttotal: 2m 53s\tremaining: 14m 1s\n",
      "137:\tlearn: 0.9734557\ttotal: 2m 55s\tremaining: 14m\n",
      "138:\tlearn: 0.9741286\ttotal: 2m 56s\tremaining: 13m 59s\n",
      "139:\tlearn: 0.9745110\ttotal: 2m 57s\tremaining: 13m 57s\n",
      "140:\tlearn: 0.9745135\ttotal: 2m 59s\tremaining: 13m 56s\n",
      "141:\tlearn: 0.9742197\ttotal: 3m\tremaining: 13m 55s\n",
      "142:\tlearn: 0.9746098\ttotal: 3m 1s\tremaining: 13m 54s\n",
      "143:\tlearn: 0.9743210\ttotal: 3m 2s\tremaining: 13m 52s\n",
      "144:\tlearn: 0.9743210\ttotal: 3m 4s\tremaining: 13m 51s\n",
      "145:\tlearn: 0.9744198\ttotal: 3m 5s\tremaining: 13m 50s\n",
      "146:\tlearn: 0.9743261\ttotal: 3m 6s\tremaining: 13m 49s\n",
      "147:\tlearn: 0.9745185\ttotal: 3m 8s\tremaining: 13m 48s\n",
      "148:\tlearn: 0.9745185\ttotal: 3m 9s\tremaining: 13m 47s\n",
      "149:\tlearn: 0.9748074\ttotal: 3m 10s\tremaining: 13m 45s\n",
      "150:\tlearn: 0.9747111\ttotal: 3m 11s\tremaining: 13m 44s\n",
      "151:\tlearn: 0.9750000\ttotal: 3m 13s\tremaining: 13m 43s\n",
      "152:\tlearn: 0.9751927\ttotal: 3m 14s\tremaining: 13m 42s\n",
      "153:\tlearn: 0.9750988\ttotal: 3m 15s\tremaining: 13m 41s\n",
      "154:\tlearn: 0.9751013\ttotal: 3m 17s\tremaining: 13m 40s\n",
      "155:\tlearn: 0.9750988\ttotal: 3m 18s\tremaining: 13m 39s\n",
      "156:\tlearn: 0.9752940\ttotal: 3m 19s\tremaining: 13m 37s\n",
      "157:\tlearn: 0.9751037\ttotal: 3m 20s\tremaining: 13m 36s\n",
      "158:\tlearn: 0.9754892\ttotal: 3m 22s\tremaining: 13m 35s\n",
      "159:\tlearn: 0.9758750\ttotal: 3m 23s\tremaining: 13m 33s\n",
      "160:\tlearn: 0.9757785\ttotal: 3m 24s\tremaining: 13m 32s\n",
      "161:\tlearn: 0.9760680\ttotal: 3m 25s\tremaining: 13m 31s\n",
      "162:\tlearn: 0.9761646\ttotal: 3m 27s\tremaining: 13m 29s\n",
      "163:\tlearn: 0.9761669\ttotal: 3m 28s\tremaining: 13m 28s\n",
      "164:\tlearn: 0.9762658\ttotal: 3m 29s\tremaining: 13m 27s\n",
      "165:\tlearn: 0.9762658\ttotal: 3m 30s\tremaining: 13m 25s\n",
      "166:\tlearn: 0.9764590\ttotal: 3m 32s\tremaining: 13m 24s\n",
      "167:\tlearn: 0.9760728\ttotal: 3m 33s\tremaining: 13m 23s\n",
      "168:\tlearn: 0.9761669\ttotal: 3m 34s\tremaining: 13m 21s\n",
      "169:\tlearn: 0.9766498\ttotal: 3m 36s\tremaining: 13m 20s\n",
      "170:\tlearn: 0.9766498\ttotal: 3m 37s\tremaining: 13m 19s\n",
      "171:\tlearn: 0.9763600\ttotal: 3m 38s\tremaining: 13m 18s\n",
      "172:\tlearn: 0.9765532\ttotal: 3m 39s\tremaining: 13m 17s\n",
      "173:\tlearn: 0.9766522\ttotal: 3m 41s\tremaining: 13m 15s\n",
      "174:\tlearn: 0.9764590\ttotal: 3m 42s\tremaining: 13m 14s\n",
      "175:\tlearn: 0.9767488\ttotal: 3m 43s\tremaining: 13m 13s\n",
      "176:\tlearn: 0.9762658\ttotal: 3m 45s\tremaining: 13m 12s\n",
      "177:\tlearn: 0.9766498\ttotal: 3m 46s\tremaining: 13m 10s\n",
      "178:\tlearn: 0.9771332\ttotal: 3m 47s\tremaining: 13m 9s\n",
      "179:\tlearn: 0.9771332\ttotal: 3m 48s\tremaining: 13m 8s\n",
      "180:\tlearn: 0.9775203\ttotal: 3m 50s\tremaining: 13m 6s\n",
      "181:\tlearn: 0.9774235\ttotal: 3m 51s\tremaining: 13m 5s\n",
      "182:\tlearn: 0.9775225\ttotal: 3m 52s\tremaining: 13m 3s\n",
      "183:\tlearn: 0.9774257\ttotal: 3m 53s\tremaining: 13m 2s\n",
      "184:\tlearn: 0.9775225\ttotal: 3m 55s\tremaining: 13m 1s\n",
      "185:\tlearn: 0.9778152\ttotal: 3m 56s\tremaining: 13m\n",
      "186:\tlearn: 0.9777184\ttotal: 3m 57s\tremaining: 12m 58s\n",
      "187:\tlearn: 0.9777184\ttotal: 3m 58s\tremaining: 12m 57s\n",
      "188:\tlearn: 0.9775248\ttotal: 4m\tremaining: 12m 56s\n",
      "189:\tlearn: 0.9777184\ttotal: 4m 1s\tremaining: 12m 54s\n",
      "190:\tlearn: 0.9780089\ttotal: 4m 2s\tremaining: 12m 53s\n",
      "191:\tlearn: 0.9779120\ttotal: 4m 3s\tremaining: 12m 52s\n",
      "192:\tlearn: 0.9777184\ttotal: 4m 5s\tremaining: 12m 51s\n",
      "193:\tlearn: 0.9776193\ttotal: 4m 6s\tremaining: 12m 49s\n",
      "194:\tlearn: 0.9777184\ttotal: 4m 7s\tremaining: 12m 48s\n",
      "195:\tlearn: 0.9774280\ttotal: 4m 8s\tremaining: 12m 47s\n",
      "196:\tlearn: 0.9776215\ttotal: 4m 10s\tremaining: 12m 45s\n",
      "197:\tlearn: 0.9779120\ttotal: 4m 11s\tremaining: 12m 44s\n",
      "198:\tlearn: 0.9781058\ttotal: 4m 12s\tremaining: 12m 43s\n",
      "199:\tlearn: 0.9782996\ttotal: 4m 13s\tremaining: 12m 41s\n",
      "200:\tlearn: 0.9786875\ttotal: 4m 15s\tremaining: 12m 40s\n",
      "201:\tlearn: 0.9788816\ttotal: 4m 16s\tremaining: 12m 39s\n",
      "202:\tlearn: 0.9789787\ttotal: 4m 17s\tremaining: 12m 37s\n",
      "203:\tlearn: 0.9790778\ttotal: 4m 18s\tremaining: 12m 36s\n",
      "204:\tlearn: 0.9791749\ttotal: 4m 20s\tremaining: 12m 35s\n",
      "205:\tlearn: 0.9797559\ttotal: 4m 21s\tremaining: 12m 33s\n",
      "206:\tlearn: 0.9799504\ttotal: 4m 22s\tremaining: 12m 32s\n",
      "207:\tlearn: 0.9798531\ttotal: 4m 23s\tremaining: 12m 31s\n",
      "208:\tlearn: 0.9793671\ttotal: 4m 25s\tremaining: 12m 29s\n",
      "209:\tlearn: 0.9797559\ttotal: 4m 26s\tremaining: 12m 28s\n",
      "210:\tlearn: 0.9795635\ttotal: 4m 27s\tremaining: 12m 27s\n",
      "211:\tlearn: 0.9798571\ttotal: 4m 28s\tremaining: 12m 26s\n",
      "212:\tlearn: 0.9799544\ttotal: 4m 30s\tremaining: 12m 24s\n",
      "213:\tlearn: 0.9802462\ttotal: 4m 31s\tremaining: 12m 23s\n",
      "214:\tlearn: 0.9800516\ttotal: 4m 32s\tremaining: 12m 22s\n",
      "215:\tlearn: 0.9802462\ttotal: 4m 34s\tremaining: 12m 20s\n",
      "216:\tlearn: 0.9804408\ttotal: 4m 35s\tremaining: 12m 19s\n",
      "217:\tlearn: 0.9804408\ttotal: 4m 36s\tremaining: 12m 18s\n",
      "218:\tlearn: 0.9805382\ttotal: 4m 37s\tremaining: 12m 16s\n",
      "219:\tlearn: 0.9807310\ttotal: 4m 39s\tremaining: 12m 15s\n",
      "220:\tlearn: 0.9803415\ttotal: 4m 40s\tremaining: 12m 14s\n",
      "221:\tlearn: 0.9800496\ttotal: 4m 41s\tremaining: 12m 12s\n",
      "222:\tlearn: 0.9797579\ttotal: 4m 42s\tremaining: 12m 11s\n",
      "223:\tlearn: 0.9799544\ttotal: 4m 44s\tremaining: 12m 10s\n",
      "224:\tlearn: 0.9800516\ttotal: 4m 45s\tremaining: 12m 9s\n",
      "225:\tlearn: 0.9805382\ttotal: 4m 46s\tremaining: 12m 7s\n",
      "226:\tlearn: 0.9804408\ttotal: 4m 47s\tremaining: 12m 6s\n",
      "227:\tlearn: 0.9805382\ttotal: 4m 49s\tremaining: 12m 5s\n",
      "228:\tlearn: 0.9803435\ttotal: 4m 50s\tremaining: 12m 4s\n",
      "229:\tlearn: 0.9804408\ttotal: 4m 51s\tremaining: 12m 2s\n",
      "230:\tlearn: 0.9804408\ttotal: 4m 52s\tremaining: 12m 1s\n",
      "231:\tlearn: 0.9805382\ttotal: 4m 54s\tremaining: 12m\n",
      "232:\tlearn: 0.9803435\ttotal: 4m 55s\tremaining: 11m 59s\n",
      "233:\tlearn: 0.9806356\ttotal: 4m 56s\tremaining: 11m 57s\n",
      "234:\tlearn: 0.9809278\ttotal: 4m 57s\tremaining: 11m 56s\n",
      "235:\tlearn: 0.9810252\ttotal: 4m 59s\tremaining: 11m 55s\n",
      "236:\tlearn: 0.9812202\ttotal: 5m\tremaining: 11m 53s\n",
      "237:\tlearn: 0.9813177\ttotal: 5m 1s\tremaining: 11m 52s\n",
      "238:\tlearn: 0.9811227\ttotal: 5m 3s\tremaining: 11m 51s\n",
      "239:\tlearn: 0.9813177\ttotal: 5m 4s\tremaining: 11m 50s\n",
      "240:\tlearn: 0.9817079\ttotal: 5m 5s\tremaining: 11m 48s\n",
      "241:\tlearn: 0.9820008\ttotal: 5m 6s\tremaining: 11m 47s\n",
      "242:\tlearn: 0.9818055\ttotal: 5m 8s\tremaining: 11m 46s\n",
      "243:\tlearn: 0.9821961\ttotal: 5m 9s\tremaining: 11m 44s\n",
      "244:\tlearn: 0.9820985\ttotal: 5m 10s\tremaining: 11m 43s\n",
      "245:\tlearn: 0.9820985\ttotal: 5m 11s\tremaining: 11m 42s\n",
      "246:\tlearn: 0.9825871\ttotal: 5m 13s\tremaining: 11m 41s\n",
      "247:\tlearn: 0.9824893\ttotal: 5m 14s\tremaining: 11m 39s\n",
      "248:\tlearn: 0.9825871\ttotal: 5m 15s\tremaining: 11m 38s\n",
      "249:\tlearn: 0.9826848\ttotal: 5m 16s\tremaining: 11m 37s\n",
      "250:\tlearn: 0.9826848\ttotal: 5m 18s\tremaining: 11m 35s\n",
      "251:\tlearn: 0.9825871\ttotal: 5m 19s\tremaining: 11m 34s\n",
      "252:\tlearn: 0.9826848\ttotal: 5m 20s\tremaining: 11m 33s\n",
      "253:\tlearn: 0.9824893\ttotal: 5m 21s\tremaining: 11m 31s\n",
      "254:\tlearn: 0.9823933\ttotal: 5m 23s\tremaining: 11m 30s\n",
      "255:\tlearn: 0.9825888\ttotal: 5m 24s\tremaining: 11m 29s\n",
      "256:\tlearn: 0.9826866\ttotal: 5m 25s\tremaining: 11m 27s\n",
      "257:\tlearn: 0.9824893\ttotal: 5m 26s\tremaining: 11m 26s\n",
      "258:\tlearn: 0.9825853\ttotal: 5m 28s\tremaining: 11m 25s\n",
      "259:\tlearn: 0.9826848\ttotal: 5m 29s\tremaining: 11m 23s\n",
      "260:\tlearn: 0.9827809\ttotal: 5m 30s\tremaining: 11m 22s\n",
      "261:\tlearn: 0.9825888\ttotal: 5m 31s\tremaining: 11m 21s\n",
      "262:\tlearn: 0.9824910\ttotal: 5m 33s\tremaining: 11m 19s\n",
      "263:\tlearn: 0.9827844\ttotal: 5m 34s\tremaining: 11m 18s\n",
      "264:\tlearn: 0.9828805\ttotal: 5m 35s\tremaining: 11m 17s\n",
      "265:\tlearn: 0.9829783\ttotal: 5m 36s\tremaining: 11m 16s\n",
      "266:\tlearn: 0.9832719\ttotal: 5m 38s\tremaining: 11m 14s\n",
      "267:\tlearn: 0.9832719\ttotal: 5m 39s\tremaining: 11m 13s\n",
      "268:\tlearn: 0.9832736\ttotal: 5m 40s\tremaining: 11m 12s\n",
      "269:\tlearn: 0.9833698\ttotal: 5m 41s\tremaining: 11m 10s\n",
      "270:\tlearn: 0.9834678\ttotal: 5m 42s\tremaining: 11m 9s\n",
      "271:\tlearn: 0.9834678\ttotal: 5m 44s\tremaining: 11m 8s\n",
      "272:\tlearn: 0.9835657\ttotal: 5m 45s\tremaining: 11m 6s\n",
      "273:\tlearn: 0.9834678\ttotal: 5m 46s\tremaining: 11m 5s\n",
      "274:\tlearn: 0.9838613\ttotal: 5m 48s\tremaining: 11m 4s\n",
      "275:\tlearn: 0.9840558\ttotal: 5m 49s\tremaining: 11m 3s\n",
      "276:\tlearn: 0.9841539\ttotal: 5m 50s\tremaining: 11m 1s\n",
      "277:\tlearn: 0.9842520\ttotal: 5m 51s\tremaining: 11m\n",
      "278:\tlearn: 0.9842520\ttotal: 5m 53s\tremaining: 10m 59s\n",
      "279:\tlearn: 0.9844498\ttotal: 5m 54s\tremaining: 10m 58s\n",
      "280:\tlearn: 0.9843516\ttotal: 5m 55s\tremaining: 10m 56s\n",
      "281:\tlearn: 0.9845464\ttotal: 5m 57s\tremaining: 10m 55s\n",
      "282:\tlearn: 0.9843532\ttotal: 5m 58s\tremaining: 10m 54s\n",
      "283:\tlearn: 0.9846476\ttotal: 5m 59s\tremaining: 10m 53s\n",
      "284:\tlearn: 0.9847442\ttotal: 6m\tremaining: 10m 52s\n",
      "285:\tlearn: 0.9846491\ttotal: 6m 2s\tremaining: 10m 51s\n",
      "286:\tlearn: 0.9849437\ttotal: 6m 3s\tremaining: 10m 49s\n",
      "287:\tlearn: 0.9848455\ttotal: 6m 4s\tremaining: 10m 48s\n",
      "288:\tlearn: 0.9851401\ttotal: 6m 6s\tremaining: 10m 47s\n",
      "289:\tlearn: 0.9848440\ttotal: 6m 7s\tremaining: 10m 45s\n",
      "290:\tlearn: 0.9855318\ttotal: 6m 8s\tremaining: 10m 44s\n",
      "291:\tlearn: 0.9855333\ttotal: 6m 9s\tremaining: 10m 43s\n",
      "292:\tlearn: 0.9858283\ttotal: 6m 11s\tremaining: 10m 42s\n",
      "293:\tlearn: 0.9857300\ttotal: 6m 12s\tremaining: 10m 40s\n",
      "294:\tlearn: 0.9857300\ttotal: 6m 13s\tremaining: 10m 39s\n",
      "295:\tlearn: 0.9857300\ttotal: 6m 14s\tremaining: 10m 38s\n",
      "296:\tlearn: 0.9858283\ttotal: 6m 16s\tremaining: 10m 37s\n",
      "297:\tlearn: 0.9859267\ttotal: 6m 17s\tremaining: 10m 35s\n",
      "298:\tlearn: 0.9859267\ttotal: 6m 18s\tremaining: 10m 34s\n",
      "299:\tlearn: 0.9859267\ttotal: 6m 19s\tremaining: 10m 33s\n",
      "300:\tlearn: 0.9860252\ttotal: 6m 21s\tremaining: 10m 32s\n",
      "301:\tlearn: 0.9863205\ttotal: 6m 22s\tremaining: 10m 30s\n",
      "302:\tlearn: 0.9865175\ttotal: 6m 23s\tremaining: 10m 29s\n",
      "303:\tlearn: 0.9865175\ttotal: 6m 25s\tremaining: 10m 28s\n",
      "304:\tlearn: 0.9865175\ttotal: 6m 26s\tremaining: 10m 26s\n",
      "305:\tlearn: 0.9864190\ttotal: 6m 27s\tremaining: 10m 25s\n",
      "306:\tlearn: 0.9862220\ttotal: 6m 28s\tremaining: 10m 24s\n",
      "307:\tlearn: 0.9862220\ttotal: 6m 30s\tremaining: 10m 23s\n",
      "308:\tlearn: 0.9865175\ttotal: 6m 31s\tremaining: 10m 21s\n",
      "309:\tlearn: 0.9867146\ttotal: 6m 32s\tremaining: 10m 20s\n",
      "310:\tlearn: 0.9867146\ttotal: 6m 33s\tremaining: 10m 19s\n",
      "311:\tlearn: 0.9865175\ttotal: 6m 35s\tremaining: 10m 17s\n",
      "312:\tlearn: 0.9864190\ttotal: 6m 36s\tremaining: 10m 16s\n",
      "313:\tlearn: 0.9862220\ttotal: 6m 37s\tremaining: 10m 15s\n",
      "314:\tlearn: 0.9862220\ttotal: 6m 38s\tremaining: 10m 13s\n",
      "315:\tlearn: 0.9863205\ttotal: 6m 40s\tremaining: 10m 12s\n",
      "316:\tlearn: 0.9864190\ttotal: 6m 41s\tremaining: 10m 11s\n",
      "317:\tlearn: 0.9865175\ttotal: 6m 42s\tremaining: 10m 10s\n",
      "318:\tlearn: 0.9866161\ttotal: 6m 43s\tremaining: 10m 8s\n",
      "319:\tlearn: 0.9867146\ttotal: 6m 44s\tremaining: 10m 7s\n",
      "320:\tlearn: 0.9866161\ttotal: 6m 46s\tremaining: 10m 6s\n",
      "321:\tlearn: 0.9869118\ttotal: 6m 47s\tremaining: 10m 4s\n",
      "322:\tlearn: 0.9870104\ttotal: 6m 48s\tremaining: 10m 3s\n",
      "323:\tlearn: 0.9874050\ttotal: 6m 49s\tremaining: 10m 2s\n",
      "324:\tlearn: 0.9876025\ttotal: 6m 51s\tremaining: 10m 1s\n",
      "325:\tlearn: 0.9876025\ttotal: 6m 52s\tremaining: 9m 59s\n",
      "326:\tlearn: 0.9874050\ttotal: 6m 53s\tremaining: 9m 58s\n",
      "327:\tlearn: 0.9876025\ttotal: 6m 55s\tremaining: 9m 57s\n",
      "328:\tlearn: 0.9878000\ttotal: 6m 56s\tremaining: 9m 56s\n",
      "329:\tlearn: 0.9879976\ttotal: 6m 57s\tremaining: 9m 54s\n",
      "330:\tlearn: 0.9878000\ttotal: 6m 58s\tremaining: 9m 53s\n",
      "331:\tlearn: 0.9879976\ttotal: 7m\tremaining: 9m 52s\n",
      "332:\tlearn: 0.9881953\ttotal: 7m 1s\tremaining: 9m 50s\n",
      "333:\tlearn: 0.9884919\ttotal: 7m 2s\tremaining: 9m 49s\n",
      "334:\tlearn: 0.9883930\ttotal: 7m 3s\tremaining: 9m 48s\n",
      "335:\tlearn: 0.9884919\ttotal: 7m 5s\tremaining: 9m 47s\n",
      "336:\tlearn: 0.9883930\ttotal: 7m 6s\tremaining: 9m 45s\n",
      "337:\tlearn: 0.9885909\ttotal: 7m 7s\tremaining: 9m 44s\n",
      "338:\tlearn: 0.9885909\ttotal: 7m 8s\tremaining: 9m 43s\n",
      "339:\tlearn: 0.9887888\ttotal: 7m 10s\tremaining: 9m 42s\n",
      "340:\tlearn: 0.9886898\ttotal: 7m 11s\tremaining: 9m 40s\n",
      "341:\tlearn: 0.9887888\ttotal: 7m 12s\tremaining: 9m 39s\n",
      "342:\tlearn: 0.9887888\ttotal: 7m 13s\tremaining: 9m 38s\n",
      "343:\tlearn: 0.9886898\ttotal: 7m 15s\tremaining: 9m 36s\n",
      "344:\tlearn: 0.9886898\ttotal: 7m 16s\tremaining: 9m 35s\n",
      "345:\tlearn: 0.9886898\ttotal: 7m 17s\tremaining: 9m 34s\n",
      "346:\tlearn: 0.9888878\ttotal: 7m 18s\tremaining: 9m 33s\n",
      "347:\tlearn: 0.9888878\ttotal: 7m 20s\tremaining: 9m 31s\n",
      "348:\tlearn: 0.9887888\ttotal: 7m 21s\tremaining: 9m 30s\n",
      "349:\tlearn: 0.9888878\ttotal: 7m 22s\tremaining: 9m 29s\n",
      "350:\tlearn: 0.9887888\ttotal: 7m 23s\tremaining: 9m 27s\n",
      "351:\tlearn: 0.9887888\ttotal: 7m 25s\tremaining: 9m 26s\n",
      "352:\tlearn: 0.9888878\ttotal: 7m 26s\tremaining: 9m 25s\n",
      "353:\tlearn: 0.9888878\ttotal: 7m 27s\tremaining: 9m 24s\n",
      "354:\tlearn: 0.9888878\ttotal: 7m 28s\tremaining: 9m 22s\n",
      "355:\tlearn: 0.9889868\ttotal: 7m 30s\tremaining: 9m 21s\n",
      "356:\tlearn: 0.9888878\ttotal: 7m 31s\tremaining: 9m 20s\n",
      "357:\tlearn: 0.9888878\ttotal: 7m 32s\tremaining: 9m 18s\n",
      "358:\tlearn: 0.9888878\ttotal: 7m 33s\tremaining: 9m 17s\n",
      "359:\tlearn: 0.9890858\ttotal: 7m 35s\tremaining: 9m 16s\n",
      "360:\tlearn: 0.9893830\ttotal: 7m 36s\tremaining: 9m 14s\n",
      "361:\tlearn: 0.9893830\ttotal: 7m 37s\tremaining: 9m 13s\n",
      "362:\tlearn: 0.9894821\ttotal: 7m 38s\tremaining: 9m 12s\n",
      "363:\tlearn: 0.9894821\ttotal: 7m 40s\tremaining: 9m 11s\n",
      "364:\tlearn: 0.9894821\ttotal: 7m 41s\tremaining: 9m 9s\n",
      "365:\tlearn: 0.9896804\ttotal: 7m 42s\tremaining: 9m 8s\n",
      "366:\tlearn: 0.9896804\ttotal: 7m 43s\tremaining: 9m 7s\n",
      "367:\tlearn: 0.9896804\ttotal: 7m 45s\tremaining: 9m 5s\n",
      "368:\tlearn: 0.9896804\ttotal: 7m 46s\tremaining: 9m 4s\n",
      "369:\tlearn: 0.9897796\ttotal: 7m 47s\tremaining: 9m 3s\n",
      "370:\tlearn: 0.9898787\ttotal: 7m 48s\tremaining: 9m 2s\n",
      "371:\tlearn: 0.9898787\ttotal: 7m 50s\tremaining: 9m\n",
      "372:\tlearn: 0.9899780\ttotal: 7m 51s\tremaining: 8m 59s\n",
      "373:\tlearn: 0.9897796\ttotal: 7m 52s\tremaining: 8m 58s\n",
      "374:\tlearn: 0.9898787\ttotal: 7m 53s\tremaining: 8m 56s\n",
      "375:\tlearn: 0.9897796\ttotal: 7m 55s\tremaining: 8m 55s\n",
      "376:\tlearn: 0.9899780\ttotal: 7m 56s\tremaining: 8m 54s\n",
      "377:\tlearn: 0.9899780\ttotal: 7m 57s\tremaining: 8m 53s\n",
      "378:\tlearn: 0.9899780\ttotal: 7m 58s\tremaining: 8m 51s\n",
      "379:\tlearn: 0.9900772\ttotal: 8m\tremaining: 8m 50s\n",
      "380:\tlearn: 0.9899780\ttotal: 8m 1s\tremaining: 8m 49s\n",
      "381:\tlearn: 0.9900772\ttotal: 8m 2s\tremaining: 8m 48s\n",
      "382:\tlearn: 0.9901764\ttotal: 8m 3s\tremaining: 8m 46s\n",
      "383:\tlearn: 0.9901764\ttotal: 8m 5s\tremaining: 8m 45s\n",
      "384:\tlearn: 0.9901764\ttotal: 8m 6s\tremaining: 8m 44s\n",
      "385:\tlearn: 0.9902757\ttotal: 8m 7s\tremaining: 8m 42s\n",
      "386:\tlearn: 0.9902757\ttotal: 8m 8s\tremaining: 8m 41s\n",
      "387:\tlearn: 0.9901764\ttotal: 8m 10s\tremaining: 8m 40s\n",
      "388:\tlearn: 0.9902757\ttotal: 8m 11s\tremaining: 8m 39s\n",
      "389:\tlearn: 0.9902757\ttotal: 8m 12s\tremaining: 8m 37s\n",
      "390:\tlearn: 0.9904743\ttotal: 8m 13s\tremaining: 8m 36s\n",
      "391:\tlearn: 0.9905736\ttotal: 8m 15s\tremaining: 8m 35s\n",
      "392:\tlearn: 0.9903750\ttotal: 8m 16s\tremaining: 8m 34s\n",
      "393:\tlearn: 0.9903750\ttotal: 8m 17s\tremaining: 8m 32s\n",
      "394:\tlearn: 0.9903750\ttotal: 8m 18s\tremaining: 8m 31s\n",
      "395:\tlearn: 0.9903750\ttotal: 8m 20s\tremaining: 8m 30s\n",
      "396:\tlearn: 0.9904743\ttotal: 8m 21s\tremaining: 8m 28s\n",
      "397:\tlearn: 0.9904743\ttotal: 8m 22s\tremaining: 8m 27s\n",
      "398:\tlearn: 0.9905736\ttotal: 8m 23s\tremaining: 8m 26s\n",
      "399:\tlearn: 0.9905736\ttotal: 8m 25s\tremaining: 8m 25s\n",
      "400:\tlearn: 0.9908717\ttotal: 8m 26s\tremaining: 8m 23s\n",
      "401:\tlearn: 0.9906730\ttotal: 8m 27s\tremaining: 8m 22s\n",
      "402:\tlearn: 0.9907723\ttotal: 8m 28s\tremaining: 8m 21s\n",
      "403:\tlearn: 0.9907723\ttotal: 8m 30s\tremaining: 8m 20s\n",
      "404:\tlearn: 0.9906730\ttotal: 8m 31s\tremaining: 8m 18s\n",
      "405:\tlearn: 0.9905736\ttotal: 8m 32s\tremaining: 8m 17s\n",
      "406:\tlearn: 0.9905736\ttotal: 8m 33s\tremaining: 8m 16s\n",
      "407:\tlearn: 0.9908717\ttotal: 8m 35s\tremaining: 8m 14s\n",
      "408:\tlearn: 0.9908717\ttotal: 8m 36s\tremaining: 8m 13s\n",
      "409:\tlearn: 0.9909711\ttotal: 8m 37s\tremaining: 8m 12s\n",
      "410:\tlearn: 0.9909711\ttotal: 8m 38s\tremaining: 8m 11s\n",
      "411:\tlearn: 0.9910705\ttotal: 8m 40s\tremaining: 8m 9s\n",
      "412:\tlearn: 0.9913689\ttotal: 8m 41s\tremaining: 8m 8s\n",
      "413:\tlearn: 0.9910705\ttotal: 8m 42s\tremaining: 8m 7s\n",
      "414:\tlearn: 0.9911700\ttotal: 8m 43s\tremaining: 8m 6s\n",
      "415:\tlearn: 0.9911700\ttotal: 8m 45s\tremaining: 8m 4s\n",
      "416:\tlearn: 0.9911700\ttotal: 8m 46s\tremaining: 8m 3s\n",
      "417:\tlearn: 0.9911700\ttotal: 8m 47s\tremaining: 8m 2s\n",
      "418:\tlearn: 0.9912694\ttotal: 8m 48s\tremaining: 8m\n",
      "419:\tlearn: 0.9912694\ttotal: 8m 50s\tremaining: 7m 59s\n",
      "420:\tlearn: 0.9913689\ttotal: 8m 51s\tremaining: 7m 58s\n",
      "421:\tlearn: 0.9913689\ttotal: 8m 52s\tremaining: 7m 57s\n",
      "422:\tlearn: 0.9913689\ttotal: 8m 53s\tremaining: 7m 55s\n",
      "423:\tlearn: 0.9914684\ttotal: 8m 55s\tremaining: 7m 54s\n",
      "424:\tlearn: 0.9914684\ttotal: 8m 56s\tremaining: 7m 53s\n",
      "425:\tlearn: 0.9914684\ttotal: 8m 57s\tremaining: 7m 51s\n",
      "426:\tlearn: 0.9913689\ttotal: 8m 58s\tremaining: 7m 50s\n",
      "427:\tlearn: 0.9912694\ttotal: 9m\tremaining: 7m 49s\n",
      "428:\tlearn: 0.9914684\ttotal: 9m 1s\tremaining: 7m 48s\n",
      "429:\tlearn: 0.9913689\ttotal: 9m 2s\tremaining: 7m 46s\n",
      "430:\tlearn: 0.9915680\ttotal: 9m 3s\tremaining: 7m 45s\n",
      "431:\tlearn: 0.9913689\ttotal: 9m 5s\tremaining: 7m 44s\n",
      "432:\tlearn: 0.9913689\ttotal: 9m 6s\tremaining: 7m 43s\n",
      "433:\tlearn: 0.9916675\ttotal: 9m 7s\tremaining: 7m 41s\n",
      "434:\tlearn: 0.9916675\ttotal: 9m 8s\tremaining: 7m 40s\n",
      "435:\tlearn: 0.9916675\ttotal: 9m 10s\tremaining: 7m 39s\n",
      "436:\tlearn: 0.9916675\ttotal: 9m 11s\tremaining: 7m 37s\n",
      "437:\tlearn: 0.9917671\ttotal: 9m 12s\tremaining: 7m 36s\n",
      "438:\tlearn: 0.9916675\ttotal: 9m 13s\tremaining: 7m 35s\n",
      "439:\tlearn: 0.9916675\ttotal: 9m 15s\tremaining: 7m 34s\n",
      "440:\tlearn: 0.9918667\ttotal: 9m 16s\tremaining: 7m 32s\n",
      "441:\tlearn: 0.9917671\ttotal: 9m 17s\tremaining: 7m 31s\n",
      "442:\tlearn: 0.9918667\ttotal: 9m 18s\tremaining: 7m 30s\n",
      "443:\tlearn: 0.9918667\ttotal: 9m 20s\tremaining: 7m 29s\n",
      "444:\tlearn: 0.9919663\ttotal: 9m 21s\tremaining: 7m 27s\n",
      "445:\tlearn: 0.9918667\ttotal: 9m 22s\tremaining: 7m 26s\n",
      "446:\tlearn: 0.9920659\ttotal: 9m 23s\tremaining: 7m 25s\n",
      "447:\tlearn: 0.9917671\ttotal: 9m 25s\tremaining: 7m 24s\n",
      "448:\tlearn: 0.9919663\ttotal: 9m 26s\tremaining: 7m 22s\n",
      "449:\tlearn: 0.9919663\ttotal: 9m 27s\tremaining: 7m 21s\n",
      "450:\tlearn: 0.9919663\ttotal: 9m 28s\tremaining: 7m 20s\n",
      "451:\tlearn: 0.9920659\ttotal: 9m 30s\tremaining: 7m 19s\n",
      "452:\tlearn: 0.9920659\ttotal: 9m 31s\tremaining: 7m 17s\n",
      "453:\tlearn: 0.9923649\ttotal: 9m 32s\tremaining: 7m 16s\n",
      "454:\tlearn: 0.9922652\ttotal: 9m 33s\tremaining: 7m 15s\n",
      "455:\tlearn: 0.9920659\ttotal: 9m 35s\tremaining: 7m 13s\n",
      "456:\tlearn: 0.9922652\ttotal: 9m 36s\tremaining: 7m 12s\n",
      "457:\tlearn: 0.9923649\ttotal: 9m 37s\tremaining: 7m 11s\n",
      "458:\tlearn: 0.9923649\ttotal: 9m 38s\tremaining: 7m 10s\n",
      "459:\tlearn: 0.9923649\ttotal: 9m 40s\tremaining: 7m 8s\n",
      "460:\tlearn: 0.9923649\ttotal: 9m 41s\tremaining: 7m 7s\n",
      "461:\tlearn: 0.9923649\ttotal: 9m 42s\tremaining: 7m 6s\n",
      "462:\tlearn: 0.9923649\ttotal: 9m 43s\tremaining: 7m 4s\n",
      "463:\tlearn: 0.9923649\ttotal: 9m 45s\tremaining: 7m 3s\n",
      "464:\tlearn: 0.9924646\ttotal: 9m 46s\tremaining: 7m 2s\n",
      "465:\tlearn: 0.9925643\ttotal: 9m 47s\tremaining: 7m 1s\n",
      "466:\tlearn: 0.9926641\ttotal: 9m 48s\tremaining: 6m 59s\n",
      "467:\tlearn: 0.9925643\ttotal: 9m 50s\tremaining: 6m 58s\n",
      "468:\tlearn: 0.9926641\ttotal: 9m 51s\tremaining: 6m 57s\n",
      "469:\tlearn: 0.9926641\ttotal: 9m 52s\tremaining: 6m 56s\n",
      "470:\tlearn: 0.9926641\ttotal: 9m 53s\tremaining: 6m 54s\n",
      "471:\tlearn: 0.9926641\ttotal: 9m 55s\tremaining: 6m 53s\n",
      "472:\tlearn: 0.9929634\ttotal: 9m 56s\tremaining: 6m 52s\n",
      "473:\tlearn: 0.9929634\ttotal: 9m 57s\tremaining: 6m 50s\n",
      "474:\tlearn: 0.9929634\ttotal: 9m 58s\tremaining: 6m 49s\n",
      "475:\tlearn: 0.9929634\ttotal: 10m\tremaining: 6m 48s\n",
      "476:\tlearn: 0.9929634\ttotal: 10m 1s\tremaining: 6m 47s\n",
      "477:\tlearn: 0.9929634\ttotal: 10m 2s\tremaining: 6m 45s\n",
      "478:\tlearn: 0.9929634\ttotal: 10m 3s\tremaining: 6m 44s\n",
      "479:\tlearn: 0.9929634\ttotal: 10m 5s\tremaining: 6m 43s\n",
      "480:\tlearn: 0.9929634\ttotal: 10m 6s\tremaining: 6m 42s\n",
      "481:\tlearn: 0.9930632\ttotal: 10m 7s\tremaining: 6m 40s\n",
      "482:\tlearn: 0.9929634\ttotal: 10m 8s\tremaining: 6m 39s\n",
      "483:\tlearn: 0.9930632\ttotal: 10m 10s\tremaining: 6m 38s\n",
      "484:\tlearn: 0.9930632\ttotal: 10m 11s\tremaining: 6m 37s\n",
      "485:\tlearn: 0.9930632\ttotal: 10m 12s\tremaining: 6m 35s\n",
      "486:\tlearn: 0.9930632\ttotal: 10m 13s\tremaining: 6m 34s\n",
      "487:\tlearn: 0.9930632\ttotal: 10m 15s\tremaining: 6m 33s\n",
      "488:\tlearn: 0.9930632\ttotal: 10m 16s\tremaining: 6m 31s\n",
      "489:\tlearn: 0.9930632\ttotal: 10m 17s\tremaining: 6m 30s\n",
      "490:\tlearn: 0.9930632\ttotal: 10m 18s\tremaining: 6m 29s\n",
      "491:\tlearn: 0.9930632\ttotal: 10m 20s\tremaining: 6m 28s\n",
      "492:\tlearn: 0.9930632\ttotal: 10m 21s\tremaining: 6m 26s\n",
      "493:\tlearn: 0.9930632\ttotal: 10m 22s\tremaining: 6m 25s\n",
      "494:\tlearn: 0.9930632\ttotal: 10m 23s\tremaining: 6m 24s\n",
      "495:\tlearn: 0.9930632\ttotal: 10m 25s\tremaining: 6m 23s\n",
      "496:\tlearn: 0.9930632\ttotal: 10m 26s\tremaining: 6m 21s\n",
      "497:\tlearn: 0.9930632\ttotal: 10m 27s\tremaining: 6m 20s\n",
      "498:\tlearn: 0.9930632\ttotal: 10m 28s\tremaining: 6m 19s\n",
      "499:\tlearn: 0.9930632\ttotal: 10m 30s\tremaining: 6m 18s\n",
      "500:\tlearn: 0.9930632\ttotal: 10m 31s\tremaining: 6m 16s\n",
      "501:\tlearn: 0.9930632\ttotal: 10m 32s\tremaining: 6m 15s\n",
      "502:\tlearn: 0.9929634\ttotal: 10m 33s\tremaining: 6m 14s\n",
      "503:\tlearn: 0.9929634\ttotal: 10m 35s\tremaining: 6m 13s\n",
      "504:\tlearn: 0.9930632\ttotal: 10m 36s\tremaining: 6m 11s\n",
      "505:\tlearn: 0.9930632\ttotal: 10m 37s\tremaining: 6m 10s\n",
      "506:\tlearn: 0.9931631\ttotal: 10m 39s\tremaining: 6m 9s\n",
      "507:\tlearn: 0.9931631\ttotal: 10m 40s\tremaining: 6m 8s\n",
      "508:\tlearn: 0.9931631\ttotal: 10m 41s\tremaining: 6m 6s\n",
      "509:\tlearn: 0.9931631\ttotal: 10m 42s\tremaining: 6m 5s\n",
      "510:\tlearn: 0.9932629\ttotal: 10m 43s\tremaining: 6m 4s\n",
      "511:\tlearn: 0.9932629\ttotal: 10m 45s\tremaining: 6m 2s\n",
      "512:\tlearn: 0.9933628\ttotal: 10m 46s\tremaining: 6m 1s\n",
      "513:\tlearn: 0.9933628\ttotal: 10m 47s\tremaining: 6m\n",
      "514:\tlearn: 0.9933628\ttotal: 10m 48s\tremaining: 5m 59s\n",
      "515:\tlearn: 0.9934627\ttotal: 10m 50s\tremaining: 5m 57s\n",
      "516:\tlearn: 0.9934627\ttotal: 10m 51s\tremaining: 5m 56s\n",
      "517:\tlearn: 0.9933628\ttotal: 10m 52s\tremaining: 5m 55s\n",
      "518:\tlearn: 0.9934627\ttotal: 10m 53s\tremaining: 5m 54s\n",
      "519:\tlearn: 0.9934627\ttotal: 10m 55s\tremaining: 5m 52s\n",
      "520:\tlearn: 0.9935627\ttotal: 10m 56s\tremaining: 5m 51s\n",
      "521:\tlearn: 0.9935627\ttotal: 10m 57s\tremaining: 5m 50s\n",
      "522:\tlearn: 0.9935627\ttotal: 10m 58s\tremaining: 5m 48s\n",
      "523:\tlearn: 0.9936626\ttotal: 11m\tremaining: 5m 47s\n",
      "524:\tlearn: 0.9936626\ttotal: 11m 1s\tremaining: 5m 46s\n",
      "525:\tlearn: 0.9936626\ttotal: 11m 2s\tremaining: 5m 45s\n",
      "526:\tlearn: 0.9936626\ttotal: 11m 3s\tremaining: 5m 43s\n",
      "527:\tlearn: 0.9936626\ttotal: 11m 5s\tremaining: 5m 42s\n",
      "528:\tlearn: 0.9936626\ttotal: 11m 6s\tremaining: 5m 41s\n",
      "529:\tlearn: 0.9936626\ttotal: 11m 7s\tremaining: 5m 40s\n",
      "530:\tlearn: 0.9936626\ttotal: 11m 8s\tremaining: 5m 38s\n",
      "531:\tlearn: 0.9936626\ttotal: 11m 10s\tremaining: 5m 37s\n",
      "532:\tlearn: 0.9936626\ttotal: 11m 11s\tremaining: 5m 36s\n",
      "533:\tlearn: 0.9936626\ttotal: 11m 12s\tremaining: 5m 35s\n",
      "534:\tlearn: 0.9936626\ttotal: 11m 13s\tremaining: 5m 33s\n",
      "535:\tlearn: 0.9937626\ttotal: 11m 15s\tremaining: 5m 32s\n",
      "536:\tlearn: 0.9936626\ttotal: 11m 16s\tremaining: 5m 31s\n",
      "537:\tlearn: 0.9938626\ttotal: 11m 17s\tremaining: 5m 30s\n",
      "538:\tlearn: 0.9939626\ttotal: 11m 19s\tremaining: 5m 28s\n",
      "539:\tlearn: 0.9939626\ttotal: 11m 20s\tremaining: 5m 27s\n",
      "540:\tlearn: 0.9939626\ttotal: 11m 21s\tremaining: 5m 26s\n",
      "541:\tlearn: 0.9939626\ttotal: 11m 22s\tremaining: 5m 25s\n",
      "542:\tlearn: 0.9939626\ttotal: 11m 24s\tremaining: 5m 23s\n",
      "543:\tlearn: 0.9940626\ttotal: 11m 25s\tremaining: 5m 22s\n",
      "544:\tlearn: 0.9941626\ttotal: 11m 26s\tremaining: 5m 21s\n",
      "545:\tlearn: 0.9941626\ttotal: 11m 27s\tremaining: 5m 20s\n",
      "546:\tlearn: 0.9940626\ttotal: 11m 29s\tremaining: 5m 18s\n",
      "547:\tlearn: 0.9939626\ttotal: 11m 30s\tremaining: 5m 17s\n",
      "548:\tlearn: 0.9939626\ttotal: 11m 31s\tremaining: 5m 16s\n",
      "549:\tlearn: 0.9939626\ttotal: 11m 32s\tremaining: 5m 14s\n",
      "550:\tlearn: 0.9940626\ttotal: 11m 34s\tremaining: 5m 13s\n",
      "551:\tlearn: 0.9940626\ttotal: 11m 35s\tremaining: 5m 12s\n",
      "552:\tlearn: 0.9941626\ttotal: 11m 36s\tremaining: 5m 11s\n",
      "553:\tlearn: 0.9941626\ttotal: 11m 37s\tremaining: 5m 9s\n",
      "554:\tlearn: 0.9942627\ttotal: 11m 39s\tremaining: 5m 8s\n",
      "555:\tlearn: 0.9944629\ttotal: 11m 40s\tremaining: 5m 7s\n",
      "556:\tlearn: 0.9945630\ttotal: 11m 41s\tremaining: 5m 6s\n",
      "557:\tlearn: 0.9947633\ttotal: 11m 43s\tremaining: 5m 4s\n",
      "558:\tlearn: 0.9947633\ttotal: 11m 44s\tremaining: 5m 3s\n",
      "559:\tlearn: 0.9947633\ttotal: 11m 45s\tremaining: 5m 2s\n",
      "560:\tlearn: 0.9947633\ttotal: 11m 46s\tremaining: 5m 1s\n",
      "561:\tlearn: 0.9947633\ttotal: 11m 48s\tremaining: 4m 59s\n",
      "562:\tlearn: 0.9947633\ttotal: 11m 49s\tremaining: 4m 58s\n",
      "563:\tlearn: 0.9948635\ttotal: 11m 50s\tremaining: 4m 57s\n",
      "564:\tlearn: 0.9948635\ttotal: 11m 51s\tremaining: 4m 56s\n",
      "565:\tlearn: 0.9949637\ttotal: 11m 53s\tremaining: 4m 54s\n",
      "566:\tlearn: 0.9949637\ttotal: 11m 54s\tremaining: 4m 53s\n",
      "567:\tlearn: 0.9949637\ttotal: 11m 55s\tremaining: 4m 52s\n",
      "568:\tlearn: 0.9949637\ttotal: 11m 56s\tremaining: 4m 51s\n",
      "569:\tlearn: 0.9949637\ttotal: 11m 58s\tremaining: 4m 49s\n",
      "570:\tlearn: 0.9949637\ttotal: 11m 59s\tremaining: 4m 48s\n",
      "571:\tlearn: 0.9949637\ttotal: 12m\tremaining: 4m 47s\n",
      "572:\tlearn: 0.9951642\ttotal: 12m 1s\tremaining: 4m 45s\n",
      "573:\tlearn: 0.9949637\ttotal: 12m 3s\tremaining: 4m 44s\n",
      "574:\tlearn: 0.9950640\ttotal: 12m 4s\tremaining: 4m 43s\n",
      "575:\tlearn: 0.9950640\ttotal: 12m 5s\tremaining: 4m 42s\n",
      "576:\tlearn: 0.9951642\ttotal: 12m 6s\tremaining: 4m 40s\n",
      "577:\tlearn: 0.9950640\ttotal: 12m 8s\tremaining: 4m 39s\n",
      "578:\tlearn: 0.9951642\ttotal: 12m 9s\tremaining: 4m 38s\n",
      "579:\tlearn: 0.9952645\ttotal: 12m 10s\tremaining: 4m 37s\n",
      "580:\tlearn: 0.9954651\ttotal: 12m 11s\tremaining: 4m 35s\n",
      "581:\tlearn: 0.9953648\ttotal: 12m 13s\tremaining: 4m 34s\n",
      "582:\tlearn: 0.9952645\ttotal: 12m 14s\tremaining: 4m 33s\n",
      "583:\tlearn: 0.9953648\ttotal: 12m 15s\tremaining: 4m 32s\n",
      "584:\tlearn: 0.9953648\ttotal: 12m 16s\tremaining: 4m 30s\n",
      "585:\tlearn: 0.9953648\ttotal: 12m 18s\tremaining: 4m 29s\n",
      "586:\tlearn: 0.9953648\ttotal: 12m 19s\tremaining: 4m 28s\n",
      "587:\tlearn: 0.9954651\ttotal: 12m 20s\tremaining: 4m 27s\n",
      "588:\tlearn: 0.9955654\ttotal: 12m 21s\tremaining: 4m 25s\n",
      "589:\tlearn: 0.9956658\ttotal: 12m 23s\tremaining: 4m 24s\n",
      "590:\tlearn: 0.9956658\ttotal: 12m 24s\tremaining: 4m 23s\n",
      "591:\tlearn: 0.9956658\ttotal: 12m 25s\tremaining: 4m 22s\n",
      "592:\tlearn: 0.9956658\ttotal: 12m 27s\tremaining: 4m 20s\n",
      "593:\tlearn: 0.9956658\ttotal: 12m 28s\tremaining: 4m 19s\n",
      "594:\tlearn: 0.9957661\ttotal: 12m 29s\tremaining: 4m 18s\n",
      "595:\tlearn: 0.9957661\ttotal: 12m 30s\tremaining: 4m 16s\n",
      "596:\tlearn: 0.9957661\ttotal: 12m 32s\tremaining: 4m 15s\n",
      "597:\tlearn: 0.9957661\ttotal: 12m 33s\tremaining: 4m 14s\n",
      "598:\tlearn: 0.9957661\ttotal: 12m 34s\tremaining: 4m 13s\n",
      "599:\tlearn: 0.9958665\ttotal: 12m 35s\tremaining: 4m 11s\n",
      "600:\tlearn: 0.9958665\ttotal: 12m 37s\tremaining: 4m 10s\n",
      "601:\tlearn: 0.9959669\ttotal: 12m 38s\tremaining: 4m 9s\n",
      "602:\tlearn: 0.9958665\ttotal: 12m 39s\tremaining: 4m 8s\n",
      "603:\tlearn: 0.9959669\ttotal: 12m 40s\tremaining: 4m 6s\n",
      "604:\tlearn: 0.9959669\ttotal: 12m 42s\tremaining: 4m 5s\n",
      "605:\tlearn: 0.9959669\ttotal: 12m 43s\tremaining: 4m 4s\n",
      "606:\tlearn: 0.9959669\ttotal: 12m 44s\tremaining: 4m 3s\n",
      "607:\tlearn: 0.9959669\ttotal: 12m 45s\tremaining: 4m 1s\n",
      "608:\tlearn: 0.9959669\ttotal: 12m 47s\tremaining: 4m\n",
      "609:\tlearn: 0.9959669\ttotal: 12m 48s\tremaining: 3m 59s\n",
      "610:\tlearn: 0.9959669\ttotal: 12m 49s\tremaining: 3m 58s\n",
      "611:\tlearn: 0.9958665\ttotal: 12m 50s\tremaining: 3m 56s\n",
      "612:\tlearn: 0.9958665\ttotal: 12m 52s\tremaining: 3m 55s\n",
      "613:\tlearn: 0.9958665\ttotal: 12m 53s\tremaining: 3m 54s\n",
      "614:\tlearn: 0.9958665\ttotal: 12m 54s\tremaining: 3m 53s\n",
      "615:\tlearn: 0.9959669\ttotal: 12m 56s\tremaining: 3m 51s\n",
      "616:\tlearn: 0.9957661\ttotal: 12m 57s\tremaining: 3m 50s\n",
      "617:\tlearn: 0.9958665\ttotal: 12m 58s\tremaining: 3m 49s\n",
      "618:\tlearn: 0.9959669\ttotal: 12m 59s\tremaining: 3m 48s\n",
      "619:\tlearn: 0.9959669\ttotal: 13m 1s\tremaining: 3m 46s\n",
      "620:\tlearn: 0.9959669\ttotal: 13m 2s\tremaining: 3m 45s\n",
      "621:\tlearn: 0.9959669\ttotal: 13m 3s\tremaining: 3m 44s\n",
      "622:\tlearn: 0.9960674\ttotal: 13m 4s\tremaining: 3m 43s\n",
      "623:\tlearn: 0.9960674\ttotal: 13m 6s\tremaining: 3m 41s\n",
      "624:\tlearn: 0.9960674\ttotal: 13m 7s\tremaining: 3m 40s\n",
      "625:\tlearn: 0.9961678\ttotal: 13m 8s\tremaining: 3m 39s\n",
      "626:\tlearn: 0.9961678\ttotal: 13m 9s\tremaining: 3m 37s\n",
      "627:\tlearn: 0.9961678\ttotal: 13m 11s\tremaining: 3m 36s\n",
      "628:\tlearn: 0.9961678\ttotal: 13m 12s\tremaining: 3m 35s\n",
      "629:\tlearn: 0.9961678\ttotal: 13m 13s\tremaining: 3m 34s\n",
      "630:\tlearn: 0.9961678\ttotal: 13m 15s\tremaining: 3m 32s\n",
      "631:\tlearn: 0.9961678\ttotal: 13m 16s\tremaining: 3m 31s\n",
      "632:\tlearn: 0.9961678\ttotal: 13m 17s\tremaining: 3m 30s\n",
      "633:\tlearn: 0.9961678\ttotal: 13m 18s\tremaining: 3m 29s\n",
      "634:\tlearn: 0.9961678\ttotal: 13m 20s\tremaining: 3m 27s\n",
      "635:\tlearn: 0.9961678\ttotal: 13m 21s\tremaining: 3m 26s\n",
      "636:\tlearn: 0.9961678\ttotal: 13m 22s\tremaining: 3m 25s\n",
      "637:\tlearn: 0.9961678\ttotal: 13m 23s\tremaining: 3m 24s\n",
      "638:\tlearn: 0.9961678\ttotal: 13m 25s\tremaining: 3m 22s\n",
      "639:\tlearn: 0.9961678\ttotal: 13m 26s\tremaining: 3m 21s\n",
      "640:\tlearn: 0.9961678\ttotal: 13m 27s\tremaining: 3m 20s\n",
      "641:\tlearn: 0.9962683\ttotal: 13m 29s\tremaining: 3m 19s\n",
      "642:\tlearn: 0.9962683\ttotal: 13m 30s\tremaining: 3m 17s\n",
      "643:\tlearn: 0.9962683\ttotal: 13m 31s\tremaining: 3m 16s\n",
      "644:\tlearn: 0.9962683\ttotal: 13m 32s\tremaining: 3m 15s\n",
      "645:\tlearn: 0.9962683\ttotal: 13m 34s\tremaining: 3m 14s\n",
      "646:\tlearn: 0.9962683\ttotal: 13m 35s\tremaining: 3m 12s\n",
      "647:\tlearn: 0.9962683\ttotal: 13m 36s\tremaining: 3m 11s\n",
      "648:\tlearn: 0.9962683\ttotal: 13m 37s\tremaining: 3m 10s\n",
      "649:\tlearn: 0.9962683\ttotal: 13m 39s\tremaining: 3m 9s\n",
      "650:\tlearn: 0.9962683\ttotal: 13m 40s\tremaining: 3m 7s\n",
      "651:\tlearn: 0.9962683\ttotal: 13m 41s\tremaining: 3m 6s\n",
      "652:\tlearn: 0.9963688\ttotal: 13m 43s\tremaining: 3m 5s\n",
      "653:\tlearn: 0.9963688\ttotal: 13m 44s\tremaining: 3m 4s\n",
      "654:\tlearn: 0.9963688\ttotal: 13m 45s\tremaining: 3m 2s\n",
      "655:\tlearn: 0.9964693\ttotal: 13m 46s\tremaining: 3m 1s\n",
      "656:\tlearn: 0.9965698\ttotal: 13m 48s\tremaining: 3m\n",
      "657:\tlearn: 0.9964693\ttotal: 13m 49s\tremaining: 2m 59s\n",
      "658:\tlearn: 0.9964693\ttotal: 13m 50s\tremaining: 2m 57s\n",
      "659:\tlearn: 0.9965698\ttotal: 13m 52s\tremaining: 2m 56s\n",
      "660:\tlearn: 0.9966704\ttotal: 13m 53s\tremaining: 2m 55s\n",
      "661:\tlearn: 0.9966704\ttotal: 13m 54s\tremaining: 2m 53s\n",
      "662:\tlearn: 0.9967709\ttotal: 13m 55s\tremaining: 2m 52s\n",
      "663:\tlearn: 0.9967709\ttotal: 13m 57s\tremaining: 2m 51s\n",
      "664:\tlearn: 0.9966704\ttotal: 13m 58s\tremaining: 2m 50s\n",
      "665:\tlearn: 0.9966704\ttotal: 13m 59s\tremaining: 2m 48s\n",
      "666:\tlearn: 0.9966704\ttotal: 14m\tremaining: 2m 47s\n",
      "667:\tlearn: 0.9966704\ttotal: 14m 2s\tremaining: 2m 46s\n",
      "668:\tlearn: 0.9968715\ttotal: 14m 3s\tremaining: 2m 45s\n",
      "669:\tlearn: 0.9966704\ttotal: 14m 4s\tremaining: 2m 43s\n",
      "670:\tlearn: 0.9967709\ttotal: 14m 6s\tremaining: 2m 42s\n",
      "671:\tlearn: 0.9968715\ttotal: 14m 7s\tremaining: 2m 41s\n",
      "672:\tlearn: 0.9968715\ttotal: 14m 8s\tremaining: 2m 40s\n",
      "673:\tlearn: 0.9967709\ttotal: 14m 9s\tremaining: 2m 38s\n",
      "674:\tlearn: 0.9968715\ttotal: 14m 11s\tremaining: 2m 37s\n",
      "675:\tlearn: 0.9968715\ttotal: 14m 12s\tremaining: 2m 36s\n",
      "676:\tlearn: 0.9968715\ttotal: 14m 13s\tremaining: 2m 35s\n",
      "677:\tlearn: 0.9967709\ttotal: 14m 14s\tremaining: 2m 33s\n",
      "678:\tlearn: 0.9968715\ttotal: 14m 16s\tremaining: 2m 32s\n",
      "679:\tlearn: 0.9968715\ttotal: 14m 17s\tremaining: 2m 31s\n",
      "680:\tlearn: 0.9968715\ttotal: 14m 18s\tremaining: 2m 30s\n",
      "681:\tlearn: 0.9968715\ttotal: 14m 19s\tremaining: 2m 28s\n",
      "682:\tlearn: 0.9968715\ttotal: 14m 21s\tremaining: 2m 27s\n",
      "683:\tlearn: 0.9969721\ttotal: 14m 22s\tremaining: 2m 26s\n",
      "684:\tlearn: 0.9969721\ttotal: 14m 23s\tremaining: 2m 24s\n",
      "685:\tlearn: 0.9969721\ttotal: 14m 24s\tremaining: 2m 23s\n",
      "686:\tlearn: 0.9969721\ttotal: 14m 26s\tremaining: 2m 22s\n",
      "687:\tlearn: 0.9969721\ttotal: 14m 27s\tremaining: 2m 21s\n",
      "688:\tlearn: 0.9970728\ttotal: 14m 28s\tremaining: 2m 19s\n",
      "689:\tlearn: 0.9970728\ttotal: 14m 29s\tremaining: 2m 18s\n",
      "690:\tlearn: 0.9972741\ttotal: 14m 31s\tremaining: 2m 17s\n",
      "691:\tlearn: 0.9971734\ttotal: 14m 32s\tremaining: 2m 16s\n",
      "692:\tlearn: 0.9971734\ttotal: 14m 33s\tremaining: 2m 14s\n",
      "693:\tlearn: 0.9971734\ttotal: 14m 35s\tremaining: 2m 13s\n",
      "694:\tlearn: 0.9972741\ttotal: 14m 36s\tremaining: 2m 12s\n",
      "695:\tlearn: 0.9971734\ttotal: 14m 37s\tremaining: 2m 11s\n",
      "696:\tlearn: 0.9971734\ttotal: 14m 38s\tremaining: 2m 9s\n",
      "697:\tlearn: 0.9973748\ttotal: 14m 40s\tremaining: 2m 8s\n",
      "698:\tlearn: 0.9973748\ttotal: 14m 41s\tremaining: 2m 7s\n",
      "699:\tlearn: 0.9973748\ttotal: 14m 42s\tremaining: 2m 6s\n",
      "700:\tlearn: 0.9973748\ttotal: 14m 43s\tremaining: 2m 4s\n",
      "701:\tlearn: 0.9973748\ttotal: 14m 45s\tremaining: 2m 3s\n",
      "702:\tlearn: 0.9974755\ttotal: 14m 46s\tremaining: 2m 2s\n",
      "703:\tlearn: 0.9974755\ttotal: 14m 47s\tremaining: 2m 1s\n",
      "704:\tlearn: 0.9974755\ttotal: 14m 49s\tremaining: 1m 59s\n",
      "705:\tlearn: 0.9974755\ttotal: 14m 50s\tremaining: 1m 58s\n",
      "706:\tlearn: 0.9974755\ttotal: 14m 51s\tremaining: 1m 57s\n",
      "707:\tlearn: 0.9974755\ttotal: 14m 52s\tremaining: 1m 56s\n",
      "708:\tlearn: 0.9974755\ttotal: 14m 54s\tremaining: 1m 54s\n",
      "709:\tlearn: 0.9973748\ttotal: 14m 55s\tremaining: 1m 53s\n",
      "710:\tlearn: 0.9975762\ttotal: 14m 56s\tremaining: 1m 52s\n",
      "711:\tlearn: 0.9975762\ttotal: 14m 58s\tremaining: 1m 50s\n",
      "712:\tlearn: 0.9977778\ttotal: 14m 59s\tremaining: 1m 49s\n",
      "713:\tlearn: 0.9978786\ttotal: 15m\tremaining: 1m 48s\n",
      "714:\tlearn: 0.9978786\ttotal: 15m 1s\tremaining: 1m 47s\n",
      "715:\tlearn: 0.9978786\ttotal: 15m 3s\tremaining: 1m 45s\n",
      "716:\tlearn: 0.9978786\ttotal: 15m 4s\tremaining: 1m 44s\n",
      "717:\tlearn: 0.9978786\ttotal: 15m 5s\tremaining: 1m 43s\n",
      "718:\tlearn: 0.9978786\ttotal: 15m 7s\tremaining: 1m 42s\n",
      "719:\tlearn: 0.9978786\ttotal: 15m 8s\tremaining: 1m 40s\n",
      "720:\tlearn: 0.9977778\ttotal: 15m 9s\tremaining: 1m 39s\n",
      "721:\tlearn: 0.9977778\ttotal: 15m 10s\tremaining: 1m 38s\n",
      "722:\tlearn: 0.9978786\ttotal: 15m 12s\tremaining: 1m 37s\n",
      "723:\tlearn: 0.9978786\ttotal: 15m 13s\tremaining: 1m 35s\n",
      "724:\tlearn: 0.9978786\ttotal: 15m 14s\tremaining: 1m 34s\n",
      "725:\tlearn: 0.9979794\ttotal: 15m 16s\tremaining: 1m 33s\n",
      "726:\tlearn: 0.9980802\ttotal: 15m 17s\tremaining: 1m 32s\n",
      "727:\tlearn: 0.9981811\ttotal: 15m 18s\tremaining: 1m 30s\n",
      "728:\tlearn: 0.9981811\ttotal: 15m 19s\tremaining: 1m 29s\n",
      "729:\tlearn: 0.9981811\ttotal: 15m 21s\tremaining: 1m 28s\n",
      "730:\tlearn: 0.9981811\ttotal: 15m 22s\tremaining: 1m 27s\n",
      "731:\tlearn: 0.9981811\ttotal: 15m 23s\tremaining: 1m 25s\n",
      "732:\tlearn: 0.9981811\ttotal: 15m 24s\tremaining: 1m 24s\n",
      "733:\tlearn: 0.9981811\ttotal: 15m 26s\tremaining: 1m 23s\n",
      "734:\tlearn: 0.9981811\ttotal: 15m 27s\tremaining: 1m 22s\n",
      "735:\tlearn: 0.9981811\ttotal: 15m 28s\tremaining: 1m 20s\n",
      "736:\tlearn: 0.9981811\ttotal: 15m 29s\tremaining: 1m 19s\n",
      "737:\tlearn: 0.9981811\ttotal: 15m 31s\tremaining: 1m 18s\n",
      "738:\tlearn: 0.9981811\ttotal: 15m 32s\tremaining: 1m 16s\n",
      "739:\tlearn: 0.9981811\ttotal: 15m 33s\tremaining: 1m 15s\n",
      "740:\tlearn: 0.9981811\ttotal: 15m 34s\tremaining: 1m 14s\n",
      "741:\tlearn: 0.9981811\ttotal: 15m 36s\tremaining: 1m 13s\n",
      "742:\tlearn: 0.9981811\ttotal: 15m 37s\tremaining: 1m 11s\n",
      "743:\tlearn: 0.9982820\ttotal: 15m 38s\tremaining: 1m 10s\n",
      "744:\tlearn: 0.9982820\ttotal: 15m 40s\tremaining: 1m 9s\n",
      "745:\tlearn: 0.9982820\ttotal: 15m 41s\tremaining: 1m 8s\n",
      "746:\tlearn: 0.9982820\ttotal: 15m 42s\tremaining: 1m 6s\n",
      "747:\tlearn: 0.9983829\ttotal: 15m 43s\tremaining: 1m 5s\n",
      "748:\tlearn: 0.9983829\ttotal: 15m 45s\tremaining: 1m 4s\n",
      "749:\tlearn: 0.9983829\ttotal: 15m 46s\tremaining: 1m 3s\n",
      "750:\tlearn: 0.9983829\ttotal: 15m 47s\tremaining: 1m 1s\n",
      "751:\tlearn: 0.9984838\ttotal: 15m 49s\tremaining: 1m\n",
      "752:\tlearn: 0.9984838\ttotal: 15m 50s\tremaining: 59.3s\n",
      "753:\tlearn: 0.9984838\ttotal: 15m 51s\tremaining: 58.1s\n",
      "754:\tlearn: 0.9984838\ttotal: 15m 52s\tremaining: 56.8s\n",
      "755:\tlearn: 0.9984838\ttotal: 15m 54s\tremaining: 55.5s\n",
      "756:\tlearn: 0.9984838\ttotal: 15m 55s\tremaining: 54.3s\n",
      "757:\tlearn: 0.9984838\ttotal: 15m 56s\tremaining: 53s\n",
      "758:\tlearn: 0.9984838\ttotal: 15m 57s\tremaining: 51.7s\n",
      "759:\tlearn: 0.9984838\ttotal: 15m 59s\tremaining: 50.5s\n",
      "760:\tlearn: 0.9984838\ttotal: 16m\tremaining: 49.2s\n",
      "761:\tlearn: 0.9984838\ttotal: 16m 1s\tremaining: 48s\n",
      "762:\tlearn: 0.9984838\ttotal: 16m 3s\tremaining: 46.7s\n",
      "763:\tlearn: 0.9985847\ttotal: 16m 4s\tremaining: 45.4s\n",
      "764:\tlearn: 0.9985847\ttotal: 16m 5s\tremaining: 44.2s\n",
      "765:\tlearn: 0.9985847\ttotal: 16m 6s\tremaining: 42.9s\n",
      "766:\tlearn: 0.9985847\ttotal: 16m 8s\tremaining: 41.7s\n",
      "767:\tlearn: 0.9984838\ttotal: 16m 9s\tremaining: 40.4s\n",
      "768:\tlearn: 0.9984838\ttotal: 16m 10s\tremaining: 39.1s\n",
      "769:\tlearn: 0.9985847\ttotal: 16m 12s\tremaining: 37.9s\n",
      "770:\tlearn: 0.9985847\ttotal: 16m 13s\tremaining: 36.6s\n",
      "771:\tlearn: 0.9985847\ttotal: 16m 14s\tremaining: 35.3s\n",
      "772:\tlearn: 0.9985847\ttotal: 16m 15s\tremaining: 34.1s\n",
      "773:\tlearn: 0.9986857\ttotal: 16m 17s\tremaining: 32.8s\n",
      "774:\tlearn: 0.9986857\ttotal: 16m 18s\tremaining: 31.6s\n",
      "775:\tlearn: 0.9986857\ttotal: 16m 19s\tremaining: 30.3s\n",
      "776:\tlearn: 0.9985847\ttotal: 16m 21s\tremaining: 29s\n",
      "777:\tlearn: 0.9986857\ttotal: 16m 22s\tremaining: 27.8s\n",
      "778:\tlearn: 0.9986857\ttotal: 16m 23s\tremaining: 26.5s\n",
      "779:\tlearn: 0.9986857\ttotal: 16m 24s\tremaining: 25.3s\n",
      "780:\tlearn: 0.9986857\ttotal: 16m 26s\tremaining: 24s\n",
      "781:\tlearn: 0.9986857\ttotal: 16m 27s\tremaining: 22.7s\n",
      "782:\tlearn: 0.9986857\ttotal: 16m 28s\tremaining: 21.5s\n",
      "783:\tlearn: 0.9986857\ttotal: 16m 29s\tremaining: 20.2s\n",
      "784:\tlearn: 0.9986857\ttotal: 16m 31s\tremaining: 18.9s\n",
      "785:\tlearn: 0.9986857\ttotal: 16m 32s\tremaining: 17.7s\n",
      "786:\tlearn: 0.9986857\ttotal: 16m 33s\tremaining: 16.4s\n",
      "787:\tlearn: 0.9986857\ttotal: 16m 35s\tremaining: 15.2s\n",
      "788:\tlearn: 0.9986857\ttotal: 16m 36s\tremaining: 13.9s\n",
      "789:\tlearn: 0.9986857\ttotal: 16m 37s\tremaining: 12.6s\n",
      "790:\tlearn: 0.9986857\ttotal: 16m 38s\tremaining: 11.4s\n",
      "791:\tlearn: 0.9986857\ttotal: 16m 40s\tremaining: 10.1s\n",
      "792:\tlearn: 0.9986857\ttotal: 16m 41s\tremaining: 8.84s\n",
      "793:\tlearn: 0.9986857\ttotal: 16m 42s\tremaining: 7.58s\n",
      "794:\tlearn: 0.9986857\ttotal: 16m 43s\tremaining: 6.31s\n",
      "795:\tlearn: 0.9986857\ttotal: 16m 45s\tremaining: 5.05s\n",
      "796:\tlearn: 0.9986857\ttotal: 16m 46s\tremaining: 3.79s\n",
      "797:\tlearn: 0.9986857\ttotal: 16m 47s\tremaining: 2.53s\n",
      "798:\tlearn: 0.9986857\ttotal: 16m 49s\tremaining: 1.26s\n",
      "799:\tlearn: 0.9986857\ttotal: 16m 50s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=2, border_count=32, depth=12, eval_metric=Precision, iterations=800, l2_leaf_reg=1, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=5; total time=16.9min\n",
      "0:\tlearn: 0.6684814\ttotal: 1.28s\tremaining: 17m 5s\n",
      "1:\tlearn: 0.7261579\ttotal: 2.61s\tremaining: 17m 20s\n",
      "2:\tlearn: 0.7718056\ttotal: 3.91s\tremaining: 17m 19s\n",
      "3:\tlearn: 0.8021422\ttotal: 5.19s\tremaining: 17m 13s\n",
      "4:\tlearn: 0.8225020\ttotal: 6.57s\tremaining: 17m 24s\n",
      "5:\tlearn: 0.8371418\ttotal: 7.89s\tremaining: 17m 24s\n",
      "6:\tlearn: 0.8496365\ttotal: 9.21s\tremaining: 17m 23s\n",
      "7:\tlearn: 0.8707794\ttotal: 10.6s\tremaining: 17m 25s\n",
      "8:\tlearn: 0.8866621\ttotal: 11.9s\tremaining: 17m 22s\n",
      "9:\tlearn: 0.8946289\ttotal: 13.1s\tremaining: 17m 18s\n",
      "10:\tlearn: 0.9012105\ttotal: 14.5s\tremaining: 17m 17s\n",
      "11:\tlearn: 0.9057469\ttotal: 15.8s\tremaining: 17m 17s\n",
      "12:\tlearn: 0.9131666\ttotal: 17.1s\tremaining: 17m 15s\n",
      "13:\tlearn: 0.9209393\ttotal: 18.4s\tremaining: 17m 13s\n",
      "14:\tlearn: 0.9268604\ttotal: 19.8s\tremaining: 17m 14s\n",
      "15:\tlearn: 0.9295678\ttotal: 21.1s\tremaining: 17m 11s\n",
      "16:\tlearn: 0.9303717\ttotal: 22.4s\tremaining: 17m 10s\n",
      "17:\tlearn: 0.9326527\ttotal: 23.7s\tremaining: 17m 10s\n",
      "18:\tlearn: 0.9347123\ttotal: 25s\tremaining: 17m 8s\n",
      "19:\tlearn: 0.9404774\ttotal: 26.4s\tremaining: 17m 8s\n",
      "20:\tlearn: 0.9441385\ttotal: 27.7s\tremaining: 17m 8s\n",
      "21:\tlearn: 0.9456885\ttotal: 29s\tremaining: 17m 6s\n",
      "22:\tlearn: 0.9455635\ttotal: 30.3s\tremaining: 17m 3s\n",
      "23:\tlearn: 0.9478808\ttotal: 31.7s\tremaining: 17m 3s\n",
      "24:\tlearn: 0.9497146\ttotal: 33s\tremaining: 17m 1s\n",
      "25:\tlearn: 0.9517622\ttotal: 34.3s\tremaining: 17m\n",
      "26:\tlearn: 0.9534128\ttotal: 35.6s\tremaining: 16m 59s\n",
      "27:\tlearn: 0.9533832\ttotal: 36.9s\tremaining: 16m 57s\n",
      "28:\tlearn: 0.9542683\ttotal: 38.2s\tremaining: 16m 56s\n",
      "29:\tlearn: 0.9543491\ttotal: 39.6s\tremaining: 16m 55s\n",
      "30:\tlearn: 0.9547240\ttotal: 40.9s\tremaining: 16m 53s\n",
      "31:\tlearn: 0.9553265\ttotal: 42.2s\tremaining: 16m 52s\n",
      "32:\tlearn: 0.9545276\ttotal: 43.5s\tremaining: 16m 50s\n",
      "33:\tlearn: 0.9577645\ttotal: 44.8s\tremaining: 16m 49s\n",
      "34:\tlearn: 0.9578834\ttotal: 46.1s\tremaining: 16m 48s\n",
      "35:\tlearn: 0.9587264\ttotal: 47.4s\tremaining: 16m 46s\n",
      "36:\tlearn: 0.9603775\ttotal: 48.8s\tremaining: 16m 45s\n",
      "37:\tlearn: 0.9613341\ttotal: 50.1s\tremaining: 16m 43s\n",
      "38:\tlearn: 0.9611373\ttotal: 51.4s\tremaining: 16m 42s\n",
      "39:\tlearn: 0.9629593\ttotal: 52.7s\tremaining: 16m 41s\n",
      "40:\tlearn: 0.9625800\ttotal: 54s\tremaining: 16m 40s\n",
      "41:\tlearn: 0.9632982\ttotal: 55.3s\tremaining: 16m 38s\n",
      "42:\tlearn: 0.9636525\ttotal: 56.7s\tremaining: 16m 37s\n",
      "43:\tlearn: 0.9639444\ttotal: 58s\tremaining: 16m 36s\n",
      "44:\tlearn: 0.9643666\ttotal: 59.3s\tremaining: 16m 34s\n",
      "45:\tlearn: 0.9642822\ttotal: 1m\tremaining: 16m 34s\n",
      "46:\tlearn: 0.9645669\ttotal: 1m 1s\tremaining: 16m 32s\n",
      "47:\tlearn: 0.9647742\ttotal: 1m 3s\tremaining: 16m 31s\n",
      "48:\tlearn: 0.9647915\ttotal: 1m 4s\tremaining: 16m 30s\n",
      "49:\tlearn: 0.9650934\ttotal: 1m 5s\tremaining: 16m 29s\n",
      "50:\tlearn: 0.9649985\ttotal: 1m 7s\tremaining: 16m 27s\n",
      "51:\tlearn: 0.9653680\ttotal: 1m 8s\tremaining: 16m 26s\n",
      "52:\tlearn: 0.9652867\ttotal: 1m 9s\tremaining: 16m 25s\n",
      "53:\tlearn: 0.9652935\ttotal: 1m 11s\tremaining: 16m 23s\n",
      "54:\tlearn: 0.9652157\ttotal: 1m 12s\tremaining: 16m 23s\n",
      "55:\tlearn: 0.9652157\ttotal: 1m 13s\tremaining: 16m 22s\n",
      "56:\tlearn: 0.9651311\ttotal: 1m 15s\tremaining: 16m 21s\n",
      "57:\tlearn: 0.9657238\ttotal: 1m 16s\tremaining: 16m 20s\n",
      "58:\tlearn: 0.9653412\ttotal: 1m 17s\tremaining: 16m 19s\n",
      "59:\tlearn: 0.9655274\ttotal: 1m 19s\tremaining: 16m 17s\n",
      "60:\tlearn: 0.9648744\ttotal: 1m 20s\tremaining: 16m 16s\n",
      "61:\tlearn: 0.9645028\ttotal: 1m 21s\tremaining: 16m 15s\n",
      "62:\tlearn: 0.9639322\ttotal: 1m 23s\tremaining: 16m 13s\n",
      "63:\tlearn: 0.9643137\ttotal: 1m 24s\tremaining: 16m 12s\n",
      "64:\tlearn: 0.9640302\ttotal: 1m 25s\tremaining: 16m 11s\n",
      "65:\tlearn: 0.9644187\ttotal: 1m 27s\tremaining: 16m 9s\n",
      "66:\tlearn: 0.9642472\ttotal: 1m 28s\tremaining: 16m 9s\n",
      "67:\tlearn: 0.9645307\ttotal: 1m 29s\tremaining: 16m 8s\n",
      "68:\tlearn: 0.9648143\ttotal: 1m 31s\tremaining: 16m 6s\n",
      "69:\tlearn: 0.9650069\ttotal: 1m 32s\tremaining: 16m 6s\n",
      "70:\tlearn: 0.9661532\ttotal: 1m 33s\tremaining: 16m 4s\n",
      "71:\tlearn: 0.9662646\ttotal: 1m 35s\tremaining: 16m 3s\n",
      "72:\tlearn: 0.9659937\ttotal: 1m 36s\tremaining: 16m 2s\n",
      "73:\tlearn: 0.9658890\ttotal: 1m 37s\tremaining: 16m\n",
      "74:\tlearn: 0.9673113\ttotal: 1m 39s\tremaining: 15m 58s\n",
      "75:\tlearn: 0.9663561\ttotal: 1m 40s\tremaining: 15m 57s\n",
      "76:\tlearn: 0.9662646\ttotal: 1m 41s\tremaining: 15m 56s\n",
      "77:\tlearn: 0.9670168\ttotal: 1m 43s\tremaining: 15m 55s\n",
      "78:\tlearn: 0.9663561\ttotal: 1m 44s\tremaining: 15m 53s\n",
      "79:\tlearn: 0.9662613\ttotal: 1m 45s\tremaining: 15m 52s\n",
      "80:\tlearn: 0.9665457\ttotal: 1m 47s\tremaining: 15m 50s\n",
      "81:\tlearn: 0.9669251\ttotal: 1m 48s\tremaining: 15m 49s\n",
      "82:\tlearn: 0.9672131\ttotal: 1m 49s\tremaining: 15m 48s\n",
      "83:\tlearn: 0.9675930\ttotal: 1m 51s\tremaining: 15m 47s\n",
      "84:\tlearn: 0.9675012\ttotal: 1m 52s\tremaining: 15m 45s\n",
      "85:\tlearn: 0.9677926\ttotal: 1m 53s\tremaining: 15m 44s\n",
      "86:\tlearn: 0.9677926\ttotal: 1m 55s\tremaining: 15m 42s\n",
      "87:\tlearn: 0.9674222\ttotal: 1m 56s\tremaining: 15m 41s\n",
      "88:\tlearn: 0.9679953\ttotal: 1m 57s\tremaining: 15m 40s\n",
      "89:\tlearn: 0.9685596\ttotal: 1m 59s\tremaining: 15m 38s\n",
      "90:\tlearn: 0.9689374\ttotal: 2m\tremaining: 15m 37s\n",
      "91:\tlearn: 0.9693246\ttotal: 2m 1s\tremaining: 15m 36s\n",
      "92:\tlearn: 0.9693276\ttotal: 2m 3s\tremaining: 15m 35s\n",
      "93:\tlearn: 0.9698043\ttotal: 2m 4s\tremaining: 15m 33s\n",
      "94:\tlearn: 0.9697148\ttotal: 2m 5s\tremaining: 15m 33s\n",
      "95:\tlearn: 0.9696255\ttotal: 2m 7s\tremaining: 15m 32s\n",
      "96:\tlearn: 0.9698102\ttotal: 2m 8s\tremaining: 15m 30s\n",
      "97:\tlearn: 0.9694319\ttotal: 2m 9s\tremaining: 15m 29s\n",
      "98:\tlearn: 0.9698191\ttotal: 2m 11s\tremaining: 15m 28s\n",
      "99:\tlearn: 0.9699115\ttotal: 2m 12s\tremaining: 15m 26s\n",
      "100:\tlearn: 0.9697208\ttotal: 2m 13s\tremaining: 15m 25s\n",
      "101:\tlearn: 0.9696225\ttotal: 2m 15s\tremaining: 15m 24s\n",
      "102:\tlearn: 0.9701948\ttotal: 2m 16s\tremaining: 15m 23s\n",
      "103:\tlearn: 0.9708661\ttotal: 2m 17s\tremaining: 15m 21s\n",
      "104:\tlearn: 0.9707677\ttotal: 2m 19s\tremaining: 15m 20s\n",
      "105:\tlearn: 0.9710544\ttotal: 2m 20s\tremaining: 15m 19s\n",
      "106:\tlearn: 0.9711586\ttotal: 2m 21s\tremaining: 15m 18s\n",
      "107:\tlearn: 0.9706808\ttotal: 2m 23s\tremaining: 15m 17s\n",
      "108:\tlearn: 0.9707735\ttotal: 2m 24s\tremaining: 15m 15s\n",
      "109:\tlearn: 0.9701111\ttotal: 2m 25s\tremaining: 15m 14s\n",
      "110:\tlearn: 0.9704928\ttotal: 2m 27s\tremaining: 15m 13s\n",
      "111:\tlearn: 0.9708747\ttotal: 2m 28s\tremaining: 15m 11s\n",
      "112:\tlearn: 0.9707821\ttotal: 2m 29s\tremaining: 15m 10s\n",
      "113:\tlearn: 0.9709731\ttotal: 2m 31s\tremaining: 15m 9s\n",
      "114:\tlearn: 0.9707878\ttotal: 2m 32s\tremaining: 15m 7s\n",
      "115:\tlearn: 0.9711671\ttotal: 2m 33s\tremaining: 15m 6s\n",
      "116:\tlearn: 0.9709760\ttotal: 2m 35s\tremaining: 15m 5s\n",
      "117:\tlearn: 0.9706866\ttotal: 2m 36s\tremaining: 15m 4s\n",
      "118:\tlearn: 0.9711671\ttotal: 2m 37s\tremaining: 15m 2s\n",
      "119:\tlearn: 0.9710658\ttotal: 2m 39s\tremaining: 15m 1s\n",
      "120:\tlearn: 0.9719295\ttotal: 2m 40s\tremaining: 15m\n",
      "121:\tlearn: 0.9716452\ttotal: 2m 41s\tremaining: 14m 59s\n",
      "122:\tlearn: 0.9717381\ttotal: 2m 43s\tremaining: 14m 57s\n",
      "123:\tlearn: 0.9719350\ttotal: 2m 44s\tremaining: 14m 56s\n",
      "124:\tlearn: 0.9717492\ttotal: 2m 45s\tremaining: 14m 54s\n",
      "125:\tlearn: 0.9716591\ttotal: 2m 47s\tremaining: 14m 53s\n",
      "126:\tlearn: 0.9721374\ttotal: 2m 48s\tremaining: 14m 52s\n",
      "127:\tlearn: 0.9721347\ttotal: 2m 49s\tremaining: 14m 50s\n",
      "128:\tlearn: 0.9721347\ttotal: 2m 51s\tremaining: 14m 49s\n",
      "129:\tlearn: 0.9724219\ttotal: 2m 52s\tremaining: 14m 48s\n",
      "130:\tlearn: 0.9726135\ttotal: 2m 53s\tremaining: 14m 47s\n",
      "131:\tlearn: 0.9728052\ttotal: 2m 55s\tremaining: 14m 45s\n",
      "132:\tlearn: 0.9728025\ttotal: 2m 56s\tremaining: 14m 44s\n",
      "133:\tlearn: 0.9728984\ttotal: 2m 57s\tremaining: 14m 43s\n",
      "134:\tlearn: 0.9727120\ttotal: 2m 59s\tremaining: 14m 41s\n",
      "135:\tlearn: 0.9737673\ttotal: 3m\tremaining: 14m 40s\n",
      "136:\tlearn: 0.9738633\ttotal: 3m 1s\tremaining: 14m 39s\n",
      "137:\tlearn: 0.9742451\ttotal: 3m 3s\tremaining: 14m 37s\n",
      "138:\tlearn: 0.9749210\ttotal: 3m 4s\tremaining: 14m 36s\n",
      "139:\tlearn: 0.9748223\ttotal: 3m 5s\tremaining: 14m 35s\n",
      "140:\tlearn: 0.9746298\ttotal: 3m 6s\tremaining: 14m 33s\n",
      "141:\tlearn: 0.9750173\ttotal: 3m 8s\tremaining: 14m 32s\n",
      "142:\tlearn: 0.9751136\ttotal: 3m 9s\tremaining: 14m 31s\n",
      "143:\tlearn: 0.9752099\ttotal: 3m 10s\tremaining: 14m 30s\n",
      "144:\tlearn: 0.9752099\ttotal: 3m 12s\tremaining: 14m 28s\n",
      "145:\tlearn: 0.9751136\ttotal: 3m 13s\tremaining: 14m 27s\n",
      "146:\tlearn: 0.9754989\ttotal: 3m 15s\tremaining: 14m 26s\n",
      "147:\tlearn: 0.9754989\ttotal: 3m 16s\tremaining: 14m 25s\n",
      "148:\tlearn: 0.9754989\ttotal: 3m 17s\tremaining: 14m 23s\n",
      "149:\tlearn: 0.9754025\ttotal: 3m 19s\tremaining: 14m 22s\n",
      "150:\tlearn: 0.9752099\ttotal: 3m 20s\tremaining: 14m 20s\n",
      "151:\tlearn: 0.9751136\ttotal: 3m 21s\tremaining: 14m 19s\n",
      "152:\tlearn: 0.9757857\ttotal: 3m 23s\tremaining: 14m 18s\n",
      "153:\tlearn: 0.9758822\ttotal: 3m 24s\tremaining: 14m 17s\n",
      "154:\tlearn: 0.9756917\ttotal: 3m 25s\tremaining: 14m 15s\n",
      "155:\tlearn: 0.9756917\ttotal: 3m 27s\tremaining: 14m 14s\n",
      "156:\tlearn: 0.9756917\ttotal: 3m 28s\tremaining: 14m 13s\n",
      "157:\tlearn: 0.9758846\ttotal: 3m 29s\tremaining: 14m 12s\n",
      "158:\tlearn: 0.9758846\ttotal: 3m 31s\tremaining: 14m 10s\n",
      "159:\tlearn: 0.9755929\ttotal: 3m 32s\tremaining: 14m 9s\n",
      "160:\tlearn: 0.9755929\ttotal: 3m 33s\tremaining: 14m 8s\n",
      "161:\tlearn: 0.9756917\ttotal: 3m 35s\tremaining: 14m 6s\n",
      "162:\tlearn: 0.9756893\ttotal: 3m 36s\tremaining: 14m 5s\n",
      "163:\tlearn: 0.9755953\ttotal: 3m 37s\tremaining: 14m 4s\n",
      "164:\tlearn: 0.9758846\ttotal: 3m 39s\tremaining: 14m 3s\n",
      "165:\tlearn: 0.9759810\ttotal: 3m 40s\tremaining: 14m 1s\n",
      "166:\tlearn: 0.9758869\ttotal: 3m 41s\tremaining: 14m\n",
      "167:\tlearn: 0.9760775\ttotal: 3m 43s\tremaining: 13m 59s\n",
      "168:\tlearn: 0.9762729\ttotal: 3m 44s\tremaining: 13m 58s\n",
      "169:\tlearn: 0.9764659\ttotal: 3m 45s\tremaining: 13m 56s\n",
      "170:\tlearn: 0.9765625\ttotal: 3m 47s\tremaining: 13m 55s\n",
      "171:\tlearn: 0.9766568\ttotal: 3m 48s\tremaining: 13m 54s\n",
      "172:\tlearn: 0.9765602\ttotal: 3m 49s\tremaining: 13m 52s\n",
      "173:\tlearn: 0.9767534\ttotal: 3m 51s\tremaining: 13m 51s\n",
      "174:\tlearn: 0.9769467\ttotal: 3m 52s\tremaining: 13m 50s\n",
      "175:\tlearn: 0.9769467\ttotal: 3m 53s\tremaining: 13m 48s\n",
      "176:\tlearn: 0.9774347\ttotal: 3m 55s\tremaining: 13m 47s\n",
      "177:\tlearn: 0.9775314\ttotal: 3m 56s\tremaining: 13m 46s\n",
      "178:\tlearn: 0.9774347\ttotal: 3m 57s\tremaining: 13m 44s\n",
      "179:\tlearn: 0.9772412\ttotal: 3m 59s\tremaining: 13m 43s\n",
      "180:\tlearn: 0.9773380\ttotal: 4m\tremaining: 13m 42s\n",
      "181:\tlearn: 0.9775314\ttotal: 4m 1s\tremaining: 13m 40s\n",
      "182:\tlearn: 0.9779186\ttotal: 4m 3s\tremaining: 13m 39s\n",
      "183:\tlearn: 0.9779186\ttotal: 4m 4s\tremaining: 13m 38s\n",
      "184:\tlearn: 0.9779186\ttotal: 4m 5s\tremaining: 13m 36s\n",
      "185:\tlearn: 0.9776282\ttotal: 4m 7s\tremaining: 13m 35s\n",
      "186:\tlearn: 0.9777250\ttotal: 4m 8s\tremaining: 13m 34s\n",
      "187:\tlearn: 0.9775314\ttotal: 4m 9s\tremaining: 13m 32s\n",
      "188:\tlearn: 0.9782092\ttotal: 4m 11s\tremaining: 13m 31s\n",
      "189:\tlearn: 0.9779186\ttotal: 4m 12s\tremaining: 13m 30s\n",
      "190:\tlearn: 0.9780154\ttotal: 4m 13s\tremaining: 13m 28s\n",
      "191:\tlearn: 0.9779186\ttotal: 4m 15s\tremaining: 13m 27s\n",
      "192:\tlearn: 0.9779186\ttotal: 4m 16s\tremaining: 13m 26s\n",
      "193:\tlearn: 0.9776282\ttotal: 4m 17s\tremaining: 13m 25s\n",
      "194:\tlearn: 0.9777250\ttotal: 4m 19s\tremaining: 13m 23s\n",
      "195:\tlearn: 0.9779186\ttotal: 4m 20s\tremaining: 13m 22s\n",
      "196:\tlearn: 0.9780154\ttotal: 4m 21s\tremaining: 13m 21s\n",
      "197:\tlearn: 0.9783082\ttotal: 4m 23s\tremaining: 13m 19s\n",
      "198:\tlearn: 0.9782113\ttotal: 4m 24s\tremaining: 13m 18s\n",
      "199:\tlearn: 0.9781145\ttotal: 4m 25s\tremaining: 13m 17s\n",
      "200:\tlearn: 0.9783082\ttotal: 4m 27s\tremaining: 13m 15s\n",
      "201:\tlearn: 0.9784052\ttotal: 4m 28s\tremaining: 13m 14s\n",
      "202:\tlearn: 0.9790841\ttotal: 4m 29s\tremaining: 13m 13s\n",
      "203:\tlearn: 0.9792782\ttotal: 4m 31s\tremaining: 13m 11s\n",
      "204:\tlearn: 0.9795696\ttotal: 4m 32s\tremaining: 13m 10s\n",
      "205:\tlearn: 0.9795696\ttotal: 4m 33s\tremaining: 13m 9s\n",
      "206:\tlearn: 0.9798611\ttotal: 4m 35s\tremaining: 13m 8s\n",
      "207:\tlearn: 0.9799583\ttotal: 4m 36s\tremaining: 13m 6s\n",
      "208:\tlearn: 0.9798611\ttotal: 4m 37s\tremaining: 13m 5s\n",
      "209:\tlearn: 0.9800556\ttotal: 4m 39s\tremaining: 13m 4s\n",
      "210:\tlearn: 0.9800556\ttotal: 4m 40s\tremaining: 13m 2s\n",
      "211:\tlearn: 0.9801528\ttotal: 4m 41s\tremaining: 13m 1s\n",
      "212:\tlearn: 0.9800556\ttotal: 4m 43s\tremaining: 13m\n",
      "213:\tlearn: 0.9799583\ttotal: 4m 44s\tremaining: 12m 58s\n",
      "214:\tlearn: 0.9801528\ttotal: 4m 45s\tremaining: 12m 57s\n",
      "215:\tlearn: 0.9801528\ttotal: 4m 47s\tremaining: 12m 56s\n",
      "216:\tlearn: 0.9801528\ttotal: 4m 48s\tremaining: 12m 54s\n",
      "217:\tlearn: 0.9797639\ttotal: 4m 49s\tremaining: 12m 53s\n",
      "218:\tlearn: 0.9799583\ttotal: 4m 51s\tremaining: 12m 52s\n",
      "219:\tlearn: 0.9799583\ttotal: 4m 52s\tremaining: 12m 51s\n",
      "220:\tlearn: 0.9801528\ttotal: 4m 53s\tremaining: 12m 49s\n",
      "221:\tlearn: 0.9802501\ttotal: 4m 55s\tremaining: 12m 48s\n",
      "222:\tlearn: 0.9803474\ttotal: 4m 56s\tremaining: 12m 47s\n",
      "223:\tlearn: 0.9802501\ttotal: 4m 57s\tremaining: 12m 46s\n",
      "224:\tlearn: 0.9799583\ttotal: 4m 59s\tremaining: 12m 44s\n",
      "225:\tlearn: 0.9800556\ttotal: 5m\tremaining: 12m 43s\n",
      "226:\tlearn: 0.9800556\ttotal: 5m 1s\tremaining: 12m 41s\n",
      "227:\tlearn: 0.9804447\ttotal: 5m 3s\tremaining: 12m 40s\n",
      "228:\tlearn: 0.9802501\ttotal: 5m 4s\tremaining: 12m 39s\n",
      "229:\tlearn: 0.9804447\ttotal: 5m 5s\tremaining: 12m 38s\n",
      "230:\tlearn: 0.9804447\ttotal: 5m 7s\tremaining: 12m 36s\n",
      "231:\tlearn: 0.9804447\ttotal: 5m 8s\tremaining: 12m 35s\n",
      "232:\tlearn: 0.9804447\ttotal: 5m 9s\tremaining: 12m 34s\n",
      "233:\tlearn: 0.9804447\ttotal: 5m 11s\tremaining: 12m 32s\n",
      "234:\tlearn: 0.9806394\ttotal: 5m 12s\tremaining: 12m 31s\n",
      "235:\tlearn: 0.9806394\ttotal: 5m 13s\tremaining: 12m 30s\n",
      "236:\tlearn: 0.9810290\ttotal: 5m 15s\tremaining: 12m 28s\n",
      "237:\tlearn: 0.9810271\ttotal: 5m 16s\tremaining: 12m 27s\n",
      "238:\tlearn: 0.9808323\ttotal: 5m 17s\tremaining: 12m 26s\n",
      "239:\tlearn: 0.9807349\ttotal: 5m 19s\tremaining: 12m 24s\n",
      "240:\tlearn: 0.9806394\ttotal: 5m 20s\tremaining: 12m 23s\n",
      "241:\tlearn: 0.9807349\ttotal: 5m 21s\tremaining: 12m 22s\n",
      "242:\tlearn: 0.9808323\ttotal: 5m 23s\tremaining: 12m 21s\n",
      "243:\tlearn: 0.9807368\ttotal: 5m 24s\tremaining: 12m 19s\n",
      "244:\tlearn: 0.9810290\ttotal: 5m 26s\tremaining: 12m 18s\n",
      "245:\tlearn: 0.9810290\ttotal: 5m 27s\tremaining: 12m 17s\n",
      "246:\tlearn: 0.9811265\ttotal: 5m 28s\tremaining: 12m 15s\n",
      "247:\tlearn: 0.9811265\ttotal: 5m 29s\tremaining: 12m 14s\n",
      "248:\tlearn: 0.9814189\ttotal: 5m 31s\tremaining: 12m 13s\n",
      "249:\tlearn: 0.9816140\ttotal: 5m 32s\tremaining: 12m 11s\n",
      "250:\tlearn: 0.9814189\ttotal: 5m 34s\tremaining: 12m 10s\n",
      "251:\tlearn: 0.9814189\ttotal: 5m 35s\tremaining: 12m 9s\n",
      "252:\tlearn: 0.9813214\ttotal: 5m 36s\tremaining: 12m 7s\n",
      "253:\tlearn: 0.9815164\ttotal: 5m 38s\tremaining: 12m 6s\n",
      "254:\tlearn: 0.9813214\ttotal: 5m 39s\tremaining: 12m 5s\n",
      "255:\tlearn: 0.9813214\ttotal: 5m 40s\tremaining: 12m 4s\n",
      "256:\tlearn: 0.9814189\ttotal: 5m 42s\tremaining: 12m 2s\n",
      "257:\tlearn: 0.9815164\ttotal: 5m 43s\tremaining: 12m 1s\n",
      "258:\tlearn: 0.9813214\ttotal: 5m 44s\tremaining: 12m\n",
      "259:\tlearn: 0.9811265\ttotal: 5m 46s\tremaining: 11m 58s\n",
      "260:\tlearn: 0.9811265\ttotal: 5m 47s\tremaining: 11m 57s\n",
      "261:\tlearn: 0.9809316\ttotal: 5m 48s\tremaining: 11m 56s\n",
      "262:\tlearn: 0.9813214\ttotal: 5m 50s\tremaining: 11m 55s\n",
      "263:\tlearn: 0.9813214\ttotal: 5m 51s\tremaining: 11m 53s\n",
      "264:\tlearn: 0.9818091\ttotal: 5m 52s\tremaining: 11m 52s\n",
      "265:\tlearn: 0.9817134\ttotal: 5m 54s\tremaining: 11m 51s\n",
      "266:\tlearn: 0.9816158\ttotal: 5m 55s\tremaining: 11m 49s\n",
      "267:\tlearn: 0.9821038\ttotal: 5m 56s\tremaining: 11m 48s\n",
      "268:\tlearn: 0.9822015\ttotal: 5m 58s\tremaining: 11m 47s\n",
      "269:\tlearn: 0.9820062\ttotal: 5m 59s\tremaining: 11m 46s\n",
      "270:\tlearn: 0.9820062\ttotal: 6m 1s\tremaining: 11m 44s\n",
      "271:\tlearn: 0.9816158\ttotal: 6m 2s\tremaining: 11m 43s\n",
      "272:\tlearn: 0.9820062\ttotal: 6m 3s\tremaining: 11m 42s\n",
      "273:\tlearn: 0.9818110\ttotal: 6m 5s\tremaining: 11m 40s\n",
      "274:\tlearn: 0.9820062\ttotal: 6m 6s\tremaining: 11m 39s\n",
      "275:\tlearn: 0.9821038\ttotal: 6m 7s\tremaining: 11m 38s\n",
      "276:\tlearn: 0.9821038\ttotal: 6m 9s\tremaining: 11m 36s\n",
      "277:\tlearn: 0.9823968\ttotal: 6m 10s\tremaining: 11m 35s\n",
      "278:\tlearn: 0.9826900\ttotal: 6m 11s\tremaining: 11m 34s\n",
      "279:\tlearn: 0.9826900\ttotal: 6m 13s\tremaining: 11m 33s\n",
      "280:\tlearn: 0.9827878\ttotal: 6m 14s\tremaining: 11m 31s\n",
      "281:\tlearn: 0.9828856\ttotal: 6m 15s\tremaining: 11m 30s\n",
      "282:\tlearn: 0.9828856\ttotal: 6m 17s\tremaining: 11m 29s\n",
      "283:\tlearn: 0.9829834\ttotal: 6m 18s\tremaining: 11m 28s\n",
      "284:\tlearn: 0.9830812\ttotal: 6m 20s\tremaining: 11m 26s\n",
      "285:\tlearn: 0.9832769\ttotal: 6m 21s\tremaining: 11m 25s\n",
      "286:\tlearn: 0.9831791\ttotal: 6m 22s\tremaining: 11m 24s\n",
      "287:\tlearn: 0.9831791\ttotal: 6m 24s\tremaining: 11m 23s\n",
      "288:\tlearn: 0.9832769\ttotal: 6m 25s\tremaining: 11m 21s\n",
      "289:\tlearn: 0.9833748\ttotal: 6m 26s\tremaining: 11m 20s\n",
      "290:\tlearn: 0.9833748\ttotal: 6m 28s\tremaining: 11m 19s\n",
      "291:\tlearn: 0.9833748\ttotal: 6m 29s\tremaining: 11m 17s\n",
      "292:\tlearn: 0.9832769\ttotal: 6m 30s\tremaining: 11m 16s\n",
      "293:\tlearn: 0.9834727\ttotal: 6m 32s\tremaining: 11m 15s\n",
      "294:\tlearn: 0.9834727\ttotal: 6m 33s\tremaining: 11m 13s\n",
      "295:\tlearn: 0.9835706\ttotal: 6m 35s\tremaining: 11m 12s\n",
      "296:\tlearn: 0.9835706\ttotal: 6m 36s\tremaining: 11m 11s\n",
      "297:\tlearn: 0.9839625\ttotal: 6m 37s\tremaining: 11m 10s\n",
      "298:\tlearn: 0.9838645\ttotal: 6m 39s\tremaining: 11m 9s\n",
      "299:\tlearn: 0.9838645\ttotal: 6m 40s\tremaining: 11m 7s\n",
      "300:\tlearn: 0.9839625\ttotal: 6m 41s\tremaining: 11m 6s\n",
      "301:\tlearn: 0.9841586\ttotal: 6m 43s\tremaining: 11m 5s\n",
      "302:\tlearn: 0.9838645\ttotal: 6m 44s\tremaining: 11m 3s\n",
      "303:\tlearn: 0.9837666\ttotal: 6m 46s\tremaining: 11m 2s\n",
      "304:\tlearn: 0.9837666\ttotal: 6m 47s\tremaining: 11m 1s\n",
      "305:\tlearn: 0.9837666\ttotal: 6m 48s\tremaining: 10m 59s\n",
      "306:\tlearn: 0.9838645\ttotal: 6m 50s\tremaining: 10m 58s\n",
      "307:\tlearn: 0.9838645\ttotal: 6m 51s\tremaining: 10m 57s\n",
      "308:\tlearn: 0.9837666\ttotal: 6m 52s\tremaining: 10m 55s\n",
      "309:\tlearn: 0.9839625\ttotal: 6m 54s\tremaining: 10m 54s\n",
      "310:\tlearn: 0.9837666\ttotal: 6m 55s\tremaining: 10m 53s\n",
      "311:\tlearn: 0.9837666\ttotal: 6m 56s\tremaining: 10m 51s\n",
      "312:\tlearn: 0.9837666\ttotal: 6m 58s\tremaining: 10m 50s\n",
      "313:\tlearn: 0.9838645\ttotal: 6m 59s\tremaining: 10m 49s\n",
      "314:\tlearn: 0.9838645\ttotal: 7m\tremaining: 10m 47s\n",
      "315:\tlearn: 0.9839625\ttotal: 7m 2s\tremaining: 10m 46s\n",
      "316:\tlearn: 0.9839625\ttotal: 7m 3s\tremaining: 10m 45s\n",
      "317:\tlearn: 0.9839625\ttotal: 7m 4s\tremaining: 10m 43s\n",
      "318:\tlearn: 0.9839625\ttotal: 7m 6s\tremaining: 10m 42s\n",
      "319:\tlearn: 0.9840606\ttotal: 7m 7s\tremaining: 10m 41s\n",
      "320:\tlearn: 0.9841586\ttotal: 7m 8s\tremaining: 10m 39s\n",
      "321:\tlearn: 0.9841586\ttotal: 7m 10s\tremaining: 10m 38s\n",
      "322:\tlearn: 0.9841586\ttotal: 7m 11s\tremaining: 10m 37s\n",
      "323:\tlearn: 0.9842567\ttotal: 7m 12s\tremaining: 10m 35s\n",
      "324:\tlearn: 0.9843548\ttotal: 7m 14s\tremaining: 10m 34s\n",
      "325:\tlearn: 0.9844529\ttotal: 7m 15s\tremaining: 10m 33s\n",
      "326:\tlearn: 0.9845510\ttotal: 7m 16s\tremaining: 10m 31s\n",
      "327:\tlearn: 0.9847473\ttotal: 7m 18s\tremaining: 10m 30s\n",
      "328:\tlearn: 0.9850419\ttotal: 7m 19s\tremaining: 10m 29s\n",
      "329:\tlearn: 0.9850419\ttotal: 7m 20s\tremaining: 10m 27s\n",
      "330:\tlearn: 0.9851401\ttotal: 7m 22s\tremaining: 10m 26s\n",
      "331:\tlearn: 0.9851401\ttotal: 7m 23s\tremaining: 10m 25s\n",
      "332:\tlearn: 0.9853367\ttotal: 7m 24s\tremaining: 10m 23s\n",
      "333:\tlearn: 0.9853367\ttotal: 7m 26s\tremaining: 10m 22s\n",
      "334:\tlearn: 0.9853367\ttotal: 7m 27s\tremaining: 10m 21s\n",
      "335:\tlearn: 0.9854350\ttotal: 7m 28s\tremaining: 10m 19s\n",
      "336:\tlearn: 0.9853367\ttotal: 7m 30s\tremaining: 10m 18s\n",
      "337:\tlearn: 0.9855333\ttotal: 7m 31s\tremaining: 10m 17s\n",
      "338:\tlearn: 0.9855333\ttotal: 7m 32s\tremaining: 10m 15s\n",
      "339:\tlearn: 0.9855333\ttotal: 7m 34s\tremaining: 10m 14s\n",
      "340:\tlearn: 0.9854350\ttotal: 7m 35s\tremaining: 10m 13s\n",
      "341:\tlearn: 0.9856316\ttotal: 7m 37s\tremaining: 10m 12s\n",
      "342:\tlearn: 0.9855333\ttotal: 7m 38s\tremaining: 10m 10s\n",
      "343:\tlearn: 0.9854350\ttotal: 7m 39s\tremaining: 10m 9s\n",
      "344:\tlearn: 0.9855333\ttotal: 7m 41s\tremaining: 10m 8s\n",
      "345:\tlearn: 0.9854350\ttotal: 7m 42s\tremaining: 10m 6s\n",
      "346:\tlearn: 0.9855333\ttotal: 7m 43s\tremaining: 10m 5s\n",
      "347:\tlearn: 0.9855333\ttotal: 7m 45s\tremaining: 10m 4s\n",
      "348:\tlearn: 0.9853367\ttotal: 7m 46s\tremaining: 10m 2s\n",
      "349:\tlearn: 0.9854350\ttotal: 7m 47s\tremaining: 10m 1s\n",
      "350:\tlearn: 0.9854350\ttotal: 7m 49s\tremaining: 10m\n",
      "351:\tlearn: 0.9853367\ttotal: 7m 50s\tremaining: 9m 58s\n",
      "352:\tlearn: 0.9855333\ttotal: 7m 51s\tremaining: 9m 57s\n",
      "353:\tlearn: 0.9858283\ttotal: 7m 53s\tremaining: 9m 56s\n",
      "354:\tlearn: 0.9857300\ttotal: 7m 54s\tremaining: 9m 54s\n",
      "355:\tlearn: 0.9858283\ttotal: 7m 55s\tremaining: 9m 53s\n",
      "356:\tlearn: 0.9859267\ttotal: 7m 57s\tremaining: 9m 52s\n",
      "357:\tlearn: 0.9859267\ttotal: 7m 58s\tremaining: 9m 50s\n",
      "358:\tlearn: 0.9860252\ttotal: 7m 59s\tremaining: 9m 49s\n",
      "359:\tlearn: 0.9860252\ttotal: 8m 1s\tremaining: 9m 48s\n",
      "360:\tlearn: 0.9860252\ttotal: 8m 2s\tremaining: 9m 46s\n",
      "361:\tlearn: 0.9862220\ttotal: 8m 3s\tremaining: 9m 45s\n",
      "362:\tlearn: 0.9861236\ttotal: 8m 5s\tremaining: 9m 44s\n",
      "363:\tlearn: 0.9861236\ttotal: 8m 6s\tremaining: 9m 42s\n",
      "364:\tlearn: 0.9863205\ttotal: 8m 8s\tremaining: 9m 41s\n",
      "365:\tlearn: 0.9862220\ttotal: 8m 9s\tremaining: 9m 40s\n",
      "366:\tlearn: 0.9864190\ttotal: 8m 10s\tremaining: 9m 39s\n",
      "367:\tlearn: 0.9866161\ttotal: 8m 12s\tremaining: 9m 37s\n",
      "368:\tlearn: 0.9867146\ttotal: 8m 13s\tremaining: 9m 36s\n",
      "369:\tlearn: 0.9867146\ttotal: 8m 14s\tremaining: 9m 34s\n",
      "370:\tlearn: 0.9867146\ttotal: 8m 16s\tremaining: 9m 33s\n",
      "371:\tlearn: 0.9866161\ttotal: 8m 17s\tremaining: 9m 32s\n",
      "372:\tlearn: 0.9868132\ttotal: 8m 18s\tremaining: 9m 30s\n",
      "373:\tlearn: 0.9866161\ttotal: 8m 20s\tremaining: 9m 29s\n",
      "374:\tlearn: 0.9867146\ttotal: 8m 21s\tremaining: 9m 28s\n",
      "375:\tlearn: 0.9868132\ttotal: 8m 22s\tremaining: 9m 26s\n",
      "376:\tlearn: 0.9867146\ttotal: 8m 24s\tremaining: 9m 25s\n",
      "377:\tlearn: 0.9867146\ttotal: 8m 25s\tremaining: 9m 24s\n",
      "378:\tlearn: 0.9867146\ttotal: 8m 26s\tremaining: 9m 22s\n",
      "379:\tlearn: 0.9866161\ttotal: 8m 28s\tremaining: 9m 21s\n",
      "380:\tlearn: 0.9866161\ttotal: 8m 29s\tremaining: 9m 20s\n",
      "381:\tlearn: 0.9868132\ttotal: 8m 30s\tremaining: 9m 18s\n",
      "382:\tlearn: 0.9868132\ttotal: 8m 32s\tremaining: 9m 17s\n",
      "383:\tlearn: 0.9870104\ttotal: 8m 33s\tremaining: 9m 16s\n",
      "384:\tlearn: 0.9869118\ttotal: 8m 34s\tremaining: 9m 15s\n",
      "385:\tlearn: 0.9871090\ttotal: 8m 36s\tremaining: 9m 13s\n",
      "386:\tlearn: 0.9870104\ttotal: 8m 37s\tremaining: 9m 12s\n",
      "387:\tlearn: 0.9869118\ttotal: 8m 38s\tremaining: 9m 10s\n",
      "388:\tlearn: 0.9871090\ttotal: 8m 40s\tremaining: 9m 9s\n",
      "389:\tlearn: 0.9869118\ttotal: 8m 41s\tremaining: 9m 8s\n",
      "390:\tlearn: 0.9869118\ttotal: 8m 43s\tremaining: 9m 7s\n",
      "391:\tlearn: 0.9872077\ttotal: 8m 44s\tremaining: 9m 5s\n",
      "392:\tlearn: 0.9871090\ttotal: 8m 45s\tremaining: 9m 4s\n",
      "393:\tlearn: 0.9871090\ttotal: 8m 47s\tremaining: 9m 3s\n",
      "394:\tlearn: 0.9873063\ttotal: 8m 48s\tremaining: 9m 1s\n",
      "395:\tlearn: 0.9875037\ttotal: 8m 49s\tremaining: 9m\n",
      "396:\tlearn: 0.9876025\ttotal: 8m 51s\tremaining: 8m 59s\n",
      "397:\tlearn: 0.9876025\ttotal: 8m 52s\tremaining: 8m 57s\n",
      "398:\tlearn: 0.9875037\ttotal: 8m 53s\tremaining: 8m 56s\n",
      "399:\tlearn: 0.9877012\ttotal: 8m 55s\tremaining: 8m 55s\n",
      "400:\tlearn: 0.9876025\ttotal: 8m 56s\tremaining: 8m 53s\n",
      "401:\tlearn: 0.9878000\ttotal: 8m 57s\tremaining: 8m 52s\n",
      "402:\tlearn: 0.9878000\ttotal: 8m 59s\tremaining: 8m 51s\n",
      "403:\tlearn: 0.9878988\ttotal: 9m\tremaining: 8m 49s\n",
      "404:\tlearn: 0.9880964\ttotal: 9m 1s\tremaining: 8m 48s\n",
      "405:\tlearn: 0.9879976\ttotal: 9m 3s\tremaining: 8m 47s\n",
      "406:\tlearn: 0.9878988\ttotal: 9m 4s\tremaining: 8m 45s\n",
      "407:\tlearn: 0.9881953\ttotal: 9m 5s\tremaining: 8m 44s\n",
      "408:\tlearn: 0.9880964\ttotal: 9m 7s\tremaining: 8m 43s\n",
      "409:\tlearn: 0.9880964\ttotal: 9m 8s\tremaining: 8m 41s\n",
      "410:\tlearn: 0.9884919\ttotal: 9m 9s\tremaining: 8m 40s\n",
      "411:\tlearn: 0.9886898\ttotal: 9m 11s\tremaining: 8m 39s\n",
      "412:\tlearn: 0.9884919\ttotal: 9m 12s\tremaining: 8m 37s\n",
      "413:\tlearn: 0.9883930\ttotal: 9m 14s\tremaining: 8m 36s\n",
      "414:\tlearn: 0.9886898\ttotal: 9m 15s\tremaining: 8m 35s\n",
      "415:\tlearn: 0.9886898\ttotal: 9m 16s\tremaining: 8m 33s\n",
      "416:\tlearn: 0.9886898\ttotal: 9m 18s\tremaining: 8m 32s\n",
      "417:\tlearn: 0.9886898\ttotal: 9m 19s\tremaining: 8m 31s\n",
      "418:\tlearn: 0.9886898\ttotal: 9m 20s\tremaining: 8m 29s\n",
      "419:\tlearn: 0.9886898\ttotal: 9m 22s\tremaining: 8m 28s\n",
      "420:\tlearn: 0.9887888\ttotal: 9m 23s\tremaining: 8m 27s\n",
      "421:\tlearn: 0.9887888\ttotal: 9m 24s\tremaining: 8m 25s\n",
      "422:\tlearn: 0.9888878\ttotal: 9m 26s\tremaining: 8m 24s\n",
      "423:\tlearn: 0.9889868\ttotal: 9m 27s\tremaining: 8m 23s\n",
      "424:\tlearn: 0.9888878\ttotal: 9m 28s\tremaining: 8m 21s\n",
      "425:\tlearn: 0.9889868\ttotal: 9m 30s\tremaining: 8m 20s\n",
      "426:\tlearn: 0.9889868\ttotal: 9m 31s\tremaining: 8m 19s\n",
      "427:\tlearn: 0.9890858\ttotal: 9m 32s\tremaining: 8m 17s\n",
      "428:\tlearn: 0.9891849\ttotal: 9m 34s\tremaining: 8m 16s\n",
      "429:\tlearn: 0.9892839\ttotal: 9m 35s\tremaining: 8m 15s\n",
      "430:\tlearn: 0.9894821\ttotal: 9m 36s\tremaining: 8m 13s\n",
      "431:\tlearn: 0.9893830\ttotal: 9m 38s\tremaining: 8m 12s\n",
      "432:\tlearn: 0.9895812\ttotal: 9m 39s\tremaining: 8m 11s\n",
      "433:\tlearn: 0.9896804\ttotal: 9m 40s\tremaining: 8m 9s\n",
      "434:\tlearn: 0.9895812\ttotal: 9m 42s\tremaining: 8m 8s\n",
      "435:\tlearn: 0.9895812\ttotal: 9m 43s\tremaining: 8m 7s\n",
      "436:\tlearn: 0.9896804\ttotal: 9m 45s\tremaining: 8m 5s\n",
      "437:\tlearn: 0.9895812\ttotal: 9m 46s\tremaining: 8m 4s\n",
      "438:\tlearn: 0.9895812\ttotal: 9m 47s\tremaining: 8m 3s\n",
      "439:\tlearn: 0.9896804\ttotal: 9m 49s\tremaining: 8m 1s\n",
      "440:\tlearn: 0.9897796\ttotal: 9m 50s\tremaining: 8m\n",
      "441:\tlearn: 0.9897796\ttotal: 9m 51s\tremaining: 7m 59s\n",
      "442:\tlearn: 0.9899780\ttotal: 9m 53s\tremaining: 7m 58s\n",
      "443:\tlearn: 0.9901764\ttotal: 9m 54s\tremaining: 7m 56s\n",
      "444:\tlearn: 0.9900772\ttotal: 9m 55s\tremaining: 7m 55s\n",
      "445:\tlearn: 0.9900772\ttotal: 9m 57s\tremaining: 7m 53s\n",
      "446:\tlearn: 0.9900772\ttotal: 9m 58s\tremaining: 7m 52s\n",
      "447:\tlearn: 0.9899780\ttotal: 9m 59s\tremaining: 7m 51s\n",
      "448:\tlearn: 0.9899780\ttotal: 10m 1s\tremaining: 7m 49s\n",
      "449:\tlearn: 0.9901764\ttotal: 10m 2s\tremaining: 7m 48s\n",
      "450:\tlearn: 0.9900772\ttotal: 10m 3s\tremaining: 7m 47s\n",
      "451:\tlearn: 0.9900772\ttotal: 10m 5s\tremaining: 7m 46s\n",
      "452:\tlearn: 0.9902757\ttotal: 10m 6s\tremaining: 7m 44s\n",
      "453:\tlearn: 0.9903750\ttotal: 10m 7s\tremaining: 7m 43s\n",
      "454:\tlearn: 0.9902757\ttotal: 10m 9s\tremaining: 7m 42s\n",
      "455:\tlearn: 0.9904743\ttotal: 10m 10s\tremaining: 7m 40s\n",
      "456:\tlearn: 0.9903750\ttotal: 10m 12s\tremaining: 7m 39s\n",
      "457:\tlearn: 0.9903750\ttotal: 10m 13s\tremaining: 7m 37s\n",
      "458:\tlearn: 0.9903750\ttotal: 10m 14s\tremaining: 7m 36s\n",
      "459:\tlearn: 0.9903750\ttotal: 10m 16s\tremaining: 7m 35s\n",
      "460:\tlearn: 0.9906730\ttotal: 10m 17s\tremaining: 7m 33s\n",
      "461:\tlearn: 0.9906730\ttotal: 10m 18s\tremaining: 7m 32s\n",
      "462:\tlearn: 0.9906730\ttotal: 10m 20s\tremaining: 7m 31s\n",
      "463:\tlearn: 0.9906730\ttotal: 10m 21s\tremaining: 7m 29s\n",
      "464:\tlearn: 0.9907723\ttotal: 10m 22s\tremaining: 7m 28s\n",
      "465:\tlearn: 0.9907723\ttotal: 10m 24s\tremaining: 7m 27s\n",
      "466:\tlearn: 0.9906730\ttotal: 10m 25s\tremaining: 7m 25s\n",
      "467:\tlearn: 0.9906730\ttotal: 10m 26s\tremaining: 7m 24s\n",
      "468:\tlearn: 0.9906730\ttotal: 10m 28s\tremaining: 7m 23s\n",
      "469:\tlearn: 0.9905736\ttotal: 10m 29s\tremaining: 7m 21s\n",
      "470:\tlearn: 0.9906730\ttotal: 10m 30s\tremaining: 7m 20s\n",
      "471:\tlearn: 0.9907723\ttotal: 10m 32s\tremaining: 7m 19s\n",
      "472:\tlearn: 0.9908717\ttotal: 10m 33s\tremaining: 7m 17s\n",
      "473:\tlearn: 0.9909711\ttotal: 10m 34s\tremaining: 7m 16s\n",
      "474:\tlearn: 0.9912694\ttotal: 10m 36s\tremaining: 7m 15s\n",
      "475:\tlearn: 0.9912694\ttotal: 10m 37s\tremaining: 7m 13s\n",
      "476:\tlearn: 0.9912694\ttotal: 10m 38s\tremaining: 7m 12s\n",
      "477:\tlearn: 0.9912694\ttotal: 10m 40s\tremaining: 7m 11s\n",
      "478:\tlearn: 0.9915680\ttotal: 10m 41s\tremaining: 7m 9s\n",
      "479:\tlearn: 0.9915680\ttotal: 10m 42s\tremaining: 7m 8s\n",
      "480:\tlearn: 0.9915680\ttotal: 10m 44s\tremaining: 7m 7s\n",
      "481:\tlearn: 0.9916675\ttotal: 10m 45s\tremaining: 7m 5s\n",
      "482:\tlearn: 0.9916675\ttotal: 10m 46s\tremaining: 7m 4s\n",
      "483:\tlearn: 0.9917671\ttotal: 10m 48s\tremaining: 7m 3s\n",
      "484:\tlearn: 0.9917671\ttotal: 10m 49s\tremaining: 7m 1s\n",
      "485:\tlearn: 0.9918667\ttotal: 10m 50s\tremaining: 7m\n",
      "486:\tlearn: 0.9919663\ttotal: 10m 52s\tremaining: 6m 59s\n",
      "487:\tlearn: 0.9922652\ttotal: 10m 53s\tremaining: 6m 57s\n",
      "488:\tlearn: 0.9923649\ttotal: 10m 55s\tremaining: 6m 56s\n",
      "489:\tlearn: 0.9923649\ttotal: 10m 56s\tremaining: 6m 55s\n",
      "490:\tlearn: 0.9924646\ttotal: 10m 57s\tremaining: 6m 53s\n",
      "491:\tlearn: 0.9922652\ttotal: 10m 59s\tremaining: 6m 52s\n",
      "492:\tlearn: 0.9921655\ttotal: 11m\tremaining: 6m 51s\n",
      "493:\tlearn: 0.9920659\ttotal: 11m 1s\tremaining: 6m 49s\n",
      "494:\tlearn: 0.9921655\ttotal: 11m 3s\tremaining: 6m 48s\n",
      "495:\tlearn: 0.9922652\ttotal: 11m 4s\tremaining: 6m 47s\n",
      "496:\tlearn: 0.9922652\ttotal: 11m 5s\tremaining: 6m 45s\n",
      "497:\tlearn: 0.9921655\ttotal: 11m 7s\tremaining: 6m 44s\n",
      "498:\tlearn: 0.9923649\ttotal: 11m 8s\tremaining: 6m 43s\n",
      "499:\tlearn: 0.9922652\ttotal: 11m 9s\tremaining: 6m 41s\n",
      "500:\tlearn: 0.9924646\ttotal: 11m 11s\tremaining: 6m 40s\n",
      "501:\tlearn: 0.9924646\ttotal: 11m 12s\tremaining: 6m 39s\n",
      "502:\tlearn: 0.9924646\ttotal: 11m 13s\tremaining: 6m 37s\n",
      "503:\tlearn: 0.9924646\ttotal: 11m 15s\tremaining: 6m 36s\n",
      "504:\tlearn: 0.9925643\ttotal: 11m 16s\tremaining: 6m 35s\n",
      "505:\tlearn: 0.9924646\ttotal: 11m 17s\tremaining: 6m 33s\n",
      "506:\tlearn: 0.9925643\ttotal: 11m 19s\tremaining: 6m 32s\n",
      "507:\tlearn: 0.9925643\ttotal: 11m 20s\tremaining: 6m 31s\n",
      "508:\tlearn: 0.9926641\ttotal: 11m 21s\tremaining: 6m 29s\n",
      "509:\tlearn: 0.9926641\ttotal: 11m 23s\tremaining: 6m 28s\n",
      "510:\tlearn: 0.9927638\ttotal: 11m 24s\tremaining: 6m 27s\n",
      "511:\tlearn: 0.9929634\ttotal: 11m 26s\tremaining: 6m 25s\n",
      "512:\tlearn: 0.9930632\ttotal: 11m 27s\tremaining: 6m 24s\n",
      "513:\tlearn: 0.9931631\ttotal: 11m 28s\tremaining: 6m 23s\n",
      "514:\tlearn: 0.9931631\ttotal: 11m 30s\tremaining: 6m 21s\n",
      "515:\tlearn: 0.9930632\ttotal: 11m 31s\tremaining: 6m 20s\n",
      "516:\tlearn: 0.9932629\ttotal: 11m 32s\tremaining: 6m 19s\n",
      "517:\tlearn: 0.9933628\ttotal: 11m 34s\tremaining: 6m 17s\n",
      "518:\tlearn: 0.9933628\ttotal: 11m 35s\tremaining: 6m 16s\n",
      "519:\tlearn: 0.9935627\ttotal: 11m 36s\tremaining: 6m 15s\n",
      "520:\tlearn: 0.9935627\ttotal: 11m 38s\tremaining: 6m 13s\n",
      "521:\tlearn: 0.9936626\ttotal: 11m 39s\tremaining: 6m 12s\n",
      "522:\tlearn: 0.9935627\ttotal: 11m 40s\tremaining: 6m 11s\n",
      "523:\tlearn: 0.9937626\ttotal: 11m 42s\tremaining: 6m 9s\n",
      "524:\tlearn: 0.9939626\ttotal: 11m 43s\tremaining: 6m 8s\n",
      "525:\tlearn: 0.9939626\ttotal: 11m 44s\tremaining: 6m 7s\n",
      "526:\tlearn: 0.9939626\ttotal: 11m 46s\tremaining: 6m 5s\n",
      "527:\tlearn: 0.9939626\ttotal: 11m 47s\tremaining: 6m 4s\n",
      "528:\tlearn: 0.9939626\ttotal: 11m 48s\tremaining: 6m 3s\n",
      "529:\tlearn: 0.9942627\ttotal: 11m 50s\tremaining: 6m 1s\n",
      "530:\tlearn: 0.9941626\ttotal: 11m 51s\tremaining: 6m\n",
      "531:\tlearn: 0.9941626\ttotal: 11m 52s\tremaining: 5m 59s\n",
      "532:\tlearn: 0.9942627\ttotal: 11m 54s\tremaining: 5m 57s\n",
      "533:\tlearn: 0.9942627\ttotal: 11m 55s\tremaining: 5m 56s\n",
      "534:\tlearn: 0.9942627\ttotal: 11m 56s\tremaining: 5m 55s\n",
      "535:\tlearn: 0.9941626\ttotal: 11m 58s\tremaining: 5m 53s\n",
      "536:\tlearn: 0.9942627\ttotal: 11m 59s\tremaining: 5m 52s\n",
      "537:\tlearn: 0.9944629\ttotal: 12m 1s\tremaining: 5m 51s\n",
      "538:\tlearn: 0.9944629\ttotal: 12m 2s\tremaining: 5m 49s\n",
      "539:\tlearn: 0.9944629\ttotal: 12m 3s\tremaining: 5m 48s\n",
      "540:\tlearn: 0.9944629\ttotal: 12m 5s\tremaining: 5m 47s\n",
      "541:\tlearn: 0.9946632\ttotal: 12m 6s\tremaining: 5m 45s\n",
      "542:\tlearn: 0.9945630\ttotal: 12m 7s\tremaining: 5m 44s\n",
      "543:\tlearn: 0.9946632\ttotal: 12m 9s\tremaining: 5m 43s\n",
      "544:\tlearn: 0.9946632\ttotal: 12m 10s\tremaining: 5m 41s\n",
      "545:\tlearn: 0.9946632\ttotal: 12m 11s\tremaining: 5m 40s\n",
      "546:\tlearn: 0.9946632\ttotal: 12m 13s\tremaining: 5m 39s\n",
      "547:\tlearn: 0.9945630\ttotal: 12m 14s\tremaining: 5m 37s\n",
      "548:\tlearn: 0.9945630\ttotal: 12m 15s\tremaining: 5m 36s\n",
      "549:\tlearn: 0.9946632\ttotal: 12m 17s\tremaining: 5m 35s\n",
      "550:\tlearn: 0.9948635\ttotal: 12m 18s\tremaining: 5m 33s\n",
      "551:\tlearn: 0.9948635\ttotal: 12m 20s\tremaining: 5m 32s\n",
      "552:\tlearn: 0.9949637\ttotal: 12m 21s\tremaining: 5m 31s\n",
      "553:\tlearn: 0.9949637\ttotal: 12m 22s\tremaining: 5m 29s\n",
      "554:\tlearn: 0.9951642\ttotal: 12m 24s\tremaining: 5m 28s\n",
      "555:\tlearn: 0.9950640\ttotal: 12m 25s\tremaining: 5m 27s\n",
      "556:\tlearn: 0.9949637\ttotal: 12m 26s\tremaining: 5m 25s\n",
      "557:\tlearn: 0.9950640\ttotal: 12m 28s\tremaining: 5m 24s\n",
      "558:\tlearn: 0.9949637\ttotal: 12m 29s\tremaining: 5m 23s\n",
      "559:\tlearn: 0.9951642\ttotal: 12m 30s\tremaining: 5m 21s\n",
      "560:\tlearn: 0.9951642\ttotal: 12m 32s\tremaining: 5m 20s\n",
      "561:\tlearn: 0.9951642\ttotal: 12m 33s\tremaining: 5m 19s\n",
      "562:\tlearn: 0.9952645\ttotal: 12m 34s\tremaining: 5m 17s\n",
      "563:\tlearn: 0.9952645\ttotal: 12m 36s\tremaining: 5m 16s\n",
      "564:\tlearn: 0.9953648\ttotal: 12m 37s\tremaining: 5m 15s\n",
      "565:\tlearn: 0.9953648\ttotal: 12m 38s\tremaining: 5m 13s\n",
      "566:\tlearn: 0.9953648\ttotal: 12m 40s\tremaining: 5m 12s\n",
      "567:\tlearn: 0.9952645\ttotal: 12m 41s\tremaining: 5m 11s\n",
      "568:\tlearn: 0.9951642\ttotal: 12m 42s\tremaining: 5m 9s\n",
      "569:\tlearn: 0.9952645\ttotal: 12m 44s\tremaining: 5m 8s\n",
      "570:\tlearn: 0.9953648\ttotal: 12m 45s\tremaining: 5m 7s\n",
      "571:\tlearn: 0.9954651\ttotal: 12m 46s\tremaining: 5m 5s\n",
      "572:\tlearn: 0.9954651\ttotal: 12m 48s\tremaining: 5m 4s\n",
      "573:\tlearn: 0.9954651\ttotal: 12m 49s\tremaining: 5m 3s\n",
      "574:\tlearn: 0.9954651\ttotal: 12m 50s\tremaining: 5m 1s\n",
      "575:\tlearn: 0.9954651\ttotal: 12m 52s\tremaining: 5m\n",
      "576:\tlearn: 0.9954651\ttotal: 12m 53s\tremaining: 4m 59s\n",
      "577:\tlearn: 0.9954651\ttotal: 12m 54s\tremaining: 4m 57s\n",
      "578:\tlearn: 0.9954651\ttotal: 12m 56s\tremaining: 4m 56s\n",
      "579:\tlearn: 0.9954651\ttotal: 12m 57s\tremaining: 4m 54s\n",
      "580:\tlearn: 0.9954651\ttotal: 12m 58s\tremaining: 4m 53s\n",
      "581:\tlearn: 0.9954651\ttotal: 13m\tremaining: 4m 52s\n",
      "582:\tlearn: 0.9955654\ttotal: 13m 1s\tremaining: 4m 50s\n",
      "583:\tlearn: 0.9955654\ttotal: 13m 2s\tremaining: 4m 49s\n",
      "584:\tlearn: 0.9955654\ttotal: 13m 4s\tremaining: 4m 48s\n",
      "585:\tlearn: 0.9955654\ttotal: 13m 5s\tremaining: 4m 46s\n",
      "586:\tlearn: 0.9955654\ttotal: 13m 7s\tremaining: 4m 45s\n",
      "587:\tlearn: 0.9956658\ttotal: 13m 8s\tremaining: 4m 44s\n",
      "588:\tlearn: 0.9956658\ttotal: 13m 9s\tremaining: 4m 42s\n",
      "589:\tlearn: 0.9957661\ttotal: 13m 11s\tremaining: 4m 41s\n",
      "590:\tlearn: 0.9957661\ttotal: 13m 12s\tremaining: 4m 40s\n",
      "591:\tlearn: 0.9957661\ttotal: 13m 13s\tremaining: 4m 38s\n",
      "592:\tlearn: 0.9958665\ttotal: 13m 15s\tremaining: 4m 37s\n",
      "593:\tlearn: 0.9958665\ttotal: 13m 16s\tremaining: 4m 36s\n",
      "594:\tlearn: 0.9958665\ttotal: 13m 17s\tremaining: 4m 34s\n",
      "595:\tlearn: 0.9958665\ttotal: 13m 19s\tremaining: 4m 33s\n",
      "596:\tlearn: 0.9958665\ttotal: 13m 20s\tremaining: 4m 32s\n",
      "597:\tlearn: 0.9958665\ttotal: 13m 21s\tremaining: 4m 30s\n",
      "598:\tlearn: 0.9958665\ttotal: 13m 23s\tremaining: 4m 29s\n",
      "599:\tlearn: 0.9959669\ttotal: 13m 24s\tremaining: 4m 28s\n",
      "600:\tlearn: 0.9959669\ttotal: 13m 25s\tremaining: 4m 26s\n",
      "601:\tlearn: 0.9959669\ttotal: 13m 27s\tremaining: 4m 25s\n",
      "602:\tlearn: 0.9959669\ttotal: 13m 28s\tremaining: 4m 24s\n",
      "603:\tlearn: 0.9959669\ttotal: 13m 29s\tremaining: 4m 22s\n",
      "604:\tlearn: 0.9959669\ttotal: 13m 31s\tremaining: 4m 21s\n",
      "605:\tlearn: 0.9959669\ttotal: 13m 32s\tremaining: 4m 20s\n",
      "606:\tlearn: 0.9959669\ttotal: 13m 33s\tremaining: 4m 18s\n",
      "607:\tlearn: 0.9960674\ttotal: 13m 35s\tremaining: 4m 17s\n",
      "608:\tlearn: 0.9960674\ttotal: 13m 36s\tremaining: 4m 16s\n",
      "609:\tlearn: 0.9960674\ttotal: 13m 37s\tremaining: 4m 14s\n",
      "610:\tlearn: 0.9959669\ttotal: 13m 39s\tremaining: 4m 13s\n",
      "611:\tlearn: 0.9959669\ttotal: 13m 40s\tremaining: 4m 12s\n",
      "612:\tlearn: 0.9960674\ttotal: 13m 41s\tremaining: 4m 10s\n",
      "613:\tlearn: 0.9960674\ttotal: 13m 43s\tremaining: 4m 9s\n",
      "614:\tlearn: 0.9960674\ttotal: 13m 44s\tremaining: 4m 8s\n",
      "615:\tlearn: 0.9960674\ttotal: 13m 45s\tremaining: 4m 6s\n",
      "616:\tlearn: 0.9960674\ttotal: 13m 47s\tremaining: 4m 5s\n",
      "617:\tlearn: 0.9960674\ttotal: 13m 48s\tremaining: 4m 4s\n",
      "618:\tlearn: 0.9960674\ttotal: 13m 49s\tremaining: 4m 2s\n",
      "619:\tlearn: 0.9962683\ttotal: 13m 51s\tremaining: 4m 1s\n",
      "620:\tlearn: 0.9961678\ttotal: 13m 52s\tremaining: 4m\n",
      "621:\tlearn: 0.9961678\ttotal: 13m 53s\tremaining: 3m 58s\n",
      "622:\tlearn: 0.9961678\ttotal: 13m 55s\tremaining: 3m 57s\n",
      "623:\tlearn: 0.9963688\ttotal: 13m 56s\tremaining: 3m 55s\n",
      "624:\tlearn: 0.9963688\ttotal: 13m 57s\tremaining: 3m 54s\n",
      "625:\tlearn: 0.9964693\ttotal: 13m 59s\tremaining: 3m 53s\n",
      "626:\tlearn: 0.9965698\ttotal: 14m\tremaining: 3m 51s\n",
      "627:\tlearn: 0.9965698\ttotal: 14m 1s\tremaining: 3m 50s\n",
      "628:\tlearn: 0.9965698\ttotal: 14m 3s\tremaining: 3m 49s\n",
      "629:\tlearn: 0.9965698\ttotal: 14m 4s\tremaining: 3m 47s\n",
      "630:\tlearn: 0.9965698\ttotal: 14m 5s\tremaining: 3m 46s\n",
      "631:\tlearn: 0.9965698\ttotal: 14m 7s\tremaining: 3m 45s\n",
      "632:\tlearn: 0.9965698\ttotal: 14m 8s\tremaining: 3m 43s\n",
      "633:\tlearn: 0.9965698\ttotal: 14m 9s\tremaining: 3m 42s\n",
      "634:\tlearn: 0.9965698\ttotal: 14m 11s\tremaining: 3m 41s\n",
      "635:\tlearn: 0.9965698\ttotal: 14m 12s\tremaining: 3m 39s\n",
      "636:\tlearn: 0.9966704\ttotal: 14m 14s\tremaining: 3m 38s\n",
      "637:\tlearn: 0.9966704\ttotal: 14m 15s\tremaining: 3m 37s\n",
      "638:\tlearn: 0.9966704\ttotal: 14m 16s\tremaining: 3m 35s\n",
      "639:\tlearn: 0.9966704\ttotal: 14m 18s\tremaining: 3m 34s\n",
      "640:\tlearn: 0.9966704\ttotal: 14m 19s\tremaining: 3m 33s\n",
      "641:\tlearn: 0.9966704\ttotal: 14m 20s\tremaining: 3m 31s\n",
      "642:\tlearn: 0.9966704\ttotal: 14m 22s\tremaining: 3m 30s\n",
      "643:\tlearn: 0.9967709\ttotal: 14m 23s\tremaining: 3m 29s\n",
      "644:\tlearn: 0.9967709\ttotal: 14m 24s\tremaining: 3m 27s\n",
      "645:\tlearn: 0.9968715\ttotal: 14m 26s\tremaining: 3m 26s\n",
      "646:\tlearn: 0.9969721\ttotal: 14m 27s\tremaining: 3m 25s\n",
      "647:\tlearn: 0.9973748\ttotal: 14m 28s\tremaining: 3m 23s\n",
      "648:\tlearn: 0.9973748\ttotal: 14m 30s\tremaining: 3m 22s\n",
      "649:\tlearn: 0.9975762\ttotal: 14m 31s\tremaining: 3m 21s\n",
      "650:\tlearn: 0.9975762\ttotal: 14m 32s\tremaining: 3m 19s\n",
      "651:\tlearn: 0.9975762\ttotal: 14m 34s\tremaining: 3m 18s\n",
      "652:\tlearn: 0.9975762\ttotal: 14m 35s\tremaining: 3m 17s\n",
      "653:\tlearn: 0.9975762\ttotal: 14m 36s\tremaining: 3m 15s\n",
      "654:\tlearn: 0.9976770\ttotal: 14m 38s\tremaining: 3m 14s\n",
      "655:\tlearn: 0.9977778\ttotal: 14m 39s\tremaining: 3m 13s\n",
      "656:\tlearn: 0.9977778\ttotal: 14m 40s\tremaining: 3m 11s\n",
      "657:\tlearn: 0.9977778\ttotal: 14m 42s\tremaining: 3m 10s\n",
      "658:\tlearn: 0.9977778\ttotal: 14m 43s\tremaining: 3m 9s\n",
      "659:\tlearn: 0.9977778\ttotal: 14m 44s\tremaining: 3m 7s\n",
      "660:\tlearn: 0.9977778\ttotal: 14m 46s\tremaining: 3m 6s\n",
      "661:\tlearn: 0.9977778\ttotal: 14m 47s\tremaining: 3m 5s\n",
      "662:\tlearn: 0.9976770\ttotal: 14m 48s\tremaining: 3m 3s\n",
      "663:\tlearn: 0.9976770\ttotal: 14m 50s\tremaining: 3m 2s\n",
      "664:\tlearn: 0.9976770\ttotal: 14m 51s\tremaining: 3m\n",
      "665:\tlearn: 0.9976770\ttotal: 14m 52s\tremaining: 2m 59s\n",
      "666:\tlearn: 0.9976770\ttotal: 14m 54s\tremaining: 2m 58s\n",
      "667:\tlearn: 0.9977778\ttotal: 14m 55s\tremaining: 2m 56s\n",
      "668:\tlearn: 0.9977778\ttotal: 14m 56s\tremaining: 2m 55s\n",
      "669:\tlearn: 0.9977778\ttotal: 14m 58s\tremaining: 2m 54s\n",
      "670:\tlearn: 0.9977778\ttotal: 14m 59s\tremaining: 2m 52s\n",
      "671:\tlearn: 0.9977778\ttotal: 15m 1s\tremaining: 2m 51s\n",
      "672:\tlearn: 0.9977778\ttotal: 15m 2s\tremaining: 2m 50s\n",
      "673:\tlearn: 0.9978786\ttotal: 15m 3s\tremaining: 2m 48s\n",
      "674:\tlearn: 0.9978786\ttotal: 15m 5s\tremaining: 2m 47s\n",
      "675:\tlearn: 0.9978786\ttotal: 15m 6s\tremaining: 2m 46s\n",
      "676:\tlearn: 0.9978786\ttotal: 15m 8s\tremaining: 2m 45s\n",
      "677:\tlearn: 0.9978786\ttotal: 15m 9s\tremaining: 2m 43s\n",
      "678:\tlearn: 0.9978786\ttotal: 15m 10s\tremaining: 2m 42s\n",
      "679:\tlearn: 0.9979794\ttotal: 15m 12s\tremaining: 2m 41s\n",
      "680:\tlearn: 0.9979794\ttotal: 15m 13s\tremaining: 2m 39s\n",
      "681:\tlearn: 0.9979794\ttotal: 15m 15s\tremaining: 2m 38s\n",
      "682:\tlearn: 0.9979794\ttotal: 15m 16s\tremaining: 2m 37s\n",
      "683:\tlearn: 0.9979794\ttotal: 15m 18s\tremaining: 2m 35s\n",
      "684:\tlearn: 0.9979794\ttotal: 15m 19s\tremaining: 2m 34s\n",
      "685:\tlearn: 0.9981811\ttotal: 15m 21s\tremaining: 2m 33s\n",
      "686:\tlearn: 0.9981811\ttotal: 15m 22s\tremaining: 2m 31s\n",
      "687:\tlearn: 0.9981811\ttotal: 15m 23s\tremaining: 2m 30s\n",
      "688:\tlearn: 0.9981811\ttotal: 15m 25s\tremaining: 2m 29s\n",
      "689:\tlearn: 0.9981811\ttotal: 15m 26s\tremaining: 2m 27s\n",
      "690:\tlearn: 0.9982820\ttotal: 15m 27s\tremaining: 2m 26s\n",
      "691:\tlearn: 0.9982820\ttotal: 15m 29s\tremaining: 2m 25s\n",
      "692:\tlearn: 0.9982820\ttotal: 15m 30s\tremaining: 2m 23s\n",
      "693:\tlearn: 0.9982820\ttotal: 15m 31s\tremaining: 2m 22s\n",
      "694:\tlearn: 0.9982820\ttotal: 15m 33s\tremaining: 2m 20s\n",
      "695:\tlearn: 0.9982820\ttotal: 15m 34s\tremaining: 2m 19s\n",
      "696:\tlearn: 0.9982820\ttotal: 15m 35s\tremaining: 2m 18s\n",
      "697:\tlearn: 0.9982820\ttotal: 15m 37s\tremaining: 2m 16s\n",
      "698:\tlearn: 0.9982820\ttotal: 15m 38s\tremaining: 2m 15s\n",
      "699:\tlearn: 0.9982820\ttotal: 15m 39s\tremaining: 2m 14s\n",
      "700:\tlearn: 0.9982820\ttotal: 15m 41s\tremaining: 2m 12s\n",
      "701:\tlearn: 0.9982820\ttotal: 15m 42s\tremaining: 2m 11s\n",
      "702:\tlearn: 0.9982820\ttotal: 15m 44s\tremaining: 2m 10s\n",
      "703:\tlearn: 0.9982820\ttotal: 15m 46s\tremaining: 2m 9s\n",
      "704:\tlearn: 0.9982820\ttotal: 15m 47s\tremaining: 2m 7s\n",
      "705:\tlearn: 0.9982820\ttotal: 15m 48s\tremaining: 2m 6s\n",
      "706:\tlearn: 0.9982820\ttotal: 15m 50s\tremaining: 2m 4s\n",
      "707:\tlearn: 0.9983829\ttotal: 15m 51s\tremaining: 2m 3s\n",
      "708:\tlearn: 0.9983829\ttotal: 15m 53s\tremaining: 2m 2s\n",
      "709:\tlearn: 0.9983829\ttotal: 15m 54s\tremaining: 2m 1s\n",
      "710:\tlearn: 0.9983829\ttotal: 15m 56s\tremaining: 1m 59s\n",
      "711:\tlearn: 0.9983829\ttotal: 15m 57s\tremaining: 1m 58s\n",
      "712:\tlearn: 0.9983829\ttotal: 15m 58s\tremaining: 1m 57s\n",
      "713:\tlearn: 0.9983829\ttotal: 16m\tremaining: 1m 55s\n",
      "714:\tlearn: 0.9983829\ttotal: 16m 1s\tremaining: 1m 54s\n",
      "715:\tlearn: 0.9983829\ttotal: 16m 3s\tremaining: 1m 52s\n",
      "716:\tlearn: 0.9983829\ttotal: 16m 4s\tremaining: 1m 51s\n",
      "717:\tlearn: 0.9983829\ttotal: 16m 5s\tremaining: 1m 50s\n",
      "718:\tlearn: 0.9984838\ttotal: 16m 7s\tremaining: 1m 48s\n",
      "719:\tlearn: 0.9984838\ttotal: 16m 8s\tremaining: 1m 47s\n",
      "720:\tlearn: 0.9984838\ttotal: 16m 9s\tremaining: 1m 46s\n",
      "721:\tlearn: 0.9984838\ttotal: 16m 11s\tremaining: 1m 44s\n",
      "722:\tlearn: 0.9984838\ttotal: 16m 12s\tremaining: 1m 43s\n",
      "723:\tlearn: 0.9984838\ttotal: 16m 13s\tremaining: 1m 42s\n",
      "724:\tlearn: 0.9984838\ttotal: 16m 15s\tremaining: 1m 40s\n",
      "725:\tlearn: 0.9984838\ttotal: 16m 16s\tremaining: 1m 39s\n",
      "726:\tlearn: 0.9984838\ttotal: 16m 17s\tremaining: 1m 38s\n",
      "727:\tlearn: 0.9984838\ttotal: 16m 19s\tremaining: 1m 36s\n",
      "728:\tlearn: 0.9984838\ttotal: 16m 20s\tremaining: 1m 35s\n",
      "729:\tlearn: 0.9984838\ttotal: 16m 22s\tremaining: 1m 34s\n",
      "730:\tlearn: 0.9984838\ttotal: 16m 23s\tremaining: 1m 32s\n",
      "731:\tlearn: 0.9984838\ttotal: 16m 24s\tremaining: 1m 31s\n",
      "732:\tlearn: 0.9984838\ttotal: 16m 26s\tremaining: 1m 30s\n",
      "733:\tlearn: 0.9984838\ttotal: 16m 27s\tremaining: 1m 28s\n",
      "734:\tlearn: 0.9984838\ttotal: 16m 28s\tremaining: 1m 27s\n",
      "735:\tlearn: 0.9984838\ttotal: 16m 30s\tremaining: 1m 26s\n",
      "736:\tlearn: 0.9984838\ttotal: 16m 31s\tremaining: 1m 24s\n",
      "737:\tlearn: 0.9984838\ttotal: 16m 32s\tremaining: 1m 23s\n",
      "738:\tlearn: 0.9984838\ttotal: 16m 34s\tremaining: 1m 22s\n",
      "739:\tlearn: 0.9984838\ttotal: 16m 35s\tremaining: 1m 20s\n",
      "740:\tlearn: 0.9985847\ttotal: 16m 36s\tremaining: 1m 19s\n",
      "741:\tlearn: 0.9985847\ttotal: 16m 38s\tremaining: 1m 18s\n",
      "742:\tlearn: 0.9985847\ttotal: 16m 39s\tremaining: 1m 16s\n",
      "743:\tlearn: 0.9985847\ttotal: 16m 40s\tremaining: 1m 15s\n",
      "744:\tlearn: 0.9985847\ttotal: 16m 42s\tremaining: 1m 14s\n",
      "745:\tlearn: 0.9985847\ttotal: 16m 43s\tremaining: 1m 12s\n",
      "746:\tlearn: 0.9986857\ttotal: 16m 45s\tremaining: 1m 11s\n",
      "747:\tlearn: 0.9986857\ttotal: 16m 46s\tremaining: 1m 9s\n",
      "748:\tlearn: 0.9985847\ttotal: 16m 47s\tremaining: 1m 8s\n",
      "749:\tlearn: 0.9985847\ttotal: 16m 49s\tremaining: 1m 7s\n",
      "750:\tlearn: 0.9986857\ttotal: 16m 50s\tremaining: 1m 5s\n",
      "751:\tlearn: 0.9986857\ttotal: 16m 51s\tremaining: 1m 4s\n",
      "752:\tlearn: 0.9986857\ttotal: 16m 53s\tremaining: 1m 3s\n",
      "753:\tlearn: 0.9986857\ttotal: 16m 54s\tremaining: 1m 1s\n",
      "754:\tlearn: 0.9986857\ttotal: 16m 55s\tremaining: 1m\n",
      "755:\tlearn: 0.9986857\ttotal: 16m 57s\tremaining: 59.2s\n",
      "756:\tlearn: 0.9986857\ttotal: 16m 58s\tremaining: 57.9s\n",
      "757:\tlearn: 0.9988877\ttotal: 16m 59s\tremaining: 56.5s\n",
      "758:\tlearn: 0.9988877\ttotal: 17m 1s\tremaining: 55.2s\n",
      "759:\tlearn: 0.9988877\ttotal: 17m 2s\tremaining: 53.8s\n",
      "760:\tlearn: 0.9988877\ttotal: 17m 4s\tremaining: 52.5s\n",
      "761:\tlearn: 0.9988877\ttotal: 17m 6s\tremaining: 51.2s\n",
      "762:\tlearn: 0.9988877\ttotal: 17m 8s\tremaining: 49.9s\n",
      "763:\tlearn: 0.9988877\ttotal: 17m 9s\tremaining: 48.5s\n",
      "764:\tlearn: 0.9988877\ttotal: 17m 11s\tremaining: 47.2s\n",
      "765:\tlearn: 0.9988877\ttotal: 17m 12s\tremaining: 45.8s\n",
      "766:\tlearn: 0.9988877\ttotal: 17m 14s\tremaining: 44.5s\n",
      "767:\tlearn: 0.9988877\ttotal: 17m 15s\tremaining: 43.2s\n",
      "768:\tlearn: 0.9990897\ttotal: 17m 16s\tremaining: 41.8s\n",
      "769:\tlearn: 0.9990897\ttotal: 17m 18s\tremaining: 40.5s\n",
      "770:\tlearn: 0.9990897\ttotal: 17m 19s\tremaining: 39.1s\n",
      "771:\tlearn: 0.9990897\ttotal: 17m 21s\tremaining: 37.8s\n",
      "772:\tlearn: 0.9990897\ttotal: 17m 22s\tremaining: 36.4s\n",
      "773:\tlearn: 0.9990897\ttotal: 17m 23s\tremaining: 35.1s\n",
      "774:\tlearn: 0.9990897\ttotal: 17m 25s\tremaining: 33.7s\n",
      "775:\tlearn: 0.9990897\ttotal: 17m 26s\tremaining: 32.4s\n",
      "776:\tlearn: 0.9990897\ttotal: 17m 28s\tremaining: 31s\n",
      "777:\tlearn: 0.9990897\ttotal: 17m 30s\tremaining: 29.7s\n",
      "778:\tlearn: 0.9990897\ttotal: 17m 31s\tremaining: 28.3s\n",
      "779:\tlearn: 0.9990897\ttotal: 17m 33s\tremaining: 27s\n",
      "780:\tlearn: 0.9990897\ttotal: 17m 34s\tremaining: 25.7s\n",
      "781:\tlearn: 0.9990897\ttotal: 17m 36s\tremaining: 24.3s\n",
      "782:\tlearn: 0.9990897\ttotal: 17m 37s\tremaining: 23s\n",
      "783:\tlearn: 0.9990897\ttotal: 17m 38s\tremaining: 21.6s\n",
      "784:\tlearn: 0.9990897\ttotal: 17m 40s\tremaining: 20.3s\n",
      "785:\tlearn: 0.9990897\ttotal: 17m 41s\tremaining: 18.9s\n",
      "786:\tlearn: 0.9990897\ttotal: 17m 42s\tremaining: 17.6s\n",
      "787:\tlearn: 0.9990897\ttotal: 17m 44s\tremaining: 16.2s\n",
      "788:\tlearn: 0.9990897\ttotal: 17m 45s\tremaining: 14.9s\n",
      "789:\tlearn: 0.9990897\ttotal: 17m 46s\tremaining: 13.5s\n",
      "790:\tlearn: 0.9990897\ttotal: 17m 48s\tremaining: 12.2s\n",
      "791:\tlearn: 0.9990897\ttotal: 17m 49s\tremaining: 10.8s\n",
      "792:\tlearn: 0.9990897\ttotal: 17m 50s\tremaining: 9.45s\n",
      "793:\tlearn: 0.9990897\ttotal: 17m 52s\tremaining: 8.1s\n",
      "794:\tlearn: 0.9992919\ttotal: 17m 53s\tremaining: 6.75s\n",
      "795:\tlearn: 0.9991908\ttotal: 17m 54s\tremaining: 5.4s\n",
      "796:\tlearn: 0.9992919\ttotal: 17m 56s\tremaining: 4.05s\n",
      "797:\tlearn: 0.9992919\ttotal: 17m 57s\tremaining: 2.7s\n",
      "798:\tlearn: 0.9992919\ttotal: 17m 58s\tremaining: 1.35s\n",
      "799:\tlearn: 0.9992919\ttotal: 18m\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=2, border_count=32, depth=12, eval_metric=Precision, iterations=800, l2_leaf_reg=1, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=5; total time=18.0min\n",
      "0:\tlearn: 0.6981581\ttotal: 1.36s\tremaining: 18m 9s\n",
      "1:\tlearn: 0.7450363\ttotal: 2.69s\tremaining: 17m 51s\n",
      "2:\tlearn: 0.7752103\ttotal: 4.08s\tremaining: 18m 3s\n",
      "3:\tlearn: 0.8042520\ttotal: 5.51s\tremaining: 18m 16s\n",
      "4:\tlearn: 0.8388724\ttotal: 6.84s\tremaining: 18m 8s\n",
      "5:\tlearn: 0.8581329\ttotal: 8.13s\tremaining: 17m 56s\n",
      "6:\tlearn: 0.8647904\ttotal: 9.47s\tremaining: 17m 52s\n",
      "7:\tlearn: 0.8860221\ttotal: 10.8s\tremaining: 17m 50s\n",
      "8:\tlearn: 0.8999703\ttotal: 12.1s\tremaining: 17m 42s\n",
      "9:\tlearn: 0.9075380\ttotal: 13.4s\tremaining: 17m 39s\n",
      "10:\tlearn: 0.9154496\ttotal: 14.7s\tremaining: 17m 32s\n",
      "11:\tlearn: 0.9179563\ttotal: 16s\tremaining: 17m 27s\n",
      "12:\tlearn: 0.9222926\ttotal: 17.2s\tremaining: 17m 22s\n",
      "13:\tlearn: 0.9275852\ttotal: 18.5s\tremaining: 17m 21s\n",
      "14:\tlearn: 0.9321563\ttotal: 19.8s\tremaining: 17m 17s\n",
      "15:\tlearn: 0.9342849\ttotal: 21.1s\tremaining: 17m 13s\n",
      "16:\tlearn: 0.9372335\ttotal: 22.4s\tremaining: 17m 12s\n",
      "17:\tlearn: 0.9372588\ttotal: 23.7s\tremaining: 17m 9s\n",
      "18:\tlearn: 0.9406528\ttotal: 25s\tremaining: 17m 6s\n",
      "19:\tlearn: 0.9463187\ttotal: 26.3s\tremaining: 17m 6s\n",
      "20:\tlearn: 0.9466852\ttotal: 27.6s\tremaining: 17m 4s\n",
      "21:\tlearn: 0.9462451\ttotal: 28.9s\tremaining: 17m 1s\n",
      "22:\tlearn: 0.9451135\ttotal: 30.2s\tremaining: 16m 59s\n",
      "23:\tlearn: 0.9474048\ttotal: 31.5s\tremaining: 16m 59s\n",
      "24:\tlearn: 0.9489181\ttotal: 32.8s\tremaining: 16m 57s\n",
      "25:\tlearn: 0.9522444\ttotal: 34.1s\tremaining: 16m 56s\n",
      "26:\tlearn: 0.9537412\ttotal: 35.5s\tremaining: 16m 56s\n",
      "27:\tlearn: 0.9543749\ttotal: 36.8s\tremaining: 16m 54s\n",
      "28:\tlearn: 0.9529586\ttotal: 38.1s\tremaining: 16m 52s\n",
      "29:\tlearn: 0.9536763\ttotal: 39.4s\tremaining: 16m 51s\n",
      "30:\tlearn: 0.9534265\ttotal: 40.7s\tremaining: 16m 49s\n",
      "31:\tlearn: 0.9553651\ttotal: 42s\tremaining: 16m 47s\n",
      "32:\tlearn: 0.9560841\ttotal: 43.3s\tremaining: 16m 46s\n",
      "33:\tlearn: 0.9570964\ttotal: 44.6s\tremaining: 16m 44s\n",
      "34:\tlearn: 0.9564360\ttotal: 45.8s\tremaining: 16m 42s\n",
      "35:\tlearn: 0.9566030\ttotal: 47.1s\tremaining: 16m 40s\n",
      "36:\tlearn: 0.9588960\ttotal: 48.5s\tremaining: 16m 39s\n",
      "37:\tlearn: 0.9587192\ttotal: 49.7s\tremaining: 16m 37s\n",
      "38:\tlearn: 0.9581080\ttotal: 51s\tremaining: 16m 35s\n",
      "39:\tlearn: 0.9588004\ttotal: 52.3s\tremaining: 16m 34s\n",
      "40:\tlearn: 0.9591817\ttotal: 53.6s\tremaining: 16m 32s\n",
      "41:\tlearn: 0.9601260\ttotal: 54.9s\tremaining: 16m 31s\n",
      "42:\tlearn: 0.9603385\ttotal: 56.2s\tremaining: 16m 30s\n",
      "43:\tlearn: 0.9609329\ttotal: 57.6s\tremaining: 16m 28s\n",
      "44:\tlearn: 0.9604875\ttotal: 58.8s\tremaining: 16m 27s\n",
      "45:\tlearn: 0.9610658\ttotal: 1m\tremaining: 16m 25s\n",
      "46:\tlearn: 0.9615309\ttotal: 1m 1s\tremaining: 16m 24s\n",
      "47:\tlearn: 0.9624852\ttotal: 1m 2s\tremaining: 16m 22s\n",
      "48:\tlearn: 0.9634411\ttotal: 1m 4s\tremaining: 16m 21s\n",
      "49:\tlearn: 0.9641238\ttotal: 1m 5s\tremaining: 16m 20s\n",
      "50:\tlearn: 0.9636632\ttotal: 1m 6s\tremaining: 16m 18s\n",
      "51:\tlearn: 0.9644300\ttotal: 1m 7s\tremaining: 16m 17s\n",
      "52:\tlearn: 0.9635755\ttotal: 1m 9s\tremaining: 16m 15s\n",
      "53:\tlearn: 0.9637474\ttotal: 1m 10s\tremaining: 16m 15s\n",
      "54:\tlearn: 0.9634843\ttotal: 1m 11s\tremaining: 16m 13s\n",
      "55:\tlearn: 0.9639622\ttotal: 1m 13s\tremaining: 16m 12s\n",
      "56:\tlearn: 0.9647256\ttotal: 1m 14s\tremaining: 16m 11s\n",
      "57:\tlearn: 0.9664661\ttotal: 1m 15s\tremaining: 16m 9s\n",
      "58:\tlearn: 0.9666568\ttotal: 1m 17s\tremaining: 16m 8s\n",
      "59:\tlearn: 0.9665680\ttotal: 1m 18s\tremaining: 16m 7s\n",
      "60:\tlearn: 0.9666535\ttotal: 1m 19s\tremaining: 16m 5s\n",
      "61:\tlearn: 0.9670254\ttotal: 1m 20s\tremaining: 16m 3s\n",
      "62:\tlearn: 0.9673312\ttotal: 1m 22s\tremaining: 16m 2s\n",
      "63:\tlearn: 0.9670579\ttotal: 1m 23s\tremaining: 16m 1s\n",
      "64:\tlearn: 0.9667718\ttotal: 1m 24s\tremaining: 15m 59s\n",
      "65:\tlearn: 0.9665680\ttotal: 1m 26s\tremaining: 15m 58s\n",
      "66:\tlearn: 0.9666765\ttotal: 1m 27s\tremaining: 15m 57s\n",
      "67:\tlearn: 0.9661251\ttotal: 1m 28s\tremaining: 15m 55s\n",
      "68:\tlearn: 0.9665223\ttotal: 1m 30s\tremaining: 15m 54s\n",
      "69:\tlearn: 0.9667257\ttotal: 1m 31s\tremaining: 15m 53s\n",
      "70:\tlearn: 0.9674845\ttotal: 1m 32s\tremaining: 15m 51s\n",
      "71:\tlearn: 0.9669324\ttotal: 1m 33s\tremaining: 15m 50s\n",
      "72:\tlearn: 0.9674116\ttotal: 1m 35s\tremaining: 15m 49s\n",
      "73:\tlearn: 0.9675037\ttotal: 1m 36s\tremaining: 15m 47s\n",
      "74:\tlearn: 0.9667290\ttotal: 1m 37s\tremaining: 15m 46s\n",
      "75:\tlearn: 0.9672212\ttotal: 1m 39s\tremaining: 15m 45s\n",
      "76:\tlearn: 0.9684636\ttotal: 1m 40s\tremaining: 15m 44s\n",
      "77:\tlearn: 0.9682759\ttotal: 1m 41s\tremaining: 15m 43s\n",
      "78:\tlearn: 0.9679898\ttotal: 1m 43s\tremaining: 15m 41s\n",
      "79:\tlearn: 0.9676117\ttotal: 1m 44s\tremaining: 15m 40s\n",
      "80:\tlearn: 0.9676943\ttotal: 1m 45s\tremaining: 15m 39s\n",
      "81:\tlearn: 0.9676054\ttotal: 1m 47s\tremaining: 15m 38s\n",
      "82:\tlearn: 0.9683775\ttotal: 1m 48s\tremaining: 15m 37s\n",
      "83:\tlearn: 0.9685776\ttotal: 1m 49s\tremaining: 15m 35s\n",
      "84:\tlearn: 0.9686761\ttotal: 1m 51s\tremaining: 15m 34s\n",
      "85:\tlearn: 0.9691595\ttotal: 1m 52s\tremaining: 15m 33s\n",
      "86:\tlearn: 0.9697448\ttotal: 1m 53s\tremaining: 15m 32s\n",
      "87:\tlearn: 0.9697567\ttotal: 1m 55s\tremaining: 15m 30s\n",
      "88:\tlearn: 0.9695656\ttotal: 1m 56s\tremaining: 15m 29s\n",
      "89:\tlearn: 0.9695716\ttotal: 1m 57s\tremaining: 15m 28s\n",
      "90:\tlearn: 0.9687162\ttotal: 1m 58s\tremaining: 15m 26s\n",
      "91:\tlearn: 0.9686116\ttotal: 2m\tremaining: 15m 25s\n",
      "92:\tlearn: 0.9691868\ttotal: 2m 1s\tremaining: 15m 24s\n",
      "93:\tlearn: 0.9702580\ttotal: 2m 2s\tremaining: 15m 23s\n",
      "94:\tlearn: 0.9699714\ttotal: 2m 4s\tremaining: 15m 22s\n",
      "95:\tlearn: 0.9695896\ttotal: 2m 5s\tremaining: 15m 21s\n",
      "96:\tlearn: 0.9700728\ttotal: 2m 6s\tremaining: 15m 19s\n",
      "97:\tlearn: 0.9703653\ttotal: 2m 8s\tremaining: 15m 18s\n",
      "98:\tlearn: 0.9713187\ttotal: 2m 9s\tremaining: 15m 17s\n",
      "99:\tlearn: 0.9712230\ttotal: 2m 10s\tremaining: 15m 16s\n",
      "100:\tlearn: 0.9715159\ttotal: 2m 12s\tremaining: 15m 15s\n",
      "101:\tlearn: 0.9711358\ttotal: 2m 13s\tremaining: 15m 14s\n",
      "102:\tlearn: 0.9713187\ttotal: 2m 14s\tremaining: 15m 12s\n",
      "103:\tlearn: 0.9719018\ttotal: 2m 16s\tremaining: 15m 11s\n",
      "104:\tlearn: 0.9719046\ttotal: 2m 17s\tremaining: 15m 10s\n",
      "105:\tlearn: 0.9715243\ttotal: 2m 18s\tremaining: 15m 9s\n",
      "106:\tlearn: 0.9712372\ttotal: 2m 20s\tremaining: 15m 8s\n",
      "107:\tlearn: 0.9712457\ttotal: 2m 21s\tremaining: 15m 7s\n",
      "108:\tlearn: 0.9708633\ttotal: 2m 22s\tremaining: 15m 5s\n",
      "109:\tlearn: 0.9712457\ttotal: 2m 24s\tremaining: 15m 4s\n",
      "110:\tlearn: 0.9709589\ttotal: 2m 25s\tremaining: 15m 3s\n",
      "111:\tlearn: 0.9712514\ttotal: 2m 26s\tremaining: 15m 1s\n",
      "112:\tlearn: 0.9712542\ttotal: 2m 28s\tremaining: 15m\n",
      "113:\tlearn: 0.9712598\ttotal: 2m 29s\tremaining: 14m 59s\n",
      "114:\tlearn: 0.9713554\ttotal: 2m 30s\tremaining: 14m 58s\n",
      "115:\tlearn: 0.9711671\ttotal: 2m 32s\tremaining: 14m 56s\n",
      "116:\tlearn: 0.9713583\ttotal: 2m 33s\tremaining: 14m 55s\n",
      "117:\tlearn: 0.9715495\ttotal: 2m 34s\tremaining: 14m 54s\n",
      "118:\tlearn: 0.9720280\ttotal: 2m 36s\tremaining: 14m 53s\n",
      "119:\tlearn: 0.9719322\ttotal: 2m 37s\tremaining: 14m 52s\n",
      "120:\tlearn: 0.9726027\ttotal: 2m 38s\tremaining: 14m 50s\n",
      "121:\tlearn: 0.9726959\ttotal: 2m 40s\tremaining: 14m 49s\n",
      "122:\tlearn: 0.9726027\ttotal: 2m 41s\tremaining: 14m 48s\n",
      "123:\tlearn: 0.9726986\ttotal: 2m 42s\tremaining: 14m 46s\n",
      "124:\tlearn: 0.9724084\ttotal: 2m 43s\tremaining: 14m 45s\n",
      "125:\tlearn: 0.9727013\ttotal: 2m 45s\tremaining: 14m 44s\n",
      "126:\tlearn: 0.9724138\ttotal: 2m 46s\tremaining: 14m 43s\n",
      "127:\tlearn: 0.9720280\ttotal: 2m 47s\tremaining: 14m 41s\n",
      "128:\tlearn: 0.9726027\ttotal: 2m 49s\tremaining: 14m 40s\n",
      "129:\tlearn: 0.9729890\ttotal: 2m 50s\tremaining: 14m 39s\n",
      "130:\tlearn: 0.9729943\ttotal: 2m 51s\tremaining: 14m 37s\n",
      "131:\tlearn: 0.9725096\ttotal: 2m 53s\tremaining: 14m 36s\n",
      "132:\tlearn: 0.9728957\ttotal: 2m 54s\tremaining: 14m 35s\n",
      "133:\tlearn: 0.9732821\ttotal: 2m 55s\tremaining: 14m 33s\n",
      "134:\tlearn: 0.9733780\ttotal: 2m 57s\tremaining: 14m 32s\n",
      "135:\tlearn: 0.9738530\ttotal: 2m 58s\tremaining: 14m 31s\n",
      "136:\tlearn: 0.9737569\ttotal: 2m 59s\tremaining: 14m 30s\n",
      "137:\tlearn: 0.9742400\ttotal: 3m 1s\tremaining: 14m 28s\n",
      "138:\tlearn: 0.9746248\ttotal: 3m 2s\tremaining: 14m 27s\n",
      "139:\tlearn: 0.9747260\ttotal: 3m 3s\tremaining: 14m 26s\n",
      "140:\tlearn: 0.9746273\ttotal: 3m 5s\tremaining: 14m 25s\n",
      "141:\tlearn: 0.9744349\ttotal: 3m 6s\tremaining: 14m 24s\n",
      "142:\tlearn: 0.9746298\ttotal: 3m 7s\tremaining: 14m 22s\n",
      "143:\tlearn: 0.9748198\ttotal: 3m 9s\tremaining: 14m 21s\n",
      "144:\tlearn: 0.9748223\ttotal: 3m 10s\tremaining: 14m 20s\n",
      "145:\tlearn: 0.9750123\ttotal: 3m 11s\tremaining: 14m 19s\n",
      "146:\tlearn: 0.9752050\ttotal: 3m 13s\tremaining: 14m 17s\n",
      "147:\tlearn: 0.9753038\ttotal: 3m 14s\tremaining: 14m 16s\n",
      "148:\tlearn: 0.9752074\ttotal: 3m 15s\tremaining: 14m 15s\n",
      "149:\tlearn: 0.9753013\ttotal: 3m 17s\tremaining: 14m 13s\n",
      "150:\tlearn: 0.9752050\ttotal: 3m 18s\tremaining: 14m 12s\n",
      "151:\tlearn: 0.9753013\ttotal: 3m 19s\tremaining: 14m 11s\n",
      "152:\tlearn: 0.9755905\ttotal: 3m 21s\tremaining: 14m 10s\n",
      "153:\tlearn: 0.9756869\ttotal: 3m 22s\tremaining: 14m 9s\n",
      "154:\tlearn: 0.9753977\ttotal: 3m 23s\tremaining: 14m 7s\n",
      "155:\tlearn: 0.9756893\ttotal: 3m 25s\tremaining: 14m 6s\n",
      "156:\tlearn: 0.9758822\ttotal: 3m 26s\tremaining: 14m 5s\n",
      "157:\tlearn: 0.9761716\ttotal: 3m 27s\tremaining: 14m 3s\n",
      "158:\tlearn: 0.9757857\ttotal: 3m 29s\tremaining: 14m 2s\n",
      "159:\tlearn: 0.9759786\ttotal: 3m 30s\tremaining: 14m 1s\n",
      "160:\tlearn: 0.9757857\ttotal: 3m 31s\tremaining: 14m\n",
      "161:\tlearn: 0.9761716\ttotal: 3m 32s\tremaining: 13m 58s\n",
      "162:\tlearn: 0.9758822\ttotal: 3m 34s\tremaining: 13m 57s\n",
      "163:\tlearn: 0.9761716\ttotal: 3m 35s\tremaining: 13m 56s\n",
      "164:\tlearn: 0.9764613\ttotal: 3m 36s\tremaining: 13m 55s\n",
      "165:\tlearn: 0.9767511\ttotal: 3m 38s\tremaining: 13m 53s\n",
      "166:\tlearn: 0.9763647\ttotal: 3m 39s\tremaining: 13m 52s\n",
      "167:\tlearn: 0.9763647\ttotal: 3m 40s\tremaining: 13m 51s\n",
      "168:\tlearn: 0.9767511\ttotal: 3m 42s\tremaining: 13m 50s\n",
      "169:\tlearn: 0.9766545\ttotal: 3m 43s\tremaining: 13m 49s\n",
      "170:\tlearn: 0.9765602\ttotal: 3m 45s\tremaining: 13m 47s\n",
      "171:\tlearn: 0.9766568\ttotal: 3m 46s\tremaining: 13m 46s\n",
      "172:\tlearn: 0.9765602\ttotal: 3m 47s\tremaining: 13m 45s\n",
      "173:\tlearn: 0.9768523\ttotal: 3m 48s\tremaining: 13m 43s\n",
      "174:\tlearn: 0.9766591\ttotal: 3m 50s\tremaining: 13m 42s\n",
      "175:\tlearn: 0.9768523\ttotal: 3m 51s\tremaining: 13m 41s\n",
      "176:\tlearn: 0.9770479\ttotal: 3m 53s\tremaining: 13m 40s\n",
      "177:\tlearn: 0.9771446\ttotal: 3m 54s\tremaining: 13m 39s\n",
      "178:\tlearn: 0.9777250\ttotal: 3m 55s\tremaining: 13m 37s\n",
      "179:\tlearn: 0.9776282\ttotal: 3m 57s\tremaining: 13m 36s\n",
      "180:\tlearn: 0.9778218\ttotal: 3m 58s\tremaining: 13m 35s\n",
      "181:\tlearn: 0.9776282\ttotal: 3m 59s\tremaining: 13m 34s\n",
      "182:\tlearn: 0.9774347\ttotal: 4m 1s\tremaining: 13m 33s\n",
      "183:\tlearn: 0.9780154\ttotal: 4m 2s\tremaining: 13m 31s\n",
      "184:\tlearn: 0.9779186\ttotal: 4m 3s\tremaining: 13m 30s\n",
      "185:\tlearn: 0.9774347\ttotal: 4m 5s\tremaining: 13m 29s\n",
      "186:\tlearn: 0.9775314\ttotal: 4m 6s\tremaining: 13m 28s\n",
      "187:\tlearn: 0.9776282\ttotal: 4m 7s\tremaining: 13m 26s\n",
      "188:\tlearn: 0.9775314\ttotal: 4m 9s\tremaining: 13m 25s\n",
      "189:\tlearn: 0.9777250\ttotal: 4m 10s\tremaining: 13m 24s\n",
      "190:\tlearn: 0.9779186\ttotal: 4m 11s\tremaining: 13m 23s\n",
      "191:\tlearn: 0.9781123\ttotal: 4m 13s\tremaining: 13m 22s\n",
      "192:\tlearn: 0.9780154\ttotal: 4m 14s\tremaining: 13m 21s\n",
      "193:\tlearn: 0.9781123\ttotal: 4m 16s\tremaining: 13m 19s\n",
      "194:\tlearn: 0.9782092\ttotal: 4m 17s\tremaining: 13m 18s\n",
      "195:\tlearn: 0.9785000\ttotal: 4m 18s\tremaining: 13m 17s\n",
      "196:\tlearn: 0.9785000\ttotal: 4m 20s\tremaining: 13m 16s\n",
      "197:\tlearn: 0.9785000\ttotal: 4m 21s\tremaining: 13m 15s\n",
      "198:\tlearn: 0.9784030\ttotal: 4m 23s\tremaining: 13m 14s\n",
      "199:\tlearn: 0.9784030\ttotal: 4m 24s\tremaining: 13m 13s\n",
      "200:\tlearn: 0.9786939\ttotal: 4m 25s\tremaining: 13m 11s\n",
      "201:\tlearn: 0.9784030\ttotal: 4m 26s\tremaining: 13m 10s\n",
      "202:\tlearn: 0.9786939\ttotal: 4m 28s\tremaining: 13m 9s\n",
      "203:\tlearn: 0.9786939\ttotal: 4m 29s\tremaining: 13m 7s\n",
      "204:\tlearn: 0.9786939\ttotal: 4m 30s\tremaining: 13m 6s\n",
      "205:\tlearn: 0.9789849\ttotal: 4m 32s\tremaining: 13m 5s\n",
      "206:\tlearn: 0.9795675\ttotal: 4m 33s\tremaining: 13m 3s\n",
      "207:\tlearn: 0.9792762\ttotal: 4m 34s\tremaining: 13m 2s\n",
      "208:\tlearn: 0.9792762\ttotal: 4m 36s\tremaining: 13m 1s\n",
      "209:\tlearn: 0.9793733\ttotal: 4m 37s\tremaining: 12m 59s\n",
      "210:\tlearn: 0.9796647\ttotal: 4m 38s\tremaining: 12m 58s\n",
      "211:\tlearn: 0.9796647\ttotal: 4m 40s\tremaining: 12m 56s\n",
      "212:\tlearn: 0.9794704\ttotal: 4m 41s\tremaining: 12m 55s\n",
      "213:\tlearn: 0.9800536\ttotal: 4m 42s\tremaining: 12m 54s\n",
      "214:\tlearn: 0.9800536\ttotal: 4m 44s\tremaining: 12m 52s\n",
      "215:\tlearn: 0.9799563\ttotal: 4m 45s\tremaining: 12m 51s\n",
      "216:\tlearn: 0.9800536\ttotal: 4m 46s\tremaining: 12m 50s\n",
      "217:\tlearn: 0.9800536\ttotal: 4m 48s\tremaining: 12m 48s\n",
      "218:\tlearn: 0.9800536\ttotal: 4m 49s\tremaining: 12m 47s\n",
      "219:\tlearn: 0.9801509\ttotal: 4m 50s\tremaining: 12m 46s\n",
      "220:\tlearn: 0.9801509\ttotal: 4m 51s\tremaining: 12m 44s\n",
      "221:\tlearn: 0.9803454\ttotal: 4m 53s\tremaining: 12m 43s\n",
      "222:\tlearn: 0.9803454\ttotal: 4m 54s\tremaining: 12m 42s\n",
      "223:\tlearn: 0.9802481\ttotal: 4m 55s\tremaining: 12m 41s\n",
      "224:\tlearn: 0.9803454\ttotal: 4m 57s\tremaining: 12m 39s\n",
      "225:\tlearn: 0.9803454\ttotal: 4m 58s\tremaining: 12m 38s\n",
      "226:\tlearn: 0.9803454\ttotal: 5m\tremaining: 12m 37s\n",
      "227:\tlearn: 0.9808323\ttotal: 5m 1s\tremaining: 12m 35s\n",
      "228:\tlearn: 0.9810271\ttotal: 5m 2s\tremaining: 12m 34s\n",
      "229:\tlearn: 0.9809297\ttotal: 5m 3s\tremaining: 12m 33s\n",
      "230:\tlearn: 0.9809297\ttotal: 5m 5s\tremaining: 12m 31s\n",
      "231:\tlearn: 0.9806375\ttotal: 5m 6s\tremaining: 12m 30s\n",
      "232:\tlearn: 0.9805401\ttotal: 5m 7s\tremaining: 12m 29s\n",
      "233:\tlearn: 0.9805401\ttotal: 5m 9s\tremaining: 12m 27s\n",
      "234:\tlearn: 0.9806375\ttotal: 5m 10s\tremaining: 12m 26s\n",
      "235:\tlearn: 0.9807349\ttotal: 5m 11s\tremaining: 12m 25s\n",
      "236:\tlearn: 0.9806375\ttotal: 5m 13s\tremaining: 12m 23s\n",
      "237:\tlearn: 0.9809297\ttotal: 5m 14s\tremaining: 12m 22s\n",
      "238:\tlearn: 0.9808323\ttotal: 5m 15s\tremaining: 12m 21s\n",
      "239:\tlearn: 0.9809297\ttotal: 5m 17s\tremaining: 12m 19s\n",
      "240:\tlearn: 0.9811246\ttotal: 5m 18s\tremaining: 12m 18s\n",
      "241:\tlearn: 0.9811246\ttotal: 5m 19s\tremaining: 12m 17s\n",
      "242:\tlearn: 0.9812221\ttotal: 5m 20s\tremaining: 12m 15s\n",
      "243:\tlearn: 0.9813196\ttotal: 5m 22s\tremaining: 12m 14s\n",
      "244:\tlearn: 0.9814171\ttotal: 5m 23s\tremaining: 12m 13s\n",
      "245:\tlearn: 0.9814171\ttotal: 5m 24s\tremaining: 12m 11s\n",
      "246:\tlearn: 0.9816122\ttotal: 5m 26s\tremaining: 12m 10s\n",
      "247:\tlearn: 0.9814171\ttotal: 5m 27s\tremaining: 12m 9s\n",
      "248:\tlearn: 0.9814171\ttotal: 5m 28s\tremaining: 12m 7s\n",
      "249:\tlearn: 0.9821002\ttotal: 5m 30s\tremaining: 12m 6s\n",
      "250:\tlearn: 0.9819068\ttotal: 5m 31s\tremaining: 12m 5s\n",
      "251:\tlearn: 0.9818073\ttotal: 5m 32s\tremaining: 12m 3s\n",
      "252:\tlearn: 0.9821002\ttotal: 5m 34s\tremaining: 12m 2s\n",
      "253:\tlearn: 0.9824928\ttotal: 5m 35s\tremaining: 12m 1s\n",
      "254:\tlearn: 0.9821997\ttotal: 5m 36s\tremaining: 12m\n",
      "255:\tlearn: 0.9825905\ttotal: 5m 38s\tremaining: 11m 58s\n",
      "256:\tlearn: 0.9826883\ttotal: 5m 39s\tremaining: 11m 57s\n",
      "257:\tlearn: 0.9827861\ttotal: 5m 40s\tremaining: 11m 56s\n",
      "258:\tlearn: 0.9829817\ttotal: 5m 42s\tremaining: 11m 55s\n",
      "259:\tlearn: 0.9827861\ttotal: 5m 43s\tremaining: 11m 53s\n",
      "260:\tlearn: 0.9828839\ttotal: 5m 44s\tremaining: 11m 52s\n",
      "261:\tlearn: 0.9828839\ttotal: 5m 46s\tremaining: 11m 51s\n",
      "262:\tlearn: 0.9828839\ttotal: 5m 47s\tremaining: 11m 49s\n",
      "263:\tlearn: 0.9832753\ttotal: 5m 48s\tremaining: 11m 48s\n",
      "264:\tlearn: 0.9833732\ttotal: 5m 50s\tremaining: 11m 47s\n",
      "265:\tlearn: 0.9831774\ttotal: 5m 51s\tremaining: 11m 45s\n",
      "266:\tlearn: 0.9834711\ttotal: 5m 52s\tremaining: 11m 44s\n",
      "267:\tlearn: 0.9831774\ttotal: 5m 54s\tremaining: 11m 43s\n",
      "268:\tlearn: 0.9832753\ttotal: 5m 55s\tremaining: 11m 41s\n",
      "269:\tlearn: 0.9833732\ttotal: 5m 56s\tremaining: 11m 40s\n",
      "270:\tlearn: 0.9834711\ttotal: 5m 58s\tremaining: 11m 39s\n",
      "271:\tlearn: 0.9833732\ttotal: 5m 59s\tremaining: 11m 37s\n",
      "272:\tlearn: 0.9837649\ttotal: 6m\tremaining: 11m 36s\n",
      "273:\tlearn: 0.9837649\ttotal: 6m 2s\tremaining: 11m 35s\n",
      "274:\tlearn: 0.9837649\ttotal: 6m 3s\tremaining: 11m 34s\n",
      "275:\tlearn: 0.9838629\ttotal: 6m 4s\tremaining: 11m 32s\n",
      "276:\tlearn: 0.9840590\ttotal: 6m 6s\tremaining: 11m 31s\n",
      "277:\tlearn: 0.9840590\ttotal: 6m 7s\tremaining: 11m 30s\n",
      "278:\tlearn: 0.9840590\ttotal: 6m 8s\tremaining: 11m 28s\n",
      "279:\tlearn: 0.9843532\ttotal: 6m 10s\tremaining: 11m 27s\n",
      "280:\tlearn: 0.9843532\ttotal: 6m 11s\tremaining: 11m 26s\n",
      "281:\tlearn: 0.9846476\ttotal: 6m 12s\tremaining: 11m 24s\n",
      "282:\tlearn: 0.9845494\ttotal: 6m 14s\tremaining: 11m 23s\n",
      "283:\tlearn: 0.9844513\ttotal: 6m 15s\tremaining: 11m 22s\n",
      "284:\tlearn: 0.9843532\ttotal: 6m 16s\tremaining: 11m 20s\n",
      "285:\tlearn: 0.9848440\ttotal: 6m 18s\tremaining: 11m 19s\n",
      "286:\tlearn: 0.9847458\ttotal: 6m 19s\tremaining: 11m 18s\n",
      "287:\tlearn: 0.9846476\ttotal: 6m 20s\tremaining: 11m 16s\n",
      "288:\tlearn: 0.9845494\ttotal: 6m 22s\tremaining: 11m 15s\n",
      "289:\tlearn: 0.9844513\ttotal: 6m 23s\tremaining: 11m 14s\n",
      "290:\tlearn: 0.9844513\ttotal: 6m 24s\tremaining: 11m 12s\n",
      "291:\tlearn: 0.9844513\ttotal: 6m 26s\tremaining: 11m 11s\n",
      "292:\tlearn: 0.9848440\ttotal: 6m 27s\tremaining: 11m 10s\n",
      "293:\tlearn: 0.9849422\ttotal: 6m 28s\tremaining: 11m 9s\n",
      "294:\tlearn: 0.9852369\ttotal: 6m 30s\tremaining: 11m 7s\n",
      "295:\tlearn: 0.9851386\ttotal: 6m 31s\tremaining: 11m 6s\n",
      "296:\tlearn: 0.9850404\ttotal: 6m 32s\tremaining: 11m 5s\n",
      "297:\tlearn: 0.9853352\ttotal: 6m 34s\tremaining: 11m 3s\n",
      "298:\tlearn: 0.9853352\ttotal: 6m 35s\tremaining: 11m 2s\n",
      "299:\tlearn: 0.9855318\ttotal: 6m 36s\tremaining: 11m 1s\n",
      "300:\tlearn: 0.9856302\ttotal: 6m 37s\tremaining: 10m 59s\n",
      "301:\tlearn: 0.9855318\ttotal: 6m 39s\tremaining: 10m 58s\n",
      "302:\tlearn: 0.9858269\ttotal: 6m 40s\tremaining: 10m 57s\n",
      "303:\tlearn: 0.9856302\ttotal: 6m 41s\tremaining: 10m 55s\n",
      "304:\tlearn: 0.9856302\ttotal: 6m 43s\tremaining: 10m 54s\n",
      "305:\tlearn: 0.9857285\ttotal: 6m 44s\tremaining: 10m 53s\n",
      "306:\tlearn: 0.9858269\ttotal: 6m 46s\tremaining: 10m 51s\n",
      "307:\tlearn: 0.9857285\ttotal: 6m 47s\tremaining: 10m 50s\n",
      "308:\tlearn: 0.9859253\ttotal: 6m 48s\tremaining: 10m 49s\n",
      "309:\tlearn: 0.9860238\ttotal: 6m 49s\tremaining: 10m 47s\n",
      "310:\tlearn: 0.9860238\ttotal: 6m 51s\tremaining: 10m 46s\n",
      "311:\tlearn: 0.9860238\ttotal: 6m 52s\tremaining: 10m 45s\n",
      "312:\tlearn: 0.9861222\ttotal: 6m 53s\tremaining: 10m 44s\n",
      "313:\tlearn: 0.9862207\ttotal: 6m 55s\tremaining: 10m 42s\n",
      "314:\tlearn: 0.9864177\ttotal: 6m 56s\tremaining: 10m 41s\n",
      "315:\tlearn: 0.9865162\ttotal: 6m 57s\tremaining: 10m 40s\n",
      "316:\tlearn: 0.9865162\ttotal: 6m 59s\tremaining: 10m 38s\n",
      "317:\tlearn: 0.9864190\ttotal: 7m\tremaining: 10m 37s\n",
      "318:\tlearn: 0.9864190\ttotal: 7m 1s\tremaining: 10m 36s\n",
      "319:\tlearn: 0.9865162\ttotal: 7m 3s\tremaining: 10m 34s\n",
      "320:\tlearn: 0.9867133\ttotal: 7m 4s\tremaining: 10m 33s\n",
      "321:\tlearn: 0.9866147\ttotal: 7m 5s\tremaining: 10m 32s\n",
      "322:\tlearn: 0.9867133\ttotal: 7m 7s\tremaining: 10m 30s\n",
      "323:\tlearn: 0.9865162\ttotal: 7m 8s\tremaining: 10m 29s\n",
      "324:\tlearn: 0.9866147\ttotal: 7m 9s\tremaining: 10m 28s\n",
      "325:\tlearn: 0.9866147\ttotal: 7m 11s\tremaining: 10m 26s\n",
      "326:\tlearn: 0.9867133\ttotal: 7m 12s\tremaining: 10m 25s\n",
      "327:\tlearn: 0.9867133\ttotal: 7m 13s\tremaining: 10m 24s\n",
      "328:\tlearn: 0.9870091\ttotal: 7m 15s\tremaining: 10m 22s\n",
      "329:\tlearn: 0.9870091\ttotal: 7m 16s\tremaining: 10m 21s\n",
      "330:\tlearn: 0.9871077\ttotal: 7m 17s\tremaining: 10m 20s\n",
      "331:\tlearn: 0.9870091\ttotal: 7m 19s\tremaining: 10m 18s\n",
      "332:\tlearn: 0.9870091\ttotal: 7m 20s\tremaining: 10m 17s\n",
      "333:\tlearn: 0.9869105\ttotal: 7m 21s\tremaining: 10m 16s\n",
      "334:\tlearn: 0.9869105\ttotal: 7m 23s\tremaining: 10m 15s\n",
      "335:\tlearn: 0.9872064\ttotal: 7m 24s\tremaining: 10m 13s\n",
      "336:\tlearn: 0.9871077\ttotal: 7m 25s\tremaining: 10m 12s\n",
      "337:\tlearn: 0.9872077\ttotal: 7m 27s\tremaining: 10m 11s\n",
      "338:\tlearn: 0.9872077\ttotal: 7m 28s\tremaining: 10m 9s\n",
      "339:\tlearn: 0.9872077\ttotal: 7m 29s\tremaining: 10m 8s\n",
      "340:\tlearn: 0.9872077\ttotal: 7m 31s\tremaining: 10m 7s\n",
      "341:\tlearn: 0.9873063\ttotal: 7m 32s\tremaining: 10m 6s\n",
      "342:\tlearn: 0.9874050\ttotal: 7m 34s\tremaining: 10m 5s\n",
      "343:\tlearn: 0.9874050\ttotal: 7m 35s\tremaining: 10m 3s\n",
      "344:\tlearn: 0.9875037\ttotal: 7m 36s\tremaining: 10m 2s\n",
      "345:\tlearn: 0.9875037\ttotal: 7m 38s\tremaining: 10m 1s\n",
      "346:\tlearn: 0.9874050\ttotal: 7m 39s\tremaining: 9m 59s\n",
      "347:\tlearn: 0.9875037\ttotal: 7m 40s\tremaining: 9m 58s\n",
      "348:\tlearn: 0.9876025\ttotal: 7m 42s\tremaining: 9m 57s\n",
      "349:\tlearn: 0.9876025\ttotal: 7m 43s\tremaining: 9m 56s\n",
      "350:\tlearn: 0.9877012\ttotal: 7m 44s\tremaining: 9m 54s\n",
      "351:\tlearn: 0.9877012\ttotal: 7m 46s\tremaining: 9m 53s\n",
      "352:\tlearn: 0.9876025\ttotal: 7m 47s\tremaining: 9m 52s\n",
      "353:\tlearn: 0.9877012\ttotal: 7m 49s\tremaining: 9m 51s\n",
      "354:\tlearn: 0.9878000\ttotal: 7m 51s\tremaining: 9m 50s\n",
      "355:\tlearn: 0.9877012\ttotal: 7m 52s\tremaining: 9m 49s\n",
      "356:\tlearn: 0.9877012\ttotal: 7m 53s\tremaining: 9m 48s\n",
      "357:\tlearn: 0.9878000\ttotal: 7m 55s\tremaining: 9m 46s\n",
      "358:\tlearn: 0.9878000\ttotal: 7m 56s\tremaining: 9m 45s\n",
      "359:\tlearn: 0.9878988\ttotal: 7m 57s\tremaining: 9m 44s\n",
      "360:\tlearn: 0.9880964\ttotal: 7m 59s\tremaining: 9m 43s\n",
      "361:\tlearn: 0.9880964\ttotal: 8m 1s\tremaining: 9m 42s\n",
      "362:\tlearn: 0.9880964\ttotal: 8m 2s\tremaining: 9m 41s\n",
      "363:\tlearn: 0.9880964\ttotal: 8m 4s\tremaining: 9m 39s\n",
      "364:\tlearn: 0.9882941\ttotal: 8m 5s\tremaining: 9m 38s\n",
      "365:\tlearn: 0.9881953\ttotal: 8m 7s\tremaining: 9m 37s\n",
      "366:\tlearn: 0.9881953\ttotal: 8m 9s\tremaining: 9m 36s\n",
      "367:\tlearn: 0.9882941\ttotal: 8m 10s\tremaining: 9m 35s\n",
      "368:\tlearn: 0.9884919\ttotal: 8m 11s\tremaining: 9m 34s\n",
      "369:\tlearn: 0.9884919\ttotal: 8m 13s\tremaining: 9m 33s\n",
      "370:\tlearn: 0.9885909\ttotal: 8m 14s\tremaining: 9m 32s\n",
      "371:\tlearn: 0.9884919\ttotal: 8m 16s\tremaining: 9m 31s\n",
      "372:\tlearn: 0.9885909\ttotal: 8m 17s\tremaining: 9m 29s\n",
      "373:\tlearn: 0.9885909\ttotal: 8m 19s\tremaining: 9m 28s\n",
      "374:\tlearn: 0.9884919\ttotal: 8m 20s\tremaining: 9m 27s\n",
      "375:\tlearn: 0.9884919\ttotal: 8m 22s\tremaining: 9m 26s\n",
      "376:\tlearn: 0.9885909\ttotal: 8m 23s\tremaining: 9m 25s\n",
      "377:\tlearn: 0.9886898\ttotal: 8m 25s\tremaining: 9m 23s\n",
      "378:\tlearn: 0.9885909\ttotal: 8m 26s\tremaining: 9m 22s\n",
      "379:\tlearn: 0.9886898\ttotal: 8m 28s\tremaining: 9m 21s\n",
      "380:\tlearn: 0.9886898\ttotal: 8m 29s\tremaining: 9m 20s\n",
      "381:\tlearn: 0.9887888\ttotal: 8m 31s\tremaining: 9m 19s\n",
      "382:\tlearn: 0.9886898\ttotal: 8m 32s\tremaining: 9m 18s\n",
      "383:\tlearn: 0.9888878\ttotal: 8m 34s\tremaining: 9m 17s\n",
      "384:\tlearn: 0.9890858\ttotal: 8m 35s\tremaining: 9m 15s\n",
      "385:\tlearn: 0.9890858\ttotal: 8m 37s\tremaining: 9m 14s\n",
      "386:\tlearn: 0.9890858\ttotal: 8m 38s\tremaining: 9m 13s\n",
      "387:\tlearn: 0.9890858\ttotal: 8m 40s\tremaining: 9m 12s\n",
      "388:\tlearn: 0.9890858\ttotal: 8m 41s\tremaining: 9m 10s\n",
      "389:\tlearn: 0.9889868\ttotal: 8m 42s\tremaining: 9m 9s\n",
      "390:\tlearn: 0.9888878\ttotal: 8m 44s\tremaining: 9m 8s\n",
      "391:\tlearn: 0.9889868\ttotal: 8m 45s\tremaining: 9m 7s\n",
      "392:\tlearn: 0.9890858\ttotal: 8m 46s\tremaining: 9m 5s\n",
      "393:\tlearn: 0.9891849\ttotal: 8m 48s\tremaining: 9m 4s\n",
      "394:\tlearn: 0.9891849\ttotal: 8m 49s\tremaining: 9m 3s\n",
      "395:\tlearn: 0.9890858\ttotal: 8m 51s\tremaining: 9m 2s\n",
      "396:\tlearn: 0.9891849\ttotal: 8m 53s\tremaining: 9m 1s\n",
      "397:\tlearn: 0.9892839\ttotal: 8m 54s\tremaining: 8m 59s\n",
      "398:\tlearn: 0.9892839\ttotal: 8m 55s\tremaining: 8m 58s\n",
      "399:\tlearn: 0.9894821\ttotal: 8m 57s\tremaining: 8m 57s\n",
      "400:\tlearn: 0.9894821\ttotal: 8m 58s\tremaining: 8m 56s\n",
      "401:\tlearn: 0.9896804\ttotal: 9m\tremaining: 8m 54s\n",
      "402:\tlearn: 0.9895812\ttotal: 9m 1s\tremaining: 8m 53s\n",
      "403:\tlearn: 0.9893830\ttotal: 9m 3s\tremaining: 8m 52s\n",
      "404:\tlearn: 0.9893830\ttotal: 9m 4s\tremaining: 8m 50s\n",
      "405:\tlearn: 0.9896804\ttotal: 9m 5s\tremaining: 8m 49s\n",
      "406:\tlearn: 0.9896804\ttotal: 9m 7s\tremaining: 8m 48s\n",
      "407:\tlearn: 0.9898787\ttotal: 9m 8s\tremaining: 8m 46s\n",
      "408:\tlearn: 0.9897796\ttotal: 9m 9s\tremaining: 8m 45s\n",
      "409:\tlearn: 0.9900772\ttotal: 9m 11s\tremaining: 8m 44s\n",
      "410:\tlearn: 0.9901764\ttotal: 9m 12s\tremaining: 8m 42s\n",
      "411:\tlearn: 0.9901764\ttotal: 9m 13s\tremaining: 8m 41s\n",
      "412:\tlearn: 0.9901764\ttotal: 9m 15s\tremaining: 8m 40s\n",
      "413:\tlearn: 0.9900772\ttotal: 9m 16s\tremaining: 8m 38s\n",
      "414:\tlearn: 0.9900772\ttotal: 9m 17s\tremaining: 8m 37s\n",
      "415:\tlearn: 0.9901764\ttotal: 9m 19s\tremaining: 8m 36s\n",
      "416:\tlearn: 0.9899780\ttotal: 9m 20s\tremaining: 8m 35s\n",
      "417:\tlearn: 0.9900772\ttotal: 9m 22s\tremaining: 8m 33s\n",
      "418:\tlearn: 0.9902757\ttotal: 9m 23s\tremaining: 8m 32s\n",
      "419:\tlearn: 0.9902757\ttotal: 9m 24s\tremaining: 8m 31s\n",
      "420:\tlearn: 0.9901764\ttotal: 9m 26s\tremaining: 8m 29s\n",
      "421:\tlearn: 0.9901764\ttotal: 9m 27s\tremaining: 8m 28s\n",
      "422:\tlearn: 0.9902757\ttotal: 9m 28s\tremaining: 8m 27s\n",
      "423:\tlearn: 0.9902757\ttotal: 9m 30s\tremaining: 8m 25s\n",
      "424:\tlearn: 0.9902757\ttotal: 9m 31s\tremaining: 8m 24s\n",
      "425:\tlearn: 0.9901764\ttotal: 9m 33s\tremaining: 8m 23s\n",
      "426:\tlearn: 0.9903750\ttotal: 9m 34s\tremaining: 8m 21s\n",
      "427:\tlearn: 0.9906730\ttotal: 9m 35s\tremaining: 8m 20s\n",
      "428:\tlearn: 0.9906730\ttotal: 9m 37s\tremaining: 8m 19s\n",
      "429:\tlearn: 0.9906730\ttotal: 9m 38s\tremaining: 8m 17s\n",
      "430:\tlearn: 0.9907723\ttotal: 9m 39s\tremaining: 8m 16s\n",
      "431:\tlearn: 0.9907723\ttotal: 9m 41s\tremaining: 8m 15s\n",
      "432:\tlearn: 0.9909711\ttotal: 9m 42s\tremaining: 8m 13s\n",
      "433:\tlearn: 0.9909711\ttotal: 9m 43s\tremaining: 8m 12s\n",
      "434:\tlearn: 0.9909711\ttotal: 9m 45s\tremaining: 8m 11s\n",
      "435:\tlearn: 0.9910705\ttotal: 9m 46s\tremaining: 8m 9s\n",
      "436:\tlearn: 0.9909711\ttotal: 9m 48s\tremaining: 8m 8s\n",
      "437:\tlearn: 0.9909711\ttotal: 9m 49s\tremaining: 8m 7s\n",
      "438:\tlearn: 0.9908717\ttotal: 9m 50s\tremaining: 8m 5s\n",
      "439:\tlearn: 0.9908717\ttotal: 9m 52s\tremaining: 8m 4s\n",
      "440:\tlearn: 0.9908717\ttotal: 9m 53s\tremaining: 8m 3s\n",
      "441:\tlearn: 0.9909711\ttotal: 9m 54s\tremaining: 8m 1s\n",
      "442:\tlearn: 0.9909711\ttotal: 9m 56s\tremaining: 8m\n",
      "443:\tlearn: 0.9911700\ttotal: 9m 57s\tremaining: 7m 59s\n",
      "444:\tlearn: 0.9911700\ttotal: 9m 58s\tremaining: 7m 57s\n",
      "445:\tlearn: 0.9911700\ttotal: 10m\tremaining: 7m 56s\n",
      "446:\tlearn: 0.9910705\ttotal: 10m 1s\tremaining: 7m 55s\n",
      "447:\tlearn: 0.9910705\ttotal: 10m 3s\tremaining: 7m 54s\n",
      "448:\tlearn: 0.9910705\ttotal: 10m 4s\tremaining: 7m 52s\n",
      "449:\tlearn: 0.9910705\ttotal: 10m 6s\tremaining: 7m 51s\n",
      "450:\tlearn: 0.9909711\ttotal: 10m 7s\tremaining: 7m 50s\n",
      "451:\tlearn: 0.9910705\ttotal: 10m 9s\tremaining: 7m 49s\n",
      "452:\tlearn: 0.9910705\ttotal: 10m 10s\tremaining: 7m 47s\n",
      "453:\tlearn: 0.9912694\ttotal: 10m 12s\tremaining: 7m 46s\n",
      "454:\tlearn: 0.9913689\ttotal: 10m 14s\tremaining: 7m 45s\n",
      "455:\tlearn: 0.9912694\ttotal: 10m 15s\tremaining: 7m 44s\n",
      "456:\tlearn: 0.9913689\ttotal: 10m 17s\tremaining: 7m 43s\n",
      "457:\tlearn: 0.9916675\ttotal: 10m 18s\tremaining: 7m 42s\n",
      "458:\tlearn: 0.9916675\ttotal: 10m 20s\tremaining: 7m 40s\n",
      "459:\tlearn: 0.9915680\ttotal: 10m 21s\tremaining: 7m 39s\n",
      "460:\tlearn: 0.9914684\ttotal: 10m 23s\tremaining: 7m 38s\n",
      "461:\tlearn: 0.9914684\ttotal: 10m 24s\tremaining: 7m 36s\n",
      "462:\tlearn: 0.9914684\ttotal: 10m 25s\tremaining: 7m 35s\n",
      "463:\tlearn: 0.9914684\ttotal: 10m 27s\tremaining: 7m 34s\n",
      "464:\tlearn: 0.9916675\ttotal: 10m 28s\tremaining: 7m 32s\n",
      "465:\tlearn: 0.9918667\ttotal: 10m 29s\tremaining: 7m 31s\n",
      "466:\tlearn: 0.9918667\ttotal: 10m 31s\tremaining: 7m 30s\n",
      "467:\tlearn: 0.9916675\ttotal: 10m 32s\tremaining: 7m 28s\n",
      "468:\tlearn: 0.9917671\ttotal: 10m 33s\tremaining: 7m 27s\n",
      "469:\tlearn: 0.9918667\ttotal: 10m 35s\tremaining: 7m 26s\n",
      "470:\tlearn: 0.9920659\ttotal: 10m 36s\tremaining: 7m 24s\n",
      "471:\tlearn: 0.9921655\ttotal: 10m 38s\tremaining: 7m 23s\n",
      "472:\tlearn: 0.9921655\ttotal: 10m 39s\tremaining: 7m 22s\n",
      "473:\tlearn: 0.9922652\ttotal: 10m 40s\tremaining: 7m 20s\n",
      "474:\tlearn: 0.9923649\ttotal: 10m 42s\tremaining: 7m 19s\n",
      "475:\tlearn: 0.9923649\ttotal: 10m 43s\tremaining: 7m 18s\n",
      "476:\tlearn: 0.9923649\ttotal: 10m 44s\tremaining: 7m 16s\n",
      "477:\tlearn: 0.9923649\ttotal: 10m 46s\tremaining: 7m 15s\n",
      "478:\tlearn: 0.9924646\ttotal: 10m 47s\tremaining: 7m 14s\n",
      "479:\tlearn: 0.9924646\ttotal: 10m 48s\tremaining: 7m 12s\n",
      "480:\tlearn: 0.9924646\ttotal: 10m 50s\tremaining: 7m 11s\n",
      "481:\tlearn: 0.9923649\ttotal: 10m 51s\tremaining: 7m 9s\n",
      "482:\tlearn: 0.9924646\ttotal: 10m 53s\tremaining: 7m 8s\n",
      "483:\tlearn: 0.9924646\ttotal: 10m 54s\tremaining: 7m 7s\n",
      "484:\tlearn: 0.9924646\ttotal: 10m 55s\tremaining: 7m 5s\n",
      "485:\tlearn: 0.9925643\ttotal: 10m 57s\tremaining: 7m 4s\n",
      "486:\tlearn: 0.9926641\ttotal: 10m 58s\tremaining: 7m 3s\n",
      "487:\tlearn: 0.9927638\ttotal: 10m 59s\tremaining: 7m 1s\n",
      "488:\tlearn: 0.9925643\ttotal: 11m 1s\tremaining: 7m\n",
      "489:\tlearn: 0.9926641\ttotal: 11m 2s\tremaining: 6m 59s\n",
      "490:\tlearn: 0.9927638\ttotal: 11m 4s\tremaining: 6m 57s\n",
      "491:\tlearn: 0.9927638\ttotal: 11m 5s\tremaining: 6m 56s\n",
      "492:\tlearn: 0.9927638\ttotal: 11m 6s\tremaining: 6m 55s\n",
      "493:\tlearn: 0.9927638\ttotal: 11m 8s\tremaining: 6m 53s\n",
      "494:\tlearn: 0.9928636\ttotal: 11m 9s\tremaining: 6m 52s\n",
      "495:\tlearn: 0.9928636\ttotal: 11m 10s\tremaining: 6m 51s\n",
      "496:\tlearn: 0.9928636\ttotal: 11m 12s\tremaining: 6m 49s\n",
      "497:\tlearn: 0.9928636\ttotal: 11m 13s\tremaining: 6m 48s\n",
      "498:\tlearn: 0.9928636\ttotal: 11m 15s\tremaining: 6m 47s\n",
      "499:\tlearn: 0.9928636\ttotal: 11m 16s\tremaining: 6m 45s\n",
      "500:\tlearn: 0.9928636\ttotal: 11m 17s\tremaining: 6m 44s\n",
      "501:\tlearn: 0.9927638\ttotal: 11m 19s\tremaining: 6m 43s\n",
      "502:\tlearn: 0.9927638\ttotal: 11m 20s\tremaining: 6m 41s\n",
      "503:\tlearn: 0.9927638\ttotal: 11m 21s\tremaining: 6m 40s\n",
      "504:\tlearn: 0.9926641\ttotal: 11m 23s\tremaining: 6m 39s\n",
      "505:\tlearn: 0.9926641\ttotal: 11m 24s\tremaining: 6m 37s\n",
      "506:\tlearn: 0.9927638\ttotal: 11m 25s\tremaining: 6m 36s\n",
      "507:\tlearn: 0.9929634\ttotal: 11m 27s\tremaining: 6m 35s\n",
      "508:\tlearn: 0.9928636\ttotal: 11m 28s\tremaining: 6m 33s\n",
      "509:\tlearn: 0.9928636\ttotal: 11m 29s\tremaining: 6m 32s\n",
      "510:\tlearn: 0.9927638\ttotal: 11m 31s\tremaining: 6m 31s\n",
      "511:\tlearn: 0.9928636\ttotal: 11m 32s\tremaining: 6m 29s\n",
      "512:\tlearn: 0.9929634\ttotal: 11m 34s\tremaining: 6m 28s\n",
      "513:\tlearn: 0.9929634\ttotal: 11m 35s\tremaining: 6m 26s\n",
      "514:\tlearn: 0.9931631\ttotal: 11m 36s\tremaining: 6m 25s\n",
      "515:\tlearn: 0.9932629\ttotal: 11m 38s\tremaining: 6m 24s\n",
      "516:\tlearn: 0.9932629\ttotal: 11m 39s\tremaining: 6m 22s\n",
      "517:\tlearn: 0.9933628\ttotal: 11m 40s\tremaining: 6m 21s\n",
      "518:\tlearn: 0.9932629\ttotal: 11m 42s\tremaining: 6m 20s\n",
      "519:\tlearn: 0.9933628\ttotal: 11m 43s\tremaining: 6m 18s\n",
      "520:\tlearn: 0.9933628\ttotal: 11m 45s\tremaining: 6m 17s\n",
      "521:\tlearn: 0.9933628\ttotal: 11m 46s\tremaining: 6m 16s\n",
      "522:\tlearn: 0.9934627\ttotal: 11m 47s\tremaining: 6m 14s\n",
      "523:\tlearn: 0.9938626\ttotal: 11m 49s\tremaining: 6m 13s\n",
      "524:\tlearn: 0.9938626\ttotal: 11m 50s\tremaining: 6m 12s\n",
      "525:\tlearn: 0.9939626\ttotal: 11m 51s\tremaining: 6m 10s\n",
      "526:\tlearn: 0.9939626\ttotal: 11m 53s\tremaining: 6m 9s\n",
      "527:\tlearn: 0.9939626\ttotal: 11m 54s\tremaining: 6m 8s\n",
      "528:\tlearn: 0.9939626\ttotal: 11m 55s\tremaining: 6m 6s\n",
      "529:\tlearn: 0.9940626\ttotal: 11m 57s\tremaining: 6m 5s\n",
      "530:\tlearn: 0.9940626\ttotal: 11m 58s\tremaining: 6m 4s\n",
      "531:\tlearn: 0.9940626\ttotal: 12m\tremaining: 6m 2s\n",
      "532:\tlearn: 0.9940626\ttotal: 12m 1s\tremaining: 6m 1s\n",
      "533:\tlearn: 0.9940626\ttotal: 12m 2s\tremaining: 6m\n",
      "534:\tlearn: 0.9940626\ttotal: 12m 4s\tremaining: 5m 58s\n",
      "535:\tlearn: 0.9941626\ttotal: 12m 5s\tremaining: 5m 57s\n",
      "536:\tlearn: 0.9943628\ttotal: 12m 6s\tremaining: 5m 55s\n",
      "537:\tlearn: 0.9943628\ttotal: 12m 8s\tremaining: 5m 54s\n",
      "538:\tlearn: 0.9943628\ttotal: 12m 9s\tremaining: 5m 53s\n",
      "539:\tlearn: 0.9940626\ttotal: 12m 10s\tremaining: 5m 51s\n",
      "540:\tlearn: 0.9942627\ttotal: 12m 12s\tremaining: 5m 50s\n",
      "541:\tlearn: 0.9944629\ttotal: 12m 13s\tremaining: 5m 49s\n",
      "542:\tlearn: 0.9945630\ttotal: 12m 14s\tremaining: 5m 47s\n",
      "543:\tlearn: 0.9945630\ttotal: 12m 16s\tremaining: 5m 46s\n",
      "544:\tlearn: 0.9945630\ttotal: 12m 17s\tremaining: 5m 45s\n",
      "545:\tlearn: 0.9945630\ttotal: 12m 19s\tremaining: 5m 43s\n",
      "546:\tlearn: 0.9945630\ttotal: 12m 20s\tremaining: 5m 42s\n",
      "547:\tlearn: 0.9945630\ttotal: 12m 21s\tremaining: 5m 41s\n",
      "548:\tlearn: 0.9946632\ttotal: 12m 23s\tremaining: 5m 39s\n",
      "549:\tlearn: 0.9945630\ttotal: 12m 24s\tremaining: 5m 38s\n",
      "550:\tlearn: 0.9946632\ttotal: 12m 25s\tremaining: 5m 37s\n",
      "551:\tlearn: 0.9945630\ttotal: 12m 27s\tremaining: 5m 35s\n",
      "552:\tlearn: 0.9945630\ttotal: 12m 28s\tremaining: 5m 34s\n",
      "553:\tlearn: 0.9946632\ttotal: 12m 29s\tremaining: 5m 33s\n",
      "554:\tlearn: 0.9946632\ttotal: 12m 31s\tremaining: 5m 31s\n",
      "555:\tlearn: 0.9946632\ttotal: 12m 32s\tremaining: 5m 30s\n",
      "556:\tlearn: 0.9946632\ttotal: 12m 34s\tremaining: 5m 28s\n",
      "557:\tlearn: 0.9945630\ttotal: 12m 35s\tremaining: 5m 27s\n",
      "558:\tlearn: 0.9946632\ttotal: 12m 36s\tremaining: 5m 26s\n",
      "559:\tlearn: 0.9946632\ttotal: 12m 38s\tremaining: 5m 24s\n",
      "560:\tlearn: 0.9946632\ttotal: 12m 39s\tremaining: 5m 23s\n",
      "561:\tlearn: 0.9946632\ttotal: 12m 40s\tremaining: 5m 22s\n",
      "562:\tlearn: 0.9946632\ttotal: 12m 42s\tremaining: 5m 20s\n",
      "563:\tlearn: 0.9945630\ttotal: 12m 43s\tremaining: 5m 19s\n",
      "564:\tlearn: 0.9945630\ttotal: 12m 44s\tremaining: 5m 18s\n",
      "565:\tlearn: 0.9945630\ttotal: 12m 46s\tremaining: 5m 16s\n",
      "566:\tlearn: 0.9945630\ttotal: 12m 47s\tremaining: 5m 15s\n",
      "567:\tlearn: 0.9946632\ttotal: 12m 48s\tremaining: 5m 14s\n",
      "568:\tlearn: 0.9944629\ttotal: 12m 50s\tremaining: 5m 12s\n",
      "569:\tlearn: 0.9945630\ttotal: 12m 51s\tremaining: 5m 11s\n",
      "570:\tlearn: 0.9945630\ttotal: 12m 53s\tremaining: 5m 10s\n",
      "571:\tlearn: 0.9945630\ttotal: 12m 54s\tremaining: 5m 8s\n",
      "572:\tlearn: 0.9946632\ttotal: 12m 55s\tremaining: 5m 7s\n",
      "573:\tlearn: 0.9945630\ttotal: 12m 57s\tremaining: 5m 5s\n",
      "574:\tlearn: 0.9945630\ttotal: 12m 58s\tremaining: 5m 4s\n",
      "575:\tlearn: 0.9946632\ttotal: 12m 59s\tremaining: 5m 3s\n",
      "576:\tlearn: 0.9946632\ttotal: 13m 1s\tremaining: 5m 1s\n",
      "577:\tlearn: 0.9945630\ttotal: 13m 2s\tremaining: 5m\n",
      "578:\tlearn: 0.9946632\ttotal: 13m 3s\tremaining: 4m 59s\n",
      "579:\tlearn: 0.9946632\ttotal: 13m 5s\tremaining: 4m 57s\n",
      "580:\tlearn: 0.9947633\ttotal: 13m 6s\tremaining: 4m 56s\n",
      "581:\tlearn: 0.9947633\ttotal: 13m 8s\tremaining: 4m 55s\n",
      "582:\tlearn: 0.9947633\ttotal: 13m 9s\tremaining: 4m 53s\n",
      "583:\tlearn: 0.9947633\ttotal: 13m 10s\tremaining: 4m 52s\n",
      "584:\tlearn: 0.9948635\ttotal: 13m 12s\tremaining: 4m 51s\n",
      "585:\tlearn: 0.9948635\ttotal: 13m 13s\tremaining: 4m 49s\n",
      "586:\tlearn: 0.9949637\ttotal: 13m 14s\tremaining: 4m 48s\n",
      "587:\tlearn: 0.9948635\ttotal: 13m 16s\tremaining: 4m 47s\n",
      "588:\tlearn: 0.9948635\ttotal: 13m 17s\tremaining: 4m 45s\n",
      "589:\tlearn: 0.9948635\ttotal: 13m 19s\tremaining: 4m 44s\n",
      "590:\tlearn: 0.9948635\ttotal: 13m 20s\tremaining: 4m 43s\n",
      "591:\tlearn: 0.9949637\ttotal: 13m 21s\tremaining: 4m 41s\n",
      "592:\tlearn: 0.9950640\ttotal: 13m 23s\tremaining: 4m 40s\n",
      "593:\tlearn: 0.9950640\ttotal: 13m 24s\tremaining: 4m 39s\n",
      "594:\tlearn: 0.9950640\ttotal: 13m 25s\tremaining: 4m 37s\n",
      "595:\tlearn: 0.9950640\ttotal: 13m 27s\tremaining: 4m 36s\n",
      "596:\tlearn: 0.9951642\ttotal: 13m 28s\tremaining: 4m 34s\n",
      "597:\tlearn: 0.9953648\ttotal: 13m 30s\tremaining: 4m 33s\n",
      "598:\tlearn: 0.9954651\ttotal: 13m 31s\tremaining: 4m 32s\n",
      "599:\tlearn: 0.9955654\ttotal: 13m 32s\tremaining: 4m 30s\n",
      "600:\tlearn: 0.9955654\ttotal: 13m 34s\tremaining: 4m 29s\n",
      "601:\tlearn: 0.9956658\ttotal: 13m 35s\tremaining: 4m 28s\n",
      "602:\tlearn: 0.9956658\ttotal: 13m 36s\tremaining: 4m 26s\n",
      "603:\tlearn: 0.9956658\ttotal: 13m 38s\tremaining: 4m 25s\n",
      "604:\tlearn: 0.9956658\ttotal: 13m 39s\tremaining: 4m 24s\n",
      "605:\tlearn: 0.9958665\ttotal: 13m 40s\tremaining: 4m 22s\n",
      "606:\tlearn: 0.9958665\ttotal: 13m 42s\tremaining: 4m 21s\n",
      "607:\tlearn: 0.9959669\ttotal: 13m 43s\tremaining: 4m 20s\n",
      "608:\tlearn: 0.9959669\ttotal: 13m 44s\tremaining: 4m 18s\n",
      "609:\tlearn: 0.9957661\ttotal: 13m 46s\tremaining: 4m 17s\n",
      "610:\tlearn: 0.9957661\ttotal: 13m 47s\tremaining: 4m 16s\n",
      "611:\tlearn: 0.9957661\ttotal: 13m 48s\tremaining: 4m 14s\n",
      "612:\tlearn: 0.9958665\ttotal: 13m 50s\tremaining: 4m 13s\n",
      "613:\tlearn: 0.9957661\ttotal: 13m 51s\tremaining: 4m 11s\n",
      "614:\tlearn: 0.9959669\ttotal: 13m 53s\tremaining: 4m 10s\n",
      "615:\tlearn: 0.9960674\ttotal: 13m 54s\tremaining: 4m 9s\n",
      "616:\tlearn: 0.9960674\ttotal: 13m 55s\tremaining: 4m 7s\n",
      "617:\tlearn: 0.9960674\ttotal: 13m 57s\tremaining: 4m 6s\n",
      "618:\tlearn: 0.9960674\ttotal: 13m 58s\tremaining: 4m 5s\n",
      "619:\tlearn: 0.9960674\ttotal: 14m\tremaining: 4m 3s\n",
      "620:\tlearn: 0.9960674\ttotal: 14m 1s\tremaining: 4m 2s\n",
      "621:\tlearn: 0.9961678\ttotal: 14m 2s\tremaining: 4m 1s\n",
      "622:\tlearn: 0.9961678\ttotal: 14m 4s\tremaining: 3m 59s\n",
      "623:\tlearn: 0.9961678\ttotal: 14m 5s\tremaining: 3m 58s\n",
      "624:\tlearn: 0.9961678\ttotal: 14m 7s\tremaining: 3m 57s\n",
      "625:\tlearn: 0.9960674\ttotal: 14m 8s\tremaining: 3m 55s\n",
      "626:\tlearn: 0.9961678\ttotal: 14m 9s\tremaining: 3m 54s\n",
      "627:\tlearn: 0.9960674\ttotal: 14m 11s\tremaining: 3m 53s\n",
      "628:\tlearn: 0.9960674\ttotal: 14m 12s\tremaining: 3m 51s\n",
      "629:\tlearn: 0.9961678\ttotal: 14m 13s\tremaining: 3m 50s\n",
      "630:\tlearn: 0.9962683\ttotal: 14m 15s\tremaining: 3m 49s\n",
      "631:\tlearn: 0.9962683\ttotal: 14m 16s\tremaining: 3m 47s\n",
      "632:\tlearn: 0.9962683\ttotal: 14m 17s\tremaining: 3m 46s\n",
      "633:\tlearn: 0.9963688\ttotal: 14m 19s\tremaining: 3m 45s\n",
      "634:\tlearn: 0.9963688\ttotal: 14m 20s\tremaining: 3m 43s\n",
      "635:\tlearn: 0.9963688\ttotal: 14m 21s\tremaining: 3m 42s\n",
      "636:\tlearn: 0.9962683\ttotal: 14m 23s\tremaining: 3m 40s\n",
      "637:\tlearn: 0.9963688\ttotal: 14m 24s\tremaining: 3m 39s\n",
      "638:\tlearn: 0.9963688\ttotal: 14m 26s\tremaining: 3m 38s\n",
      "639:\tlearn: 0.9965698\ttotal: 14m 27s\tremaining: 3m 36s\n",
      "640:\tlearn: 0.9965698\ttotal: 14m 28s\tremaining: 3m 35s\n",
      "641:\tlearn: 0.9965698\ttotal: 14m 30s\tremaining: 3m 34s\n",
      "642:\tlearn: 0.9965698\ttotal: 14m 31s\tremaining: 3m 32s\n",
      "643:\tlearn: 0.9966704\ttotal: 14m 32s\tremaining: 3m 31s\n",
      "644:\tlearn: 0.9966704\ttotal: 14m 34s\tremaining: 3m 30s\n",
      "645:\tlearn: 0.9967709\ttotal: 14m 35s\tremaining: 3m 28s\n",
      "646:\tlearn: 0.9966704\ttotal: 14m 36s\tremaining: 3m 27s\n",
      "647:\tlearn: 0.9966704\ttotal: 14m 38s\tremaining: 3m 25s\n",
      "648:\tlearn: 0.9965698\ttotal: 14m 39s\tremaining: 3m 24s\n",
      "649:\tlearn: 0.9966704\ttotal: 14m 40s\tremaining: 3m 23s\n",
      "650:\tlearn: 0.9966704\ttotal: 14m 42s\tremaining: 3m 21s\n",
      "651:\tlearn: 0.9967709\ttotal: 14m 43s\tremaining: 3m 20s\n",
      "652:\tlearn: 0.9968715\ttotal: 14m 44s\tremaining: 3m 19s\n",
      "653:\tlearn: 0.9969721\ttotal: 14m 46s\tremaining: 3m 17s\n",
      "654:\tlearn: 0.9969721\ttotal: 14m 47s\tremaining: 3m 16s\n",
      "655:\tlearn: 0.9969721\ttotal: 14m 48s\tremaining: 3m 15s\n",
      "656:\tlearn: 0.9969721\ttotal: 14m 50s\tremaining: 3m 13s\n",
      "657:\tlearn: 0.9969721\ttotal: 14m 51s\tremaining: 3m 12s\n",
      "658:\tlearn: 0.9969721\ttotal: 14m 52s\tremaining: 3m 11s\n",
      "659:\tlearn: 0.9969721\ttotal: 14m 54s\tremaining: 3m 9s\n",
      "660:\tlearn: 0.9969721\ttotal: 14m 55s\tremaining: 3m 8s\n",
      "661:\tlearn: 0.9969721\ttotal: 14m 56s\tremaining: 3m 6s\n",
      "662:\tlearn: 0.9970728\ttotal: 14m 58s\tremaining: 3m 5s\n",
      "663:\tlearn: 0.9971734\ttotal: 14m 59s\tremaining: 3m 4s\n",
      "664:\tlearn: 0.9970728\ttotal: 15m\tremaining: 3m 2s\n",
      "665:\tlearn: 0.9971734\ttotal: 15m 2s\tremaining: 3m 1s\n",
      "666:\tlearn: 0.9971734\ttotal: 15m 3s\tremaining: 3m\n",
      "667:\tlearn: 0.9971734\ttotal: 15m 4s\tremaining: 2m 58s\n",
      "668:\tlearn: 0.9972741\ttotal: 15m 6s\tremaining: 2m 57s\n",
      "669:\tlearn: 0.9972741\ttotal: 15m 7s\tremaining: 2m 56s\n",
      "670:\tlearn: 0.9972741\ttotal: 15m 8s\tremaining: 2m 54s\n",
      "671:\tlearn: 0.9972741\ttotal: 15m 10s\tremaining: 2m 53s\n",
      "672:\tlearn: 0.9974755\ttotal: 15m 11s\tremaining: 2m 52s\n",
      "673:\tlearn: 0.9974755\ttotal: 15m 13s\tremaining: 2m 50s\n",
      "674:\tlearn: 0.9974755\ttotal: 15m 14s\tremaining: 2m 49s\n",
      "675:\tlearn: 0.9975762\ttotal: 15m 15s\tremaining: 2m 47s\n",
      "676:\tlearn: 0.9975762\ttotal: 15m 17s\tremaining: 2m 46s\n",
      "677:\tlearn: 0.9975762\ttotal: 15m 18s\tremaining: 2m 45s\n",
      "678:\tlearn: 0.9975762\ttotal: 15m 19s\tremaining: 2m 43s\n",
      "679:\tlearn: 0.9975762\ttotal: 15m 21s\tremaining: 2m 42s\n",
      "680:\tlearn: 0.9975762\ttotal: 15m 22s\tremaining: 2m 41s\n",
      "681:\tlearn: 0.9975762\ttotal: 15m 23s\tremaining: 2m 39s\n",
      "682:\tlearn: 0.9976770\ttotal: 15m 25s\tremaining: 2m 38s\n",
      "683:\tlearn: 0.9976770\ttotal: 15m 26s\tremaining: 2m 37s\n",
      "684:\tlearn: 0.9975762\ttotal: 15m 27s\tremaining: 2m 35s\n",
      "685:\tlearn: 0.9976770\ttotal: 15m 29s\tremaining: 2m 34s\n",
      "686:\tlearn: 0.9976770\ttotal: 15m 30s\tremaining: 2m 33s\n",
      "687:\tlearn: 0.9976770\ttotal: 15m 31s\tremaining: 2m 31s\n",
      "688:\tlearn: 0.9976770\ttotal: 15m 33s\tremaining: 2m 30s\n",
      "689:\tlearn: 0.9976770\ttotal: 15m 34s\tremaining: 2m 28s\n",
      "690:\tlearn: 0.9976770\ttotal: 15m 35s\tremaining: 2m 27s\n",
      "691:\tlearn: 0.9976770\ttotal: 15m 37s\tremaining: 2m 26s\n",
      "692:\tlearn: 0.9976770\ttotal: 15m 38s\tremaining: 2m 24s\n",
      "693:\tlearn: 0.9976770\ttotal: 15m 39s\tremaining: 2m 23s\n",
      "694:\tlearn: 0.9976770\ttotal: 15m 41s\tremaining: 2m 22s\n",
      "695:\tlearn: 0.9976770\ttotal: 15m 42s\tremaining: 2m 20s\n",
      "696:\tlearn: 0.9976770\ttotal: 15m 43s\tremaining: 2m 19s\n",
      "697:\tlearn: 0.9976770\ttotal: 15m 45s\tremaining: 2m 18s\n",
      "698:\tlearn: 0.9976770\ttotal: 15m 46s\tremaining: 2m 16s\n",
      "699:\tlearn: 0.9976770\ttotal: 15m 47s\tremaining: 2m 15s\n",
      "700:\tlearn: 0.9976770\ttotal: 15m 49s\tremaining: 2m 14s\n",
      "701:\tlearn: 0.9976770\ttotal: 15m 50s\tremaining: 2m 12s\n",
      "702:\tlearn: 0.9976770\ttotal: 15m 51s\tremaining: 2m 11s\n",
      "703:\tlearn: 0.9976770\ttotal: 15m 53s\tremaining: 2m 9s\n",
      "704:\tlearn: 0.9976770\ttotal: 15m 54s\tremaining: 2m 8s\n",
      "705:\tlearn: 0.9976770\ttotal: 15m 55s\tremaining: 2m 7s\n",
      "706:\tlearn: 0.9976770\ttotal: 15m 57s\tremaining: 2m 5s\n",
      "707:\tlearn: 0.9976770\ttotal: 15m 58s\tremaining: 2m 4s\n",
      "708:\tlearn: 0.9977778\ttotal: 15m 59s\tremaining: 2m 3s\n",
      "709:\tlearn: 0.9978786\ttotal: 16m 1s\tremaining: 2m 1s\n",
      "710:\tlearn: 0.9978786\ttotal: 16m 2s\tremaining: 2m\n",
      "711:\tlearn: 0.9978786\ttotal: 16m 3s\tremaining: 1m 59s\n",
      "712:\tlearn: 0.9979794\ttotal: 16m 5s\tremaining: 1m 57s\n",
      "713:\tlearn: 0.9978786\ttotal: 16m 6s\tremaining: 1m 56s\n",
      "714:\tlearn: 0.9978786\ttotal: 16m 7s\tremaining: 1m 55s\n",
      "715:\tlearn: 0.9978786\ttotal: 16m 9s\tremaining: 1m 53s\n",
      "716:\tlearn: 0.9978786\ttotal: 16m 10s\tremaining: 1m 52s\n",
      "717:\tlearn: 0.9979794\ttotal: 16m 11s\tremaining: 1m 51s\n",
      "718:\tlearn: 0.9979794\ttotal: 16m 13s\tremaining: 1m 49s\n",
      "719:\tlearn: 0.9979794\ttotal: 16m 14s\tremaining: 1m 48s\n",
      "720:\tlearn: 0.9979794\ttotal: 16m 15s\tremaining: 1m 46s\n",
      "721:\tlearn: 0.9979794\ttotal: 16m 17s\tremaining: 1m 45s\n",
      "722:\tlearn: 0.9979794\ttotal: 16m 18s\tremaining: 1m 44s\n",
      "723:\tlearn: 0.9979794\ttotal: 16m 19s\tremaining: 1m 42s\n",
      "724:\tlearn: 0.9979794\ttotal: 16m 21s\tremaining: 1m 41s\n",
      "725:\tlearn: 0.9979794\ttotal: 16m 22s\tremaining: 1m 40s\n",
      "726:\tlearn: 0.9979794\ttotal: 16m 24s\tremaining: 1m 38s\n",
      "727:\tlearn: 0.9979794\ttotal: 16m 25s\tremaining: 1m 37s\n",
      "728:\tlearn: 0.9979794\ttotal: 16m 26s\tremaining: 1m 36s\n",
      "729:\tlearn: 0.9980802\ttotal: 16m 28s\tremaining: 1m 34s\n",
      "730:\tlearn: 0.9980802\ttotal: 16m 29s\tremaining: 1m 33s\n",
      "731:\tlearn: 0.9980802\ttotal: 16m 30s\tremaining: 1m 32s\n",
      "732:\tlearn: 0.9980802\ttotal: 16m 32s\tremaining: 1m 30s\n",
      "733:\tlearn: 0.9980802\ttotal: 16m 33s\tremaining: 1m 29s\n",
      "734:\tlearn: 0.9980802\ttotal: 16m 34s\tremaining: 1m 27s\n",
      "735:\tlearn: 0.9980802\ttotal: 16m 36s\tremaining: 1m 26s\n",
      "736:\tlearn: 0.9980802\ttotal: 16m 37s\tremaining: 1m 25s\n",
      "737:\tlearn: 0.9980802\ttotal: 16m 38s\tremaining: 1m 23s\n",
      "738:\tlearn: 0.9981811\ttotal: 16m 40s\tremaining: 1m 22s\n",
      "739:\tlearn: 0.9980802\ttotal: 16m 41s\tremaining: 1m 21s\n",
      "740:\tlearn: 0.9980802\ttotal: 16m 42s\tremaining: 1m 19s\n",
      "741:\tlearn: 0.9980802\ttotal: 16m 44s\tremaining: 1m 18s\n",
      "742:\tlearn: 0.9980802\ttotal: 16m 45s\tremaining: 1m 17s\n",
      "743:\tlearn: 0.9980802\ttotal: 16m 46s\tremaining: 1m 15s\n",
      "744:\tlearn: 0.9980802\ttotal: 16m 48s\tremaining: 1m 14s\n",
      "745:\tlearn: 0.9980802\ttotal: 16m 49s\tremaining: 1m 13s\n",
      "746:\tlearn: 0.9980802\ttotal: 16m 50s\tremaining: 1m 11s\n",
      "747:\tlearn: 0.9980802\ttotal: 16m 52s\tremaining: 1m 10s\n",
      "748:\tlearn: 0.9980802\ttotal: 16m 53s\tremaining: 1m 9s\n",
      "749:\tlearn: 0.9980802\ttotal: 16m 55s\tremaining: 1m 7s\n",
      "750:\tlearn: 0.9981811\ttotal: 16m 56s\tremaining: 1m 6s\n",
      "751:\tlearn: 0.9980802\ttotal: 16m 57s\tremaining: 1m 4s\n",
      "752:\tlearn: 0.9981811\ttotal: 16m 59s\tremaining: 1m 3s\n",
      "753:\tlearn: 0.9981811\ttotal: 17m\tremaining: 1m 2s\n",
      "754:\tlearn: 0.9981811\ttotal: 17m 1s\tremaining: 1m\n",
      "755:\tlearn: 0.9981811\ttotal: 17m 3s\tremaining: 59.6s\n",
      "756:\tlearn: 0.9981811\ttotal: 17m 4s\tremaining: 58.2s\n",
      "757:\tlearn: 0.9981811\ttotal: 17m 5s\tremaining: 56.8s\n",
      "758:\tlearn: 0.9981811\ttotal: 17m 7s\tremaining: 55.5s\n",
      "759:\tlearn: 0.9981811\ttotal: 17m 8s\tremaining: 54.1s\n",
      "760:\tlearn: 0.9981811\ttotal: 17m 9s\tremaining: 52.8s\n",
      "761:\tlearn: 0.9981811\ttotal: 17m 11s\tremaining: 51.4s\n",
      "762:\tlearn: 0.9981811\ttotal: 17m 12s\tremaining: 50.1s\n",
      "763:\tlearn: 0.9981811\ttotal: 17m 13s\tremaining: 48.7s\n",
      "764:\tlearn: 0.9981811\ttotal: 17m 15s\tremaining: 47.4s\n",
      "765:\tlearn: 0.9981811\ttotal: 17m 16s\tremaining: 46s\n",
      "766:\tlearn: 0.9981811\ttotal: 17m 18s\tremaining: 44.7s\n",
      "767:\tlearn: 0.9981811\ttotal: 17m 19s\tremaining: 43.3s\n",
      "768:\tlearn: 0.9981811\ttotal: 17m 20s\tremaining: 42s\n",
      "769:\tlearn: 0.9981811\ttotal: 17m 22s\tremaining: 40.6s\n",
      "770:\tlearn: 0.9981811\ttotal: 17m 23s\tremaining: 39.2s\n",
      "771:\tlearn: 0.9981811\ttotal: 17m 24s\tremaining: 37.9s\n",
      "772:\tlearn: 0.9981811\ttotal: 17m 26s\tremaining: 36.5s\n",
      "773:\tlearn: 0.9981811\ttotal: 17m 27s\tremaining: 35.2s\n",
      "774:\tlearn: 0.9981811\ttotal: 17m 28s\tremaining: 33.8s\n",
      "775:\tlearn: 0.9981811\ttotal: 17m 30s\tremaining: 32.5s\n",
      "776:\tlearn: 0.9981811\ttotal: 17m 31s\tremaining: 31.1s\n",
      "777:\tlearn: 0.9981811\ttotal: 17m 32s\tremaining: 29.8s\n",
      "778:\tlearn: 0.9981811\ttotal: 17m 34s\tremaining: 28.4s\n",
      "779:\tlearn: 0.9981811\ttotal: 17m 35s\tremaining: 27.1s\n",
      "780:\tlearn: 0.9981811\ttotal: 17m 36s\tremaining: 25.7s\n",
      "781:\tlearn: 0.9981811\ttotal: 17m 38s\tremaining: 24.4s\n",
      "782:\tlearn: 0.9981811\ttotal: 17m 39s\tremaining: 23s\n",
      "783:\tlearn: 0.9981811\ttotal: 17m 40s\tremaining: 21.7s\n",
      "784:\tlearn: 0.9981811\ttotal: 17m 42s\tremaining: 20.3s\n",
      "785:\tlearn: 0.9981811\ttotal: 17m 43s\tremaining: 18.9s\n",
      "786:\tlearn: 0.9981811\ttotal: 17m 45s\tremaining: 17.6s\n",
      "787:\tlearn: 0.9981811\ttotal: 17m 46s\tremaining: 16.2s\n",
      "788:\tlearn: 0.9981811\ttotal: 17m 47s\tremaining: 14.9s\n",
      "789:\tlearn: 0.9981811\ttotal: 17m 49s\tremaining: 13.5s\n",
      "790:\tlearn: 0.9982820\ttotal: 17m 50s\tremaining: 12.2s\n",
      "791:\tlearn: 0.9982820\ttotal: 17m 51s\tremaining: 10.8s\n",
      "792:\tlearn: 0.9982820\ttotal: 17m 53s\tremaining: 9.47s\n",
      "793:\tlearn: 0.9982820\ttotal: 17m 54s\tremaining: 8.12s\n",
      "794:\tlearn: 0.9982820\ttotal: 17m 55s\tremaining: 6.77s\n",
      "795:\tlearn: 0.9983829\ttotal: 17m 57s\tremaining: 5.41s\n",
      "796:\tlearn: 0.9983829\ttotal: 17m 58s\tremaining: 4.06s\n",
      "797:\tlearn: 0.9983829\ttotal: 17m 59s\tremaining: 2.71s\n",
      "798:\tlearn: 0.9983829\ttotal: 18m 1s\tremaining: 1.35s\n",
      "799:\tlearn: 0.9983829\ttotal: 18m 2s\tremaining: 0us\n",
      "[CV] END auto_class_weights=SqrtBalanced, bagging_temperature=2, border_count=32, depth=12, eval_metric=Precision, iterations=800, l2_leaf_reg=1, leaf_estimation_method=Gradient, learning_rate=0.01, random_strength=5; total time=18.1min\n",
      "0:\ttotal: 20.2s\tremaining: 2h 48m 11s\n",
      "1:\ttotal: 40.3s\tremaining: 2h 47m 6s\n",
      "2:\ttotal: 1m\tremaining: 2h 45m 54s\n",
      "3:\ttotal: 1m 19s\tremaining: 2h 45m 19s\n",
      "4:\ttotal: 1m 39s\tremaining: 2h 44m 51s\n",
      "5:\ttotal: 1m 59s\tremaining: 2h 44m 31s\n",
      "6:\ttotal: 2m 19s\tremaining: 2h 44m 9s\n",
      "7:\ttotal: 2m 39s\tremaining: 2h 43m 32s\n",
      "8:\ttotal: 2m 59s\tremaining: 2h 43m 3s\n",
      "9:\ttotal: 3m 19s\tremaining: 2h 42m 44s\n",
      "10:\ttotal: 3m 39s\tremaining: 2h 42m 22s\n",
      "11:\ttotal: 3m 59s\tremaining: 2h 42m\n",
      "12:\ttotal: 4m 18s\tremaining: 2h 41m 41s\n",
      "13:\ttotal: 4m 38s\tremaining: 2h 41m 18s\n",
      "14:\ttotal: 4m 58s\tremaining: 2h 40m 57s\n",
      "15:\ttotal: 5m 18s\tremaining: 2h 40m 39s\n",
      "16:\ttotal: 5m 38s\tremaining: 2h 40m 24s\n",
      "17:\ttotal: 5m 58s\tremaining: 2h 39m 57s\n",
      "18:\ttotal: 6m 18s\tremaining: 2h 39m 36s\n",
      "19:\ttotal: 6m 38s\tremaining: 2h 39m 14s\n",
      "20:\ttotal: 6m 58s\tremaining: 2h 38m 54s\n",
      "21:\ttotal: 7m 18s\tremaining: 2h 38m 38s\n",
      "22:\ttotal: 7m 38s\tremaining: 2h 38m 18s\n",
      "23:\ttotal: 7m 57s\tremaining: 2h 37m 59s\n",
      "24:\ttotal: 8m 17s\tremaining: 2h 37m 38s\n",
      "25:\ttotal: 8m 37s\tremaining: 2h 37m 17s\n",
      "26:\ttotal: 8m 57s\tremaining: 2h 36m 55s\n",
      "27:\ttotal: 9m 17s\tremaining: 2h 36m 31s\n",
      "28:\ttotal: 9m 37s\tremaining: 2h 36m 12s\n",
      "29:\ttotal: 9m 56s\tremaining: 2h 35m 50s\n",
      "30:\ttotal: 10m 16s\tremaining: 2h 35m 29s\n",
      "31:\ttotal: 10m 36s\tremaining: 2h 35m 9s\n",
      "32:\ttotal: 10m 56s\tremaining: 2h 34m 48s\n",
      "33:\ttotal: 11m 16s\tremaining: 2h 34m 29s\n",
      "34:\ttotal: 11m 36s\tremaining: 2h 34m 8s\n",
      "35:\ttotal: 11m 55s\tremaining: 2h 33m 47s\n",
      "36:\ttotal: 12m 15s\tremaining: 2h 33m 26s\n",
      "37:\ttotal: 12m 35s\tremaining: 2h 33m 4s\n",
      "38:\ttotal: 12m 55s\tremaining: 2h 32m 43s\n",
      "39:\ttotal: 13m 15s\tremaining: 2h 32m 22s\n",
      "40:\ttotal: 13m 34s\tremaining: 2h 32m 2s\n",
      "41:\ttotal: 13m 54s\tremaining: 2h 31m 43s\n",
      "42:\ttotal: 14m 14s\tremaining: 2h 31m 23s\n",
      "43:\ttotal: 14m 34s\tremaining: 2h 31m 4s\n",
      "44:\ttotal: 14m 54s\tremaining: 2h 30m 43s\n",
      "45:\ttotal: 15m 14s\tremaining: 2h 30m 25s\n",
      "46:\ttotal: 15m 34s\tremaining: 2h 30m 4s\n",
      "47:\ttotal: 15m 54s\tremaining: 2h 29m 45s\n",
      "48:\ttotal: 16m 14s\tremaining: 2h 29m 25s\n",
      "49:\ttotal: 16m 33s\tremaining: 2h 29m 5s\n",
      "50:\ttotal: 16m 53s\tremaining: 2h 28m 45s\n",
      "51:\ttotal: 17m 13s\tremaining: 2h 28m 24s\n",
      "52:\ttotal: 17m 33s\tremaining: 2h 28m 1s\n",
      "53:\ttotal: 17m 53s\tremaining: 2h 27m 42s\n",
      "54:\ttotal: 18m 12s\tremaining: 2h 27m 22s\n",
      "55:\ttotal: 18m 32s\tremaining: 2h 27m 2s\n",
      "56:\ttotal: 18m 52s\tremaining: 2h 26m 42s\n",
      "57:\ttotal: 19m 12s\tremaining: 2h 26m 21s\n",
      "58:\ttotal: 19m 32s\tremaining: 2h 26m\n",
      "59:\ttotal: 19m 52s\tremaining: 2h 25m 41s\n",
      "60:\ttotal: 20m 11s\tremaining: 2h 25m 20s\n",
      "61:\ttotal: 20m 31s\tremaining: 2h 25m\n",
      "62:\ttotal: 20m 51s\tremaining: 2h 24m 40s\n",
      "63:\ttotal: 21m 11s\tremaining: 2h 24m 19s\n",
      "64:\ttotal: 21m 30s\tremaining: 2h 23m 59s\n",
      "65:\ttotal: 21m 50s\tremaining: 2h 23m 39s\n",
      "66:\ttotal: 22m 10s\tremaining: 2h 23m 20s\n",
      "67:\ttotal: 22m 30s\tremaining: 2h 23m\n",
      "68:\ttotal: 22m 50s\tremaining: 2h 22m 40s\n",
      "69:\ttotal: 23m 10s\tremaining: 2h 22m 21s\n",
      "70:\ttotal: 23m 30s\tremaining: 2h 22m 2s\n",
      "71:\ttotal: 23m 50s\tremaining: 2h 21m 42s\n",
      "72:\ttotal: 24m 10s\tremaining: 2h 21m 22s\n",
      "73:\ttotal: 24m 30s\tremaining: 2h 21m 3s\n",
      "74:\ttotal: 24m 50s\tremaining: 2h 20m 43s\n",
      "75:\ttotal: 25m 9s\tremaining: 2h 20m 23s\n",
      "76:\ttotal: 25m 29s\tremaining: 2h 20m 5s\n",
      "77:\ttotal: 25m 49s\tremaining: 2h 19m 45s\n",
      "78:\ttotal: 26m 9s\tremaining: 2h 19m 25s\n",
      "79:\ttotal: 26m 29s\tremaining: 2h 19m 6s\n",
      "80:\ttotal: 26m 49s\tremaining: 2h 18m 46s\n",
      "81:\ttotal: 27m 9s\tremaining: 2h 18m 26s\n",
      "82:\ttotal: 27m 29s\tremaining: 2h 18m 6s\n",
      "83:\ttotal: 27m 49s\tremaining: 2h 17m 47s\n",
      "84:\ttotal: 28m 9s\tremaining: 2h 17m 26s\n",
      "85:\ttotal: 28m 29s\tremaining: 2h 17m 7s\n",
      "86:\ttotal: 28m 49s\tremaining: 2h 16m 48s\n",
      "87:\ttotal: 29m 8s\tremaining: 2h 16m 28s\n",
      "88:\ttotal: 29m 28s\tremaining: 2h 16m 8s\n",
      "89:\ttotal: 29m 49s\tremaining: 2h 15m 50s\n",
      "90:\ttotal: 30m 8s\tremaining: 2h 15m 29s\n",
      "91:\ttotal: 30m 28s\tremaining: 2h 15m 10s\n",
      "92:\ttotal: 30m 48s\tremaining: 2h 14m 50s\n",
      "93:\ttotal: 31m 8s\tremaining: 2h 14m 30s\n",
      "94:\ttotal: 31m 28s\tremaining: 2h 14m 10s\n",
      "95:\ttotal: 31m 48s\tremaining: 2h 13m 50s\n",
      "96:\ttotal: 32m 8s\tremaining: 2h 13m 30s\n",
      "97:\ttotal: 32m 27s\tremaining: 2h 13m 10s\n",
      "98:\ttotal: 32m 47s\tremaining: 2h 12m 50s\n",
      "99:\ttotal: 33m 7s\tremaining: 2h 12m 31s\n",
      "100:\ttotal: 33m 27s\tremaining: 2h 12m 11s\n",
      "101:\ttotal: 33m 47s\tremaining: 2h 11m 51s\n",
      "102:\ttotal: 34m 7s\tremaining: 2h 11m 30s\n",
      "103:\ttotal: 34m 26s\tremaining: 2h 11m 9s\n",
      "104:\ttotal: 34m 46s\tremaining: 2h 10m 48s\n",
      "105:\ttotal: 35m 6s\tremaining: 2h 10m 28s\n",
      "106:\ttotal: 35m 25s\tremaining: 2h 10m 8s\n",
      "107:\ttotal: 35m 45s\tremaining: 2h 9m 47s\n",
      "108:\ttotal: 36m 5s\tremaining: 2h 9m 27s\n",
      "109:\ttotal: 36m 25s\tremaining: 2h 9m 7s\n",
      "110:\ttotal: 36m 45s\tremaining: 2h 8m 47s\n",
      "111:\ttotal: 37m 4s\tremaining: 2h 8m 27s\n",
      "112:\ttotal: 37m 24s\tremaining: 2h 8m 8s\n",
      "113:\ttotal: 37m 44s\tremaining: 2h 7m 48s\n",
      "114:\ttotal: 38m 4s\tremaining: 2h 7m 28s\n",
      "115:\ttotal: 38m 24s\tremaining: 2h 7m 8s\n",
      "116:\ttotal: 38m 44s\tremaining: 2h 6m 48s\n",
      "117:\ttotal: 39m 4s\tremaining: 2h 6m 28s\n",
      "118:\ttotal: 39m 24s\tremaining: 2h 6m 8s\n",
      "119:\ttotal: 39m 43s\tremaining: 2h 5m 49s\n",
      "120:\ttotal: 40m 3s\tremaining: 2h 5m 29s\n",
      "121:\ttotal: 40m 23s\tremaining: 2h 5m 9s\n",
      "122:\ttotal: 40m 43s\tremaining: 2h 4m 50s\n",
      "123:\ttotal: 41m 3s\tremaining: 2h 4m 30s\n",
      "124:\ttotal: 41m 23s\tremaining: 2h 4m 10s\n",
      "125:\ttotal: 41m 43s\tremaining: 2h 3m 50s\n",
      "126:\ttotal: 42m 3s\tremaining: 2h 3m 31s\n",
      "127:\ttotal: 42m 23s\tremaining: 2h 3m 10s\n",
      "128:\ttotal: 42m 42s\tremaining: 2h 2m 51s\n",
      "129:\ttotal: 43m 2s\tremaining: 2h 2m 31s\n",
      "130:\ttotal: 43m 22s\tremaining: 2h 2m 11s\n",
      "131:\ttotal: 43m 42s\tremaining: 2h 1m 51s\n",
      "132:\ttotal: 44m 2s\tremaining: 2h 1m 31s\n",
      "133:\ttotal: 44m 22s\tremaining: 2h 1m 11s\n",
      "134:\ttotal: 44m 41s\tremaining: 2h 51s\n",
      "135:\ttotal: 45m 1s\tremaining: 2h 31s\n",
      "136:\ttotal: 45m 21s\tremaining: 2h 12s\n",
      "137:\ttotal: 45m 41s\tremaining: 1h 59m 52s\n",
      "138:\ttotal: 46m 1s\tremaining: 1h 59m 32s\n",
      "139:\ttotal: 46m 21s\tremaining: 1h 59m 13s\n",
      "140:\ttotal: 46m 41s\tremaining: 1h 58m 53s\n",
      "141:\ttotal: 47m 1s\tremaining: 1h 58m 33s\n",
      "142:\ttotal: 47m 21s\tremaining: 1h 58m 13s\n",
      "143:\ttotal: 47m 41s\tremaining: 1h 57m 53s\n",
      "144:\ttotal: 48m 1s\tremaining: 1h 57m 33s\n",
      "145:\ttotal: 48m 20s\tremaining: 1h 57m 13s\n",
      "146:\ttotal: 48m 40s\tremaining: 1h 56m 54s\n",
      "147:\ttotal: 49m\tremaining: 1h 56m 33s\n",
      "148:\ttotal: 49m 20s\tremaining: 1h 56m 13s\n",
      "149:\ttotal: 49m 40s\tremaining: 1h 55m 54s\n",
      "150:\ttotal: 50m\tremaining: 1h 55m 34s\n",
      "151:\ttotal: 50m 19s\tremaining: 1h 55m 13s\n",
      "152:\ttotal: 50m 39s\tremaining: 1h 54m 53s\n",
      "153:\ttotal: 50m 59s\tremaining: 1h 54m 33s\n",
      "154:\ttotal: 51m 19s\tremaining: 1h 54m 13s\n",
      "155:\ttotal: 51m 39s\tremaining: 1h 53m 53s\n",
      "156:\ttotal: 51m 58s\tremaining: 1h 53m 33s\n",
      "157:\ttotal: 52m 18s\tremaining: 1h 53m 13s\n",
      "158:\ttotal: 52m 38s\tremaining: 1h 52m 54s\n",
      "159:\ttotal: 52m 58s\tremaining: 1h 52m 34s\n",
      "160:\ttotal: 53m 18s\tremaining: 1h 52m 13s\n",
      "161:\ttotal: 53m 37s\tremaining: 1h 51m 54s\n",
      "162:\ttotal: 53m 57s\tremaining: 1h 51m 34s\n",
      "163:\ttotal: 54m 17s\tremaining: 1h 51m 13s\n",
      "164:\ttotal: 54m 37s\tremaining: 1h 50m 54s\n",
      "165:\ttotal: 54m 57s\tremaining: 1h 50m 34s\n",
      "166:\ttotal: 55m 17s\tremaining: 1h 50m 14s\n",
      "167:\ttotal: 55m 37s\tremaining: 1h 49m 55s\n",
      "168:\ttotal: 55m 57s\tremaining: 1h 49m 35s\n",
      "169:\ttotal: 56m 17s\tremaining: 1h 49m 15s\n",
      "170:\ttotal: 56m 37s\tremaining: 1h 48m 56s\n",
      "171:\ttotal: 56m 59s\tremaining: 1h 48m 40s\n",
      "172:\ttotal: 57m 21s\tremaining: 1h 48m 24s\n",
      "173:\ttotal: 57m 41s\tremaining: 1h 48m 6s\n",
      "174:\ttotal: 58m 2s\tremaining: 1h 47m 47s\n",
      "175:\ttotal: 58m 22s\tremaining: 1h 47m 28s\n",
      "176:\ttotal: 58m 42s\tremaining: 1h 47m 8s\n",
      "177:\ttotal: 59m 4s\tremaining: 1h 46m 51s\n",
      "178:\ttotal: 59m 24s\tremaining: 1h 46m 31s\n",
      "179:\ttotal: 59m 46s\tremaining: 1h 46m 16s\n",
      "180:\ttotal: 1h 8s\tremaining: 1h 46m\n",
      "181:\ttotal: 1h 31s\tremaining: 1h 45m 45s\n",
      "182:\ttotal: 1h 54s\tremaining: 1h 45m 29s\n",
      "183:\ttotal: 1h 1m 16s\tremaining: 1h 45m 14s\n",
      "184:\ttotal: 1h 1m 38s\tremaining: 1h 44m 56s\n",
      "185:\ttotal: 1h 1m 59s\tremaining: 1h 44m 38s\n",
      "186:\ttotal: 1h 2m 19s\tremaining: 1h 44m 19s\n",
      "187:\ttotal: 1h 2m 40s\tremaining: 1h 44m\n",
      "188:\ttotal: 1h 3m 1s\tremaining: 1h 43m 41s\n",
      "189:\ttotal: 1h 3m 22s\tremaining: 1h 43m 24s\n",
      "190:\ttotal: 1h 3m 43s\tremaining: 1h 43m 6s\n",
      "191:\ttotal: 1h 4m 4s\tremaining: 1h 42m 47s\n",
      "192:\ttotal: 1h 4m 25s\tremaining: 1h 42m 28s\n",
      "193:\ttotal: 1h 4m 45s\tremaining: 1h 42m 8s\n",
      "194:\ttotal: 1h 5m 5s\tremaining: 1h 41m 48s\n",
      "195:\ttotal: 1h 5m 26s\tremaining: 1h 41m 29s\n",
      "196:\ttotal: 1h 5m 46s\tremaining: 1h 41m 10s\n",
      "197:\ttotal: 1h 6m 7s\tremaining: 1h 40m 50s\n",
      "198:\ttotal: 1h 6m 27s\tremaining: 1h 40m 30s\n",
      "199:\ttotal: 1h 6m 46s\tremaining: 1h 40m 10s\n",
      "200:\ttotal: 1h 7m 7s\tremaining: 1h 39m 50s\n",
      "201:\ttotal: 1h 7m 27s\tremaining: 1h 39m 30s\n",
      "202:\ttotal: 1h 7m 47s\tremaining: 1h 39m 10s\n",
      "203:\ttotal: 1h 8m 7s\tremaining: 1h 38m 50s\n",
      "204:\ttotal: 1h 8m 27s\tremaining: 1h 38m 31s\n",
      "205:\ttotal: 1h 8m 47s\tremaining: 1h 38m 11s\n",
      "206:\ttotal: 1h 9m 7s\tremaining: 1h 37m 50s\n",
      "207:\ttotal: 1h 9m 28s\tremaining: 1h 37m 31s\n",
      "208:\ttotal: 1h 9m 47s\tremaining: 1h 37m 11s\n",
      "209:\ttotal: 1h 10m 7s\tremaining: 1h 36m 51s\n",
      "210:\ttotal: 1h 10m 28s\tremaining: 1h 36m 31s\n",
      "211:\ttotal: 1h 10m 48s\tremaining: 1h 36m 11s\n",
      "212:\ttotal: 1h 11m 8s\tremaining: 1h 35m 51s\n",
      "213:\ttotal: 1h 11m 28s\tremaining: 1h 35m 31s\n",
      "214:\ttotal: 1h 11m 48s\tremaining: 1h 35m 11s\n",
      "215:\ttotal: 1h 12m 8s\tremaining: 1h 34m 50s\n",
      "216:\ttotal: 1h 12m 28s\tremaining: 1h 34m 31s\n",
      "217:\ttotal: 1h 12m 48s\tremaining: 1h 34m 11s\n",
      "218:\ttotal: 1h 13m 8s\tremaining: 1h 33m 51s\n",
      "219:\ttotal: 1h 13m 28s\tremaining: 1h 33m 31s\n",
      "220:\ttotal: 1h 13m 48s\tremaining: 1h 33m 11s\n",
      "221:\ttotal: 1h 14m 8s\tremaining: 1h 32m 51s\n",
      "222:\ttotal: 1h 14m 28s\tremaining: 1h 32m 31s\n",
      "223:\ttotal: 1h 14m 49s\tremaining: 1h 32m 11s\n",
      "224:\ttotal: 1h 15m 9s\tremaining: 1h 31m 51s\n",
      "225:\ttotal: 1h 15m 29s\tremaining: 1h 31m 31s\n",
      "226:\ttotal: 1h 15m 49s\tremaining: 1h 31m 11s\n",
      "227:\ttotal: 1h 16m 10s\tremaining: 1h 30m 52s\n",
      "228:\ttotal: 1h 16m 30s\tremaining: 1h 30m 32s\n",
      "229:\ttotal: 1h 16m 50s\tremaining: 1h 30m 12s\n",
      "230:\ttotal: 1h 17m 10s\tremaining: 1h 29m 52s\n",
      "231:\ttotal: 1h 17m 30s\tremaining: 1h 29m 32s\n",
      "232:\ttotal: 1h 17m 50s\tremaining: 1h 29m 12s\n",
      "233:\ttotal: 1h 18m 10s\tremaining: 1h 28m 51s\n",
      "234:\ttotal: 1h 18m 30s\tremaining: 1h 28m 31s\n",
      "235:\ttotal: 1h 18m 50s\tremaining: 1h 28m 11s\n",
      "236:\ttotal: 1h 19m 10s\tremaining: 1h 27m 51s\n",
      "237:\ttotal: 1h 19m 30s\tremaining: 1h 27m 31s\n",
      "238:\ttotal: 1h 19m 50s\tremaining: 1h 27m 11s\n",
      "239:\ttotal: 1h 20m 10s\tremaining: 1h 26m 51s\n",
      "240:\ttotal: 1h 20m 30s\tremaining: 1h 26m 31s\n",
      "241:\ttotal: 1h 20m 51s\tremaining: 1h 26m 11s\n",
      "242:\ttotal: 1h 21m 10s\tremaining: 1h 25m 51s\n",
      "243:\ttotal: 1h 21m 31s\tremaining: 1h 25m 31s\n",
      "244:\ttotal: 1h 21m 51s\tremaining: 1h 25m 11s\n",
      "245:\ttotal: 1h 22m 11s\tremaining: 1h 24m 51s\n",
      "246:\ttotal: 1h 22m 31s\tremaining: 1h 24m 31s\n",
      "247:\ttotal: 1h 22m 51s\tremaining: 1h 24m 11s\n",
      "248:\ttotal: 1h 23m 11s\tremaining: 1h 23m 51s\n",
      "249:\ttotal: 1h 23m 31s\tremaining: 1h 23m 31s\n",
      "250:\ttotal: 1h 23m 51s\tremaining: 1h 23m 11s\n",
      "251:\ttotal: 1h 24m 11s\tremaining: 1h 22m 51s\n",
      "252:\ttotal: 1h 24m 31s\tremaining: 1h 22m 31s\n",
      "253:\ttotal: 1h 24m 51s\tremaining: 1h 22m 11s\n",
      "254:\ttotal: 1h 25m 11s\tremaining: 1h 21m 51s\n",
      "255:\ttotal: 1h 25m 31s\tremaining: 1h 21m 31s\n",
      "256:\ttotal: 1h 25m 52s\tremaining: 1h 21m 11s\n",
      "257:\ttotal: 1h 26m 12s\tremaining: 1h 20m 51s\n",
      "258:\ttotal: 1h 26m 32s\tremaining: 1h 20m 31s\n",
      "259:\ttotal: 1h 26m 52s\tremaining: 1h 20m 11s\n",
      "260:\ttotal: 1h 27m 12s\tremaining: 1h 19m 51s\n",
      "261:\ttotal: 1h 27m 32s\tremaining: 1h 19m 31s\n",
      "262:\ttotal: 1h 27m 52s\tremaining: 1h 19m 11s\n",
      "263:\ttotal: 1h 28m 12s\tremaining: 1h 18m 51s\n",
      "264:\ttotal: 1h 28m 33s\tremaining: 1h 18m 31s\n",
      "265:\ttotal: 1h 28m 53s\tremaining: 1h 18m 11s\n",
      "266:\ttotal: 1h 29m 13s\tremaining: 1h 17m 51s\n",
      "267:\ttotal: 1h 29m 33s\tremaining: 1h 17m 31s\n",
      "268:\ttotal: 1h 29m 53s\tremaining: 1h 17m 11s\n",
      "269:\ttotal: 1h 30m 13s\tremaining: 1h 16m 51s\n",
      "270:\ttotal: 1h 30m 33s\tremaining: 1h 16m 31s\n",
      "271:\ttotal: 1h 30m 54s\tremaining: 1h 16m 11s\n",
      "272:\ttotal: 1h 31m 14s\tremaining: 1h 15m 51s\n",
      "273:\ttotal: 1h 31m 34s\tremaining: 1h 15m 31s\n",
      "274:\ttotal: 1h 31m 54s\tremaining: 1h 15m 11s\n",
      "275:\ttotal: 1h 32m 14s\tremaining: 1h 14m 51s\n",
      "276:\ttotal: 1h 32m 34s\tremaining: 1h 14m 31s\n",
      "277:\ttotal: 1h 32m 53s\tremaining: 1h 14m 11s\n",
      "278:\ttotal: 1h 33m 13s\tremaining: 1h 13m 50s\n",
      "279:\ttotal: 1h 33m 33s\tremaining: 1h 13m 30s\n",
      "280:\ttotal: 1h 33m 53s\tremaining: 1h 13m 10s\n",
      "281:\ttotal: 1h 34m 13s\tremaining: 1h 12m 50s\n",
      "282:\ttotal: 1h 34m 33s\tremaining: 1h 12m 30s\n",
      "283:\ttotal: 1h 34m 53s\tremaining: 1h 12m 10s\n",
      "284:\ttotal: 1h 35m 13s\tremaining: 1h 11m 50s\n",
      "285:\ttotal: 1h 35m 33s\tremaining: 1h 11m 29s\n",
      "286:\ttotal: 1h 35m 53s\tremaining: 1h 11m 10s\n",
      "287:\ttotal: 1h 36m 13s\tremaining: 1h 10m 50s\n",
      "288:\ttotal: 1h 36m 33s\tremaining: 1h 10m 30s\n",
      "289:\ttotal: 1h 36m 54s\tremaining: 1h 10m 10s\n",
      "290:\ttotal: 1h 37m 14s\tremaining: 1h 9m 50s\n",
      "291:\ttotal: 1h 37m 34s\tremaining: 1h 9m 30s\n",
      "292:\ttotal: 1h 37m 54s\tremaining: 1h 9m 9s\n",
      "293:\ttotal: 1h 38m 14s\tremaining: 1h 8m 50s\n",
      "294:\ttotal: 1h 38m 34s\tremaining: 1h 8m 30s\n",
      "295:\ttotal: 1h 38m 54s\tremaining: 1h 8m 10s\n",
      "296:\ttotal: 1h 39m 14s\tremaining: 1h 7m 50s\n",
      "297:\ttotal: 1h 39m 34s\tremaining: 1h 7m 30s\n",
      "298:\ttotal: 1h 39m 54s\tremaining: 1h 7m 9s\n",
      "299:\ttotal: 1h 40m 14s\tremaining: 1h 6m 49s\n",
      "300:\ttotal: 1h 40m 34s\tremaining: 1h 6m 29s\n",
      "301:\ttotal: 1h 40m 54s\tremaining: 1h 6m 9s\n",
      "302:\ttotal: 1h 41m 14s\tremaining: 1h 5m 49s\n",
      "303:\ttotal: 1h 41m 35s\tremaining: 1h 5m 29s\n",
      "304:\ttotal: 1h 41m 55s\tremaining: 1h 5m 9s\n",
      "305:\ttotal: 1h 42m 15s\tremaining: 1h 4m 49s\n",
      "306:\ttotal: 1h 42m 35s\tremaining: 1h 4m 29s\n",
      "307:\ttotal: 1h 42m 55s\tremaining: 1h 4m 9s\n",
      "308:\ttotal: 1h 43m 15s\tremaining: 1h 3m 49s\n",
      "309:\ttotal: 1h 43m 35s\tremaining: 1h 3m 29s\n",
      "310:\ttotal: 1h 43m 55s\tremaining: 1h 3m 9s\n",
      "311:\ttotal: 1h 44m 15s\tremaining: 1h 2m 49s\n",
      "312:\ttotal: 1h 44m 35s\tremaining: 1h 2m 29s\n",
      "313:\ttotal: 1h 44m 55s\tremaining: 1h 2m 9s\n",
      "314:\ttotal: 1h 45m 15s\tremaining: 1h 1m 49s\n",
      "315:\ttotal: 1h 45m 35s\tremaining: 1h 1m 29s\n",
      "316:\ttotal: 1h 45m 56s\tremaining: 1h 1m 9s\n",
      "317:\ttotal: 1h 46m 16s\tremaining: 1h 49s\n",
      "318:\ttotal: 1h 46m 36s\tremaining: 1h 29s\n",
      "319:\ttotal: 1h 46m 56s\tremaining: 1h 9s\n",
      "320:\ttotal: 1h 47m 16s\tremaining: 59m 48s\n",
      "321:\ttotal: 1h 47m 36s\tremaining: 59m 28s\n",
      "322:\ttotal: 1h 47m 56s\tremaining: 59m 8s\n",
      "323:\ttotal: 1h 48m 16s\tremaining: 58m 48s\n",
      "324:\ttotal: 1h 48m 36s\tremaining: 58m 28s\n",
      "325:\ttotal: 1h 48m 55s\tremaining: 58m 8s\n",
      "326:\ttotal: 1h 49m 16s\tremaining: 57m 48s\n",
      "327:\ttotal: 1h 49m 36s\tremaining: 57m 28s\n",
      "328:\ttotal: 1h 49m 56s\tremaining: 57m 8s\n",
      "329:\ttotal: 1h 50m 15s\tremaining: 56m 48s\n",
      "330:\ttotal: 1h 50m 35s\tremaining: 56m 28s\n",
      "331:\ttotal: 1h 50m 55s\tremaining: 56m 8s\n",
      "332:\ttotal: 1h 51m 15s\tremaining: 55m 47s\n",
      "333:\ttotal: 1h 51m 35s\tremaining: 55m 27s\n",
      "334:\ttotal: 1h 51m 55s\tremaining: 55m 7s\n",
      "335:\ttotal: 1h 52m 15s\tremaining: 54m 47s\n",
      "336:\ttotal: 1h 52m 35s\tremaining: 54m 27s\n",
      "337:\ttotal: 1h 52m 55s\tremaining: 54m 7s\n",
      "338:\ttotal: 1h 53m 15s\tremaining: 53m 47s\n",
      "339:\ttotal: 1h 53m 35s\tremaining: 53m 27s\n",
      "340:\ttotal: 1h 53m 56s\tremaining: 53m 7s\n",
      "341:\ttotal: 1h 54m 15s\tremaining: 52m 47s\n",
      "342:\ttotal: 1h 54m 36s\tremaining: 52m 27s\n",
      "343:\ttotal: 1h 54m 56s\tremaining: 52m 7s\n",
      "344:\ttotal: 1h 55m 16s\tremaining: 51m 47s\n",
      "345:\ttotal: 1h 55m 36s\tremaining: 51m 27s\n",
      "346:\ttotal: 1h 55m 56s\tremaining: 51m 7s\n",
      "347:\ttotal: 1h 56m 16s\tremaining: 50m 47s\n",
      "348:\ttotal: 1h 56m 36s\tremaining: 50m 27s\n",
      "349:\ttotal: 1h 56m 57s\tremaining: 50m 7s\n",
      "350:\ttotal: 1h 57m 17s\tremaining: 49m 47s\n",
      "351:\ttotal: 1h 57m 36s\tremaining: 49m 27s\n",
      "352:\ttotal: 1h 57m 57s\tremaining: 49m 7s\n",
      "353:\ttotal: 1h 58m 17s\tremaining: 48m 47s\n",
      "354:\ttotal: 1h 58m 37s\tremaining: 48m 26s\n",
      "355:\ttotal: 1h 58m 57s\tremaining: 48m 6s\n",
      "356:\ttotal: 1h 59m 17s\tremaining: 47m 46s\n",
      "357:\ttotal: 1h 59m 37s\tremaining: 47m 26s\n",
      "358:\ttotal: 1h 59m 57s\tremaining: 47m 6s\n",
      "359:\ttotal: 2h 17s\tremaining: 46m 46s\n",
      "360:\ttotal: 2h 37s\tremaining: 46m 26s\n",
      "361:\ttotal: 2h 57s\tremaining: 46m 6s\n",
      "362:\ttotal: 2h 1m 17s\tremaining: 45m 46s\n",
      "363:\ttotal: 2h 1m 37s\tremaining: 45m 26s\n",
      "364:\ttotal: 2h 1m 57s\tremaining: 45m 6s\n",
      "365:\ttotal: 2h 2m 17s\tremaining: 44m 46s\n",
      "366:\ttotal: 2h 2m 37s\tremaining: 44m 26s\n",
      "367:\ttotal: 2h 2m 56s\tremaining: 44m 6s\n",
      "368:\ttotal: 2h 3m 16s\tremaining: 43m 45s\n",
      "369:\ttotal: 2h 3m 36s\tremaining: 43m 25s\n",
      "370:\ttotal: 2h 3m 56s\tremaining: 43m 5s\n",
      "371:\ttotal: 2h 4m 17s\tremaining: 42m 45s\n",
      "372:\ttotal: 2h 4m 37s\tremaining: 42m 25s\n",
      "373:\ttotal: 2h 4m 57s\tremaining: 42m 5s\n",
      "374:\ttotal: 2h 5m 17s\tremaining: 41m 45s\n",
      "375:\ttotal: 2h 5m 37s\tremaining: 41m 25s\n",
      "376:\ttotal: 2h 5m 57s\tremaining: 41m 5s\n",
      "377:\ttotal: 2h 6m 17s\tremaining: 40m 45s\n",
      "378:\ttotal: 2h 6m 37s\tremaining: 40m 25s\n",
      "379:\ttotal: 2h 6m 57s\tremaining: 40m 5s\n",
      "380:\ttotal: 2h 7m 17s\tremaining: 39m 45s\n",
      "381:\ttotal: 2h 7m 37s\tremaining: 39m 25s\n",
      "382:\ttotal: 2h 7m 57s\tremaining: 39m 5s\n",
      "383:\ttotal: 2h 8m 17s\tremaining: 38m 45s\n",
      "384:\ttotal: 2h 8m 37s\tremaining: 38m 25s\n",
      "385:\ttotal: 2h 8m 57s\tremaining: 38m 5s\n",
      "386:\ttotal: 2h 9m 17s\tremaining: 37m 45s\n",
      "387:\ttotal: 2h 9m 37s\tremaining: 37m 25s\n",
      "388:\ttotal: 2h 9m 57s\tremaining: 37m 5s\n",
      "389:\ttotal: 2h 10m 17s\tremaining: 36m 45s\n",
      "390:\ttotal: 2h 10m 37s\tremaining: 36m 24s\n",
      "391:\ttotal: 2h 10m 57s\tremaining: 36m 4s\n",
      "392:\ttotal: 2h 11m 18s\tremaining: 35m 44s\n",
      "393:\ttotal: 2h 11m 38s\tremaining: 35m 24s\n",
      "394:\ttotal: 2h 11m 57s\tremaining: 35m 4s\n",
      "395:\ttotal: 2h 12m 18s\tremaining: 34m 44s\n",
      "396:\ttotal: 2h 12m 38s\tremaining: 34m 24s\n",
      "397:\ttotal: 2h 12m 58s\tremaining: 34m 4s\n",
      "398:\ttotal: 2h 13m 18s\tremaining: 33m 44s\n",
      "399:\ttotal: 2h 13m 38s\tremaining: 33m 24s\n",
      "400:\ttotal: 2h 13m 58s\tremaining: 33m 4s\n",
      "401:\ttotal: 2h 14m 18s\tremaining: 32m 44s\n",
      "402:\ttotal: 2h 14m 38s\tremaining: 32m 24s\n",
      "403:\ttotal: 2h 14m 58s\tremaining: 32m 4s\n",
      "404:\ttotal: 2h 15m 18s\tremaining: 31m 44s\n",
      "405:\ttotal: 2h 15m 39s\tremaining: 31m 24s\n",
      "406:\ttotal: 2h 15m 59s\tremaining: 31m 4s\n",
      "407:\ttotal: 2h 16m 19s\tremaining: 30m 44s\n",
      "408:\ttotal: 2h 16m 40s\tremaining: 30m 24s\n",
      "409:\ttotal: 2h 17m\tremaining: 30m 4s\n",
      "410:\ttotal: 2h 17m 20s\tremaining: 29m 44s\n",
      "411:\ttotal: 2h 17m 40s\tremaining: 29m 24s\n",
      "412:\ttotal: 2h 18m\tremaining: 29m 4s\n",
      "413:\ttotal: 2h 18m 20s\tremaining: 28m 44s\n",
      "414:\ttotal: 2h 18m 40s\tremaining: 28m 24s\n",
      "415:\ttotal: 2h 19m\tremaining: 28m 4s\n",
      "416:\ttotal: 2h 19m 20s\tremaining: 27m 44s\n",
      "417:\ttotal: 2h 19m 40s\tremaining: 27m 24s\n",
      "418:\ttotal: 2h 20m\tremaining: 27m 4s\n",
      "419:\ttotal: 2h 20m 20s\tremaining: 26m 43s\n",
      "420:\ttotal: 2h 20m 41s\tremaining: 26m 23s\n",
      "421:\ttotal: 2h 21m 1s\tremaining: 26m 3s\n",
      "422:\ttotal: 2h 21m 21s\tremaining: 25m 43s\n",
      "423:\ttotal: 2h 21m 41s\tremaining: 25m 23s\n",
      "424:\ttotal: 2h 22m 1s\tremaining: 25m 3s\n",
      "425:\ttotal: 2h 22m 21s\tremaining: 24m 43s\n",
      "426:\ttotal: 2h 22m 41s\tremaining: 24m 23s\n",
      "427:\ttotal: 2h 23m 1s\tremaining: 24m 3s\n",
      "428:\ttotal: 2h 23m 21s\tremaining: 23m 43s\n",
      "429:\ttotal: 2h 23m 41s\tremaining: 23m 23s\n",
      "430:\ttotal: 2h 24m 1s\tremaining: 23m 3s\n",
      "431:\ttotal: 2h 24m 21s\tremaining: 22m 43s\n",
      "432:\ttotal: 2h 24m 41s\tremaining: 22m 23s\n",
      "433:\ttotal: 2h 25m 1s\tremaining: 22m 3s\n",
      "434:\ttotal: 2h 25m 21s\tremaining: 21m 43s\n",
      "435:\ttotal: 2h 25m 41s\tremaining: 21m 23s\n",
      "436:\ttotal: 2h 26m 1s\tremaining: 21m 3s\n",
      "437:\ttotal: 2h 26m 21s\tremaining: 20m 43s\n",
      "438:\ttotal: 2h 26m 41s\tremaining: 20m 23s\n",
      "439:\ttotal: 2h 27m 1s\tremaining: 20m 2s\n",
      "440:\ttotal: 2h 27m 21s\tremaining: 19m 42s\n",
      "441:\ttotal: 2h 27m 41s\tremaining: 19m 22s\n",
      "442:\ttotal: 2h 28m 1s\tremaining: 19m 2s\n",
      "443:\ttotal: 2h 28m 21s\tremaining: 18m 42s\n",
      "444:\ttotal: 2h 28m 41s\tremaining: 18m 22s\n",
      "445:\ttotal: 2h 29m 2s\tremaining: 18m 2s\n",
      "446:\ttotal: 2h 29m 21s\tremaining: 17m 42s\n",
      "447:\ttotal: 2h 29m 41s\tremaining: 17m 22s\n",
      "448:\ttotal: 2h 30m 1s\tremaining: 17m 2s\n",
      "449:\ttotal: 2h 30m 22s\tremaining: 16m 42s\n",
      "450:\ttotal: 2h 30m 42s\tremaining: 16m 22s\n",
      "451:\ttotal: 2h 31m 2s\tremaining: 16m 2s\n",
      "452:\ttotal: 2h 31m 22s\tremaining: 15m 42s\n",
      "453:\ttotal: 2h 31m 42s\tremaining: 15m 22s\n",
      "454:\ttotal: 2h 32m 2s\tremaining: 15m 2s\n",
      "455:\ttotal: 2h 32m 22s\tremaining: 14m 42s\n",
      "456:\ttotal: 2h 32m 42s\tremaining: 14m 22s\n",
      "457:\ttotal: 2h 33m 3s\tremaining: 14m 2s\n",
      "458:\ttotal: 2h 33m 23s\tremaining: 13m 42s\n",
      "459:\ttotal: 2h 33m 43s\tremaining: 13m 22s\n",
      "460:\ttotal: 2h 34m 3s\tremaining: 13m 1s\n",
      "461:\ttotal: 2h 34m 23s\tremaining: 12m 41s\n",
      "462:\ttotal: 2h 34m 43s\tremaining: 12m 21s\n",
      "463:\ttotal: 2h 35m 3s\tremaining: 12m 1s\n",
      "464:\ttotal: 2h 35m 23s\tremaining: 11m 41s\n",
      "465:\ttotal: 2h 35m 43s\tremaining: 11m 21s\n",
      "466:\ttotal: 2h 36m 3s\tremaining: 11m 1s\n",
      "467:\ttotal: 2h 36m 24s\tremaining: 10m 41s\n",
      "468:\ttotal: 2h 36m 44s\tremaining: 10m 21s\n",
      "469:\ttotal: 2h 37m 4s\tremaining: 10m 1s\n",
      "470:\ttotal: 2h 37m 24s\tremaining: 9m 41s\n",
      "471:\ttotal: 2h 37m 44s\tremaining: 9m 21s\n",
      "472:\ttotal: 2h 38m 4s\tremaining: 9m 1s\n",
      "473:\ttotal: 2h 38m 24s\tremaining: 8m 41s\n",
      "474:\ttotal: 2h 38m 44s\tremaining: 8m 21s\n",
      "475:\ttotal: 2h 39m 4s\tremaining: 8m 1s\n",
      "476:\ttotal: 2h 39m 24s\tremaining: 7m 41s\n",
      "477:\ttotal: 2h 39m 44s\tremaining: 7m 21s\n",
      "478:\ttotal: 2h 40m 4s\tremaining: 7m 1s\n",
      "479:\ttotal: 2h 40m 24s\tremaining: 6m 41s\n",
      "480:\ttotal: 2h 40m 44s\tremaining: 6m 20s\n",
      "481:\ttotal: 2h 41m 4s\tremaining: 6m\n",
      "482:\ttotal: 2h 41m 24s\tremaining: 5m 40s\n",
      "483:\ttotal: 2h 41m 44s\tremaining: 5m 20s\n",
      "484:\ttotal: 2h 42m 4s\tremaining: 5m\n",
      "485:\ttotal: 2h 42m 24s\tremaining: 4m 40s\n",
      "486:\ttotal: 2h 42m 44s\tremaining: 4m 20s\n",
      "487:\ttotal: 2h 43m 4s\tremaining: 4m\n",
      "488:\ttotal: 2h 43m 24s\tremaining: 3m 40s\n",
      "489:\ttotal: 2h 43m 44s\tremaining: 3m 20s\n",
      "490:\ttotal: 2h 44m 4s\tremaining: 3m\n",
      "491:\ttotal: 2h 44m 24s\tremaining: 2m 40s\n",
      "492:\ttotal: 2h 44m 44s\tremaining: 2m 20s\n",
      "493:\ttotal: 2h 45m 4s\tremaining: 2m\n",
      "494:\ttotal: 2h 45m 24s\tremaining: 1m 40s\n",
      "495:\ttotal: 2h 45m 45s\tremaining: 1m 20s\n",
      "496:\ttotal: 2h 46m 5s\tremaining: 1m\n",
      "497:\ttotal: 2h 46m 25s\tremaining: 40.1s\n",
      "498:\ttotal: 2h 46m 45s\tremaining: 20.1s\n",
      "499:\ttotal: 2h 47m 5s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0.5, border_count=128, depth=13, eval_metric=AUC, iterations=500, l2_leaf_reg=3, leaf_estimation_method=Gradient, learning_rate=0.5, random_strength=0.1; total time=167.1min\n",
      "0:\ttotal: 20.2s\tremaining: 2h 48m 6s\n",
      "1:\ttotal: 40.5s\tremaining: 2h 48m 7s\n",
      "2:\ttotal: 1m\tremaining: 2h 47m 59s\n",
      "3:\ttotal: 1m 21s\tremaining: 2h 47m 40s\n",
      "4:\ttotal: 1m 41s\tremaining: 2h 47m 13s\n",
      "5:\ttotal: 2m 1s\tremaining: 2h 46m 47s\n",
      "6:\ttotal: 2m 21s\tremaining: 2h 46m 16s\n",
      "7:\ttotal: 2m 42s\tremaining: 2h 46m 21s\n",
      "8:\ttotal: 3m 2s\tremaining: 2h 45m 58s\n",
      "9:\ttotal: 3m 22s\tremaining: 2h 45m 29s\n",
      "10:\ttotal: 3m 42s\tremaining: 2h 45m 9s\n",
      "11:\ttotal: 4m 3s\tremaining: 2h 44m 46s\n",
      "12:\ttotal: 4m 23s\tremaining: 2h 44m 20s\n",
      "13:\ttotal: 4m 43s\tremaining: 2h 43m 59s\n",
      "14:\ttotal: 5m 3s\tremaining: 2h 43m 31s\n",
      "15:\ttotal: 5m 23s\tremaining: 2h 43m 7s\n",
      "16:\ttotal: 5m 43s\tremaining: 2h 42m 42s\n",
      "17:\ttotal: 6m 3s\tremaining: 2h 42m 18s\n",
      "18:\ttotal: 6m 23s\tremaining: 2h 41m 57s\n",
      "19:\ttotal: 6m 43s\tremaining: 2h 41m 34s\n",
      "20:\ttotal: 7m 3s\tremaining: 2h 41m 11s\n",
      "21:\ttotal: 7m 24s\tremaining: 2h 40m 52s\n",
      "22:\ttotal: 7m 44s\tremaining: 2h 40m 29s\n",
      "23:\ttotal: 8m 4s\tremaining: 2h 40m 8s\n",
      "24:\ttotal: 8m 24s\tremaining: 2h 39m 46s\n",
      "25:\ttotal: 8m 44s\tremaining: 2h 39m 26s\n",
      "26:\ttotal: 9m 5s\tremaining: 2h 39m 8s\n",
      "27:\ttotal: 9m 25s\tremaining: 2h 38m 47s\n",
      "28:\ttotal: 9m 45s\tremaining: 2h 38m 27s\n",
      "29:\ttotal: 10m 5s\tremaining: 2h 38m 5s\n",
      "30:\ttotal: 10m 25s\tremaining: 2h 37m 43s\n",
      "31:\ttotal: 10m 45s\tremaining: 2h 37m 23s\n",
      "32:\ttotal: 11m 5s\tremaining: 2h 37m\n",
      "33:\ttotal: 11m 25s\tremaining: 2h 36m 40s\n",
      "34:\ttotal: 11m 46s\tremaining: 2h 36m 20s\n",
      "35:\ttotal: 12m 6s\tremaining: 2h 35m 59s\n",
      "36:\ttotal: 12m 26s\tremaining: 2h 35m 40s\n",
      "37:\ttotal: 12m 46s\tremaining: 2h 35m 20s\n",
      "38:\ttotal: 13m 6s\tremaining: 2h 35m 1s\n",
      "39:\ttotal: 13m 27s\tremaining: 2h 34m 44s\n",
      "40:\ttotal: 13m 47s\tremaining: 2h 34m 25s\n",
      "41:\ttotal: 14m 7s\tremaining: 2h 34m 6s\n",
      "42:\ttotal: 14m 28s\tremaining: 2h 33m 47s\n",
      "43:\ttotal: 14m 48s\tremaining: 2h 33m 28s\n",
      "44:\ttotal: 15m 9s\tremaining: 2h 33m 11s\n",
      "45:\ttotal: 15m 29s\tremaining: 2h 32m 50s\n",
      "46:\ttotal: 15m 49s\tremaining: 2h 32m 29s\n",
      "47:\ttotal: 16m 9s\tremaining: 2h 32m 8s\n",
      "48:\ttotal: 16m 29s\tremaining: 2h 31m 47s\n",
      "49:\ttotal: 16m 49s\tremaining: 2h 31m 27s\n",
      "50:\ttotal: 17m 9s\tremaining: 2h 31m 5s\n",
      "51:\ttotal: 17m 29s\tremaining: 2h 30m 44s\n",
      "52:\ttotal: 17m 50s\tremaining: 2h 30m 24s\n",
      "53:\ttotal: 18m 10s\tremaining: 2h 30m 4s\n",
      "54:\ttotal: 18m 30s\tremaining: 2h 29m 44s\n",
      "55:\ttotal: 18m 50s\tremaining: 2h 29m 24s\n",
      "56:\ttotal: 19m 10s\tremaining: 2h 29m 4s\n",
      "57:\ttotal: 19m 31s\tremaining: 2h 28m 44s\n",
      "58:\ttotal: 19m 51s\tremaining: 2h 28m 25s\n",
      "59:\ttotal: 20m 11s\tremaining: 2h 28m 5s\n",
      "60:\ttotal: 20m 31s\tremaining: 2h 27m 46s\n",
      "61:\ttotal: 20m 52s\tremaining: 2h 27m 26s\n",
      "62:\ttotal: 21m 12s\tremaining: 2h 27m 6s\n",
      "63:\ttotal: 21m 32s\tremaining: 2h 26m 45s\n",
      "64:\ttotal: 21m 52s\tremaining: 2h 26m 25s\n",
      "65:\ttotal: 22m 12s\tremaining: 2h 26m 3s\n",
      "66:\ttotal: 22m 32s\tremaining: 2h 25m 42s\n",
      "67:\ttotal: 22m 53s\tremaining: 2h 25m 22s\n",
      "68:\ttotal: 23m 13s\tremaining: 2h 25m 3s\n",
      "69:\ttotal: 23m 33s\tremaining: 2h 24m 43s\n",
      "70:\ttotal: 23m 53s\tremaining: 2h 24m 24s\n",
      "71:\ttotal: 24m 14s\tremaining: 2h 24m 4s\n",
      "72:\ttotal: 24m 34s\tremaining: 2h 23m 44s\n",
      "73:\ttotal: 24m 54s\tremaining: 2h 23m 23s\n",
      "74:\ttotal: 25m 14s\tremaining: 2h 23m 2s\n",
      "75:\ttotal: 25m 34s\tremaining: 2h 22m 41s\n",
      "76:\ttotal: 25m 54s\tremaining: 2h 22m 20s\n",
      "77:\ttotal: 26m 14s\tremaining: 2h 22m\n",
      "78:\ttotal: 26m 35s\tremaining: 2h 21m 40s\n",
      "79:\ttotal: 26m 55s\tremaining: 2h 21m 19s\n",
      "80:\ttotal: 27m 15s\tremaining: 2h 20m 59s\n",
      "81:\ttotal: 27m 35s\tremaining: 2h 20m 39s\n",
      "82:\ttotal: 27m 55s\tremaining: 2h 20m 18s\n",
      "83:\ttotal: 28m 15s\tremaining: 2h 19m 58s\n",
      "84:\ttotal: 28m 36s\tremaining: 2h 19m 38s\n",
      "85:\ttotal: 28m 56s\tremaining: 2h 19m 18s\n",
      "86:\ttotal: 29m 16s\tremaining: 2h 18m 58s\n",
      "87:\ttotal: 29m 36s\tremaining: 2h 18m 38s\n",
      "88:\ttotal: 29m 56s\tremaining: 2h 18m 17s\n",
      "89:\ttotal: 30m 17s\tremaining: 2h 17m 58s\n",
      "90:\ttotal: 30m 36s\tremaining: 2h 17m 35s\n",
      "91:\ttotal: 30m 56s\tremaining: 2h 17m 14s\n",
      "92:\ttotal: 31m 17s\tremaining: 2h 16m 54s\n",
      "93:\ttotal: 31m 37s\tremaining: 2h 16m 34s\n",
      "94:\ttotal: 31m 57s\tremaining: 2h 16m 14s\n",
      "95:\ttotal: 32m 17s\tremaining: 2h 15m 54s\n",
      "96:\ttotal: 32m 38s\tremaining: 2h 15m 34s\n",
      "97:\ttotal: 32m 58s\tremaining: 2h 15m 14s\n",
      "98:\ttotal: 33m 18s\tremaining: 2h 14m 54s\n",
      "99:\ttotal: 33m 38s\tremaining: 2h 14m 34s\n",
      "100:\ttotal: 33m 58s\tremaining: 2h 14m 14s\n",
      "101:\ttotal: 34m 19s\tremaining: 2h 13m 55s\n",
      "102:\ttotal: 34m 39s\tremaining: 2h 13m 35s\n",
      "103:\ttotal: 34m 59s\tremaining: 2h 13m 15s\n",
      "104:\ttotal: 35m 20s\tremaining: 2h 12m 55s\n",
      "105:\ttotal: 35m 40s\tremaining: 2h 12m 35s\n",
      "106:\ttotal: 36m\tremaining: 2h 12m 14s\n",
      "107:\ttotal: 36m 20s\tremaining: 2h 11m 54s\n",
      "108:\ttotal: 36m 40s\tremaining: 2h 11m 34s\n",
      "109:\ttotal: 37m 1s\tremaining: 2h 11m 14s\n",
      "110:\ttotal: 37m 21s\tremaining: 2h 10m 54s\n",
      "111:\ttotal: 37m 41s\tremaining: 2h 10m 34s\n",
      "112:\ttotal: 38m 1s\tremaining: 2h 10m 14s\n",
      "113:\ttotal: 38m 21s\tremaining: 2h 9m 54s\n",
      "114:\ttotal: 38m 42s\tremaining: 2h 9m 34s\n",
      "115:\ttotal: 39m 2s\tremaining: 2h 9m 13s\n",
      "116:\ttotal: 39m 22s\tremaining: 2h 8m 53s\n",
      "117:\ttotal: 39m 42s\tremaining: 2h 8m 33s\n",
      "118:\ttotal: 40m 2s\tremaining: 2h 8m 13s\n",
      "119:\ttotal: 40m 23s\tremaining: 2h 7m 52s\n",
      "120:\ttotal: 40m 43s\tremaining: 2h 7m 32s\n",
      "121:\ttotal: 41m 3s\tremaining: 2h 7m 12s\n",
      "122:\ttotal: 41m 23s\tremaining: 2h 6m 52s\n",
      "123:\ttotal: 41m 43s\tremaining: 2h 6m 32s\n",
      "124:\ttotal: 42m 4s\tremaining: 2h 6m 12s\n",
      "125:\ttotal: 42m 24s\tremaining: 2h 5m 51s\n",
      "126:\ttotal: 42m 44s\tremaining: 2h 5m 31s\n",
      "127:\ttotal: 43m 4s\tremaining: 2h 5m 11s\n",
      "128:\ttotal: 43m 24s\tremaining: 2h 4m 51s\n",
      "129:\ttotal: 43m 45s\tremaining: 2h 4m 31s\n",
      "130:\ttotal: 44m 5s\tremaining: 2h 4m 10s\n",
      "131:\ttotal: 44m 25s\tremaining: 2h 3m 50s\n",
      "132:\ttotal: 44m 45s\tremaining: 2h 3m 29s\n",
      "133:\ttotal: 45m 5s\tremaining: 2h 3m 9s\n",
      "134:\ttotal: 45m 25s\tremaining: 2h 2m 49s\n",
      "135:\ttotal: 45m 45s\tremaining: 2h 2m 28s\n",
      "136:\ttotal: 46m 5s\tremaining: 2h 2m 8s\n",
      "137:\ttotal: 46m 25s\tremaining: 2h 1m 48s\n",
      "138:\ttotal: 46m 45s\tremaining: 2h 1m 27s\n",
      "139:\ttotal: 47m 6s\tremaining: 2h 1m 7s\n",
      "140:\ttotal: 47m 26s\tremaining: 2h 47s\n",
      "141:\ttotal: 47m 46s\tremaining: 2h 26s\n",
      "142:\ttotal: 48m 6s\tremaining: 2h 6s\n",
      "143:\ttotal: 48m 26s\tremaining: 1h 59m 46s\n",
      "144:\ttotal: 48m 47s\tremaining: 1h 59m 26s\n",
      "145:\ttotal: 49m 7s\tremaining: 1h 59m 6s\n",
      "146:\ttotal: 49m 27s\tremaining: 1h 58m 45s\n",
      "147:\ttotal: 49m 47s\tremaining: 1h 58m 26s\n",
      "148:\ttotal: 50m 7s\tremaining: 1h 58m 5s\n",
      "149:\ttotal: 50m 27s\tremaining: 1h 57m 45s\n",
      "150:\ttotal: 50m 48s\tremaining: 1h 57m 24s\n",
      "151:\ttotal: 51m 8s\tremaining: 1h 57m 4s\n",
      "152:\ttotal: 51m 28s\tremaining: 1h 56m 44s\n",
      "153:\ttotal: 51m 48s\tremaining: 1h 56m 23s\n",
      "154:\ttotal: 52m 8s\tremaining: 1h 56m 3s\n",
      "155:\ttotal: 52m 28s\tremaining: 1h 55m 42s\n",
      "156:\ttotal: 52m 48s\tremaining: 1h 55m 22s\n",
      "157:\ttotal: 53m 8s\tremaining: 1h 55m 2s\n",
      "158:\ttotal: 53m 28s\tremaining: 1h 54m 42s\n",
      "159:\ttotal: 53m 48s\tremaining: 1h 54m 21s\n",
      "160:\ttotal: 54m 9s\tremaining: 1h 54m 1s\n",
      "161:\ttotal: 54m 29s\tremaining: 1h 53m 41s\n",
      "162:\ttotal: 54m 49s\tremaining: 1h 53m 21s\n",
      "163:\ttotal: 55m 10s\tremaining: 1h 53m 1s\n",
      "164:\ttotal: 55m 30s\tremaining: 1h 52m 41s\n",
      "165:\ttotal: 55m 50s\tremaining: 1h 52m 20s\n",
      "166:\ttotal: 56m 10s\tremaining: 1h 52m\n",
      "167:\ttotal: 56m 30s\tremaining: 1h 51m 40s\n",
      "168:\ttotal: 56m 50s\tremaining: 1h 51m 19s\n",
      "169:\ttotal: 57m 10s\tremaining: 1h 50m 59s\n",
      "170:\ttotal: 57m 30s\tremaining: 1h 50m 38s\n",
      "171:\ttotal: 57m 50s\tremaining: 1h 50m 18s\n",
      "172:\ttotal: 58m 10s\tremaining: 1h 49m 58s\n",
      "173:\ttotal: 58m 31s\tremaining: 1h 49m 38s\n",
      "174:\ttotal: 58m 51s\tremaining: 1h 49m 17s\n",
      "175:\ttotal: 59m 11s\tremaining: 1h 48m 57s\n",
      "176:\ttotal: 59m 31s\tremaining: 1h 48m 37s\n",
      "177:\ttotal: 59m 51s\tremaining: 1h 48m 17s\n",
      "178:\ttotal: 1h 11s\tremaining: 1h 47m 56s\n",
      "179:\ttotal: 1h 32s\tremaining: 1h 47m 37s\n",
      "180:\ttotal: 1h 52s\tremaining: 1h 47m 17s\n",
      "181:\ttotal: 1h 1m 12s\tremaining: 1h 46m 56s\n",
      "182:\ttotal: 1h 1m 32s\tremaining: 1h 46m 36s\n",
      "183:\ttotal: 1h 1m 52s\tremaining: 1h 46m 16s\n",
      "184:\ttotal: 1h 2m 12s\tremaining: 1h 45m 55s\n",
      "185:\ttotal: 1h 2m 32s\tremaining: 1h 45m 35s\n",
      "186:\ttotal: 1h 2m 52s\tremaining: 1h 45m 14s\n",
      "187:\ttotal: 1h 3m 12s\tremaining: 1h 44m 54s\n",
      "188:\ttotal: 1h 3m 32s\tremaining: 1h 44m 33s\n",
      "189:\ttotal: 1h 3m 52s\tremaining: 1h 44m 13s\n",
      "190:\ttotal: 1h 4m 12s\tremaining: 1h 43m 53s\n",
      "191:\ttotal: 1h 4m 32s\tremaining: 1h 43m 32s\n",
      "192:\ttotal: 1h 4m 52s\tremaining: 1h 43m 12s\n",
      "193:\ttotal: 1h 5m 12s\tremaining: 1h 42m 51s\n",
      "194:\ttotal: 1h 5m 32s\tremaining: 1h 42m 30s\n",
      "195:\ttotal: 1h 5m 52s\tremaining: 1h 42m 10s\n",
      "196:\ttotal: 1h 6m 12s\tremaining: 1h 41m 49s\n",
      "197:\ttotal: 1h 6m 32s\tremaining: 1h 41m 29s\n",
      "198:\ttotal: 1h 6m 52s\tremaining: 1h 41m 8s\n",
      "199:\ttotal: 1h 7m 12s\tremaining: 1h 40m 48s\n",
      "200:\ttotal: 1h 7m 32s\tremaining: 1h 40m 28s\n",
      "201:\ttotal: 1h 7m 52s\tremaining: 1h 40m 7s\n",
      "202:\ttotal: 1h 8m 12s\tremaining: 1h 39m 47s\n",
      "203:\ttotal: 1h 8m 32s\tremaining: 1h 39m 26s\n",
      "204:\ttotal: 1h 8m 52s\tremaining: 1h 39m 6s\n",
      "205:\ttotal: 1h 9m 12s\tremaining: 1h 38m 46s\n",
      "206:\ttotal: 1h 9m 32s\tremaining: 1h 38m 25s\n",
      "207:\ttotal: 1h 9m 52s\tremaining: 1h 38m 5s\n",
      "208:\ttotal: 1h 10m 12s\tremaining: 1h 37m 45s\n",
      "209:\ttotal: 1h 10m 32s\tremaining: 1h 37m 24s\n",
      "210:\ttotal: 1h 10m 52s\tremaining: 1h 37m 5s\n",
      "211:\ttotal: 1h 11m 12s\tremaining: 1h 36m 44s\n",
      "212:\ttotal: 1h 11m 33s\tremaining: 1h 36m 24s\n",
      "213:\ttotal: 1h 11m 53s\tremaining: 1h 36m 4s\n",
      "214:\ttotal: 1h 12m 13s\tremaining: 1h 35m 43s\n",
      "215:\ttotal: 1h 12m 33s\tremaining: 1h 35m 23s\n",
      "216:\ttotal: 1h 12m 53s\tremaining: 1h 35m 3s\n",
      "217:\ttotal: 1h 13m 13s\tremaining: 1h 34m 43s\n",
      "218:\ttotal: 1h 13m 33s\tremaining: 1h 34m 22s\n",
      "219:\ttotal: 1h 13m 53s\tremaining: 1h 34m 2s\n",
      "220:\ttotal: 1h 14m 14s\tremaining: 1h 33m 42s\n",
      "221:\ttotal: 1h 14m 34s\tremaining: 1h 33m 22s\n",
      "222:\ttotal: 1h 14m 54s\tremaining: 1h 33m 2s\n",
      "223:\ttotal: 1h 15m 14s\tremaining: 1h 32m 41s\n",
      "224:\ttotal: 1h 15m 33s\tremaining: 1h 32m 21s\n",
      "225:\ttotal: 1h 15m 54s\tremaining: 1h 32m 1s\n",
      "226:\ttotal: 1h 16m 14s\tremaining: 1h 31m 41s\n",
      "227:\ttotal: 1h 16m 34s\tremaining: 1h 31m 20s\n",
      "228:\ttotal: 1h 16m 54s\tremaining: 1h 31m\n",
      "229:\ttotal: 1h 17m 14s\tremaining: 1h 30m 40s\n",
      "230:\ttotal: 1h 17m 33s\tremaining: 1h 30m 19s\n",
      "231:\ttotal: 1h 17m 53s\tremaining: 1h 29m 59s\n",
      "232:\ttotal: 1h 18m 14s\tremaining: 1h 29m 39s\n",
      "233:\ttotal: 1h 18m 34s\tremaining: 1h 29m 18s\n",
      "234:\ttotal: 1h 18m 53s\tremaining: 1h 28m 58s\n",
      "235:\ttotal: 1h 19m 13s\tremaining: 1h 28m 37s\n",
      "236:\ttotal: 1h 19m 33s\tremaining: 1h 28m 17s\n",
      "237:\ttotal: 1h 19m 53s\tremaining: 1h 27m 56s\n",
      "238:\ttotal: 1h 20m 13s\tremaining: 1h 27m 36s\n",
      "239:\ttotal: 1h 20m 33s\tremaining: 1h 27m 16s\n",
      "240:\ttotal: 1h 20m 53s\tremaining: 1h 26m 55s\n",
      "241:\ttotal: 1h 21m 13s\tremaining: 1h 26m 35s\n",
      "242:\ttotal: 1h 21m 33s\tremaining: 1h 26m 15s\n",
      "243:\ttotal: 1h 21m 52s\tremaining: 1h 25m 54s\n",
      "244:\ttotal: 1h 22m 12s\tremaining: 1h 25m 34s\n",
      "245:\ttotal: 1h 22m 32s\tremaining: 1h 25m 13s\n",
      "246:\ttotal: 1h 22m 52s\tremaining: 1h 24m 53s\n",
      "247:\ttotal: 1h 23m 12s\tremaining: 1h 24m 33s\n",
      "248:\ttotal: 1h 23m 32s\tremaining: 1h 24m 13s\n",
      "249:\ttotal: 1h 23m 53s\tremaining: 1h 23m 53s\n",
      "250:\ttotal: 1h 24m 13s\tremaining: 1h 23m 32s\n",
      "251:\ttotal: 1h 24m 33s\tremaining: 1h 23m 12s\n",
      "252:\ttotal: 1h 24m 53s\tremaining: 1h 22m 52s\n",
      "253:\ttotal: 1h 25m 13s\tremaining: 1h 22m 31s\n",
      "254:\ttotal: 1h 25m 32s\tremaining: 1h 22m 11s\n",
      "255:\ttotal: 1h 25m 52s\tremaining: 1h 21m 51s\n",
      "256:\ttotal: 1h 26m 12s\tremaining: 1h 21m 30s\n",
      "257:\ttotal: 1h 26m 32s\tremaining: 1h 21m 10s\n",
      "258:\ttotal: 1h 26m 52s\tremaining: 1h 20m 50s\n",
      "259:\ttotal: 1h 27m 12s\tremaining: 1h 20m 29s\n",
      "260:\ttotal: 1h 27m 32s\tremaining: 1h 20m 9s\n",
      "261:\ttotal: 1h 27m 52s\tremaining: 1h 19m 49s\n",
      "262:\ttotal: 1h 28m 12s\tremaining: 1h 19m 29s\n",
      "263:\ttotal: 1h 28m 32s\tremaining: 1h 19m 8s\n",
      "264:\ttotal: 1h 28m 52s\tremaining: 1h 18m 48s\n",
      "265:\ttotal: 1h 29m 12s\tremaining: 1h 18m 28s\n",
      "266:\ttotal: 1h 29m 32s\tremaining: 1h 18m 8s\n",
      "267:\ttotal: 1h 29m 52s\tremaining: 1h 17m 48s\n",
      "268:\ttotal: 1h 30m 12s\tremaining: 1h 17m 27s\n",
      "269:\ttotal: 1h 30m 32s\tremaining: 1h 17m 7s\n",
      "270:\ttotal: 1h 30m 52s\tremaining: 1h 16m 47s\n",
      "271:\ttotal: 1h 31m 12s\tremaining: 1h 16m 27s\n",
      "272:\ttotal: 1h 31m 32s\tremaining: 1h 16m 7s\n",
      "273:\ttotal: 1h 31m 52s\tremaining: 1h 15m 47s\n",
      "274:\ttotal: 1h 32m 12s\tremaining: 1h 15m 26s\n",
      "275:\ttotal: 1h 32m 32s\tremaining: 1h 15m 6s\n",
      "276:\ttotal: 1h 32m 52s\tremaining: 1h 14m 46s\n",
      "277:\ttotal: 1h 33m 12s\tremaining: 1h 14m 26s\n",
      "278:\ttotal: 1h 33m 32s\tremaining: 1h 14m 5s\n",
      "279:\ttotal: 1h 33m 52s\tremaining: 1h 13m 45s\n",
      "280:\ttotal: 1h 34m 12s\tremaining: 1h 13m 25s\n",
      "281:\ttotal: 1h 34m 33s\tremaining: 1h 13m 5s\n",
      "282:\ttotal: 1h 34m 53s\tremaining: 1h 12m 45s\n",
      "283:\ttotal: 1h 35m 13s\tremaining: 1h 12m 25s\n",
      "284:\ttotal: 1h 35m 33s\tremaining: 1h 12m 4s\n",
      "285:\ttotal: 1h 35m 53s\tremaining: 1h 11m 44s\n",
      "286:\ttotal: 1h 36m 13s\tremaining: 1h 11m 24s\n",
      "287:\ttotal: 1h 36m 33s\tremaining: 1h 11m 4s\n",
      "288:\ttotal: 1h 36m 53s\tremaining: 1h 10m 44s\n",
      "289:\ttotal: 1h 37m 13s\tremaining: 1h 10m 24s\n",
      "290:\ttotal: 1h 37m 32s\tremaining: 1h 10m 3s\n",
      "291:\ttotal: 1h 37m 52s\tremaining: 1h 9m 43s\n",
      "292:\ttotal: 1h 38m 12s\tremaining: 1h 9m 23s\n",
      "293:\ttotal: 1h 38m 32s\tremaining: 1h 9m 3s\n",
      "294:\ttotal: 1h 38m 52s\tremaining: 1h 8m 42s\n",
      "295:\ttotal: 1h 39m 12s\tremaining: 1h 8m 22s\n",
      "296:\ttotal: 1h 39m 32s\tremaining: 1h 8m 2s\n",
      "297:\ttotal: 1h 39m 52s\tremaining: 1h 7m 42s\n",
      "298:\ttotal: 1h 40m 12s\tremaining: 1h 7m 21s\n",
      "299:\ttotal: 1h 40m 32s\tremaining: 1h 7m 1s\n",
      "300:\ttotal: 1h 40m 52s\tremaining: 1h 6m 41s\n",
      "301:\ttotal: 1h 41m 12s\tremaining: 1h 6m 21s\n",
      "302:\ttotal: 1h 41m 32s\tremaining: 1h 6m 1s\n",
      "303:\ttotal: 1h 41m 52s\tremaining: 1h 5m 41s\n",
      "304:\ttotal: 1h 42m 12s\tremaining: 1h 5m 20s\n",
      "305:\ttotal: 1h 42m 33s\tremaining: 1h 5m 1s\n",
      "306:\ttotal: 1h 42m 53s\tremaining: 1h 4m 40s\n",
      "307:\ttotal: 1h 43m 12s\tremaining: 1h 4m 20s\n",
      "308:\ttotal: 1h 43m 32s\tremaining: 1h 4m\n",
      "309:\ttotal: 1h 43m 53s\tremaining: 1h 3m 40s\n",
      "310:\ttotal: 1h 44m 13s\tremaining: 1h 3m 20s\n",
      "311:\ttotal: 1h 44m 33s\tremaining: 1h 2m 59s\n",
      "312:\ttotal: 1h 44m 53s\tremaining: 1h 2m 39s\n",
      "313:\ttotal: 1h 45m 13s\tremaining: 1h 2m 19s\n",
      "314:\ttotal: 1h 45m 32s\tremaining: 1h 1m 59s\n",
      "315:\ttotal: 1h 45m 53s\tremaining: 1h 1m 39s\n",
      "316:\ttotal: 1h 46m 13s\tremaining: 1h 1m 19s\n",
      "317:\ttotal: 1h 46m 33s\tremaining: 1h 58s\n",
      "318:\ttotal: 1h 46m 53s\tremaining: 1h 38s\n",
      "319:\ttotal: 1h 47m 13s\tremaining: 1h 18s\n",
      "320:\ttotal: 1h 47m 33s\tremaining: 59m 58s\n",
      "321:\ttotal: 1h 47m 53s\tremaining: 59m 38s\n",
      "322:\ttotal: 1h 48m 13s\tremaining: 59m 18s\n",
      "323:\ttotal: 1h 48m 33s\tremaining: 58m 58s\n",
      "324:\ttotal: 1h 48m 53s\tremaining: 58m 37s\n",
      "325:\ttotal: 1h 49m 13s\tremaining: 58m 17s\n",
      "326:\ttotal: 1h 49m 33s\tremaining: 57m 57s\n",
      "327:\ttotal: 1h 49m 53s\tremaining: 57m 37s\n",
      "328:\ttotal: 1h 50m 13s\tremaining: 57m 17s\n",
      "329:\ttotal: 1h 50m 33s\tremaining: 56m 57s\n",
      "330:\ttotal: 1h 50m 53s\tremaining: 56m 37s\n",
      "331:\ttotal: 1h 51m 13s\tremaining: 56m 17s\n",
      "332:\ttotal: 1h 51m 34s\tremaining: 55m 57s\n",
      "333:\ttotal: 1h 51m 53s\tremaining: 55m 36s\n",
      "334:\ttotal: 1h 52m 13s\tremaining: 55m 16s\n",
      "335:\ttotal: 1h 52m 33s\tremaining: 54m 56s\n",
      "336:\ttotal: 1h 52m 54s\tremaining: 54m 36s\n",
      "337:\ttotal: 1h 53m 14s\tremaining: 54m 16s\n",
      "338:\ttotal: 1h 53m 34s\tremaining: 53m 56s\n",
      "339:\ttotal: 1h 53m 54s\tremaining: 53m 36s\n",
      "340:\ttotal: 1h 54m 14s\tremaining: 53m 16s\n",
      "341:\ttotal: 1h 54m 34s\tremaining: 52m 56s\n",
      "342:\ttotal: 1h 54m 54s\tremaining: 52m 35s\n",
      "343:\ttotal: 1h 55m 14s\tremaining: 52m 15s\n",
      "344:\ttotal: 1h 55m 34s\tremaining: 51m 55s\n",
      "345:\ttotal: 1h 55m 54s\tremaining: 51m 35s\n",
      "346:\ttotal: 1h 56m 14s\tremaining: 51m 15s\n",
      "347:\ttotal: 1h 56m 34s\tremaining: 50m 54s\n",
      "348:\ttotal: 1h 56m 54s\tremaining: 50m 34s\n",
      "349:\ttotal: 1h 57m 14s\tremaining: 50m 14s\n",
      "350:\ttotal: 1h 57m 34s\tremaining: 49m 54s\n",
      "351:\ttotal: 1h 57m 54s\tremaining: 49m 34s\n",
      "352:\ttotal: 1h 58m 14s\tremaining: 49m 14s\n",
      "353:\ttotal: 1h 58m 34s\tremaining: 48m 54s\n",
      "354:\ttotal: 1h 58m 54s\tremaining: 48m 34s\n",
      "355:\ttotal: 1h 59m 14s\tremaining: 48m 13s\n",
      "356:\ttotal: 1h 59m 34s\tremaining: 47m 53s\n",
      "357:\ttotal: 1h 59m 54s\tremaining: 47m 33s\n",
      "358:\ttotal: 2h 15s\tremaining: 47m 13s\n",
      "359:\ttotal: 2h 34s\tremaining: 46m 53s\n",
      "360:\ttotal: 2h 54s\tremaining: 46m 33s\n",
      "361:\ttotal: 2h 1m 15s\tremaining: 46m 13s\n",
      "362:\ttotal: 2h 1m 35s\tremaining: 45m 53s\n",
      "363:\ttotal: 2h 1m 55s\tremaining: 45m 33s\n",
      "364:\ttotal: 2h 2m 15s\tremaining: 45m 13s\n",
      "365:\ttotal: 2h 2m 35s\tremaining: 44m 52s\n",
      "366:\ttotal: 2h 2m 55s\tremaining: 44m 32s\n",
      "367:\ttotal: 2h 3m 15s\tremaining: 44m 12s\n",
      "368:\ttotal: 2h 3m 35s\tremaining: 43m 52s\n",
      "369:\ttotal: 2h 3m 55s\tremaining: 43m 32s\n",
      "370:\ttotal: 2h 4m 15s\tremaining: 43m 12s\n",
      "371:\ttotal: 2h 4m 35s\tremaining: 42m 52s\n",
      "372:\ttotal: 2h 4m 55s\tremaining: 42m 32s\n",
      "373:\ttotal: 2h 5m 15s\tremaining: 42m 11s\n",
      "374:\ttotal: 2h 5m 35s\tremaining: 41m 51s\n",
      "375:\ttotal: 2h 5m 55s\tremaining: 41m 31s\n",
      "376:\ttotal: 2h 6m 15s\tremaining: 41m 11s\n",
      "377:\ttotal: 2h 6m 35s\tremaining: 40m 51s\n",
      "378:\ttotal: 2h 6m 55s\tremaining: 40m 31s\n",
      "379:\ttotal: 2h 7m 15s\tremaining: 40m 11s\n",
      "380:\ttotal: 2h 7m 34s\tremaining: 39m 50s\n",
      "381:\ttotal: 2h 7m 55s\tremaining: 39m 30s\n",
      "382:\ttotal: 2h 8m 15s\tremaining: 39m 10s\n",
      "383:\ttotal: 2h 8m 34s\tremaining: 38m 50s\n",
      "384:\ttotal: 2h 8m 55s\tremaining: 38m 30s\n",
      "385:\ttotal: 2h 9m 15s\tremaining: 38m 10s\n",
      "386:\ttotal: 2h 9m 35s\tremaining: 37m 50s\n",
      "387:\ttotal: 2h 9m 55s\tremaining: 37m 30s\n",
      "388:\ttotal: 2h 10m 15s\tremaining: 37m 10s\n",
      "389:\ttotal: 2h 10m 35s\tremaining: 36m 50s\n",
      "390:\ttotal: 2h 10m 55s\tremaining: 36m 29s\n",
      "391:\ttotal: 2h 11m 15s\tremaining: 36m 9s\n",
      "392:\ttotal: 2h 11m 35s\tremaining: 35m 49s\n",
      "393:\ttotal: 2h 11m 55s\tremaining: 35m 29s\n",
      "394:\ttotal: 2h 12m 16s\tremaining: 35m 9s\n",
      "395:\ttotal: 2h 12m 36s\tremaining: 34m 49s\n",
      "396:\ttotal: 2h 12m 55s\tremaining: 34m 29s\n",
      "397:\ttotal: 2h 13m 15s\tremaining: 34m 9s\n",
      "398:\ttotal: 2h 13m 36s\tremaining: 33m 49s\n",
      "399:\ttotal: 2h 13m 56s\tremaining: 33m 29s\n",
      "400:\ttotal: 2h 14m 16s\tremaining: 33m 8s\n",
      "401:\ttotal: 2h 14m 36s\tremaining: 32m 48s\n",
      "402:\ttotal: 2h 14m 56s\tremaining: 32m 28s\n",
      "403:\ttotal: 2h 15m 16s\tremaining: 32m 8s\n",
      "404:\ttotal: 2h 15m 36s\tremaining: 31m 48s\n",
      "405:\ttotal: 2h 15m 56s\tremaining: 31m 28s\n",
      "406:\ttotal: 2h 16m 16s\tremaining: 31m 8s\n",
      "407:\ttotal: 2h 16m 36s\tremaining: 30m 48s\n",
      "408:\ttotal: 2h 16m 57s\tremaining: 30m 28s\n",
      "409:\ttotal: 2h 17m 17s\tremaining: 30m 8s\n",
      "410:\ttotal: 2h 17m 37s\tremaining: 29m 48s\n",
      "411:\ttotal: 2h 17m 57s\tremaining: 29m 28s\n",
      "412:\ttotal: 2h 18m 17s\tremaining: 29m 7s\n",
      "413:\ttotal: 2h 18m 37s\tremaining: 28m 47s\n",
      "414:\ttotal: 2h 18m 57s\tremaining: 28m 27s\n",
      "415:\ttotal: 2h 19m 17s\tremaining: 28m 7s\n",
      "416:\ttotal: 2h 19m 37s\tremaining: 27m 47s\n",
      "417:\ttotal: 2h 19m 57s\tremaining: 27m 27s\n",
      "418:\ttotal: 2h 20m 17s\tremaining: 27m 7s\n",
      "419:\ttotal: 2h 20m 37s\tremaining: 26m 47s\n",
      "420:\ttotal: 2h 20m 57s\tremaining: 26m 27s\n",
      "421:\ttotal: 2h 21m 17s\tremaining: 26m 6s\n",
      "422:\ttotal: 2h 21m 37s\tremaining: 25m 46s\n",
      "423:\ttotal: 2h 21m 57s\tremaining: 25m 26s\n",
      "424:\ttotal: 2h 22m 17s\tremaining: 25m 6s\n",
      "425:\ttotal: 2h 22m 37s\tremaining: 24m 46s\n",
      "426:\ttotal: 2h 22m 57s\tremaining: 24m 26s\n",
      "427:\ttotal: 2h 23m 17s\tremaining: 24m 6s\n",
      "428:\ttotal: 2h 23m 37s\tremaining: 23m 46s\n",
      "429:\ttotal: 2h 23m 57s\tremaining: 23m 26s\n",
      "430:\ttotal: 2h 24m 17s\tremaining: 23m 6s\n",
      "431:\ttotal: 2h 24m 37s\tremaining: 22m 45s\n",
      "432:\ttotal: 2h 24m 57s\tremaining: 22m 25s\n",
      "433:\ttotal: 2h 25m 17s\tremaining: 22m 5s\n",
      "434:\ttotal: 2h 25m 37s\tremaining: 21m 45s\n",
      "435:\ttotal: 2h 25m 57s\tremaining: 21m 25s\n",
      "436:\ttotal: 2h 26m 16s\tremaining: 21m 5s\n",
      "437:\ttotal: 2h 26m 36s\tremaining: 20m 45s\n",
      "438:\ttotal: 2h 26m 56s\tremaining: 20m 25s\n",
      "439:\ttotal: 2h 27m 16s\tremaining: 20m 5s\n",
      "440:\ttotal: 2h 27m 37s\tremaining: 19m 44s\n",
      "441:\ttotal: 2h 27m 57s\tremaining: 19m 24s\n",
      "442:\ttotal: 2h 28m 17s\tremaining: 19m 4s\n",
      "443:\ttotal: 2h 28m 37s\tremaining: 18m 44s\n",
      "444:\ttotal: 2h 28m 57s\tremaining: 18m 24s\n",
      "445:\ttotal: 2h 29m 17s\tremaining: 18m 4s\n",
      "446:\ttotal: 2h 29m 37s\tremaining: 17m 44s\n",
      "447:\ttotal: 2h 29m 57s\tremaining: 17m 24s\n",
      "448:\ttotal: 2h 30m 17s\tremaining: 17m 4s\n",
      "449:\ttotal: 2h 30m 36s\tremaining: 16m 44s\n",
      "450:\ttotal: 2h 30m 56s\tremaining: 16m 24s\n",
      "451:\ttotal: 2h 31m 16s\tremaining: 16m 3s\n",
      "452:\ttotal: 2h 31m 36s\tremaining: 15m 43s\n",
      "453:\ttotal: 2h 31m 57s\tremaining: 15m 23s\n",
      "454:\ttotal: 2h 32m 17s\tremaining: 15m 3s\n",
      "455:\ttotal: 2h 32m 37s\tremaining: 14m 43s\n",
      "456:\ttotal: 2h 32m 56s\tremaining: 14m 23s\n",
      "457:\ttotal: 2h 33m 16s\tremaining: 14m 3s\n",
      "458:\ttotal: 2h 33m 37s\tremaining: 13m 43s\n",
      "459:\ttotal: 2h 33m 56s\tremaining: 13m 23s\n",
      "460:\ttotal: 2h 34m 17s\tremaining: 13m 3s\n",
      "461:\ttotal: 2h 34m 37s\tremaining: 12m 43s\n",
      "462:\ttotal: 2h 34m 57s\tremaining: 12m 22s\n",
      "463:\ttotal: 2h 35m 17s\tremaining: 12m 2s\n",
      "464:\ttotal: 2h 35m 37s\tremaining: 11m 42s\n",
      "465:\ttotal: 2h 35m 57s\tremaining: 11m 22s\n",
      "466:\ttotal: 2h 36m 17s\tremaining: 11m 2s\n",
      "467:\ttotal: 2h 36m 37s\tremaining: 10m 42s\n",
      "468:\ttotal: 2h 36m 57s\tremaining: 10m 22s\n",
      "469:\ttotal: 2h 37m 17s\tremaining: 10m 2s\n",
      "470:\ttotal: 2h 37m 37s\tremaining: 9m 42s\n",
      "471:\ttotal: 2h 37m 57s\tremaining: 9m 22s\n",
      "472:\ttotal: 2h 38m 17s\tremaining: 9m 2s\n",
      "473:\ttotal: 2h 38m 37s\tremaining: 8m 42s\n",
      "474:\ttotal: 2h 38m 58s\tremaining: 8m 22s\n",
      "475:\ttotal: 2h 39m 18s\tremaining: 8m 1s\n",
      "476:\ttotal: 2h 39m 37s\tremaining: 7m 41s\n",
      "477:\ttotal: 2h 39m 58s\tremaining: 7m 21s\n",
      "478:\ttotal: 2h 40m 18s\tremaining: 7m 1s\n",
      "479:\ttotal: 2h 40m 37s\tremaining: 6m 41s\n",
      "480:\ttotal: 2h 40m 58s\tremaining: 6m 21s\n",
      "481:\ttotal: 2h 41m 18s\tremaining: 6m 1s\n",
      "482:\ttotal: 2h 41m 38s\tremaining: 5m 41s\n",
      "483:\ttotal: 2h 41m 58s\tremaining: 5m 21s\n",
      "484:\ttotal: 2h 42m 18s\tremaining: 5m 1s\n",
      "485:\ttotal: 2h 42m 38s\tremaining: 4m 41s\n",
      "486:\ttotal: 2h 42m 58s\tremaining: 4m 21s\n",
      "487:\ttotal: 2h 43m 18s\tremaining: 4m\n",
      "488:\ttotal: 2h 43m 38s\tremaining: 3m 40s\n",
      "489:\ttotal: 2h 43m 58s\tremaining: 3m 20s\n",
      "490:\ttotal: 2h 44m 19s\tremaining: 3m\n",
      "491:\ttotal: 2h 44m 39s\tremaining: 2m 40s\n",
      "492:\ttotal: 2h 44m 59s\tremaining: 2m 20s\n",
      "493:\ttotal: 2h 45m 19s\tremaining: 2m\n",
      "494:\ttotal: 2h 45m 39s\tremaining: 1m 40s\n",
      "495:\ttotal: 2h 45m 59s\tremaining: 1m 20s\n",
      "496:\ttotal: 2h 46m 19s\tremaining: 1m\n",
      "497:\ttotal: 2h 46m 39s\tremaining: 40.2s\n",
      "498:\ttotal: 2h 46m 59s\tremaining: 20.1s\n",
      "499:\ttotal: 2h 47m 19s\tremaining: 0us\n",
      "[CV] END auto_class_weights=Balanced, bagging_temperature=0.5, border_count=128, depth=13, eval_metric=AUC, iterations=500, l2_leaf_reg=3, leaf_estimation_method=Gradient, learning_rate=0.5, random_strength=0.1; total time=167.3min\n",
      "0:\ttotal: 20.2s\tremaining: 2h 48m 11s\n",
      "1:\ttotal: 40.5s\tremaining: 2h 48m 11s\n",
      "2:\ttotal: 1m\tremaining: 2h 47m 39s\n",
      "3:\ttotal: 1m 21s\tremaining: 2h 47m 38s\n",
      "4:\ttotal: 1m 41s\tremaining: 2h 47m 27s\n",
      "5:\ttotal: 2m 1s\tremaining: 2h 47m 1s\n",
      "6:\ttotal: 2m 21s\tremaining: 2h 46m 38s\n",
      "7:\ttotal: 2m 42s\tremaining: 2h 46m 19s\n",
      "8:\ttotal: 3m 2s\tremaining: 2h 45m 45s\n",
      "9:\ttotal: 3m 22s\tremaining: 2h 45m 21s\n",
      "10:\ttotal: 3m 42s\tremaining: 2h 45m 6s\n",
      "11:\ttotal: 4m 2s\tremaining: 2h 44m 40s\n",
      "12:\ttotal: 4m 23s\tremaining: 2h 44m 16s\n",
      "13:\ttotal: 4m 43s\tremaining: 2h 43m 55s\n",
      "14:\ttotal: 5m 3s\tremaining: 2h 43m 31s\n",
      "15:\ttotal: 5m 23s\tremaining: 2h 43m 4s\n",
      "16:\ttotal: 5m 43s\tremaining: 2h 42m 46s\n",
      "17:\ttotal: 6m 3s\tremaining: 2h 42m 24s\n",
      "18:\ttotal: 6m 24s\tremaining: 2h 42m 8s\n",
      "19:\ttotal: 6m 44s\tremaining: 2h 41m 54s\n",
      "20:\ttotal: 7m 5s\tremaining: 2h 41m 39s\n",
      "21:\ttotal: 7m 25s\tremaining: 2h 41m 19s\n",
      "22:\ttotal: 7m 46s\tremaining: 2h 41m 4s\n",
      "23:\ttotal: 8m 6s\tremaining: 2h 40m 49s\n",
      "24:\ttotal: 8m 26s\tremaining: 2h 40m 27s\n",
      "25:\ttotal: 8m 47s\tremaining: 2h 40m 7s\n",
      "26:\ttotal: 9m 7s\tremaining: 2h 39m 48s\n",
      "27:\ttotal: 9m 27s\tremaining: 2h 39m 28s\n",
      "28:\ttotal: 9m 47s\tremaining: 2h 39m 6s\n",
      "29:\ttotal: 10m 7s\tremaining: 2h 38m 43s\n",
      "30:\ttotal: 10m 28s\tremaining: 2h 38m 24s\n",
      "31:\ttotal: 10m 48s\tremaining: 2h 38m 6s\n",
      "32:\ttotal: 11m 8s\tremaining: 2h 37m 45s\n",
      "33:\ttotal: 11m 29s\tremaining: 2h 37m 25s\n",
      "34:\ttotal: 11m 49s\tremaining: 2h 37m 1s\n",
      "35:\ttotal: 12m 9s\tremaining: 2h 36m 37s\n",
      "36:\ttotal: 12m 29s\tremaining: 2h 36m 15s\n",
      "37:\ttotal: 12m 49s\tremaining: 2h 35m 52s\n",
      "38:\ttotal: 13m 9s\tremaining: 2h 35m 30s\n",
      "39:\ttotal: 13m 29s\tremaining: 2h 35m 11s\n",
      "40:\ttotal: 13m 50s\tremaining: 2h 34m 52s\n",
      "41:\ttotal: 14m 10s\tremaining: 2h 34m 29s\n",
      "42:\ttotal: 14m 30s\tremaining: 2h 34m 8s\n",
      "43:\ttotal: 14m 50s\tremaining: 2h 33m 48s\n",
      "44:\ttotal: 15m 10s\tremaining: 2h 33m 28s\n",
      "45:\ttotal: 15m 30s\tremaining: 2h 33m 8s\n",
      "46:\ttotal: 15m 51s\tremaining: 2h 32m 46s\n",
      "47:\ttotal: 16m 11s\tremaining: 2h 32m 24s\n",
      "48:\ttotal: 16m 31s\tremaining: 2h 32m 4s\n",
      "49:\ttotal: 16m 51s\tremaining: 2h 31m 45s\n",
      "50:\ttotal: 17m 11s\tremaining: 2h 31m 24s\n",
      "51:\ttotal: 17m 32s\tremaining: 2h 31m 3s\n",
      "52:\ttotal: 17m 52s\tremaining: 2h 30m 42s\n",
      "53:\ttotal: 18m 12s\tremaining: 2h 30m 21s\n",
      "54:\ttotal: 18m 32s\tremaining: 2h 30m\n",
      "55:\ttotal: 18m 52s\tremaining: 2h 29m 39s\n",
      "56:\ttotal: 19m 12s\tremaining: 2h 29m 19s\n",
      "57:\ttotal: 19m 33s\tremaining: 2h 28m 59s\n",
      "58:\ttotal: 19m 53s\tremaining: 2h 28m 41s\n",
      "59:\ttotal: 20m 13s\tremaining: 2h 28m 20s\n",
      "60:\ttotal: 20m 34s\tremaining: 2h 28m 1s\n",
      "61:\ttotal: 20m 54s\tremaining: 2h 27m 41s\n",
      "62:\ttotal: 21m 14s\tremaining: 2h 27m 19s\n",
      "63:\ttotal: 21m 34s\tremaining: 2h 27m 1s\n",
      "64:\ttotal: 21m 54s\tremaining: 2h 26m 40s\n",
      "65:\ttotal: 22m 15s\tremaining: 2h 26m 20s\n",
      "66:\ttotal: 22m 35s\tremaining: 2h 26m\n",
      "67:\ttotal: 22m 55s\tremaining: 2h 25m 40s\n",
      "68:\ttotal: 23m 15s\tremaining: 2h 25m 19s\n",
      "69:\ttotal: 23m 36s\tremaining: 2h 24m 59s\n",
      "70:\ttotal: 23m 56s\tremaining: 2h 24m 38s\n",
      "71:\ttotal: 24m 16s\tremaining: 2h 24m 17s\n",
      "72:\ttotal: 24m 36s\tremaining: 2h 23m 56s\n",
      "73:\ttotal: 24m 56s\tremaining: 2h 23m 35s\n",
      "74:\ttotal: 25m 16s\tremaining: 2h 23m 15s\n",
      "75:\ttotal: 25m 37s\tremaining: 2h 22m 59s\n",
      "76:\ttotal: 25m 57s\tremaining: 2h 22m 38s\n",
      "77:\ttotal: 26m 17s\tremaining: 2h 22m 15s\n",
      "78:\ttotal: 26m 38s\tremaining: 2h 21m 58s\n",
      "79:\ttotal: 26m 59s\tremaining: 2h 21m 41s\n",
      "80:\ttotal: 27m 19s\tremaining: 2h 21m 20s\n",
      "81:\ttotal: 27m 39s\tremaining: 2h 20m 59s\n",
      "82:\ttotal: 27m 59s\tremaining: 2h 20m 37s\n",
      "83:\ttotal: 28m 19s\tremaining: 2h 20m 14s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Felipe\\Desktop\\Proyectos\\NLP_Politica\\Classification\\lda_comparision.ipynb Cell 120\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felipe/Desktop/Proyectos/NLP_Politica/Classification/lda_comparision.ipynb#Y230sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m catb \u001b[39m=\u001b[39m CatBoostClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felipe/Desktop/Proyectos/NLP_Politica/Classification/lda_comparision.ipynb#Y230sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m catb_randomized_search \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39m catb, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felipe/Desktop/Proyectos/NLP_Politica/Classification/lda_comparision.ipynb#Y230sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                          param_distributions\u001b[39m=\u001b[39m catb_parameters, n_iter\u001b[39m=\u001b[39mn_iter, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Felipe/Desktop/Proyectos/NLP_Politica/Classification/lda_comparision.ipynb#Y230sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m catb_randomized_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1769\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1768\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1769\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1770\u001b[0m         ParameterSampler(\n\u001b[0;32m   1771\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1772\u001b[0m         )\n\u001b[0;32m   1773\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\catboost\\core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5126\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5128\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5129\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5130\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "cv = 3\n",
    "\n",
    "catb = CatBoostClassifier()\n",
    "\n",
    "catb_randomized_search = RandomizedSearchCV(estimator= catb, \n",
    "                                         param_distributions= catb_parameters, n_iter=n_iter, cv=cv, scoring='accuracy', n_jobs=None, verbose=2)\n",
    "\n",
    "catb_randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catb_randomized_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m catb_randomized_search\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m y_pred_proba \u001b[39m=\u001b[39m catb_randomized_search\u001b[39m.\u001b[39mpredict_proba(X_test)\n\u001b[0;32m      3\u001b[0m print_performance(y_test, y_pred, y_pred_proba)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'catb_randomized_search' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = catb_randomized_search.predict(X_test)\n",
    "y_pred_proba = catb_randomized_search.predict_proba(X_test)\n",
    "print_performance(y_test, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model for each desafio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cls = load_model('lda_xgb_randomized_search.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición en train y test\n",
    "y = df_predic_scaled.loc[:, df_predic_scaled.columns == 'target']['target'].values.tolist()\n",
    "X = df_predic_scaled.loc[:, df_predic_scaled.columns != 'target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 15\n",
      "Accuracy: 0.969769\n",
      "Precision: 0.847395\n",
      "Recall: 0.994178\n",
      "F1 score: 0.914936\n",
      "AUC: 0.979587\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 13\n",
      "Accuracy: 0.967968\n",
      "Precision: 0.862653\n",
      "Recall: 0.994577\n",
      "F1 score: 0.923929\n",
      "AUC: 0.978037\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 14\n",
      "Accuracy: 0.993479\n",
      "Precision: 0.954338\n",
      "Recall: 0.992874\n",
      "F1 score: 0.973225\n",
      "AUC: 0.993217\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 12\n",
      "Accuracy: 0.935547\n",
      "Precision: 0.674174\n",
      "Recall: 0.973970\n",
      "F1 score: 0.796806\n",
      "AUC: 0.951894\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 16\n",
      "Accuracy: 0.967920\n",
      "Precision: 0.831884\n",
      "Recall: 0.989655\n",
      "F1 score: 0.903937\n",
      "AUC: 0.976832\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 17\n",
      "Accuracy: 0.952767\n",
      "Precision: 0.690423\n",
      "Recall: 0.996785\n",
      "F1 score: 0.815789\n",
      "AUC: 0.972196\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desafio: 18\n",
      "Accuracy: 0.933829\n",
      "Precision: 0.646707\n",
      "Recall: 0.996923\n",
      "F1 score: 0.784504\n",
      "AUC: 0.961041\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for des in df.desafio.unique():\n",
    "    \n",
    "    print(f'\\nDesafio: {des}')\n",
    "    \n",
    "    indices_des = [i for i,x in enumerate(X_test['id_pairs'].values) if x[0] in df[df['desafio']==des]['ID'].values]\n",
    "\n",
    "    X_test_des = X_test.iloc[indices_des].drop('id_pairs', axis=1)\n",
    "\n",
    "    y_test_des = [x for i,x in enumerate(y_test) if i in indices_des]\n",
    "    \n",
    "    y_pred = xgb_cls.predict(X_test_des)\n",
    "    y_pred_proba = xgb_cls.predict_proba(X_test_des)\n",
    "    print_performance(y_test_des, y_pred, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.9732347142857142 0.956061 red\n",
      "F1 score 0.8677742857142857 0.773109 red\n",
      "Recall 0.9940817142857142 0.990769 red\n",
      "Precision 0.7766534285714286 0.633858 red\n",
      "Accuracy 0.958096 0.92974 red\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metricas = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'AUC'][::-1]\n",
    "\n",
    "valores_12 = [0.933014, 0.661829, 0.989154, 0.793043, 0.956899][::-1]\n",
    "valores_13 = [0.966271, 0.853568, 0.998915, 0.920540, 0.978624][::-1]\n",
    "valores_14 = [0.991778, 0.937500, 0.997625, 0.966628, 0.994305][::-1]\n",
    "valores_15 = [0.974530, 0.868957, 0.994178, 0.927359, 0.982433][::-1]\n",
    "valores_16 = [0.961609, 0.804775, 0.987931, 0.886997, 0.972402][::-1]\n",
    "valores_17 = [0.949730, 0.676087, 1.000000, 0.806744, 0.971919][::-1]\n",
    "valores_18 = [0.929740, 0.633858, 0.990769, 0.773109, 0.956061][::-1]\n",
    "\n",
    "extra_trees = [0.914388, 0.634365, 0.973024, 0.768019, 0.938708][::-1]\n",
    "general_xgboost = [0.960042, 0.787270, 0.994335, 0.878770, 0.974266][::-1]\n",
    "\n",
    "# create horizontal bar plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(metricas, valores_18)\n",
    "\n",
    "# add x value as label to each bar\n",
    "for i, v in enumerate(valores_18):\n",
    "    \n",
    "    all_valores = valores_12[i]+valores_13[i]+valores_14[i]+valores_15[i]+valores_16[i]+valores_17[i]+valores_18[i]\n",
    "    \n",
    "    color = ['blue' if v >= all_valores/7 else 'red'][0]\n",
    "    \n",
    "    print(metricas[i],all_valores/7, v, color)\n",
    "    \n",
    "    ax.text(v, i, str(round(v*100))+'%', color=color, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "XGBoost is the best model with 96% acc\n",
    "\n",
    "only 300 dimensions is an advantage for LSA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (politics_nlp)",
   "language": "python",
   "name": "politics_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "031cd11bda6bcd93663944d47e2c931b86f93790ddbde947fe92f4f9a545460f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
